(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(e){function t(t){for(var o,r,s=t[0],c=t[1],l=t[2],u=0,h=[];u<s.length;u++)r=s[u],Object.prototype.hasOwnProperty.call(i,r)&&i[r]&&h.push(i[r][0]),i[r]=0;for(o in c)Object.prototype.hasOwnProperty.call(c,o)&&(e[o]=c[o]);for(d&&d(t);h.length;)h.shift()();return a.push.apply(a,l||[]),n()}function n(){for(var e,t=0;t<a.length;t++){for(var n=a[t],o=!0,s=1;s<n.length;s++){var c=n[s];0!==i[c]&&(o=!1)}o&&(a.splice(t--,1),e=r(r.s=n[0]))}return e}var o={},i={8:0},a=[];function r(t){if(o[t])return o[t].exports;var n=o[t]={i:t,l:!1,exports:{}};return e[t].call(n.exports,n,n.exports,r),n.l=!0,n.exports}r.e=function(e){var t=[],n=i[e];if(0!==n)if(n)t.push(n[2]);else{var o=new Promise((function(t,o){n=i[e]=[t,o]}));t.push(n[2]=o);var a,s=document.createElement("script");s.charset="utf-8",s.timeout=120,r.nc&&s.setAttribute("nonce",r.nc),s.src=function(e){return r.p+"assets/js/"+({9:"vendors~docsearch"}[e]||e)+"."+{1:"aa7263b9",2:"2592c867",3:"37b72b77",4:"78a9ed34",5:"a1cdcd65",6:"c06380fc",7:"9f1adf34",9:"3f1b6593",10:"75b27a27",11:"4b0b4a97",12:"1b71dca1",13:"dd85cc85",14:"e4e32a51",15:"60664810",16:"d687b08b",17:"7d6a80fd",18:"6ced62cb",19:"a61c7c5e",20:"7d63257c",21:"5f65dd83",22:"0d04ae52",23:"28165ed9",24:"db8b26a8",25:"75e761fb",26:"16d8db89",27:"99353468",28:"a2cac47c",29:"26243eec",30:"2a576fbc",31:"4a1caf6d",32:"5d34f7fc",33:"0f2645ac",34:"38e65a26",35:"a9786e99",36:"1489c3d8",37:"48286875",38:"41aa0e5c",39:"4bee2b92",40:"57dc9a8f",41:"8b3e151d",42:"b64cf8ac",43:"10a7f532",44:"6ed248bc",45:"194f36ed",46:"260bf22f",47:"90bee20b",48:"12ca2bae",49:"f52b9328",50:"398ba5af",51:"83f25a70",52:"f7b2bb3c",53:"d123c321",54:"10818dcd",55:"511b85cf",56:"82154841",57:"3dd62a42",58:"60de3600",59:"037e01b1",60:"1e7fc078",61:"24865d8a",62:"d377d742",63:"c1db52da",64:"e7e9cab2",65:"7bdfdbd8",66:"740b8b01",67:"646ce2cb",68:"83175e2b",69:"026f8c64",70:"74d4cdfd",71:"81d26439",72:"ef654634",73:"256229b4",74:"257b922b",75:"01cfc145",76:"437c2c65",77:"ce41ac77",78:"f8b459ff",79:"beaa369a",80:"63f122a9",81:"fd4b3523",82:"dc2d1182",83:"055cb231",84:"b4c5efc7",85:"bf464ec7",86:"61cdb5bc",87:"44b7f637",88:"d080cbb9",89:"ce44b27c",90:"f1c2c5e5",91:"d7c056f8",92:"01b69887",93:"5fbc3c74",94:"4eebcc1b",95:"3153b017",96:"5f08cd95",97:"f9843a98",98:"771c9bac",99:"333be770",100:"ad792c68",101:"364b5354",102:"f946602d",103:"d63b1ee1"}[e]+".js"}(e);var c=new Error;a=function(t){s.onerror=s.onload=null,clearTimeout(l);var n=i[e];if(0!==n){if(n){var o=t&&("load"===t.type?"missing":t.type),a=t&&t.target&&t.target.src;c.message="Loading chunk "+e+" failed.\n("+o+": "+a+")",c.name="ChunkLoadError",c.type=o,c.request=a,n[1](c)}i[e]=void 0}};var l=setTimeout((function(){a({type:"timeout",target:s})}),12e4);s.onerror=s.onload=a,document.head.appendChild(s)}return Promise.all(t)},r.m=e,r.c=o,r.d=function(e,t,n){r.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:n})},r.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},r.t=function(e,t){if(1&t&&(e=r(e)),8&t)return e;if(4&t&&"object"==typeof e&&e&&e.__esModule)return e;var n=Object.create(null);if(r.r(n),Object.defineProperty(n,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var o in e)r.d(n,o,function(t){return e[t]}.bind(null,o));return n},r.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return r.d(t,"a",t),t},r.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},r.p="/",r.oe=function(e){throw console.error(e),e};var s=window.webpackJsonp=window.webpackJsonp||[],c=s.push.bind(s);s.push=t,s=s.slice();for(var l=0;l<s.length;l++)t(s[l]);var d=c;a.push([105,0]),n()}([function(e,t,n){"use strict";function o(e,t,n,o,i,a,r,s){var c,l="function"==typeof e?e.options:e;if(t&&(l.render=t,l.staticRenderFns=n,l._compiled=!0),o&&(l.functional=!0),a&&(l._scopeId="data-v-"+a),r?(c=function(e){(e=e||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(e=__VUE_SSR_CONTEXT__),i&&i.call(this,e),e&&e._registeredComponents&&e._registeredComponents.add(r)},l._ssrRegister=c):i&&(c=s?function(){i.call(this,(l.functional?this.parent:this).$root.$options.shadowRoot)}:i),c)if(l.functional){l._injectStyles=c;var d=l.render;l.render=function(e,t){return c.call(t),d(e,t)}}else{var u=l.beforeCreate;l.beforeCreate=u?[].concat(u,c):[c]}return{exports:e,options:l}}n.d(t,"a",(function(){return o}))},function(e,t,n){"use strict";var o=function(e){return e&&e.Math===Math&&e};e.exports=o("object"==typeof globalThis&&globalThis)||o("object"==typeof window&&window)||o("object"==typeof self&&self)||o("object"==typeof global&&global)||o("object"==typeof this&&this)||function(){return this}()||Function("return this")()},function(e,t,n){"use strict";var o="object"==typeof document&&document.all;e.exports=void 0===o&&void 0!==o?function(e){return"function"==typeof e||e===o}:function(e){return"function"==typeof e}},function(e,t,n){"use strict";var o=n(26),i=Function.prototype,a=i.call,r=o&&i.bind.bind(a,a);e.exports=o?r:function(e){return function(){return a.apply(e,arguments)}}},function(e,t,n){"use strict";e.exports=function(e){try{return!!e()}catch(e){return!0}}},function(e,t,n){"use strict";var o=n(4);e.exports=!o((function(){return 7!==Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(e,t){var n=Array.isArray;e.exports=n},function(e,t,n){var o=n(67),i="object"==typeof self&&self&&self.Object===Object&&self,a=o||i||Function("return this")();e.exports=a},function(e,t,n){"use strict";var o=n(2);e.exports=function(e){return"object"==typeof e?null!==e:o(e)}},function(e,t,n){"use strict";var o=n(3),i=n(31),a=o({}.hasOwnProperty);e.exports=Object.hasOwn||function(e,t){return a(i(e),t)}},function(e,t,n){var o=n(163),i=n(166);e.exports=function(e,t){var n=i(e,t);return o(n)?n:void 0}},function(e,t){e.exports=function(e){return null!=e&&"object"==typeof e}},function(e,t,n){var o=n(14),i=n(148),a=n(149),r=o?o.toStringTag:void 0;e.exports=function(e){return null==e?void 0===e?"[object Undefined]":"[object Null]":r&&r in Object(e)?i(e):a(e)}},function(e,t,n){"use strict";var o=n(5),i=n(15),a=n(34);e.exports=o?function(e,t,n){return i.f(e,t,a(1,n))}:function(e,t,n){return e[t]=n,e}},function(e,t,n){var o=n(7).Symbol;e.exports=o},function(e,t,n){"use strict";var o=n(5),i=n(62),a=n(101),r=n(24),s=n(53),c=TypeError,l=Object.defineProperty,d=Object.getOwnPropertyDescriptor;t.f=o?a?function(e,t,n){if(r(e),t=s(t),r(n),"function"==typeof e&&"prototype"===t&&"value"in n&&"writable"in n&&!n.writable){var o=d(e,t);o&&o.writable&&(e[t]=n.value,n={configurable:"configurable"in n?n.configurable:o.configurable,enumerable:"enumerable"in n?n.enumerable:o.enumerable,writable:!1})}return l(e,t,n)}:l:function(e,t,n){if(r(e),t=s(t),r(n),i)try{return l(e,t,n)}catch(e){}if("get"in n||"set"in n)throw new c("Accessors not supported");return"value"in n&&(e[t]=n.value),e}},function(e,t,n){"use strict";var o=n(3),i=o({}.toString),a=o("".slice);e.exports=function(e){return a(i(e),8,-1)}},function(e,t,n){var o=n(153),i=n(154),a=n(155),r=n(156),s=n(157);function c(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var o=e[t];this.set(o[0],o[1])}}c.prototype.clear=o,c.prototype.delete=i,c.prototype.get=a,c.prototype.has=r,c.prototype.set=s,e.exports=c},function(e,t,n){var o=n(69);e.exports=function(e,t){for(var n=e.length;n--;)if(o(e[n][0],t))return n;return-1}},function(e,t,n){var o=n(10)(Object,"create");e.exports=o},function(e,t,n){var o=n(175);e.exports=function(e,t){var n=e.__data__;return o(t)?n["string"==typeof t?"string":"hash"]:n.map}},function(e,t,n){var o=n(44);e.exports=function(e){if("string"==typeof e||o(e))return e;var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(e,t){var n=/^\s+|\s+$/g,o=/^[-+]0x[0-9a-f]+$/i,i=/^0b[01]+$/i,a=/^0o[0-7]+$/i,r=parseInt,s="object"==typeof global&&global&&global.Object===Object&&global,c="object"==typeof self&&self&&self.Object===Object&&self,l=s||c||Function("return this")(),d=Object.prototype.toString,u=Math.max,h=Math.min,p=function(){return l.Date.now()};function m(e){var t=typeof e;return!!e&&("object"==t||"function"==t)}function f(e){if("number"==typeof e)return e;if(function(e){return"symbol"==typeof e||function(e){return!!e&&"object"==typeof e}(e)&&"[object Symbol]"==d.call(e)}(e))return NaN;if(m(e)){var t="function"==typeof e.valueOf?e.valueOf():e;e=m(t)?t+"":t}if("string"!=typeof e)return 0===e?e:+e;e=e.replace(n,"");var s=i.test(e);return s||a.test(e)?r(e.slice(2),s?2:8):o.test(e)?NaN:+e}e.exports=function(e,t,n){var o,i,a,r,s,c,l=0,d=!1,w=!1,g=!0;if("function"!=typeof e)throw new TypeError("Expected a function");function y(t){var n=o,a=i;return o=i=void 0,l=t,r=e.apply(a,n)}function v(e){return l=e,s=setTimeout(k,t),d?y(e):r}function b(e){var n=e-c;return void 0===c||n>=t||n<0||w&&e-l>=a}function k(){var e=p();if(b(e))return x(e);s=setTimeout(k,function(e){var n=t-(e-c);return w?h(n,a-(e-l)):n}(e))}function x(e){return s=void 0,g&&o?y(e):(o=i=void 0,r)}function _(){var e=p(),n=b(e);if(o=arguments,i=this,c=e,n){if(void 0===s)return v(c);if(w)return s=setTimeout(k,t),y(c)}return void 0===s&&(s=setTimeout(k,t)),r}return t=f(t)||0,m(n)&&(d=!!n.leading,a=(w="maxWait"in n)?u(f(n.maxWait)||0,t):a,g="trailing"in n?!!n.trailing:g),_.cancel=function(){void 0!==s&&clearTimeout(s),l=0,o=c=i=s=void 0},_.flush=function(){return void 0===s?r:x(p())},_}},function(e,t,n){var o,i;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(i="function"==typeof(o=function(){var e,t,n={version:"0.2.0"},o=n.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function i(e,t,n){return e<t?t:e>n?n:e}function a(e){return 100*(-1+e)}n.configure=function(e){var t,n;for(t in e)void 0!==(n=e[t])&&e.hasOwnProperty(t)&&(o[t]=n);return this},n.status=null,n.set=function(e){var t=n.isStarted();e=i(e,o.minimum,1),n.status=1===e?null:e;var c=n.render(!t),l=c.querySelector(o.barSelector),d=o.speed,u=o.easing;return c.offsetWidth,r((function(t){""===o.positionUsing&&(o.positionUsing=n.getPositioningCSS()),s(l,function(e,t,n){var i;return(i="translate3d"===o.positionUsing?{transform:"translate3d("+a(e)+"%,0,0)"}:"translate"===o.positionUsing?{transform:"translate("+a(e)+"%,0)"}:{"margin-left":a(e)+"%"}).transition="all "+t+"ms "+n,i}(e,d,u)),1===e?(s(c,{transition:"none",opacity:1}),c.offsetWidth,setTimeout((function(){s(c,{transition:"all "+d+"ms linear",opacity:0}),setTimeout((function(){n.remove(),t()}),d)}),d)):setTimeout(t,d)})),this},n.isStarted=function(){return"number"==typeof n.status},n.start=function(){n.status||n.set(0);var e=function(){setTimeout((function(){n.status&&(n.trickle(),e())}),o.trickleSpeed)};return o.trickle&&e(),this},n.done=function(e){return e||n.status?n.inc(.3+.5*Math.random()).set(1):this},n.inc=function(e){var t=n.status;return t?("number"!=typeof e&&(e=(1-t)*i(Math.random()*t,.1,.95)),t=i(t+e,0,.994),n.set(t)):n.start()},n.trickle=function(){return n.inc(Math.random()*o.trickleRate)},e=0,t=0,n.promise=function(o){return o&&"resolved"!==o.state()?(0===t&&n.start(),e++,t++,o.always((function(){0==--t?(e=0,n.done()):n.set((e-t)/e)})),this):this},n.render=function(e){if(n.isRendered())return document.getElementById("nprogress");l(document.documentElement,"nprogress-busy");var t=document.createElement("div");t.id="nprogress",t.innerHTML=o.template;var i,r=t.querySelector(o.barSelector),c=e?"-100":a(n.status||0),d=document.querySelector(o.parent);return s(r,{transition:"all 0 linear",transform:"translate3d("+c+"%,0,0)"}),o.showSpinner||(i=t.querySelector(o.spinnerSelector))&&h(i),d!=document.body&&l(d,"nprogress-custom-parent"),d.appendChild(t),t},n.remove=function(){d(document.documentElement,"nprogress-busy"),d(document.querySelector(o.parent),"nprogress-custom-parent");var e=document.getElementById("nprogress");e&&h(e)},n.isRendered=function(){return!!document.getElementById("nprogress")},n.getPositioningCSS=function(){var e=document.body.style,t="WebkitTransform"in e?"Webkit":"MozTransform"in e?"Moz":"msTransform"in e?"ms":"OTransform"in e?"O":"";return t+"Perspective"in e?"translate3d":t+"Transform"in e?"translate":"margin"};var r=function(){var e=[];function t(){var n=e.shift();n&&n(t)}return function(n){e.push(n),1==e.length&&t()}}(),s=function(){var e=["Webkit","O","Moz","ms"],t={};function n(n){return n=n.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(e,t){return t.toUpperCase()})),t[n]||(t[n]=function(t){var n=document.body.style;if(t in n)return t;for(var o,i=e.length,a=t.charAt(0).toUpperCase()+t.slice(1);i--;)if((o=e[i]+a)in n)return o;return t}(n))}function o(e,t,o){t=n(t),e.style[t]=o}return function(e,t){var n,i,a=arguments;if(2==a.length)for(n in t)void 0!==(i=t[n])&&t.hasOwnProperty(n)&&o(e,n,i);else o(e,a[1],a[2])}}();function c(e,t){return("string"==typeof e?e:u(e)).indexOf(" "+t+" ")>=0}function l(e,t){var n=u(e),o=n+t;c(n,t)||(e.className=o.substring(1))}function d(e,t){var n,o=u(e);c(e,t)&&(n=o.replace(" "+t+" "," "),e.className=n.substring(1,n.length-1))}function u(e){return(" "+(e.className||"")+" ").replace(/\s+/gi," ")}function h(e){e&&e.parentNode&&e.parentNode.removeChild(e)}return n})?o.call(t,n,t,e):o)||(e.exports=i)},function(e,t,n){"use strict";var o=n(8),i=String,a=TypeError;e.exports=function(e){if(o(e))return e;throw new a(i(e)+" is not an object")}},function(e,t,n){"use strict";var o=n(1),i=n(50).f,a=n(13),r=n(95),s=n(36),c=n(63),l=n(124);e.exports=function(e,t){var n,d,u,h,p,m=e.target,f=e.global,w=e.stat;if(n=f?o:w?o[m]||s(m,{}):o[m]&&o[m].prototype)for(d in t){if(h=t[d],u=e.dontCallGetSet?(p=i(n,d))&&p.value:n[d],!l(f?d:m+(w?".":"#")+d,e.forced)&&void 0!==u){if(typeof h==typeof u)continue;c(h,u)}(e.sham||u&&u.sham)&&a(h,"sham",!0),r(n,d,h,e)}}},function(e,t,n){"use strict";var o=n(4);e.exports=!o((function(){var e=function(){}.bind();return"function"!=typeof e||e.hasOwnProperty("prototype")}))},function(e,t,n){"use strict";var o=n(47),i=n(51);e.exports=function(e){return o(i(e))}},function(e,t,n){"use strict";var o=n(1),i=n(2),a=function(e){return i(e)?e:void 0};e.exports=function(e,t){return arguments.length<2?a(o[e]):o[e]&&o[e][t]}},function(e,t,n){"use strict";var o=n(2),i=n(111),a=TypeError;e.exports=function(e){if(o(e))return e;throw new a(i(e)+" is not a function")}},function(e,t,n){"use strict";var o=n(1),i=n(59),a=n(9),r=n(61),s=n(57),c=n(56),l=o.Symbol,d=i("wks"),u=c?l.for||l:l&&l.withoutSetter||r;e.exports=function(e){return a(d,e)||(d[e]=s&&a(l,e)?l[e]:u("Symbol."+e)),d[e]}},function(e,t,n){"use strict";var o=n(51),i=Object;e.exports=function(e){return i(o(e))}},function(e,t,n){"use strict";var o=n(122);e.exports=function(e){return o(e.length)}},function(e,t,n){"use strict";var o=n(26),i=Function.prototype.call;e.exports=o?i.bind(i):function(){return i.apply(i,arguments)}},function(e,t,n){"use strict";e.exports=function(e,t){return{enumerable:!(1&e),configurable:!(2&e),writable:!(4&e),value:t}}},function(e,t,n){"use strict";var o=n(60),i=n(1),a=n(36),r=e.exports=i["__core-js_shared__"]||a("__core-js_shared__",{});(r.versions||(r.versions=[])).push({version:"3.36.0",mode:o?"pure":"global",copyright:"© 2014-2024 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.36.0/LICENSE",source:"https://github.com/zloirock/core-js"})},function(e,t,n){"use strict";var o=n(1),i=Object.defineProperty;e.exports=function(e,t){try{i(o,e,{value:t,configurable:!0,writable:!0})}catch(n){o[e]=t}return t}},function(e,t,n){var o=n(147),i=n(11),a=Object.prototype,r=a.hasOwnProperty,s=a.propertyIsEnumerable,c=o(function(){return arguments}())?o:function(e){return i(e)&&r.call(e,"callee")&&!s.call(e,"callee")};e.exports=c},function(e,t,n){var o=n(10)(n(7),"Map");e.exports=o},function(e,t){e.exports=function(e){var t=typeof e;return null!=e&&("object"==t||"function"==t)}},function(e,t,n){var o=n(167),i=n(174),a=n(176),r=n(177),s=n(178);function c(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var o=e[t];this.set(o[0],o[1])}}c.prototype.clear=o,c.prototype.delete=i,c.prototype.get=a,c.prototype.has=r,c.prototype.set=s,e.exports=c},function(e,t){e.exports=function(e){var t=-1,n=Array(e.size);return e.forEach((function(e){n[++t]=e})),n}},function(e,t){e.exports=function(e){return"number"==typeof e&&e>-1&&e%1==0&&e<=9007199254740991}},function(e,t,n){var o=n(6),i=n(44),a=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,r=/^\w*$/;e.exports=function(e,t){if(o(e))return!1;var n=typeof e;return!("number"!=n&&"symbol"!=n&&"boolean"!=n&&null!=e&&!i(e))||(r.test(e)||!a.test(e)||null!=t&&e in Object(t))}},function(e,t,n){var o=n(12),i=n(11);e.exports=function(e){return"symbol"==typeof e||i(e)&&"[object Symbol]"==o(e)}},function(e,t){e.exports=function(e){return e}},function(e,t){function n(e,t){for(var n=0,o=e.length-1;o>=0;o--){var i=e[o];"."===i?e.splice(o,1):".."===i?(e.splice(o,1),n++):n&&(e.splice(o,1),n--)}if(t)for(;n--;n)e.unshift("..");return e}function o(e,t){if(e.filter)return e.filter(t);for(var n=[],o=0;o<e.length;o++)t(e[o],o,e)&&n.push(e[o]);return n}t.resolve=function(){for(var e="",t=!1,i=arguments.length-1;i>=-1&&!t;i--){var a=i>=0?arguments[i]:process.cwd();if("string"!=typeof a)throw new TypeError("Arguments to path.resolve must be strings");a&&(e=a+"/"+e,t="/"===a.charAt(0))}return(t?"/":"")+(e=n(o(e.split("/"),(function(e){return!!e})),!t).join("/"))||"."},t.normalize=function(e){var a=t.isAbsolute(e),r="/"===i(e,-1);return(e=n(o(e.split("/"),(function(e){return!!e})),!a).join("/"))||a||(e="."),e&&r&&(e+="/"),(a?"/":"")+e},t.isAbsolute=function(e){return"/"===e.charAt(0)},t.join=function(){var e=Array.prototype.slice.call(arguments,0);return t.normalize(o(e,(function(e,t){if("string"!=typeof e)throw new TypeError("Arguments to path.join must be strings");return e})).join("/"))},t.relative=function(e,n){function o(e){for(var t=0;t<e.length&&""===e[t];t++);for(var n=e.length-1;n>=0&&""===e[n];n--);return t>n?[]:e.slice(t,n-t+1)}e=t.resolve(e).substr(1),n=t.resolve(n).substr(1);for(var i=o(e.split("/")),a=o(n.split("/")),r=Math.min(i.length,a.length),s=r,c=0;c<r;c++)if(i[c]!==a[c]){s=c;break}var l=[];for(c=s;c<i.length;c++)l.push("..");return(l=l.concat(a.slice(s))).join("/")},t.sep="/",t.delimiter=":",t.dirname=function(e){if("string"!=typeof e&&(e+=""),0===e.length)return".";for(var t=e.charCodeAt(0),n=47===t,o=-1,i=!0,a=e.length-1;a>=1;--a)if(47===(t=e.charCodeAt(a))){if(!i){o=a;break}}else i=!1;return-1===o?n?"/":".":n&&1===o?"/":e.slice(0,o)},t.basename=function(e,t){var n=function(e){"string"!=typeof e&&(e+="");var t,n=0,o=-1,i=!0;for(t=e.length-1;t>=0;--t)if(47===e.charCodeAt(t)){if(!i){n=t+1;break}}else-1===o&&(i=!1,o=t+1);return-1===o?"":e.slice(n,o)}(e);return t&&n.substr(-1*t.length)===t&&(n=n.substr(0,n.length-t.length)),n},t.extname=function(e){"string"!=typeof e&&(e+="");for(var t=-1,n=0,o=-1,i=!0,a=0,r=e.length-1;r>=0;--r){var s=e.charCodeAt(r);if(47!==s)-1===o&&(i=!1,o=r+1),46===s?-1===t?t=r:1!==a&&(a=1):-1!==t&&(a=-1);else if(!i){n=r+1;break}}return-1===t||-1===o||0===a||1===a&&t===o-1&&t===n+1?"":e.slice(t,o)};var i="b"==="ab".substr(-1)?function(e,t,n){return e.substr(t,n)}:function(e,t,n){return t<0&&(t=e.length+t),e.substr(t,n)}},function(e,t,n){"use strict";var o=n(3),i=n(4),a=n(16),r=Object,s=o("".split);e.exports=i((function(){return!r("z").propertyIsEnumerable(0)}))?function(e){return"String"===a(e)?s(e,""):r(e)}:r},function(e,t,n){"use strict";e.exports={}},function(e,t){e.exports=function(e){return e.webpackPolyfill||(e.deprecate=function(){},e.paths=[],e.children||(e.children=[]),Object.defineProperty(e,"loaded",{enumerable:!0,get:function(){return e.l}}),Object.defineProperty(e,"id",{enumerable:!0,get:function(){return e.i}}),e.webpackPolyfill=1),e}},function(e,t,n){"use strict";var o=n(5),i=n(33),a=n(107),r=n(34),s=n(27),c=n(53),l=n(9),d=n(62),u=Object.getOwnPropertyDescriptor;t.f=o?u:function(e,t){if(e=s(e),t=c(t),d)try{return u(e,t)}catch(e){}if(l(e,t))return r(!i(a.f,e,t),e[t])}},function(e,t,n){"use strict";var o=n(52),i=TypeError;e.exports=function(e){if(o(e))throw new i("Can't call method on "+e);return e}},function(e,t,n){"use strict";e.exports=function(e){return null==e}},function(e,t,n){"use strict";var o=n(108),i=n(54);e.exports=function(e){var t=o(e,"string");return i(t)?t:t+""}},function(e,t,n){"use strict";var o=n(28),i=n(2),a=n(55),r=n(56),s=Object;e.exports=r?function(e){return"symbol"==typeof e}:function(e){var t=o("Symbol");return i(t)&&a(t.prototype,s(e))}},function(e,t,n){"use strict";var o=n(3);e.exports=o({}.isPrototypeOf)},function(e,t,n){"use strict";var o=n(57);e.exports=o&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(e,t,n){"use strict";var o=n(58),i=n(4),a=n(1).String;e.exports=!!Object.getOwnPropertySymbols&&!i((function(){var e=Symbol("symbol detection");return!a(e)||!(Object(e)instanceof Symbol)||!Symbol.sham&&o&&o<41}))},function(e,t,n){"use strict";var o,i,a=n(1),r=n(109),s=a.process,c=a.Deno,l=s&&s.versions||c&&c.version,d=l&&l.v8;d&&(i=(o=d.split("."))[0]>0&&o[0]<4?1:+(o[0]+o[1])),!i&&r&&(!(o=r.match(/Edge\/(\d+)/))||o[1]>=74)&&(o=r.match(/Chrome\/(\d+)/))&&(i=+o[1]),e.exports=i},function(e,t,n){"use strict";var o=n(35);e.exports=function(e,t){return o[e]||(o[e]=t||{})}},function(e,t,n){"use strict";e.exports=!1},function(e,t,n){"use strict";var o=n(3),i=0,a=Math.random(),r=o(1..toString);e.exports=function(e){return"Symbol("+(void 0===e?"":e)+")_"+r(++i+a,36)}},function(e,t,n){"use strict";var o=n(5),i=n(4),a=n(100);e.exports=!o&&!i((function(){return 7!==Object.defineProperty(a("div"),"a",{get:function(){return 7}}).a}))},function(e,t,n){"use strict";var o=n(9),i=n(117),a=n(50),r=n(15);e.exports=function(e,t,n){for(var s=i(t),c=r.f,l=a.f,d=0;d<s.length;d++){var u=s[d];o(e,u)||n&&o(n,u)||c(e,u,l(t,u))}}},function(e,t,n){"use strict";var o=n(121);e.exports=function(e){var t=+e;return t!=t||0===t?0:o(t)}},function(e,t,n){"use strict";var o=n(130),i=n(24),a=n(131);e.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var e,t=!1,n={};try{(e=o(Object.prototype,"__proto__","set"))(n,[]),t=n instanceof Array}catch(e){}return function(n,o){return i(n),a(o),t?e(n,o):n.__proto__=o,n}}():void 0)},function(e,t){e.exports=function(e,t){for(var n=-1,o=t.length,i=e.length;++n<o;)e[i+n]=t[n];return e}},function(e,t){var n="object"==typeof global&&global&&global.Object===Object&&global;e.exports=n},function(e,t,n){var o=n(17),i=n(158),a=n(159),r=n(160),s=n(161),c=n(162);function l(e){var t=this.__data__=new o(e);this.size=t.size}l.prototype.clear=i,l.prototype.delete=a,l.prototype.get=r,l.prototype.has=s,l.prototype.set=c,e.exports=l},function(e,t){e.exports=function(e,t){return e===t||e!=e&&t!=t}},function(e,t,n){var o=n(12),i=n(39);e.exports=function(e){if(!i(e))return!1;var t=o(e);return"[object Function]"==t||"[object GeneratorFunction]"==t||"[object AsyncFunction]"==t||"[object Proxy]"==t}},function(e,t){var n=Function.prototype.toString;e.exports=function(e){if(null!=e){try{return n.call(e)}catch(e){}try{return e+""}catch(e){}}return""}},function(e,t,n){var o=n(179),i=n(11);e.exports=function e(t,n,a,r,s){return t===n||(null==t||null==n||!i(t)&&!i(n)?t!=t&&n!=n:o(t,n,a,r,e,s))}},function(e,t,n){var o=n(74),i=n(182),a=n(75);e.exports=function(e,t,n,r,s,c){var l=1&n,d=e.length,u=t.length;if(d!=u&&!(l&&u>d))return!1;var h=c.get(e),p=c.get(t);if(h&&p)return h==t&&p==e;var m=-1,f=!0,w=2&n?new o:void 0;for(c.set(e,t),c.set(t,e);++m<d;){var g=e[m],y=t[m];if(r)var v=l?r(y,g,m,t,e,c):r(g,y,m,e,t,c);if(void 0!==v){if(v)continue;f=!1;break}if(w){if(!i(t,(function(e,t){if(!a(w,t)&&(g===e||s(g,e,n,r,c)))return w.push(t)}))){f=!1;break}}else if(g!==y&&!s(g,y,n,r,c)){f=!1;break}}return c.delete(e),c.delete(t),f}},function(e,t,n){var o=n(40),i=n(180),a=n(181);function r(e){var t=-1,n=null==e?0:e.length;for(this.__data__=new o;++t<n;)this.add(e[t])}r.prototype.add=r.prototype.push=i,r.prototype.has=a,e.exports=r},function(e,t){e.exports=function(e,t){return e.has(t)}},function(e,t,n){var o=n(192),i=n(198),a=n(80);e.exports=function(e){return a(e)?o(e):i(e)}},function(e,t,n){(function(e){var o=n(7),i=n(194),a=t&&!t.nodeType&&t,r=a&&"object"==typeof e&&e&&!e.nodeType&&e,s=r&&r.exports===a?o.Buffer:void 0,c=(s?s.isBuffer:void 0)||i;e.exports=c}).call(this,n(49)(e))},function(e,t){var n=/^(?:0|[1-9]\d*)$/;e.exports=function(e,t){var o=typeof e;return!!(t=null==t?9007199254740991:t)&&("number"==o||"symbol"!=o&&n.test(e))&&e>-1&&e%1==0&&e<t}},function(e,t,n){var o=n(195),i=n(196),a=n(197),r=a&&a.isTypedArray,s=r?i(r):o;e.exports=s},function(e,t,n){var o=n(70),i=n(42);e.exports=function(e){return null!=e&&i(e.length)&&!o(e)}},function(e,t,n){var o=n(10)(n(7),"Set");e.exports=o},function(e,t,n){var o=n(39);e.exports=function(e){return e==e&&!o(e)}},function(e,t){e.exports=function(e,t){return function(n){return null!=n&&(n[e]===t&&(void 0!==t||e in Object(n)))}}},function(e,t,n){var o=n(85),i=n(21);e.exports=function(e,t){for(var n=0,a=(t=o(t,e)).length;null!=e&&n<a;)e=e[i(t[n++])];return n&&n==a?e:void 0}},function(e,t,n){var o=n(6),i=n(43),a=n(209),r=n(212);e.exports=function(e,t){return o(e)?e:i(e,t)?[e]:a(r(e))}},function(e,t,n){},function(e,t,n){},function(e,t,n){},function(e,t,n){},function(e,t,n){},function(e,t,n){},function(e,t,n){var o=n(145),i=n(150),a=n(221),r=n(229),s=n(238),c=n(97),l=a((function(e){var t=c(e);return s(t)&&(t=void 0),r(o(e,1,s,!0),i(t,2))}));e.exports=l},function(e,t,n){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var o=/["'&<>]/;e.exports=function(e){var t,n=""+e,i=o.exec(n);if(!i)return n;var a="",r=0,s=0;for(r=i.index;r<n.length;r++){switch(n.charCodeAt(r)){case 34:t="&quot;";break;case 38:t="&amp;";break;case 39:t="&#39;";break;case 60:t="&lt;";break;case 62:t="&gt;";break;default:continue}s!==r&&(a+=n.substring(s,r)),s=r+1,a+=t}return s!==r?a+n.substring(s,r):a}},function(e,t,n){"use strict";var o=n(25),i=n(31),a=n(32),r=n(142),s=n(144);o({target:"Array",proto:!0,arity:1,forced:n(4)((function(){return 4294967297!==[].push.call({length:4294967296},1)}))||!function(){try{Object.defineProperty([],"length",{writable:!1}).push()}catch(e){return e instanceof TypeError}}()},{push:function(e){var t=i(this),n=a(t),o=arguments.length;s(n+o);for(var c=0;c<o;c++)t[n]=arguments[c],n++;return r(t,n),n}})},function(e,t,n){"use strict";var o=n(2),i=n(15),a=n(98),r=n(36);e.exports=function(e,t,n,s){s||(s={});var c=s.enumerable,l=void 0!==s.name?s.name:t;if(o(n)&&a(n,l,s),s.global)c?e[t]=n:r(t,n);else{try{s.unsafe?e[t]&&(c=!0):delete e[t]}catch(e){}c?e[t]=n:i.f(e,t,{value:n,enumerable:!1,configurable:!s.nonConfigurable,writable:!s.nonWritable})}return e}},function(e,t,n){"use strict";var o=n(136),i=String;e.exports=function(e){if("Symbol"===o(e))throw new TypeError("Cannot convert a Symbol value to a string");return i(e)}},function(e,t){e.exports=function(e){var t=null==e?0:e.length;return t?e[t-1]:void 0}},function(e,t,n){"use strict";var o=n(3),i=n(4),a=n(2),r=n(9),s=n(5),c=n(113).CONFIGURABLE,l=n(114),d=n(115),u=d.enforce,h=d.get,p=String,m=Object.defineProperty,f=o("".slice),w=o("".replace),g=o([].join),y=s&&!i((function(){return 8!==m((function(){}),"length",{value:8}).length})),v=String(String).split("String"),b=e.exports=function(e,t,n){"Symbol("===f(p(t),0,7)&&(t="["+w(p(t),/^Symbol\(([^)]*)\).*$/,"$1")+"]"),n&&n.getter&&(t="get "+t),n&&n.setter&&(t="set "+t),(!r(e,"name")||c&&e.name!==t)&&(s?m(e,"name",{value:t,configurable:!0}):e.name=t),y&&n&&r(n,"arity")&&e.length!==n.arity&&m(e,"length",{value:n.arity});try{n&&r(n,"constructor")&&n.constructor?s&&m(e,"prototype",{writable:!1}):e.prototype&&(e.prototype=void 0)}catch(e){}var o=u(e);return r(o,"source")||(o.source=g(v,"string"==typeof t?t:"")),e};Function.prototype.toString=b((function(){return a(this)&&h(this).source||l(this)}),"toString")},function(e,t,n){"use strict";e.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(e,t,n){"use strict";var o=n(1),i=n(8),a=o.document,r=i(a)&&i(a.createElement);e.exports=function(e){return r?a.createElement(e):{}}},function(e,t,n){"use strict";var o=n(5),i=n(4);e.exports=o&&i((function(){return 42!==Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(e,t,n){"use strict";var o=n(59),i=n(61),a=o("keys");e.exports=function(e){return a[e]||(a[e]=i(e))}},function(e,t,n){"use strict";var o=n(3),i=n(9),a=n(27),r=n(119).indexOf,s=n(48),c=o([].push);e.exports=function(e,t){var n,o=a(e),l=0,d=[];for(n in o)!i(s,n)&&i(o,n)&&c(d,n);for(;t.length>l;)i(o,n=t[l++])&&(~r(d,n)||c(d,n));return d}},function(e,t,n){"use strict";var o=n(25),i=n(1),a=n(128),r=n(129),s=i.WebAssembly,c=7!==new Error("e",{cause:7}).cause,l=function(e,t){var n={};n[e]=r(e,t,c),o({global:!0,constructor:!0,arity:1,forced:c},n)},d=function(e,t){if(s&&s[e]){var n={};n[e]=r("WebAssembly."+e,t,c),o({target:"WebAssembly",stat:!0,constructor:!0,arity:1,forced:c},n)}};l("Error",(function(e){return function(t){return a(e,this,arguments)}})),l("EvalError",(function(e){return function(t){return a(e,this,arguments)}})),l("RangeError",(function(e){return function(t){return a(e,this,arguments)}})),l("ReferenceError",(function(e){return function(t){return a(e,this,arguments)}})),l("SyntaxError",(function(e){return function(t){return a(e,this,arguments)}})),l("TypeError",(function(e){return function(t){return a(e,this,arguments)}})),l("URIError",(function(e){return function(t){return a(e,this,arguments)}})),d("CompileError",(function(e){return function(t){return a(e,this,arguments)}})),d("LinkError",(function(e){return function(t){return a(e,this,arguments)}})),d("RuntimeError",(function(e){return function(t){return a(e,this,arguments)}}))},function(e,t,n){e.exports=n(249)},function(e,t,n){"use strict";var o=n(25),i=n(125).left,a=n(126),r=n(58);o({target:"Array",proto:!0,forced:!n(127)&&r>79&&r<83||!a("reduce")},{reduce:function(e){var t=arguments.length;return i(this,e,t,t>1?arguments[1]:void 0)}})},function(e,t,n){"use strict";var o={}.propertyIsEnumerable,i=Object.getOwnPropertyDescriptor,a=i&&!o.call({1:2},1);t.f=a?function(e){var t=i(this,e);return!!t&&t.enumerable}:o},function(e,t,n){"use strict";var o=n(33),i=n(8),a=n(54),r=n(110),s=n(112),c=n(30),l=TypeError,d=c("toPrimitive");e.exports=function(e,t){if(!i(e)||a(e))return e;var n,c=r(e,d);if(c){if(void 0===t&&(t="default"),n=o(c,e,t),!i(n)||a(n))return n;throw new l("Can't convert object to primitive value")}return void 0===t&&(t="number"),s(e,t)}},function(e,t,n){"use strict";e.exports="undefined"!=typeof navigator&&String(navigator.userAgent)||""},function(e,t,n){"use strict";var o=n(29),i=n(52);e.exports=function(e,t){var n=e[t];return i(n)?void 0:o(n)}},function(e,t,n){"use strict";var o=String;e.exports=function(e){try{return o(e)}catch(e){return"Object"}}},function(e,t,n){"use strict";var o=n(33),i=n(2),a=n(8),r=TypeError;e.exports=function(e,t){var n,s;if("string"===t&&i(n=e.toString)&&!a(s=o(n,e)))return s;if(i(n=e.valueOf)&&!a(s=o(n,e)))return s;if("string"!==t&&i(n=e.toString)&&!a(s=o(n,e)))return s;throw new r("Can't convert object to primitive value")}},function(e,t,n){"use strict";var o=n(5),i=n(9),a=Function.prototype,r=o&&Object.getOwnPropertyDescriptor,s=i(a,"name"),c=s&&"something"===function(){}.name,l=s&&(!o||o&&r(a,"name").configurable);e.exports={EXISTS:s,PROPER:c,CONFIGURABLE:l}},function(e,t,n){"use strict";var o=n(3),i=n(2),a=n(35),r=o(Function.toString);i(a.inspectSource)||(a.inspectSource=function(e){return r(e)}),e.exports=a.inspectSource},function(e,t,n){"use strict";var o,i,a,r=n(116),s=n(1),c=n(8),l=n(13),d=n(9),u=n(35),h=n(102),p=n(48),m=s.TypeError,f=s.WeakMap;if(r||u.state){var w=u.state||(u.state=new f);w.get=w.get,w.has=w.has,w.set=w.set,o=function(e,t){if(w.has(e))throw new m("Object already initialized");return t.facade=e,w.set(e,t),t},i=function(e){return w.get(e)||{}},a=function(e){return w.has(e)}}else{var g=h("state");p[g]=!0,o=function(e,t){if(d(e,g))throw new m("Object already initialized");return t.facade=e,l(e,g,t),t},i=function(e){return d(e,g)?e[g]:{}},a=function(e){return d(e,g)}}e.exports={set:o,get:i,has:a,enforce:function(e){return a(e)?i(e):o(e,{})},getterFor:function(e){return function(t){var n;if(!c(t)||(n=i(t)).type!==e)throw new m("Incompatible receiver, "+e+" required");return n}}}},function(e,t,n){"use strict";var o=n(1),i=n(2),a=o.WeakMap;e.exports=i(a)&&/native code/.test(String(a))},function(e,t,n){"use strict";var o=n(28),i=n(3),a=n(118),r=n(123),s=n(24),c=i([].concat);e.exports=o("Reflect","ownKeys")||function(e){var t=a.f(s(e)),n=r.f;return n?c(t,n(e)):t}},function(e,t,n){"use strict";var o=n(103),i=n(99).concat("length","prototype");t.f=Object.getOwnPropertyNames||function(e){return o(e,i)}},function(e,t,n){"use strict";var o=n(27),i=n(120),a=n(32),r=function(e){return function(t,n,r){var s=o(t),c=a(s);if(0===c)return!e&&-1;var l,d=i(r,c);if(e&&n!=n){for(;c>d;)if((l=s[d++])!=l)return!0}else for(;c>d;d++)if((e||d in s)&&s[d]===n)return e||d||0;return!e&&-1}};e.exports={includes:r(!0),indexOf:r(!1)}},function(e,t,n){"use strict";var o=n(64),i=Math.max,a=Math.min;e.exports=function(e,t){var n=o(e);return n<0?i(n+t,0):a(n,t)}},function(e,t,n){"use strict";var o=Math.ceil,i=Math.floor;e.exports=Math.trunc||function(e){var t=+e;return(t>0?i:o)(t)}},function(e,t,n){"use strict";var o=n(64),i=Math.min;e.exports=function(e){var t=o(e);return t>0?i(t,9007199254740991):0}},function(e,t,n){"use strict";t.f=Object.getOwnPropertySymbols},function(e,t,n){"use strict";var o=n(4),i=n(2),a=/#|\.prototype\./,r=function(e,t){var n=c[s(e)];return n===d||n!==l&&(i(t)?o(t):!!t)},s=r.normalize=function(e){return String(e).replace(a,".").toLowerCase()},c=r.data={},l=r.NATIVE="N",d=r.POLYFILL="P";e.exports=r},function(e,t,n){"use strict";var o=n(29),i=n(31),a=n(47),r=n(32),s=TypeError,c="Reduce of empty array with no initial value",l=function(e){return function(t,n,l,d){var u=i(t),h=a(u),p=r(u);if(o(n),0===p&&l<2)throw new s(c);var m=e?p-1:0,f=e?-1:1;if(l<2)for(;;){if(m in h){d=h[m],m+=f;break}if(m+=f,e?m<0:p<=m)throw new s(c)}for(;e?m>=0:p>m;m+=f)m in h&&(d=n(d,h[m],m,u));return d}};e.exports={left:l(!1),right:l(!0)}},function(e,t,n){"use strict";var o=n(4);e.exports=function(e,t){var n=[][e];return!!n&&o((function(){n.call(null,t||function(){return 1},1)}))}},function(e,t,n){"use strict";var o=n(1),i=n(16);e.exports="process"===i(o.process)},function(e,t,n){"use strict";var o=n(26),i=Function.prototype,a=i.apply,r=i.call;e.exports="object"==typeof Reflect&&Reflect.apply||(o?r.bind(a):function(){return r.apply(a,arguments)})},function(e,t,n){"use strict";var o=n(28),i=n(9),a=n(13),r=n(55),s=n(65),c=n(63),l=n(133),d=n(134),u=n(135),h=n(138),p=n(139),m=n(5),f=n(60);e.exports=function(e,t,n,w){var g=w?2:1,y=e.split("."),v=y[y.length-1],b=o.apply(null,y);if(b){var k=b.prototype;if(!f&&i(k,"cause")&&delete k.cause,!n)return b;var x=o("Error"),_=t((function(e,t){var n=u(w?t:e,void 0),o=w?new b(e):new b;return void 0!==n&&a(o,"message",n),p(o,_,o.stack,2),this&&r(k,this)&&d(o,this,_),arguments.length>g&&h(o,arguments[g]),o}));if(_.prototype=k,"Error"!==v?s?s(_,x):c(_,x,{name:!0}):m&&"stackTraceLimit"in b&&(l(_,b,"stackTraceLimit"),l(_,b,"prepareStackTrace")),c(_,b),!f)try{k.name!==v&&a(k,"name",v),k.constructor=_}catch(e){}return _}}},function(e,t,n){"use strict";var o=n(3),i=n(29);e.exports=function(e,t,n){try{return o(i(Object.getOwnPropertyDescriptor(e,t)[n]))}catch(e){}}},function(e,t,n){"use strict";var o=n(132),i=String,a=TypeError;e.exports=function(e){if(o(e))return e;throw new a("Can't set "+i(e)+" as a prototype")}},function(e,t,n){"use strict";var o=n(8);e.exports=function(e){return o(e)||null===e}},function(e,t,n){"use strict";var o=n(15).f;e.exports=function(e,t,n){n in e||o(e,n,{configurable:!0,get:function(){return t[n]},set:function(e){t[n]=e}})}},function(e,t,n){"use strict";var o=n(2),i=n(8),a=n(65);e.exports=function(e,t,n){var r,s;return a&&o(r=t.constructor)&&r!==n&&i(s=r.prototype)&&s!==n.prototype&&a(e,s),e}},function(e,t,n){"use strict";var o=n(96);e.exports=function(e,t){return void 0===e?arguments.length<2?"":t:o(e)}},function(e,t,n){"use strict";var o=n(137),i=n(2),a=n(16),r=n(30)("toStringTag"),s=Object,c="Arguments"===a(function(){return arguments}());e.exports=o?a:function(e){var t,n,o;return void 0===e?"Undefined":null===e?"Null":"string"==typeof(n=function(e,t){try{return e[t]}catch(e){}}(t=s(e),r))?n:c?a(t):"Object"===(o=a(t))&&i(t.callee)?"Arguments":o}},function(e,t,n){"use strict";var o={};o[n(30)("toStringTag")]="z",e.exports="[object z]"===String(o)},function(e,t,n){"use strict";var o=n(8),i=n(13);e.exports=function(e,t){o(t)&&"cause"in t&&i(e,"cause",t.cause)}},function(e,t,n){"use strict";var o=n(13),i=n(140),a=n(141),r=Error.captureStackTrace;e.exports=function(e,t,n,s){a&&(r?r(e,t):o(e,"stack",i(n,s)))}},function(e,t,n){"use strict";var o=n(3),i=Error,a=o("".replace),r=String(new i("zxcasd").stack),s=/\n\s*at [^:]*:[^\n]*/,c=s.test(r);e.exports=function(e,t){if(c&&"string"==typeof e&&!i.prepareStackTrace)for(;t--;)e=a(e,s,"");return e}},function(e,t,n){"use strict";var o=n(4),i=n(34);e.exports=!o((function(){var e=new Error("a");return!("stack"in e)||(Object.defineProperty(e,"stack",i(1,7)),7!==e.stack)}))},function(e,t,n){"use strict";var o=n(5),i=n(143),a=TypeError,r=Object.getOwnPropertyDescriptor,s=o&&!function(){if(void 0!==this)return!0;try{Object.defineProperty([],"length",{writable:!1}).length=1}catch(e){return e instanceof TypeError}}();e.exports=s?function(e,t){if(i(e)&&!r(e,"length").writable)throw new a("Cannot set read only .length");return e.length=t}:function(e,t){return e.length=t}},function(e,t,n){"use strict";var o=n(16);e.exports=Array.isArray||function(e){return"Array"===o(e)}},function(e,t,n){"use strict";var o=TypeError;e.exports=function(e){if(e>9007199254740991)throw o("Maximum allowed index exceeded");return e}},function(e,t,n){var o=n(66),i=n(146);e.exports=function e(t,n,a,r,s){var c=-1,l=t.length;for(a||(a=i),s||(s=[]);++c<l;){var d=t[c];n>0&&a(d)?n>1?e(d,n-1,a,r,s):o(s,d):r||(s[s.length]=d)}return s}},function(e,t,n){var o=n(14),i=n(37),a=n(6),r=o?o.isConcatSpreadable:void 0;e.exports=function(e){return a(e)||i(e)||!!(r&&e&&e[r])}},function(e,t,n){var o=n(12),i=n(11);e.exports=function(e){return i(e)&&"[object Arguments]"==o(e)}},function(e,t,n){var o=n(14),i=Object.prototype,a=i.hasOwnProperty,r=i.toString,s=o?o.toStringTag:void 0;e.exports=function(e){var t=a.call(e,s),n=e[s];try{e[s]=void 0;var o=!0}catch(e){}var i=r.call(e);return o&&(t?e[s]=n:delete e[s]),i}},function(e,t){var n=Object.prototype.toString;e.exports=function(e){return n.call(e)}},function(e,t,n){var o=n(151),i=n(207),a=n(45),r=n(6),s=n(218);e.exports=function(e){return"function"==typeof e?e:null==e?a:"object"==typeof e?r(e)?i(e[0],e[1]):o(e):s(e)}},function(e,t,n){var o=n(152),i=n(206),a=n(83);e.exports=function(e){var t=i(e);return 1==t.length&&t[0][2]?a(t[0][0],t[0][1]):function(n){return n===e||o(n,e,t)}}},function(e,t,n){var o=n(68),i=n(72);e.exports=function(e,t,n,a){var r=n.length,s=r,c=!a;if(null==e)return!s;for(e=Object(e);r--;){var l=n[r];if(c&&l[2]?l[1]!==e[l[0]]:!(l[0]in e))return!1}for(;++r<s;){var d=(l=n[r])[0],u=e[d],h=l[1];if(c&&l[2]){if(void 0===u&&!(d in e))return!1}else{var p=new o;if(a)var m=a(u,h,d,e,t,p);if(!(void 0===m?i(h,u,3,a,p):m))return!1}}return!0}},function(e,t){e.exports=function(){this.__data__=[],this.size=0}},function(e,t,n){var o=n(18),i=Array.prototype.splice;e.exports=function(e){var t=this.__data__,n=o(t,e);return!(n<0)&&(n==t.length-1?t.pop():i.call(t,n,1),--this.size,!0)}},function(e,t,n){var o=n(18);e.exports=function(e){var t=this.__data__,n=o(t,e);return n<0?void 0:t[n][1]}},function(e,t,n){var o=n(18);e.exports=function(e){return o(this.__data__,e)>-1}},function(e,t,n){var o=n(18);e.exports=function(e,t){var n=this.__data__,i=o(n,e);return i<0?(++this.size,n.push([e,t])):n[i][1]=t,this}},function(e,t,n){var o=n(17);e.exports=function(){this.__data__=new o,this.size=0}},function(e,t){e.exports=function(e){var t=this.__data__,n=t.delete(e);return this.size=t.size,n}},function(e,t){e.exports=function(e){return this.__data__.get(e)}},function(e,t){e.exports=function(e){return this.__data__.has(e)}},function(e,t,n){var o=n(17),i=n(38),a=n(40);e.exports=function(e,t){var n=this.__data__;if(n instanceof o){var r=n.__data__;if(!i||r.length<199)return r.push([e,t]),this.size=++n.size,this;n=this.__data__=new a(r)}return n.set(e,t),this.size=n.size,this}},function(e,t,n){var o=n(70),i=n(164),a=n(39),r=n(71),s=/^\[object .+?Constructor\]$/,c=Function.prototype,l=Object.prototype,d=c.toString,u=l.hasOwnProperty,h=RegExp("^"+d.call(u).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");e.exports=function(e){return!(!a(e)||i(e))&&(o(e)?h:s).test(r(e))}},function(e,t,n){var o,i=n(165),a=(o=/[^.]+$/.exec(i&&i.keys&&i.keys.IE_PROTO||""))?"Symbol(src)_1."+o:"";e.exports=function(e){return!!a&&a in e}},function(e,t,n){var o=n(7)["__core-js_shared__"];e.exports=o},function(e,t){e.exports=function(e,t){return null==e?void 0:e[t]}},function(e,t,n){var o=n(168),i=n(17),a=n(38);e.exports=function(){this.size=0,this.__data__={hash:new o,map:new(a||i),string:new o}}},function(e,t,n){var o=n(169),i=n(170),a=n(171),r=n(172),s=n(173);function c(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var o=e[t];this.set(o[0],o[1])}}c.prototype.clear=o,c.prototype.delete=i,c.prototype.get=a,c.prototype.has=r,c.prototype.set=s,e.exports=c},function(e,t,n){var o=n(19);e.exports=function(){this.__data__=o?o(null):{},this.size=0}},function(e,t){e.exports=function(e){var t=this.has(e)&&delete this.__data__[e];return this.size-=t?1:0,t}},function(e,t,n){var o=n(19),i=Object.prototype.hasOwnProperty;e.exports=function(e){var t=this.__data__;if(o){var n=t[e];return"__lodash_hash_undefined__"===n?void 0:n}return i.call(t,e)?t[e]:void 0}},function(e,t,n){var o=n(19),i=Object.prototype.hasOwnProperty;e.exports=function(e){var t=this.__data__;return o?void 0!==t[e]:i.call(t,e)}},function(e,t,n){var o=n(19);e.exports=function(e,t){var n=this.__data__;return this.size+=this.has(e)?0:1,n[e]=o&&void 0===t?"__lodash_hash_undefined__":t,this}},function(e,t,n){var o=n(20);e.exports=function(e){var t=o(this,e).delete(e);return this.size-=t?1:0,t}},function(e,t){e.exports=function(e){var t=typeof e;return"string"==t||"number"==t||"symbol"==t||"boolean"==t?"__proto__"!==e:null===e}},function(e,t,n){var o=n(20);e.exports=function(e){return o(this,e).get(e)}},function(e,t,n){var o=n(20);e.exports=function(e){return o(this,e).has(e)}},function(e,t,n){var o=n(20);e.exports=function(e,t){var n=o(this,e),i=n.size;return n.set(e,t),this.size+=n.size==i?0:1,this}},function(e,t,n){var o=n(68),i=n(73),a=n(183),r=n(186),s=n(202),c=n(6),l=n(77),d=n(79),u="[object Object]",h=Object.prototype.hasOwnProperty;e.exports=function(e,t,n,p,m,f){var w=c(e),g=c(t),y=w?"[object Array]":s(e),v=g?"[object Array]":s(t),b=(y="[object Arguments]"==y?u:y)==u,k=(v="[object Arguments]"==v?u:v)==u,x=y==v;if(x&&l(e)){if(!l(t))return!1;w=!0,b=!1}if(x&&!b)return f||(f=new o),w||d(e)?i(e,t,n,p,m,f):a(e,t,y,n,p,m,f);if(!(1&n)){var _=b&&h.call(e,"__wrapped__"),T=k&&h.call(t,"__wrapped__");if(_||T){var S=_?e.value():e,C=T?t.value():t;return f||(f=new o),m(S,C,n,p,f)}}return!!x&&(f||(f=new o),r(e,t,n,p,m,f))}},function(e,t){e.exports=function(e){return this.__data__.set(e,"__lodash_hash_undefined__"),this}},function(e,t){e.exports=function(e){return this.__data__.has(e)}},function(e,t){e.exports=function(e,t){for(var n=-1,o=null==e?0:e.length;++n<o;)if(t(e[n],n,e))return!0;return!1}},function(e,t,n){var o=n(14),i=n(184),a=n(69),r=n(73),s=n(185),c=n(41),l=o?o.prototype:void 0,d=l?l.valueOf:void 0;e.exports=function(e,t,n,o,l,u,h){switch(n){case"[object DataView]":if(e.byteLength!=t.byteLength||e.byteOffset!=t.byteOffset)return!1;e=e.buffer,t=t.buffer;case"[object ArrayBuffer]":return!(e.byteLength!=t.byteLength||!u(new i(e),new i(t)));case"[object Boolean]":case"[object Date]":case"[object Number]":return a(+e,+t);case"[object Error]":return e.name==t.name&&e.message==t.message;case"[object RegExp]":case"[object String]":return e==t+"";case"[object Map]":var p=s;case"[object Set]":var m=1&o;if(p||(p=c),e.size!=t.size&&!m)return!1;var f=h.get(e);if(f)return f==t;o|=2,h.set(e,t);var w=r(p(e),p(t),o,l,u,h);return h.delete(e),w;case"[object Symbol]":if(d)return d.call(e)==d.call(t)}return!1}},function(e,t,n){var o=n(7).Uint8Array;e.exports=o},function(e,t){e.exports=function(e){var t=-1,n=Array(e.size);return e.forEach((function(e,o){n[++t]=[o,e]})),n}},function(e,t,n){var o=n(187),i=Object.prototype.hasOwnProperty;e.exports=function(e,t,n,a,r,s){var c=1&n,l=o(e),d=l.length;if(d!=o(t).length&&!c)return!1;for(var u=d;u--;){var h=l[u];if(!(c?h in t:i.call(t,h)))return!1}var p=s.get(e),m=s.get(t);if(p&&m)return p==t&&m==e;var f=!0;s.set(e,t),s.set(t,e);for(var w=c;++u<d;){var g=e[h=l[u]],y=t[h];if(a)var v=c?a(y,g,h,t,e,s):a(g,y,h,e,t,s);if(!(void 0===v?g===y||r(g,y,n,a,s):v)){f=!1;break}w||(w="constructor"==h)}if(f&&!w){var b=e.constructor,k=t.constructor;b==k||!("constructor"in e)||!("constructor"in t)||"function"==typeof b&&b instanceof b&&"function"==typeof k&&k instanceof k||(f=!1)}return s.delete(e),s.delete(t),f}},function(e,t,n){var o=n(188),i=n(189),a=n(76);e.exports=function(e){return o(e,a,i)}},function(e,t,n){var o=n(66),i=n(6);e.exports=function(e,t,n){var a=t(e);return i(e)?a:o(a,n(e))}},function(e,t,n){var o=n(190),i=n(191),a=Object.prototype.propertyIsEnumerable,r=Object.getOwnPropertySymbols,s=r?function(e){return null==e?[]:(e=Object(e),o(r(e),(function(t){return a.call(e,t)})))}:i;e.exports=s},function(e,t){e.exports=function(e,t){for(var n=-1,o=null==e?0:e.length,i=0,a=[];++n<o;){var r=e[n];t(r,n,e)&&(a[i++]=r)}return a}},function(e,t){e.exports=function(){return[]}},function(e,t,n){var o=n(193),i=n(37),a=n(6),r=n(77),s=n(78),c=n(79),l=Object.prototype.hasOwnProperty;e.exports=function(e,t){var n=a(e),d=!n&&i(e),u=!n&&!d&&r(e),h=!n&&!d&&!u&&c(e),p=n||d||u||h,m=p?o(e.length,String):[],f=m.length;for(var w in e)!t&&!l.call(e,w)||p&&("length"==w||u&&("offset"==w||"parent"==w)||h&&("buffer"==w||"byteLength"==w||"byteOffset"==w)||s(w,f))||m.push(w);return m}},function(e,t){e.exports=function(e,t){for(var n=-1,o=Array(e);++n<e;)o[n]=t(n);return o}},function(e,t){e.exports=function(){return!1}},function(e,t,n){var o=n(12),i=n(42),a=n(11),r={};r["[object Float32Array]"]=r["[object Float64Array]"]=r["[object Int8Array]"]=r["[object Int16Array]"]=r["[object Int32Array]"]=r["[object Uint8Array]"]=r["[object Uint8ClampedArray]"]=r["[object Uint16Array]"]=r["[object Uint32Array]"]=!0,r["[object Arguments]"]=r["[object Array]"]=r["[object ArrayBuffer]"]=r["[object Boolean]"]=r["[object DataView]"]=r["[object Date]"]=r["[object Error]"]=r["[object Function]"]=r["[object Map]"]=r["[object Number]"]=r["[object Object]"]=r["[object RegExp]"]=r["[object Set]"]=r["[object String]"]=r["[object WeakMap]"]=!1,e.exports=function(e){return a(e)&&i(e.length)&&!!r[o(e)]}},function(e,t){e.exports=function(e){return function(t){return e(t)}}},function(e,t,n){(function(e){var o=n(67),i=t&&!t.nodeType&&t,a=i&&"object"==typeof e&&e&&!e.nodeType&&e,r=a&&a.exports===i&&o.process,s=function(){try{var e=a&&a.require&&a.require("util").types;return e||r&&r.binding&&r.binding("util")}catch(e){}}();e.exports=s}).call(this,n(49)(e))},function(e,t,n){var o=n(199),i=n(200),a=Object.prototype.hasOwnProperty;e.exports=function(e){if(!o(e))return i(e);var t=[];for(var n in Object(e))a.call(e,n)&&"constructor"!=n&&t.push(n);return t}},function(e,t){var n=Object.prototype;e.exports=function(e){var t=e&&e.constructor;return e===("function"==typeof t&&t.prototype||n)}},function(e,t,n){var o=n(201)(Object.keys,Object);e.exports=o},function(e,t){e.exports=function(e,t){return function(n){return e(t(n))}}},function(e,t,n){var o=n(203),i=n(38),a=n(204),r=n(81),s=n(205),c=n(12),l=n(71),d=l(o),u=l(i),h=l(a),p=l(r),m=l(s),f=c;(o&&"[object DataView]"!=f(new o(new ArrayBuffer(1)))||i&&"[object Map]"!=f(new i)||a&&"[object Promise]"!=f(a.resolve())||r&&"[object Set]"!=f(new r)||s&&"[object WeakMap]"!=f(new s))&&(f=function(e){var t=c(e),n="[object Object]"==t?e.constructor:void 0,o=n?l(n):"";if(o)switch(o){case d:return"[object DataView]";case u:return"[object Map]";case h:return"[object Promise]";case p:return"[object Set]";case m:return"[object WeakMap]"}return t}),e.exports=f},function(e,t,n){var o=n(10)(n(7),"DataView");e.exports=o},function(e,t,n){var o=n(10)(n(7),"Promise");e.exports=o},function(e,t,n){var o=n(10)(n(7),"WeakMap");e.exports=o},function(e,t,n){var o=n(82),i=n(76);e.exports=function(e){for(var t=i(e),n=t.length;n--;){var a=t[n],r=e[a];t[n]=[a,r,o(r)]}return t}},function(e,t,n){var o=n(72),i=n(208),a=n(215),r=n(43),s=n(82),c=n(83),l=n(21);e.exports=function(e,t){return r(e)&&s(t)?c(l(e),t):function(n){var r=i(n,e);return void 0===r&&r===t?a(n,e):o(t,r,3)}}},function(e,t,n){var o=n(84);e.exports=function(e,t,n){var i=null==e?void 0:o(e,t);return void 0===i?n:i}},function(e,t,n){var o=n(210),i=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,a=/\\(\\)?/g,r=o((function(e){var t=[];return 46===e.charCodeAt(0)&&t.push(""),e.replace(i,(function(e,n,o,i){t.push(o?i.replace(a,"$1"):n||e)})),t}));e.exports=r},function(e,t,n){var o=n(211);e.exports=function(e){var t=o(e,(function(e){return 500===n.size&&n.clear(),e})),n=t.cache;return t}},function(e,t,n){var o=n(40);function i(e,t){if("function"!=typeof e||null!=t&&"function"!=typeof t)throw new TypeError("Expected a function");var n=function(){var o=arguments,i=t?t.apply(this,o):o[0],a=n.cache;if(a.has(i))return a.get(i);var r=e.apply(this,o);return n.cache=a.set(i,r)||a,r};return n.cache=new(i.Cache||o),n}i.Cache=o,e.exports=i},function(e,t,n){var o=n(213);e.exports=function(e){return null==e?"":o(e)}},function(e,t,n){var o=n(14),i=n(214),a=n(6),r=n(44),s=o?o.prototype:void 0,c=s?s.toString:void 0;e.exports=function e(t){if("string"==typeof t)return t;if(a(t))return i(t,e)+"";if(r(t))return c?c.call(t):"";var n=t+"";return"0"==n&&1/t==-1/0?"-0":n}},function(e,t){e.exports=function(e,t){for(var n=-1,o=null==e?0:e.length,i=Array(o);++n<o;)i[n]=t(e[n],n,e);return i}},function(e,t,n){var o=n(216),i=n(217);e.exports=function(e,t){return null!=e&&i(e,t,o)}},function(e,t){e.exports=function(e,t){return null!=e&&t in Object(e)}},function(e,t,n){var o=n(85),i=n(37),a=n(6),r=n(78),s=n(42),c=n(21);e.exports=function(e,t,n){for(var l=-1,d=(t=o(t,e)).length,u=!1;++l<d;){var h=c(t[l]);if(!(u=null!=e&&n(e,h)))break;e=e[h]}return u||++l!=d?u:!!(d=null==e?0:e.length)&&s(d)&&r(h,d)&&(a(e)||i(e))}},function(e,t,n){var o=n(219),i=n(220),a=n(43),r=n(21);e.exports=function(e){return a(e)?o(r(e)):i(e)}},function(e,t){e.exports=function(e){return function(t){return null==t?void 0:t[e]}}},function(e,t,n){var o=n(84);e.exports=function(e){return function(t){return o(t,e)}}},function(e,t,n){var o=n(45),i=n(222),a=n(224);e.exports=function(e,t){return a(i(e,t,o),e+"")}},function(e,t,n){var o=n(223),i=Math.max;e.exports=function(e,t,n){return t=i(void 0===t?e.length-1:t,0),function(){for(var a=arguments,r=-1,s=i(a.length-t,0),c=Array(s);++r<s;)c[r]=a[t+r];r=-1;for(var l=Array(t+1);++r<t;)l[r]=a[r];return l[t]=n(c),o(e,this,l)}}},function(e,t){e.exports=function(e,t,n){switch(n.length){case 0:return e.call(t);case 1:return e.call(t,n[0]);case 2:return e.call(t,n[0],n[1]);case 3:return e.call(t,n[0],n[1],n[2])}return e.apply(t,n)}},function(e,t,n){var o=n(225),i=n(228)(o);e.exports=i},function(e,t,n){var o=n(226),i=n(227),a=n(45),r=i?function(e,t){return i(e,"toString",{configurable:!0,enumerable:!1,value:o(t),writable:!0})}:a;e.exports=r},function(e,t){e.exports=function(e){return function(){return e}}},function(e,t,n){var o=n(10),i=function(){try{var e=o(Object,"defineProperty");return e({},"",{}),e}catch(e){}}();e.exports=i},function(e,t){var n=Date.now;e.exports=function(e){var t=0,o=0;return function(){var i=n(),a=16-(i-o);if(o=i,a>0){if(++t>=800)return arguments[0]}else t=0;return e.apply(void 0,arguments)}}},function(e,t,n){var o=n(74),i=n(230),a=n(235),r=n(75),s=n(236),c=n(41);e.exports=function(e,t,n){var l=-1,d=i,u=e.length,h=!0,p=[],m=p;if(n)h=!1,d=a;else if(u>=200){var f=t?null:s(e);if(f)return c(f);h=!1,d=r,m=new o}else m=t?[]:p;e:for(;++l<u;){var w=e[l],g=t?t(w):w;if(w=n||0!==w?w:0,h&&g==g){for(var y=m.length;y--;)if(m[y]===g)continue e;t&&m.push(g),p.push(w)}else d(m,g,n)||(m!==p&&m.push(g),p.push(w))}return p}},function(e,t,n){var o=n(231);e.exports=function(e,t){return!!(null==e?0:e.length)&&o(e,t,0)>-1}},function(e,t,n){var o=n(232),i=n(233),a=n(234);e.exports=function(e,t,n){return t==t?a(e,t,n):o(e,i,n)}},function(e,t){e.exports=function(e,t,n,o){for(var i=e.length,a=n+(o?1:-1);o?a--:++a<i;)if(t(e[a],a,e))return a;return-1}},function(e,t){e.exports=function(e){return e!=e}},function(e,t){e.exports=function(e,t,n){for(var o=n-1,i=e.length;++o<i;)if(e[o]===t)return o;return-1}},function(e,t){e.exports=function(e,t,n){for(var o=-1,i=null==e?0:e.length;++o<i;)if(n(t,e[o]))return!0;return!1}},function(e,t,n){var o=n(81),i=n(237),a=n(41),r=o&&1/a(new o([,-0]))[1]==1/0?function(e){return new o(e)}:i;e.exports=r},function(e,t){e.exports=function(){}},function(e,t,n){var o=n(80),i=n(11);e.exports=function(e){return i(e)&&o(e)}},function(e,t,n){"use strict";n(86)},function(e,t,n){},function(e,t,n){},function(e,t,n){},function(e,t,n){"use strict";n(87)},function(e,t,n){},function(e,t,n){"use strict";n(88)},function(e,t,n){"use strict";n(89)},function(e,t,n){"use strict";n(90)},function(e,t,n){"use strict";n(91)},function(e,t,n){"use strict";n.r(t);
/*!
 * Vue.js v2.7.16
 * (c) 2014-2023 Evan You
 * Released under the MIT License.
 */
var o=Object.freeze({}),i=Array.isArray;function a(e){return null==e}function r(e){return null!=e}function s(e){return!0===e}function c(e){return"string"==typeof e||"number"==typeof e||"symbol"==typeof e||"boolean"==typeof e}function l(e){return"function"==typeof e}function d(e){return null!==e&&"object"==typeof e}var u=Object.prototype.toString;function h(e){return"[object Object]"===u.call(e)}function p(e){return"[object RegExp]"===u.call(e)}function m(e){var t=parseFloat(String(e));return t>=0&&Math.floor(t)===t&&isFinite(e)}function f(e){return r(e)&&"function"==typeof e.then&&"function"==typeof e.catch}function w(e){return null==e?"":Array.isArray(e)||h(e)&&e.toString===u?JSON.stringify(e,g,2):String(e)}function g(e,t){return t&&t.__v_isRef?t.value:t}function y(e){var t=parseFloat(e);return isNaN(t)?e:t}function v(e,t){for(var n=Object.create(null),o=e.split(","),i=0;i<o.length;i++)n[o[i]]=!0;return t?function(e){return n[e.toLowerCase()]}:function(e){return n[e]}}v("slot,component",!0);var b=v("key,ref,slot,slot-scope,is");function k(e,t){var n=e.length;if(n){if(t===e[n-1])return void(e.length=n-1);var o=e.indexOf(t);if(o>-1)return e.splice(o,1)}}var x=Object.prototype.hasOwnProperty;function _(e,t){return x.call(e,t)}function T(e){var t=Object.create(null);return function(n){return t[n]||(t[n]=e(n))}}var S=/-(\w)/g,C=T((function(e){return e.replace(S,(function(e,t){return t?t.toUpperCase():""}))})),I=T((function(e){return e.charAt(0).toUpperCase()+e.slice(1)})),A=/\B([A-Z])/g,E=T((function(e){return e.replace(A,"-$1").toLowerCase()}));var P=Function.prototype.bind?function(e,t){return e.bind(t)}:function(e,t){function n(n){var o=arguments.length;return o?o>1?e.apply(t,arguments):e.call(t,n):e.call(t)}return n._length=e.length,n};function W(e,t){t=t||0;for(var n=e.length-t,o=new Array(n);n--;)o[n]=e[n+t];return o}function q(e,t){for(var n in t)e[n]=t[n];return e}function D(e){for(var t={},n=0;n<e.length;n++)e[n]&&q(t,e[n]);return t}function O(e,t,n){}var j=function(e,t,n){return!1},N=function(e){return e};function R(e,t){if(e===t)return!0;var n=d(e),o=d(t);if(!n||!o)return!n&&!o&&String(e)===String(t);try{var i=Array.isArray(e),a=Array.isArray(t);if(i&&a)return e.length===t.length&&e.every((function(e,n){return R(e,t[n])}));if(e instanceof Date&&t instanceof Date)return e.getTime()===t.getTime();if(i||a)return!1;var r=Object.keys(e),s=Object.keys(t);return r.length===s.length&&r.every((function(n){return R(e[n],t[n])}))}catch(e){return!1}}function L(e,t){for(var n=0;n<e.length;n++)if(R(e[n],t))return n;return-1}function z(e){var t=!1;return function(){t||(t=!0,e.apply(this,arguments))}}function F(e,t){return e===t?0===e&&1/e!=1/t:e==e||t==t}var M=["component","directive","filter"],H=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch","renderTracked","renderTriggered"],$={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:j,isReservedAttr:j,isUnknownElement:j,getTagNamespace:O,parsePlatformTagName:N,mustUseProp:j,async:!0,_lifecycleHooks:H},U=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function G(e){var t=(e+"").charCodeAt(0);return 36===t||95===t}function B(e,t,n,o){Object.defineProperty(e,t,{value:n,enumerable:!!o,writable:!0,configurable:!0})}var V=new RegExp("[^".concat(U.source,".$_\\d]"));var Y="__proto__"in{},K="undefined"!=typeof window,X=K&&window.navigator.userAgent.toLowerCase(),Q=X&&/msie|trident/.test(X),J=X&&X.indexOf("msie 9.0")>0,Z=X&&X.indexOf("edge/")>0;X&&X.indexOf("android");var ee=X&&/iphone|ipad|ipod|ios/.test(X);X&&/chrome\/\d+/.test(X),X&&/phantomjs/.test(X);var te,ne=X&&X.match(/firefox\/(\d+)/),oe={}.watch,ie=!1;if(K)try{var ae={};Object.defineProperty(ae,"passive",{get:function(){ie=!0}}),window.addEventListener("test-passive",null,ae)}catch(e){}var re=function(){return void 0===te&&(te=!K&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),te},se=K&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function ce(e){return"function"==typeof e&&/native code/.test(e.toString())}var le,de="undefined"!=typeof Symbol&&ce(Symbol)&&"undefined"!=typeof Reflect&&ce(Reflect.ownKeys);le="undefined"!=typeof Set&&ce(Set)?Set:function(){function e(){this.set=Object.create(null)}return e.prototype.has=function(e){return!0===this.set[e]},e.prototype.add=function(e){this.set[e]=!0},e.prototype.clear=function(){this.set=Object.create(null)},e}();var ue=null;function he(e){void 0===e&&(e=null),e||ue&&ue._scope.off(),ue=e,e&&e._scope.on()}var pe=function(){function e(e,t,n,o,i,a,r,s){this.tag=e,this.data=t,this.children=n,this.text=o,this.elm=i,this.ns=void 0,this.context=a,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=t&&t.key,this.componentOptions=r,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=s,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1}return Object.defineProperty(e.prototype,"child",{get:function(){return this.componentInstance},enumerable:!1,configurable:!0}),e}(),me=function(e){void 0===e&&(e="");var t=new pe;return t.text=e,t.isComment=!0,t};function fe(e){return new pe(void 0,void 0,void 0,String(e))}function we(e){var t=new pe(e.tag,e.data,e.children&&e.children.slice(),e.text,e.elm,e.context,e.componentOptions,e.asyncFactory);return t.ns=e.ns,t.isStatic=e.isStatic,t.key=e.key,t.isComment=e.isComment,t.fnContext=e.fnContext,t.fnOptions=e.fnOptions,t.fnScopeId=e.fnScopeId,t.asyncMeta=e.asyncMeta,t.isCloned=!0,t}"function"==typeof SuppressedError&&SuppressedError;var ge=0,ye=[],ve=function(){function e(){this._pending=!1,this.id=ge++,this.subs=[]}return e.prototype.addSub=function(e){this.subs.push(e)},e.prototype.removeSub=function(e){this.subs[this.subs.indexOf(e)]=null,this._pending||(this._pending=!0,ye.push(this))},e.prototype.depend=function(t){e.target&&e.target.addDep(this)},e.prototype.notify=function(e){var t=this.subs.filter((function(e){return e}));for(var n=0,o=t.length;n<o;n++){0,t[n].update()}},e}();ve.target=null;var be=[];function ke(e){be.push(e),ve.target=e}function xe(){be.pop(),ve.target=be[be.length-1]}var _e=Array.prototype,Te=Object.create(_e);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(e){var t=_e[e];B(Te,e,(function(){for(var n=[],o=0;o<arguments.length;o++)n[o]=arguments[o];var i,a=t.apply(this,n),r=this.__ob__;switch(e){case"push":case"unshift":i=n;break;case"splice":i=n.slice(2)}return i&&r.observeArray(i),r.dep.notify(),a}))}));var Se=Object.getOwnPropertyNames(Te),Ce={},Ie=!0;function Ae(e){Ie=e}var Ee={notify:O,depend:O,addSub:O,removeSub:O},Pe=function(){function e(e,t,n){if(void 0===t&&(t=!1),void 0===n&&(n=!1),this.value=e,this.shallow=t,this.mock=n,this.dep=n?Ee:new ve,this.vmCount=0,B(e,"__ob__",this),i(e)){if(!n)if(Y)e.__proto__=Te;else for(var o=0,a=Se.length;o<a;o++){B(e,s=Se[o],Te[s])}t||this.observeArray(e)}else{var r=Object.keys(e);for(o=0;o<r.length;o++){var s;qe(e,s=r[o],Ce,void 0,t,n)}}}return e.prototype.observeArray=function(e){for(var t=0,n=e.length;t<n;t++)We(e[t],!1,this.mock)},e}();function We(e,t,n){return e&&_(e,"__ob__")&&e.__ob__ instanceof Pe?e.__ob__:!Ie||!n&&re()||!i(e)&&!h(e)||!Object.isExtensible(e)||e.__v_skip||ze(e)||e instanceof pe?void 0:new Pe(e,t,n)}function qe(e,t,n,o,a,r,s){void 0===s&&(s=!1);var c=new ve,l=Object.getOwnPropertyDescriptor(e,t);if(!l||!1!==l.configurable){var d=l&&l.get,u=l&&l.set;d&&!u||n!==Ce&&2!==arguments.length||(n=e[t]);var h=a?n&&n.__ob__:We(n,!1,r);return Object.defineProperty(e,t,{enumerable:!0,configurable:!0,get:function(){var t=d?d.call(e):n;return ve.target&&(c.depend(),h&&(h.dep.depend(),i(t)&&je(t))),ze(t)&&!a?t.value:t},set:function(t){var o=d?d.call(e):n;if(F(o,t)){if(u)u.call(e,t);else{if(d)return;if(!a&&ze(o)&&!ze(t))return void(o.value=t);n=t}h=a?t&&t.__ob__:We(t,!1,r),c.notify()}}}),c}}function De(e,t,n){if(!Le(e)){var o=e.__ob__;return i(e)&&m(t)?(e.length=Math.max(e.length,t),e.splice(t,1,n),o&&!o.shallow&&o.mock&&We(n,!1,!0),n):t in e&&!(t in Object.prototype)?(e[t]=n,n):e._isVue||o&&o.vmCount?n:o?(qe(o.value,t,n,void 0,o.shallow,o.mock),o.dep.notify(),n):(e[t]=n,n)}}function Oe(e,t){if(i(e)&&m(t))e.splice(t,1);else{var n=e.__ob__;e._isVue||n&&n.vmCount||Le(e)||_(e,t)&&(delete e[t],n&&n.dep.notify())}}function je(e){for(var t=void 0,n=0,o=e.length;n<o;n++)(t=e[n])&&t.__ob__&&t.__ob__.dep.depend(),i(t)&&je(t)}function Ne(e){return Re(e,!0),B(e,"__v_isShallow",!0),e}function Re(e,t){if(!Le(e)){We(e,t,re());0}}function Le(e){return!(!e||!e.__v_isReadonly)}function ze(e){return!(!e||!0!==e.__v_isRef)}function Fe(e,t,n){Object.defineProperty(e,n,{enumerable:!0,configurable:!0,get:function(){var e=t[n];if(ze(e))return e.value;var o=e&&e.__ob__;return o&&o.dep.depend(),e},set:function(e){var o=t[n];ze(o)&&!ze(e)?o.value=e:t[n]=e}})}"".concat("watcher"," callback"),"".concat("watcher"," getter"),"".concat("watcher"," cleanup");var Me;var He=function(){function e(e){void 0===e&&(e=!1),this.detached=e,this.active=!0,this.effects=[],this.cleanups=[],this.parent=Me,!e&&Me&&(this.index=(Me.scopes||(Me.scopes=[])).push(this)-1)}return e.prototype.run=function(e){if(this.active){var t=Me;try{return Me=this,e()}finally{Me=t}}else 0},e.prototype.on=function(){Me=this},e.prototype.off=function(){Me=this.parent},e.prototype.stop=function(e){if(this.active){var t=void 0,n=void 0;for(t=0,n=this.effects.length;t<n;t++)this.effects[t].teardown();for(t=0,n=this.cleanups.length;t<n;t++)this.cleanups[t]();if(this.scopes)for(t=0,n=this.scopes.length;t<n;t++)this.scopes[t].stop(!0);if(!this.detached&&this.parent&&!e){var o=this.parent.scopes.pop();o&&o!==this&&(this.parent.scopes[this.index]=o,o.index=this.index)}this.parent=void 0,this.active=!1}},e}();function $e(e){var t=e._provided,n=e.$parent&&e.$parent._provided;return n===t?e._provided=Object.create(n):t}var Ue=T((function(e){var t="&"===e.charAt(0),n="~"===(e=t?e.slice(1):e).charAt(0),o="!"===(e=n?e.slice(1):e).charAt(0);return{name:e=o?e.slice(1):e,once:n,capture:o,passive:t}}));function Ge(e,t){function n(){var e=n.fns;if(!i(e))return It(e,null,arguments,t,"v-on handler");for(var o=e.slice(),a=0;a<o.length;a++)It(o[a],null,arguments,t,"v-on handler")}return n.fns=e,n}function Be(e,t,n,o,i,r){var c,l,d,u;for(c in e)l=e[c],d=t[c],u=Ue(c),a(l)||(a(d)?(a(l.fns)&&(l=e[c]=Ge(l,r)),s(u.once)&&(l=e[c]=i(u.name,l,u.capture)),n(u.name,l,u.capture,u.passive,u.params)):l!==d&&(d.fns=l,e[c]=d));for(c in t)a(e[c])&&o((u=Ue(c)).name,t[c],u.capture)}function Ve(e,t,n){var o;e instanceof pe&&(e=e.data.hook||(e.data.hook={}));var i=e[t];function c(){n.apply(this,arguments),k(o.fns,c)}a(i)?o=Ge([c]):r(i.fns)&&s(i.merged)?(o=i).fns.push(c):o=Ge([i,c]),o.merged=!0,e[t]=o}function Ye(e,t,n,o,i){if(r(t)){if(_(t,n))return e[n]=t[n],i||delete t[n],!0;if(_(t,o))return e[n]=t[o],i||delete t[o],!0}return!1}function Ke(e){return c(e)?[fe(e)]:i(e)?function e(t,n){var o,l,d,u,h=[];for(o=0;o<t.length;o++)a(l=t[o])||"boolean"==typeof l||(d=h.length-1,u=h[d],i(l)?l.length>0&&(Xe((l=e(l,"".concat(n||"","_").concat(o)))[0])&&Xe(u)&&(h[d]=fe(u.text+l[0].text),l.shift()),h.push.apply(h,l)):c(l)?Xe(u)?h[d]=fe(u.text+l):""!==l&&h.push(fe(l)):Xe(l)&&Xe(u)?h[d]=fe(u.text+l.text):(s(t._isVList)&&r(l.tag)&&a(l.key)&&r(n)&&(l.key="__vlist".concat(n,"_").concat(o,"__")),h.push(l)));return h}(e):void 0}function Xe(e){return r(e)&&r(e.text)&&!1===e.isComment}function Qe(e,t){var n,o,a,s,c=null;if(i(e)||"string"==typeof e)for(c=new Array(e.length),n=0,o=e.length;n<o;n++)c[n]=t(e[n],n);else if("number"==typeof e)for(c=new Array(e),n=0;n<e;n++)c[n]=t(n+1,n);else if(d(e))if(de&&e[Symbol.iterator]){c=[];for(var l=e[Symbol.iterator](),u=l.next();!u.done;)c.push(t(u.value,c.length)),u=l.next()}else for(a=Object.keys(e),c=new Array(a.length),n=0,o=a.length;n<o;n++)s=a[n],c[n]=t(e[s],s,n);return r(c)||(c=[]),c._isVList=!0,c}function Je(e,t,n,o){var i,a=this.$scopedSlots[e];a?(n=n||{},o&&(n=q(q({},o),n)),i=a(n)||(l(t)?t():t)):i=this.$slots[e]||(l(t)?t():t);var r=n&&n.slot;return r?this.$createElement("template",{slot:r},i):i}function Ze(e){return Wn(this.$options,"filters",e,!0)||N}function et(e,t){return i(e)?-1===e.indexOf(t):e!==t}function tt(e,t,n,o,i){var a=$.keyCodes[t]||n;return i&&o&&!$.keyCodes[t]?et(i,o):a?et(a,e):o?E(o)!==t:void 0===e}function nt(e,t,n,o,a){if(n)if(d(n)){i(n)&&(n=D(n));var r=void 0,s=function(i){if("class"===i||"style"===i||b(i))r=e;else{var s=e.attrs&&e.attrs.type;r=o||$.mustUseProp(t,s,i)?e.domProps||(e.domProps={}):e.attrs||(e.attrs={})}var c=C(i),l=E(i);c in r||l in r||(r[i]=n[i],a&&((e.on||(e.on={}))["update:".concat(i)]=function(e){n[i]=e}))};for(var c in n)s(c)}else;return e}function ot(e,t){var n=this._staticTrees||(this._staticTrees=[]),o=n[e];return o&&!t||at(o=n[e]=this.$options.staticRenderFns[e].call(this._renderProxy,this._c,this),"__static__".concat(e),!1),o}function it(e,t,n){return at(e,"__once__".concat(t).concat(n?"_".concat(n):""),!0),e}function at(e,t,n){if(i(e))for(var o=0;o<e.length;o++)e[o]&&"string"!=typeof e[o]&&rt(e[o],"".concat(t,"_").concat(o),n);else rt(e,t,n)}function rt(e,t,n){e.isStatic=!0,e.key=t,e.isOnce=n}function st(e,t){if(t)if(h(t)){var n=e.on=e.on?q({},e.on):{};for(var o in t){var i=n[o],a=t[o];n[o]=i?[].concat(i,a):a}}else;return e}function ct(e,t,n,o){t=t||{$stable:!n};for(var a=0;a<e.length;a++){var r=e[a];i(r)?ct(r,t,n):r&&(r.proxy&&(r.fn.proxy=!0),t[r.key]=r.fn)}return o&&(t.$key=o),t}function lt(e,t){for(var n=0;n<t.length;n+=2){var o=t[n];"string"==typeof o&&o&&(e[t[n]]=t[n+1])}return e}function dt(e,t){return"string"==typeof e?t+e:e}function ut(e){e._o=it,e._n=y,e._s=w,e._l=Qe,e._t=Je,e._q=R,e._i=L,e._m=ot,e._f=Ze,e._k=tt,e._b=nt,e._v=fe,e._e=me,e._u=ct,e._g=st,e._d=lt,e._p=dt}function ht(e,t){if(!e||!e.length)return{};for(var n={},o=0,i=e.length;o<i;o++){var a=e[o],r=a.data;if(r&&r.attrs&&r.attrs.slot&&delete r.attrs.slot,a.context!==t&&a.fnContext!==t||!r||null==r.slot)(n.default||(n.default=[])).push(a);else{var s=r.slot,c=n[s]||(n[s]=[]);"template"===a.tag?c.push.apply(c,a.children||[]):c.push(a)}}for(var l in n)n[l].every(pt)&&delete n[l];return n}function pt(e){return e.isComment&&!e.asyncFactory||" "===e.text}function mt(e){return e.isComment&&e.asyncFactory}function ft(e,t,n,i){var a,r=Object.keys(n).length>0,s=t?!!t.$stable:!r,c=t&&t.$key;if(t){if(t._normalized)return t._normalized;if(s&&i&&i!==o&&c===i.$key&&!r&&!i.$hasNormal)return i;for(var l in a={},t)t[l]&&"$"!==l[0]&&(a[l]=wt(e,n,l,t[l]))}else a={};for(var d in n)d in a||(a[d]=gt(n,d));return t&&Object.isExtensible(t)&&(t._normalized=a),B(a,"$stable",s),B(a,"$key",c),B(a,"$hasNormal",r),a}function wt(e,t,n,o){var a=function(){var t=ue;he(e);var n=arguments.length?o.apply(null,arguments):o({}),a=(n=n&&"object"==typeof n&&!i(n)?[n]:Ke(n))&&n[0];return he(t),n&&(!a||1===n.length&&a.isComment&&!mt(a))?void 0:n};return o.proxy&&Object.defineProperty(t,n,{get:a,enumerable:!0,configurable:!0}),a}function gt(e,t){return function(){return e[t]}}function yt(e){return{get attrs(){if(!e._attrsProxy){var t=e._attrsProxy={};B(t,"_v_attr_proxy",!0),vt(t,e.$attrs,o,e,"$attrs")}return e._attrsProxy},get listeners(){e._listenersProxy||vt(e._listenersProxy={},e.$listeners,o,e,"$listeners");return e._listenersProxy},get slots(){return function(e){e._slotsProxy||kt(e._slotsProxy={},e.$scopedSlots);return e._slotsProxy}(e)},emit:P(e.$emit,e),expose:function(t){t&&Object.keys(t).forEach((function(n){return Fe(e,t,n)}))}}}function vt(e,t,n,o,i){var a=!1;for(var r in t)r in e?t[r]!==n[r]&&(a=!0):(a=!0,bt(e,r,o,i));for(var r in e)r in t||(a=!0,delete e[r]);return a}function bt(e,t,n,o){Object.defineProperty(e,t,{enumerable:!0,configurable:!0,get:function(){return n[o][t]}})}function kt(e,t){for(var n in t)e[n]=t[n];for(var n in e)n in t||delete e[n]}var xt=null;function _t(e,t){return(e.__esModule||de&&"Module"===e[Symbol.toStringTag])&&(e=e.default),d(e)?t.extend(e):e}function Tt(e){if(i(e))for(var t=0;t<e.length;t++){var n=e[t];if(r(n)&&(r(n.componentOptions)||mt(n)))return n}}function St(e,t,n,o,u,h){return(i(n)||c(n))&&(u=o,o=n,n=void 0),s(h)&&(u=2),function(e,t,n,o,c){if(r(n)&&r(n.__ob__))return me();r(n)&&r(n.is)&&(t=n.is);if(!t)return me();0;i(o)&&l(o[0])&&((n=n||{}).scopedSlots={default:o[0]},o.length=0);2===c?o=Ke(o):1===c&&(o=function(e){for(var t=0;t<e.length;t++)if(i(e[t]))return Array.prototype.concat.apply([],e);return e}(o));var u,h;if("string"==typeof t){var p=void 0;h=e.$vnode&&e.$vnode.ns||$.getTagNamespace(t),u=$.isReservedTag(t)?new pe($.parsePlatformTagName(t),n,o,void 0,void 0,e):n&&n.pre||!r(p=Wn(e.$options,"components",t))?new pe(t,n,o,void 0,void 0,e):kn(p,n,e,o,t)}else u=kn(t,n,e,o);return i(u)?u:r(u)?(r(h)&&function e(t,n,o){t.ns=n,"foreignObject"===t.tag&&(n=void 0,o=!0);if(r(t.children))for(var i=0,c=t.children.length;i<c;i++){var l=t.children[i];r(l.tag)&&(a(l.ns)||s(o)&&"svg"!==l.tag)&&e(l,n,o)}}(u,h),r(n)&&function(e){d(e.style)&&Ht(e.style);d(e.class)&&Ht(e.class)}(n),u):me()}(e,t,n,o,u)}function Ct(e,t,n){ke();try{if(t)for(var o=t;o=o.$parent;){var i=o.$options.errorCaptured;if(i)for(var a=0;a<i.length;a++)try{if(!1===i[a].call(o,e,t,n))return}catch(e){At(e,o,"errorCaptured hook")}}At(e,t,n)}finally{xe()}}function It(e,t,n,o,i){var a;try{(a=n?e.apply(t,n):e.call(t))&&!a._isVue&&f(a)&&!a._handled&&(a.catch((function(e){return Ct(e,o,i+" (Promise/async)")})),a._handled=!0)}catch(e){Ct(e,o,i)}return a}function At(e,t,n){if($.errorHandler)try{return $.errorHandler.call(null,e,t,n)}catch(t){t!==e&&Et(t,null,"config.errorHandler")}Et(e,t,n)}function Et(e,t,n){if(!K||"undefined"==typeof console)throw e;console.error(e)}var Pt,Wt=!1,qt=[],Dt=!1;function Ot(){Dt=!1;var e=qt.slice(0);qt.length=0;for(var t=0;t<e.length;t++)e[t]()}if("undefined"!=typeof Promise&&ce(Promise)){var jt=Promise.resolve();Pt=function(){jt.then(Ot),ee&&setTimeout(O)},Wt=!0}else if(Q||"undefined"==typeof MutationObserver||!ce(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())Pt="undefined"!=typeof setImmediate&&ce(setImmediate)?function(){setImmediate(Ot)}:function(){setTimeout(Ot,0)};else{var Nt=1,Rt=new MutationObserver(Ot),Lt=document.createTextNode(String(Nt));Rt.observe(Lt,{characterData:!0}),Pt=function(){Nt=(Nt+1)%2,Lt.data=String(Nt)},Wt=!0}function zt(e,t){var n;if(qt.push((function(){if(e)try{e.call(t)}catch(e){Ct(e,t,"nextTick")}else n&&n(t)})),Dt||(Dt=!0,Pt()),!e&&"undefined"!=typeof Promise)return new Promise((function(e){n=e}))}function Ft(e){return function(t,n){if(void 0===n&&(n=ue),n)return function(e,t,n){var o=e.$options;o[t]=In(o[t],n)}(n,e,t)}}Ft("beforeMount"),Ft("mounted"),Ft("beforeUpdate"),Ft("updated"),Ft("beforeDestroy"),Ft("destroyed"),Ft("activated"),Ft("deactivated"),Ft("serverPrefetch"),Ft("renderTracked"),Ft("renderTriggered"),Ft("errorCaptured");var Mt=new le;function Ht(e){return function e(t,n){var o,a,r=i(t);if(!r&&!d(t)||t.__v_skip||Object.isFrozen(t)||t instanceof pe)return;if(t.__ob__){var s=t.__ob__.dep.id;if(n.has(s))return;n.add(s)}if(r)for(o=t.length;o--;)e(t[o],n);else if(ze(t))e(t.value,n);else for(a=Object.keys(t),o=a.length;o--;)e(t[a[o]],n)}(e,Mt),Mt.clear(),e}var $t,Ut=0,Gt=function(){function e(e,t,n,o,i){var a,r;a=this,void 0===(r=Me&&!Me._vm?Me:e?e._scope:void 0)&&(r=Me),r&&r.active&&r.effects.push(a),(this.vm=e)&&i&&(e._watcher=this),o?(this.deep=!!o.deep,this.user=!!o.user,this.lazy=!!o.lazy,this.sync=!!o.sync,this.before=o.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=n,this.id=++Ut,this.active=!0,this.post=!1,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new le,this.newDepIds=new le,this.expression="",l(t)?this.getter=t:(this.getter=function(e){if(!V.test(e)){var t=e.split(".");return function(e){for(var n=0;n<t.length;n++){if(!e)return;e=e[t[n]]}return e}}}(t),this.getter||(this.getter=O)),this.value=this.lazy?void 0:this.get()}return e.prototype.get=function(){var e;ke(this);var t=this.vm;try{e=this.getter.call(t,t)}catch(e){if(!this.user)throw e;Ct(e,t,'getter for watcher "'.concat(this.expression,'"'))}finally{this.deep&&Ht(e),xe(),this.cleanupDeps()}return e},e.prototype.addDep=function(e){var t=e.id;this.newDepIds.has(t)||(this.newDepIds.add(t),this.newDeps.push(e),this.depIds.has(t)||e.addSub(this))},e.prototype.cleanupDeps=function(){for(var e=this.deps.length;e--;){var t=this.deps[e];this.newDepIds.has(t.id)||t.removeSub(this)}var n=this.depIds;this.depIds=this.newDepIds,this.newDepIds=n,this.newDepIds.clear(),n=this.deps,this.deps=this.newDeps,this.newDeps=n,this.newDeps.length=0},e.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():pn(this)},e.prototype.run=function(){if(this.active){var e=this.get();if(e!==this.value||d(e)||this.deep){var t=this.value;if(this.value=e,this.user){var n='callback for watcher "'.concat(this.expression,'"');It(this.cb,this.vm,[e,t],this.vm,n)}else this.cb.call(this.vm,e,t)}}},e.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},e.prototype.depend=function(){for(var e=this.deps.length;e--;)this.deps[e].depend()},e.prototype.teardown=function(){if(this.vm&&!this.vm._isBeingDestroyed&&k(this.vm._scope.effects,this),this.active){for(var e=this.deps.length;e--;)this.deps[e].removeSub(this);this.active=!1,this.onStop&&this.onStop()}},e}();function Bt(e,t){$t.$on(e,t)}function Vt(e,t){$t.$off(e,t)}function Yt(e,t){var n=$t;return function o(){var i=t.apply(null,arguments);null!==i&&n.$off(e,o)}}function Kt(e,t,n){$t=e,Be(t,n||{},Bt,Vt,Yt,e),$t=void 0}var Xt=null;function Qt(e){var t=Xt;return Xt=e,function(){Xt=t}}function Jt(e){for(;e&&(e=e.$parent);)if(e._inactive)return!0;return!1}function Zt(e,t){if(t){if(e._directInactive=!1,Jt(e))return}else if(e._directInactive)return;if(e._inactive||null===e._inactive){e._inactive=!1;for(var n=0;n<e.$children.length;n++)Zt(e.$children[n]);en(e,"activated")}}function en(e,t,n,o){void 0===o&&(o=!0),ke();var i=ue,a=Me;o&&he(e);var r=e.$options[t],s="".concat(t," hook");if(r)for(var c=0,l=r.length;c<l;c++)It(r[c],e,n||null,e,s);e._hasHookEvent&&e.$emit("hook:"+t),o&&(he(i),a&&a.on()),xe()}var tn=[],nn=[],on={},an=!1,rn=!1,sn=0;var cn=0,ln=Date.now;if(K&&!Q){var dn=window.performance;dn&&"function"==typeof dn.now&&ln()>document.createEvent("Event").timeStamp&&(ln=function(){return dn.now()})}var un=function(e,t){if(e.post){if(!t.post)return 1}else if(t.post)return-1;return e.id-t.id};function hn(){var e,t;for(cn=ln(),rn=!0,tn.sort(un),sn=0;sn<tn.length;sn++)(e=tn[sn]).before&&e.before(),t=e.id,on[t]=null,e.run();var n=nn.slice(),o=tn.slice();sn=tn.length=nn.length=0,on={},an=rn=!1,function(e){for(var t=0;t<e.length;t++)e[t]._inactive=!0,Zt(e[t],!0)}(n),function(e){var t=e.length;for(;t--;){var n=e[t],o=n.vm;o&&o._watcher===n&&o._isMounted&&!o._isDestroyed&&en(o,"updated")}}(o),function(){for(var e=0;e<ye.length;e++){var t=ye[e];t.subs=t.subs.filter((function(e){return e})),t._pending=!1}ye.length=0}(),se&&$.devtools&&se.emit("flush")}function pn(e){var t=e.id;if(null==on[t]&&(e!==ve.target||!e.noRecurse)){if(on[t]=!0,rn){for(var n=tn.length-1;n>sn&&tn[n].id>e.id;)n--;tn.splice(n+1,0,e)}else tn.push(e);an||(an=!0,zt(hn))}}function mn(e,t){if(e){for(var n=Object.create(null),o=de?Reflect.ownKeys(e):Object.keys(e),i=0;i<o.length;i++){var a=o[i];if("__ob__"!==a){var r=e[a].from;if(r in t._provided)n[a]=t._provided[r];else if("default"in e[a]){var s=e[a].default;n[a]=l(s)?s.call(t):s}else 0}}return n}}function fn(e,t,n,a,r){var c,l=this,d=r.options;_(a,"_uid")?(c=Object.create(a))._original=a:(c=a,a=a._original);var u=s(d._compiled),h=!u;this.data=e,this.props=t,this.children=n,this.parent=a,this.listeners=e.on||o,this.injections=mn(d.inject,a),this.slots=function(){return l.$slots||ft(a,e.scopedSlots,l.$slots=ht(n,a)),l.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return ft(a,e.scopedSlots,this.slots())}}),u&&(this.$options=d,this.$slots=this.slots(),this.$scopedSlots=ft(a,e.scopedSlots,this.$slots)),d._scopeId?this._c=function(e,t,n,o){var r=St(c,e,t,n,o,h);return r&&!i(r)&&(r.fnScopeId=d._scopeId,r.fnContext=a),r}:this._c=function(e,t,n,o){return St(c,e,t,n,o,h)}}function wn(e,t,n,o,i){var a=we(e);return a.fnContext=n,a.fnOptions=o,t.slot&&((a.data||(a.data={})).slot=t.slot),a}function gn(e,t){for(var n in t)e[C(n)]=t[n]}function yn(e){return e.name||e.__name||e._componentTag}ut(fn.prototype);var vn={init:function(e,t){if(e.componentInstance&&!e.componentInstance._isDestroyed&&e.data.keepAlive){var n=e;vn.prepatch(n,n)}else{(e.componentInstance=function(e,t){var n={_isComponent:!0,_parentVnode:e,parent:t},o=e.data.inlineTemplate;r(o)&&(n.render=o.render,n.staticRenderFns=o.staticRenderFns);return new e.componentOptions.Ctor(n)}(e,Xt)).$mount(t?e.elm:void 0,t)}},prepatch:function(e,t){var n=t.componentOptions;!function(e,t,n,i,a){var r=i.data.scopedSlots,s=e.$scopedSlots,c=!!(r&&!r.$stable||s!==o&&!s.$stable||r&&e.$scopedSlots.$key!==r.$key||!r&&e.$scopedSlots.$key),l=!!(a||e.$options._renderChildren||c),d=e.$vnode;e.$options._parentVnode=i,e.$vnode=i,e._vnode&&(e._vnode.parent=i),e.$options._renderChildren=a;var u=i.data.attrs||o;e._attrsProxy&&vt(e._attrsProxy,u,d.data&&d.data.attrs||o,e,"$attrs")&&(l=!0),e.$attrs=u,n=n||o;var h=e.$options._parentListeners;if(e._listenersProxy&&vt(e._listenersProxy,n,h||o,e,"$listeners"),e.$listeners=e.$options._parentListeners=n,Kt(e,n,h),t&&e.$options.props){Ae(!1);for(var p=e._props,m=e.$options._propKeys||[],f=0;f<m.length;f++){var w=m[f],g=e.$options.props;p[w]=qn(w,g,t,e)}Ae(!0),e.$options.propsData=t}l&&(e.$slots=ht(a,i.context),e.$forceUpdate())}(t.componentInstance=e.componentInstance,n.propsData,n.listeners,t,n.children)},insert:function(e){var t,n=e.context,o=e.componentInstance;o._isMounted||(o._isMounted=!0,en(o,"mounted")),e.data.keepAlive&&(n._isMounted?((t=o)._inactive=!1,nn.push(t)):Zt(o,!0))},destroy:function(e){var t=e.componentInstance;t._isDestroyed||(e.data.keepAlive?function e(t,n){if(!(n&&(t._directInactive=!0,Jt(t))||t._inactive)){t._inactive=!0;for(var o=0;o<t.$children.length;o++)e(t.$children[o]);en(t,"deactivated")}}(t,!0):t.$destroy())}},bn=Object.keys(vn);function kn(e,t,n,c,l){if(!a(e)){var u=n.$options._base;if(d(e)&&(e=u.extend(e)),"function"==typeof e){var h;if(a(e.cid)&&void 0===(e=function(e,t){if(s(e.error)&&r(e.errorComp))return e.errorComp;if(r(e.resolved))return e.resolved;var n=xt;if(n&&r(e.owners)&&-1===e.owners.indexOf(n)&&e.owners.push(n),s(e.loading)&&r(e.loadingComp))return e.loadingComp;if(n&&!r(e.owners)){var o=e.owners=[n],i=!0,c=null,l=null;n.$on("hook:destroyed",(function(){return k(o,n)}));var u=function(e){for(var t=0,n=o.length;t<n;t++)o[t].$forceUpdate();e&&(o.length=0,null!==c&&(clearTimeout(c),c=null),null!==l&&(clearTimeout(l),l=null))},h=z((function(n){e.resolved=_t(n,t),i?o.length=0:u(!0)})),p=z((function(t){r(e.errorComp)&&(e.error=!0,u(!0))})),m=e(h,p);return d(m)&&(f(m)?a(e.resolved)&&m.then(h,p):f(m.component)&&(m.component.then(h,p),r(m.error)&&(e.errorComp=_t(m.error,t)),r(m.loading)&&(e.loadingComp=_t(m.loading,t),0===m.delay?e.loading=!0:c=setTimeout((function(){c=null,a(e.resolved)&&a(e.error)&&(e.loading=!0,u(!1))}),m.delay||200)),r(m.timeout)&&(l=setTimeout((function(){l=null,a(e.resolved)&&p(null)}),m.timeout)))),i=!1,e.loading?e.loadingComp:e.resolved}}(h=e,u)))return function(e,t,n,o,i){var a=me();return a.asyncFactory=e,a.asyncMeta={data:t,context:n,children:o,tag:i},a}(h,t,n,c,l);t=t||{},Bn(e),r(t.model)&&function(e,t){var n=e.model&&e.model.prop||"value",o=e.model&&e.model.event||"input";(t.attrs||(t.attrs={}))[n]=t.model.value;var a=t.on||(t.on={}),s=a[o],c=t.model.callback;r(s)?(i(s)?-1===s.indexOf(c):s!==c)&&(a[o]=[c].concat(s)):a[o]=c}(e.options,t);var p=function(e,t,n){var o=t.options.props;if(!a(o)){var i={},s=e.attrs,c=e.props;if(r(s)||r(c))for(var l in o){var d=E(l);Ye(i,c,l,d,!0)||Ye(i,s,l,d,!1)}return i}}(t,e);if(s(e.options.functional))return function(e,t,n,a,s){var c=e.options,l={},d=c.props;if(r(d))for(var u in d)l[u]=qn(u,d,t||o);else r(n.attrs)&&gn(l,n.attrs),r(n.props)&&gn(l,n.props);var h=new fn(n,l,s,a,e),p=c.render.call(null,h._c,h);if(p instanceof pe)return wn(p,n,h.parent,c,h);if(i(p)){for(var m=Ke(p)||[],f=new Array(m.length),w=0;w<m.length;w++)f[w]=wn(m[w],n,h.parent,c,h);return f}}(e,p,t,n,c);var m=t.on;if(t.on=t.nativeOn,s(e.options.abstract)){var w=t.slot;t={},w&&(t.slot=w)}!function(e){for(var t=e.hook||(e.hook={}),n=0;n<bn.length;n++){var o=bn[n],i=t[o],a=vn[o];i===a||i&&i._merged||(t[o]=i?xn(a,i):a)}}(t);var g=yn(e.options)||l;return new pe("vue-component-".concat(e.cid).concat(g?"-".concat(g):""),t,void 0,void 0,void 0,n,{Ctor:e,propsData:p,listeners:m,tag:l,children:c},h)}}}function xn(e,t){var n=function(n,o){e(n,o),t(n,o)};return n._merged=!0,n}var _n=O,Tn=$.optionMergeStrategies;function Sn(e,t,n){if(void 0===n&&(n=!0),!t)return e;for(var o,i,a,r=de?Reflect.ownKeys(t):Object.keys(t),s=0;s<r.length;s++)"__ob__"!==(o=r[s])&&(i=e[o],a=t[o],n&&_(e,o)?i!==a&&h(i)&&h(a)&&Sn(i,a):De(e,o,a));return e}function Cn(e,t,n){return n?function(){var o=l(t)?t.call(n,n):t,i=l(e)?e.call(n,n):e;return o?Sn(o,i):i}:t?e?function(){return Sn(l(t)?t.call(this,this):t,l(e)?e.call(this,this):e)}:t:e}function In(e,t){var n=t?e?e.concat(t):i(t)?t:[t]:e;return n?function(e){for(var t=[],n=0;n<e.length;n++)-1===t.indexOf(e[n])&&t.push(e[n]);return t}(n):n}function An(e,t,n,o){var i=Object.create(e||null);return t?q(i,t):i}Tn.data=function(e,t,n){return n?Cn(e,t,n):t&&"function"!=typeof t?e:Cn(e,t)},H.forEach((function(e){Tn[e]=In})),M.forEach((function(e){Tn[e+"s"]=An})),Tn.watch=function(e,t,n,o){if(e===oe&&(e=void 0),t===oe&&(t=void 0),!t)return Object.create(e||null);if(!e)return t;var a={};for(var r in q(a,e),t){var s=a[r],c=t[r];s&&!i(s)&&(s=[s]),a[r]=s?s.concat(c):i(c)?c:[c]}return a},Tn.props=Tn.methods=Tn.inject=Tn.computed=function(e,t,n,o){if(!e)return t;var i=Object.create(null);return q(i,e),t&&q(i,t),i},Tn.provide=function(e,t){return e?function(){var n=Object.create(null);return Sn(n,l(e)?e.call(this):e),t&&Sn(n,l(t)?t.call(this):t,!1),n}:t};var En=function(e,t){return void 0===t?e:t};function Pn(e,t,n){if(l(t)&&(t=t.options),function(e,t){var n=e.props;if(n){var o,a,r={};if(i(n))for(o=n.length;o--;)"string"==typeof(a=n[o])&&(r[C(a)]={type:null});else if(h(n))for(var s in n)a=n[s],r[C(s)]=h(a)?a:{type:a};else 0;e.props=r}}(t),function(e,t){var n=e.inject;if(n){var o=e.inject={};if(i(n))for(var a=0;a<n.length;a++)o[n[a]]={from:n[a]};else if(h(n))for(var r in n){var s=n[r];o[r]=h(s)?q({from:r},s):{from:s}}else 0}}(t),function(e){var t=e.directives;if(t)for(var n in t){var o=t[n];l(o)&&(t[n]={bind:o,update:o})}}(t),!t._base&&(t.extends&&(e=Pn(e,t.extends,n)),t.mixins))for(var o=0,a=t.mixins.length;o<a;o++)e=Pn(e,t.mixins[o],n);var r,s={};for(r in e)c(r);for(r in t)_(e,r)||c(r);function c(o){var i=Tn[o]||En;s[o]=i(e[o],t[o],n,o)}return s}function Wn(e,t,n,o){if("string"==typeof n){var i=e[t];if(_(i,n))return i[n];var a=C(n);if(_(i,a))return i[a];var r=I(a);return _(i,r)?i[r]:i[n]||i[a]||i[r]}}function qn(e,t,n,o){var i=t[e],a=!_(n,e),r=n[e],s=Nn(Boolean,i.type);if(s>-1)if(a&&!_(i,"default"))r=!1;else if(""===r||r===E(e)){var c=Nn(String,i.type);(c<0||s<c)&&(r=!0)}if(void 0===r){r=function(e,t,n){if(!_(t,"default"))return;var o=t.default;0;if(e&&e.$options.propsData&&void 0===e.$options.propsData[n]&&void 0!==e._props[n])return e._props[n];return l(o)&&"Function"!==On(t.type)?o.call(e):o}(o,i,e);var d=Ie;Ae(!0),We(r),Ae(d)}return r}var Dn=/^\s*function (\w+)/;function On(e){var t=e&&e.toString().match(Dn);return t?t[1]:""}function jn(e,t){return On(e)===On(t)}function Nn(e,t){if(!i(t))return jn(t,e)?0:-1;for(var n=0,o=t.length;n<o;n++)if(jn(t[n],e))return n;return-1}var Rn={enumerable:!0,configurable:!0,get:O,set:O};function Ln(e,t,n){Rn.get=function(){return this[t][n]},Rn.set=function(e){this[t][n]=e},Object.defineProperty(e,n,Rn)}function zn(e){var t=e.$options;if(t.props&&function(e,t){var n=e.$options.propsData||{},o=e._props=Ne({}),i=e.$options._propKeys=[];e.$parent&&Ae(!1);var a=function(a){i.push(a);var r=qn(a,t,n,e);qe(o,a,r,void 0,!0),a in e||Ln(e,"_props",a)};for(var r in t)a(r);Ae(!0)}(e,t.props),function(e){var t=e.$options,n=t.setup;if(n){var o=e._setupContext=yt(e);he(e),ke();var i=It(n,null,[e._props||Ne({}),o],e,"setup");if(xe(),he(),l(i))t.render=i;else if(d(i))if(e._setupState=i,i.__sfc){var a=e._setupProxy={};for(var r in i)"__sfc"!==r&&Fe(a,i,r)}else for(var r in i)G(r)||Fe(e,i,r);else 0}}(e),t.methods&&function(e,t){e.$options.props;for(var n in t)e[n]="function"!=typeof t[n]?O:P(t[n],e)}(e,t.methods),t.data)!function(e){var t=e.$options.data;h(t=e._data=l(t)?function(e,t){ke();try{return e.call(t,t)}catch(e){return Ct(e,t,"data()"),{}}finally{xe()}}(t,e):t||{})||(t={});var n=Object.keys(t),o=e.$options.props,i=(e.$options.methods,n.length);for(;i--;){var a=n[i];0,o&&_(o,a)||G(a)||Ln(e,"_data",a)}var r=We(t);r&&r.vmCount++}(e);else{var n=We(e._data={});n&&n.vmCount++}t.computed&&function(e,t){var n=e._computedWatchers=Object.create(null),o=re();for(var i in t){var a=t[i],r=l(a)?a:a.get;0,o||(n[i]=new Gt(e,r||O,O,Fn)),i in e||Mn(e,i,a)}}(e,t.computed),t.watch&&t.watch!==oe&&function(e,t){for(var n in t){var o=t[n];if(i(o))for(var a=0;a<o.length;a++)Un(e,n,o[a]);else Un(e,n,o)}}(e,t.watch)}var Fn={lazy:!0};function Mn(e,t,n){var o=!re();l(n)?(Rn.get=o?Hn(t):$n(n),Rn.set=O):(Rn.get=n.get?o&&!1!==n.cache?Hn(t):$n(n.get):O,Rn.set=n.set||O),Object.defineProperty(e,t,Rn)}function Hn(e){return function(){var t=this._computedWatchers&&this._computedWatchers[e];if(t)return t.dirty&&t.evaluate(),ve.target&&t.depend(),t.value}}function $n(e){return function(){return e.call(this,this)}}function Un(e,t,n,o){return h(n)&&(o=n,n=n.handler),"string"==typeof n&&(n=e[n]),e.$watch(t,n,o)}var Gn=0;function Bn(e){var t=e.options;if(e.super){var n=Bn(e.super);if(n!==e.superOptions){e.superOptions=n;var o=function(e){var t,n=e.options,o=e.sealedOptions;for(var i in n)n[i]!==o[i]&&(t||(t={}),t[i]=n[i]);return t}(e);o&&q(e.extendOptions,o),(t=e.options=Pn(n,e.extendOptions)).name&&(t.components[t.name]=e)}}return t}function Vn(e){this._init(e)}function Yn(e){e.cid=0;var t=1;e.extend=function(e){e=e||{};var n=this,o=n.cid,i=e._Ctor||(e._Ctor={});if(i[o])return i[o];var a=yn(e)||yn(n.options);var r=function(e){this._init(e)};return(r.prototype=Object.create(n.prototype)).constructor=r,r.cid=t++,r.options=Pn(n.options,e),r.super=n,r.options.props&&function(e){var t=e.options.props;for(var n in t)Ln(e.prototype,"_props",n)}(r),r.options.computed&&function(e){var t=e.options.computed;for(var n in t)Mn(e.prototype,n,t[n])}(r),r.extend=n.extend,r.mixin=n.mixin,r.use=n.use,M.forEach((function(e){r[e]=n[e]})),a&&(r.options.components[a]=r),r.superOptions=n.options,r.extendOptions=e,r.sealedOptions=q({},r.options),i[o]=r,r}}function Kn(e){return e&&(yn(e.Ctor.options)||e.tag)}function Xn(e,t){return i(e)?e.indexOf(t)>-1:"string"==typeof e?e.split(",").indexOf(t)>-1:!!p(e)&&e.test(t)}function Qn(e,t){var n=e.cache,o=e.keys,i=e._vnode,a=e.$vnode;for(var r in n){var s=n[r];if(s){var c=s.name;c&&!t(c)&&Jn(n,r,o,i)}}a.componentOptions.children=void 0}function Jn(e,t,n,o){var i=e[t];!i||o&&i.tag===o.tag||i.componentInstance.$destroy(),e[t]=null,k(n,t)}Vn.prototype._init=function(e){var t=this;t._uid=Gn++,t._isVue=!0,t.__v_skip=!0,t._scope=new He(!0),t._scope.parent=void 0,t._scope._vm=!0,e&&e._isComponent?function(e,t){var n=e.$options=Object.create(e.constructor.options),o=t._parentVnode;n.parent=t.parent,n._parentVnode=o;var i=o.componentOptions;n.propsData=i.propsData,n._parentListeners=i.listeners,n._renderChildren=i.children,n._componentTag=i.tag,t.render&&(n.render=t.render,n.staticRenderFns=t.staticRenderFns)}(t,e):t.$options=Pn(Bn(t.constructor),e||{},t),t._renderProxy=t,t._self=t,function(e){var t=e.$options,n=t.parent;if(n&&!t.abstract){for(;n.$options.abstract&&n.$parent;)n=n.$parent;n.$children.push(e)}e.$parent=n,e.$root=n?n.$root:e,e.$children=[],e.$refs={},e._provided=n?n._provided:Object.create(null),e._watcher=null,e._inactive=null,e._directInactive=!1,e._isMounted=!1,e._isDestroyed=!1,e._isBeingDestroyed=!1}(t),function(e){e._events=Object.create(null),e._hasHookEvent=!1;var t=e.$options._parentListeners;t&&Kt(e,t)}(t),function(e){e._vnode=null,e._staticTrees=null;var t=e.$options,n=e.$vnode=t._parentVnode,i=n&&n.context;e.$slots=ht(t._renderChildren,i),e.$scopedSlots=n?ft(e.$parent,n.data.scopedSlots,e.$slots):o,e._c=function(t,n,o,i){return St(e,t,n,o,i,!1)},e.$createElement=function(t,n,o,i){return St(e,t,n,o,i,!0)};var a=n&&n.data;qe(e,"$attrs",a&&a.attrs||o,null,!0),qe(e,"$listeners",t._parentListeners||o,null,!0)}(t),en(t,"beforeCreate",void 0,!1),function(e){var t=mn(e.$options.inject,e);t&&(Ae(!1),Object.keys(t).forEach((function(n){qe(e,n,t[n])})),Ae(!0))}(t),zn(t),function(e){var t=e.$options.provide;if(t){var n=l(t)?t.call(e):t;if(!d(n))return;for(var o=$e(e),i=de?Reflect.ownKeys(n):Object.keys(n),a=0;a<i.length;a++){var r=i[a];Object.defineProperty(o,r,Object.getOwnPropertyDescriptor(n,r))}}}(t),en(t,"created"),t.$options.el&&t.$mount(t.$options.el)},function(e){var t={get:function(){return this._data}},n={get:function(){return this._props}};Object.defineProperty(e.prototype,"$data",t),Object.defineProperty(e.prototype,"$props",n),e.prototype.$set=De,e.prototype.$delete=Oe,e.prototype.$watch=function(e,t,n){if(h(t))return Un(this,e,t,n);(n=n||{}).user=!0;var o=new Gt(this,e,t,n);if(n.immediate){var i='callback for immediate watcher "'.concat(o.expression,'"');ke(),It(t,this,[o.value],this,i),xe()}return function(){o.teardown()}}}(Vn),function(e){var t=/^hook:/;e.prototype.$on=function(e,n){var o=this;if(i(e))for(var a=0,r=e.length;a<r;a++)o.$on(e[a],n);else(o._events[e]||(o._events[e]=[])).push(n),t.test(e)&&(o._hasHookEvent=!0);return o},e.prototype.$once=function(e,t){var n=this;function o(){n.$off(e,o),t.apply(n,arguments)}return o.fn=t,n.$on(e,o),n},e.prototype.$off=function(e,t){var n=this;if(!arguments.length)return n._events=Object.create(null),n;if(i(e)){for(var o=0,a=e.length;o<a;o++)n.$off(e[o],t);return n}var r,s=n._events[e];if(!s)return n;if(!t)return n._events[e]=null,n;for(var c=s.length;c--;)if((r=s[c])===t||r.fn===t){s.splice(c,1);break}return n},e.prototype.$emit=function(e){var t=this,n=t._events[e];if(n){n=n.length>1?W(n):n;for(var o=W(arguments,1),i='event handler for "'.concat(e,'"'),a=0,r=n.length;a<r;a++)It(n[a],t,o,t,i)}return t}}(Vn),function(e){e.prototype._update=function(e,t){var n=this,o=n.$el,i=n._vnode,a=Qt(n);n._vnode=e,n.$el=i?n.__patch__(i,e):n.__patch__(n.$el,e,t,!1),a(),o&&(o.__vue__=null),n.$el&&(n.$el.__vue__=n);for(var r=n;r&&r.$vnode&&r.$parent&&r.$vnode===r.$parent._vnode;)r.$parent.$el=r.$el,r=r.$parent},e.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},e.prototype.$destroy=function(){var e=this;if(!e._isBeingDestroyed){en(e,"beforeDestroy"),e._isBeingDestroyed=!0;var t=e.$parent;!t||t._isBeingDestroyed||e.$options.abstract||k(t.$children,e),e._scope.stop(),e._data.__ob__&&e._data.__ob__.vmCount--,e._isDestroyed=!0,e.__patch__(e._vnode,null),en(e,"destroyed"),e.$off(),e.$el&&(e.$el.__vue__=null),e.$vnode&&(e.$vnode.parent=null)}}}(Vn),function(e){ut(e.prototype),e.prototype.$nextTick=function(e){return zt(e,this)},e.prototype._render=function(){var e=this,t=e.$options,n=t.render,o=t._parentVnode;o&&e._isMounted&&(e.$scopedSlots=ft(e.$parent,o.data.scopedSlots,e.$slots,e.$scopedSlots),e._slotsProxy&&kt(e._slotsProxy,e.$scopedSlots)),e.$vnode=o;var a,r=ue,s=xt;try{he(e),xt=e,a=n.call(e._renderProxy,e.$createElement)}catch(t){Ct(t,e,"render"),a=e._vnode}finally{xt=s,he(r)}return i(a)&&1===a.length&&(a=a[0]),a instanceof pe||(a=me()),a.parent=o,a}}(Vn);var Zn=[String,RegExp,Array],eo={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:Zn,exclude:Zn,max:[String,Number]},methods:{cacheVNode:function(){var e=this.cache,t=this.keys,n=this.vnodeToCache,o=this.keyToCache;if(n){var i=n.tag,a=n.componentInstance,r=n.componentOptions;e[o]={name:Kn(r),tag:i,componentInstance:a},t.push(o),this.max&&t.length>parseInt(this.max)&&Jn(e,t[0],t,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var e in this.cache)Jn(this.cache,e,this.keys)},mounted:function(){var e=this;this.cacheVNode(),this.$watch("include",(function(t){Qn(e,(function(e){return Xn(t,e)}))})),this.$watch("exclude",(function(t){Qn(e,(function(e){return!Xn(t,e)}))}))},updated:function(){this.cacheVNode()},render:function(){var e=this.$slots.default,t=Tt(e),n=t&&t.componentOptions;if(n){var o=Kn(n),i=this.include,a=this.exclude;if(i&&(!o||!Xn(i,o))||a&&o&&Xn(a,o))return t;var r=this.cache,s=this.keys,c=null==t.key?n.Ctor.cid+(n.tag?"::".concat(n.tag):""):t.key;r[c]?(t.componentInstance=r[c].componentInstance,k(s,c),s.push(c)):(this.vnodeToCache=t,this.keyToCache=c),t.data.keepAlive=!0}return t||e&&e[0]}}};!function(e){var t={get:function(){return $}};Object.defineProperty(e,"config",t),e.util={warn:_n,extend:q,mergeOptions:Pn,defineReactive:qe},e.set=De,e.delete=Oe,e.nextTick=zt,e.observable=function(e){return We(e),e},e.options=Object.create(null),M.forEach((function(t){e.options[t+"s"]=Object.create(null)})),e.options._base=e,q(e.options.components,eo),function(e){e.use=function(e){var t=this._installedPlugins||(this._installedPlugins=[]);if(t.indexOf(e)>-1)return this;var n=W(arguments,1);return n.unshift(this),l(e.install)?e.install.apply(e,n):l(e)&&e.apply(null,n),t.push(e),this}}(e),function(e){e.mixin=function(e){return this.options=Pn(this.options,e),this}}(e),Yn(e),function(e){M.forEach((function(t){e[t]=function(e,n){return n?("component"===t&&h(n)&&(n.name=n.name||e,n=this.options._base.extend(n)),"directive"===t&&l(n)&&(n={bind:n,update:n}),this.options[t+"s"][e]=n,n):this.options[t+"s"][e]}}))}(e)}(Vn),Object.defineProperty(Vn.prototype,"$isServer",{get:re}),Object.defineProperty(Vn.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Vn,"FunctionalRenderContext",{value:fn}),Vn.version="2.7.16";var to=v("style,class"),no=v("input,textarea,option,select,progress"),oo=v("contenteditable,draggable,spellcheck"),io=v("events,caret,typing,plaintext-only"),ao=v("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),ro="http://www.w3.org/1999/xlink",so=function(e){return":"===e.charAt(5)&&"xlink"===e.slice(0,5)},co=function(e){return so(e)?e.slice(6,e.length):""},lo=function(e){return null==e||!1===e};function uo(e){for(var t=e.data,n=e,o=e;r(o.componentInstance);)(o=o.componentInstance._vnode)&&o.data&&(t=ho(o.data,t));for(;r(n=n.parent);)n&&n.data&&(t=ho(t,n.data));return function(e,t){if(r(e)||r(t))return po(e,mo(t));return""}(t.staticClass,t.class)}function ho(e,t){return{staticClass:po(e.staticClass,t.staticClass),class:r(e.class)?[e.class,t.class]:t.class}}function po(e,t){return e?t?e+" "+t:e:t||""}function mo(e){return Array.isArray(e)?function(e){for(var t,n="",o=0,i=e.length;o<i;o++)r(t=mo(e[o]))&&""!==t&&(n&&(n+=" "),n+=t);return n}(e):d(e)?function(e){var t="";for(var n in e)e[n]&&(t&&(t+=" "),t+=n);return t}(e):"string"==typeof e?e:""}var fo={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},wo=v("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),go=v("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),yo=function(e){return wo(e)||go(e)};var vo=Object.create(null);var bo=v("text,number,password,search,email,tel,url");var ko=Object.freeze({__proto__:null,createElement:function(e,t){var n=document.createElement(e);return"select"!==e||t.data&&t.data.attrs&&void 0!==t.data.attrs.multiple&&n.setAttribute("multiple","multiple"),n},createElementNS:function(e,t){return document.createElementNS(fo[e],t)},createTextNode:function(e){return document.createTextNode(e)},createComment:function(e){return document.createComment(e)},insertBefore:function(e,t,n){e.insertBefore(t,n)},removeChild:function(e,t){e.removeChild(t)},appendChild:function(e,t){e.appendChild(t)},parentNode:function(e){return e.parentNode},nextSibling:function(e){return e.nextSibling},tagName:function(e){return e.tagName},setTextContent:function(e,t){e.textContent=t},setStyleScope:function(e,t){e.setAttribute(t,"")}}),xo={create:function(e,t){_o(t)},update:function(e,t){e.data.ref!==t.data.ref&&(_o(e,!0),_o(t))},destroy:function(e){_o(e,!0)}};function _o(e,t){var n=e.data.ref;if(r(n)){var o=e.context,a=e.componentInstance||e.elm,s=t?null:a,c=t?void 0:a;if(l(n))It(n,o,[s],o,"template ref function");else{var d=e.data.refInFor,u="string"==typeof n||"number"==typeof n,h=ze(n),p=o.$refs;if(u||h)if(d){var m=u?p[n]:n.value;t?i(m)&&k(m,a):i(m)?m.includes(a)||m.push(a):u?(p[n]=[a],To(o,n,p[n])):n.value=[a]}else if(u){if(t&&p[n]!==a)return;p[n]=c,To(o,n,s)}else if(h){if(t&&n.value!==a)return;n.value=s}else 0}}}function To(e,t,n){var o=e._setupState;o&&_(o,t)&&(ze(o[t])?o[t].value=n:o[t]=n)}var So=new pe("",{},[]),Co=["create","activate","update","remove","destroy"];function Io(e,t){return e.key===t.key&&e.asyncFactory===t.asyncFactory&&(e.tag===t.tag&&e.isComment===t.isComment&&r(e.data)===r(t.data)&&function(e,t){if("input"!==e.tag)return!0;var n,o=r(n=e.data)&&r(n=n.attrs)&&n.type,i=r(n=t.data)&&r(n=n.attrs)&&n.type;return o===i||bo(o)&&bo(i)}(e,t)||s(e.isAsyncPlaceholder)&&a(t.asyncFactory.error))}function Ao(e,t,n){var o,i,a={};for(o=t;o<=n;++o)r(i=e[o].key)&&(a[i]=o);return a}var Eo={create:Po,update:Po,destroy:function(e){Po(e,So)}};function Po(e,t){(e.data.directives||t.data.directives)&&function(e,t){var n,o,i,a=e===So,r=t===So,s=qo(e.data.directives,e.context),c=qo(t.data.directives,t.context),l=[],d=[];for(n in c)o=s[n],i=c[n],o?(i.oldValue=o.value,i.oldArg=o.arg,Oo(i,"update",t,e),i.def&&i.def.componentUpdated&&d.push(i)):(Oo(i,"bind",t,e),i.def&&i.def.inserted&&l.push(i));if(l.length){var u=function(){for(var n=0;n<l.length;n++)Oo(l[n],"inserted",t,e)};a?Ve(t,"insert",u):u()}d.length&&Ve(t,"postpatch",(function(){for(var n=0;n<d.length;n++)Oo(d[n],"componentUpdated",t,e)}));if(!a)for(n in s)c[n]||Oo(s[n],"unbind",e,e,r)}(e,t)}var Wo=Object.create(null);function qo(e,t){var n,o,i=Object.create(null);if(!e)return i;for(n=0;n<e.length;n++){if((o=e[n]).modifiers||(o.modifiers=Wo),i[Do(o)]=o,t._setupState&&t._setupState.__sfc){var a=o.def||Wn(t,"_setupState","v-"+o.name);o.def="function"==typeof a?{bind:a,update:a}:a}o.def=o.def||Wn(t.$options,"directives",o.name)}return i}function Do(e){return e.rawName||"".concat(e.name,".").concat(Object.keys(e.modifiers||{}).join("."))}function Oo(e,t,n,o,i){var a=e.def&&e.def[t];if(a)try{a(n.elm,e,n,o,i)}catch(o){Ct(o,n.context,"directive ".concat(e.name," ").concat(t," hook"))}}var jo=[xo,Eo];function No(e,t){var n=t.componentOptions;if(!(r(n)&&!1===n.Ctor.options.inheritAttrs||a(e.data.attrs)&&a(t.data.attrs))){var o,i,c=t.elm,l=e.data.attrs||{},d=t.data.attrs||{};for(o in(r(d.__ob__)||s(d._v_attr_proxy))&&(d=t.data.attrs=q({},d)),d)i=d[o],l[o]!==i&&Ro(c,o,i,t.data.pre);for(o in(Q||Z)&&d.value!==l.value&&Ro(c,"value",d.value),l)a(d[o])&&(so(o)?c.removeAttributeNS(ro,co(o)):oo(o)||c.removeAttribute(o))}}function Ro(e,t,n,o){o||e.tagName.indexOf("-")>-1?Lo(e,t,n):ao(t)?lo(n)?e.removeAttribute(t):(n="allowfullscreen"===t&&"EMBED"===e.tagName?"true":t,e.setAttribute(t,n)):oo(t)?e.setAttribute(t,function(e,t){return lo(t)||"false"===t?"false":"contenteditable"===e&&io(t)?t:"true"}(t,n)):so(t)?lo(n)?e.removeAttributeNS(ro,co(t)):e.setAttributeNS(ro,t,n):Lo(e,t,n)}function Lo(e,t,n){if(lo(n))e.removeAttribute(t);else{if(Q&&!J&&"TEXTAREA"===e.tagName&&"placeholder"===t&&""!==n&&!e.__ieph){var o=function(t){t.stopImmediatePropagation(),e.removeEventListener("input",o)};e.addEventListener("input",o),e.__ieph=!0}e.setAttribute(t,n)}}var zo={create:No,update:No};function Fo(e,t){var n=t.elm,o=t.data,i=e.data;if(!(a(o.staticClass)&&a(o.class)&&(a(i)||a(i.staticClass)&&a(i.class)))){var s=uo(t),c=n._transitionClasses;r(c)&&(s=po(s,mo(c))),s!==n._prevClass&&(n.setAttribute("class",s),n._prevClass=s)}}var Mo,Ho={create:Fo,update:Fo};function $o(e,t,n){var o=Mo;return function i(){var a=t.apply(null,arguments);null!==a&&Bo(e,i,n,o)}}var Uo=Wt&&!(ne&&Number(ne[1])<=53);function Go(e,t,n,o){if(Uo){var i=cn,a=t;t=a._wrapper=function(e){if(e.target===e.currentTarget||e.timeStamp>=i||e.timeStamp<=0||e.target.ownerDocument!==document)return a.apply(this,arguments)}}Mo.addEventListener(e,t,ie?{capture:n,passive:o}:n)}function Bo(e,t,n,o){(o||Mo).removeEventListener(e,t._wrapper||t,n)}function Vo(e,t){if(!a(e.data.on)||!a(t.data.on)){var n=t.data.on||{},o=e.data.on||{};Mo=t.elm||e.elm,function(e){if(r(e.__r)){var t=Q?"change":"input";e[t]=[].concat(e.__r,e[t]||[]),delete e.__r}r(e.__c)&&(e.change=[].concat(e.__c,e.change||[]),delete e.__c)}(n),Be(n,o,Go,Bo,$o,t.context),Mo=void 0}}var Yo,Ko={create:Vo,update:Vo,destroy:function(e){return Vo(e,So)}};function Xo(e,t){if(!a(e.data.domProps)||!a(t.data.domProps)){var n,o,i=t.elm,c=e.data.domProps||{},l=t.data.domProps||{};for(n in(r(l.__ob__)||s(l._v_attr_proxy))&&(l=t.data.domProps=q({},l)),c)n in l||(i[n]="");for(n in l){if(o=l[n],"textContent"===n||"innerHTML"===n){if(t.children&&(t.children.length=0),o===c[n])continue;1===i.childNodes.length&&i.removeChild(i.childNodes[0])}if("value"===n&&"PROGRESS"!==i.tagName){i._value=o;var d=a(o)?"":String(o);Qo(i,d)&&(i.value=d)}else if("innerHTML"===n&&go(i.tagName)&&a(i.innerHTML)){(Yo=Yo||document.createElement("div")).innerHTML="<svg>".concat(o,"</svg>");for(var u=Yo.firstChild;i.firstChild;)i.removeChild(i.firstChild);for(;u.firstChild;)i.appendChild(u.firstChild)}else if(o!==c[n])try{i[n]=o}catch(e){}}}}function Qo(e,t){return!e.composing&&("OPTION"===e.tagName||function(e,t){var n=!0;try{n=document.activeElement!==e}catch(e){}return n&&e.value!==t}(e,t)||function(e,t){var n=e.value,o=e._vModifiers;if(r(o)){if(o.number)return y(n)!==y(t);if(o.trim)return n.trim()!==t.trim()}return n!==t}(e,t))}var Jo={create:Xo,update:Xo},Zo=T((function(e){var t={},n=/:(.+)/;return e.split(/;(?![^(]*\))/g).forEach((function(e){if(e){var o=e.split(n);o.length>1&&(t[o[0].trim()]=o[1].trim())}})),t}));function ei(e){var t=ti(e.style);return e.staticStyle?q(e.staticStyle,t):t}function ti(e){return Array.isArray(e)?D(e):"string"==typeof e?Zo(e):e}var ni,oi=/^--/,ii=/\s*!important$/,ai=function(e,t,n){if(oi.test(t))e.style.setProperty(t,n);else if(ii.test(n))e.style.setProperty(E(t),n.replace(ii,""),"important");else{var o=si(t);if(Array.isArray(n))for(var i=0,a=n.length;i<a;i++)e.style[o]=n[i];else e.style[o]=n}},ri=["Webkit","Moz","ms"],si=T((function(e){if(ni=ni||document.createElement("div").style,"filter"!==(e=C(e))&&e in ni)return e;for(var t=e.charAt(0).toUpperCase()+e.slice(1),n=0;n<ri.length;n++){var o=ri[n]+t;if(o in ni)return o}}));function ci(e,t){var n=t.data,o=e.data;if(!(a(n.staticStyle)&&a(n.style)&&a(o.staticStyle)&&a(o.style))){var i,s,c=t.elm,l=o.staticStyle,d=o.normalizedStyle||o.style||{},u=l||d,h=ti(t.data.style)||{};t.data.normalizedStyle=r(h.__ob__)?q({},h):h;var p=function(e,t){var n,o={};if(t)for(var i=e;i.componentInstance;)(i=i.componentInstance._vnode)&&i.data&&(n=ei(i.data))&&q(o,n);(n=ei(e.data))&&q(o,n);for(var a=e;a=a.parent;)a.data&&(n=ei(a.data))&&q(o,n);return o}(t,!0);for(s in u)a(p[s])&&ai(c,s,"");for(s in p)i=p[s],ai(c,s,null==i?"":i)}}var li={create:ci,update:ci},di=/\s+/;function ui(e,t){if(t&&(t=t.trim()))if(e.classList)t.indexOf(" ")>-1?t.split(di).forEach((function(t){return e.classList.add(t)})):e.classList.add(t);else{var n=" ".concat(e.getAttribute("class")||""," ");n.indexOf(" "+t+" ")<0&&e.setAttribute("class",(n+t).trim())}}function hi(e,t){if(t&&(t=t.trim()))if(e.classList)t.indexOf(" ")>-1?t.split(di).forEach((function(t){return e.classList.remove(t)})):e.classList.remove(t),e.classList.length||e.removeAttribute("class");else{for(var n=" ".concat(e.getAttribute("class")||""," "),o=" "+t+" ";n.indexOf(o)>=0;)n=n.replace(o," ");(n=n.trim())?e.setAttribute("class",n):e.removeAttribute("class")}}function pi(e){if(e){if("object"==typeof e){var t={};return!1!==e.css&&q(t,mi(e.name||"v")),q(t,e),t}return"string"==typeof e?mi(e):void 0}}var mi=T((function(e){return{enterClass:"".concat(e,"-enter"),enterToClass:"".concat(e,"-enter-to"),enterActiveClass:"".concat(e,"-enter-active"),leaveClass:"".concat(e,"-leave"),leaveToClass:"".concat(e,"-leave-to"),leaveActiveClass:"".concat(e,"-leave-active")}})),fi=K&&!J,wi="transition",gi="transitionend",yi="animation",vi="animationend";fi&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(wi="WebkitTransition",gi="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(yi="WebkitAnimation",vi="webkitAnimationEnd"));var bi=K?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(e){return e()};function ki(e){bi((function(){bi(e)}))}function xi(e,t){var n=e._transitionClasses||(e._transitionClasses=[]);n.indexOf(t)<0&&(n.push(t),ui(e,t))}function _i(e,t){e._transitionClasses&&k(e._transitionClasses,t),hi(e,t)}function Ti(e,t,n){var o=Ci(e,t),i=o.type,a=o.timeout,r=o.propCount;if(!i)return n();var s="transition"===i?gi:vi,c=0,l=function(){e.removeEventListener(s,d),n()},d=function(t){t.target===e&&++c>=r&&l()};setTimeout((function(){c<r&&l()}),a+1),e.addEventListener(s,d)}var Si=/\b(transform|all)(,|$)/;function Ci(e,t){var n,o=window.getComputedStyle(e),i=(o[wi+"Delay"]||"").split(", "),a=(o[wi+"Duration"]||"").split(", "),r=Ii(i,a),s=(o[yi+"Delay"]||"").split(", "),c=(o[yi+"Duration"]||"").split(", "),l=Ii(s,c),d=0,u=0;return"transition"===t?r>0&&(n="transition",d=r,u=a.length):"animation"===t?l>0&&(n="animation",d=l,u=c.length):u=(n=(d=Math.max(r,l))>0?r>l?"transition":"animation":null)?"transition"===n?a.length:c.length:0,{type:n,timeout:d,propCount:u,hasTransform:"transition"===n&&Si.test(o[wi+"Property"])}}function Ii(e,t){for(;e.length<t.length;)e=e.concat(e);return Math.max.apply(null,t.map((function(t,n){return Ai(t)+Ai(e[n])})))}function Ai(e){return 1e3*Number(e.slice(0,-1).replace(",","."))}function Ei(e,t){var n=e.elm;r(n._leaveCb)&&(n._leaveCb.cancelled=!0,n._leaveCb());var o=pi(e.data.transition);if(!a(o)&&!r(n._enterCb)&&1===n.nodeType){for(var i=o.css,s=o.type,c=o.enterClass,u=o.enterToClass,h=o.enterActiveClass,p=o.appearClass,m=o.appearToClass,f=o.appearActiveClass,w=o.beforeEnter,g=o.enter,v=o.afterEnter,b=o.enterCancelled,k=o.beforeAppear,x=o.appear,_=o.afterAppear,T=o.appearCancelled,S=o.duration,C=Xt,I=Xt.$vnode;I&&I.parent;)C=I.context,I=I.parent;var A=!C._isMounted||!e.isRootInsert;if(!A||x||""===x){var E=A&&p?p:c,P=A&&f?f:h,W=A&&m?m:u,q=A&&k||w,D=A&&l(x)?x:g,O=A&&_||v,j=A&&T||b,N=y(d(S)?S.enter:S);0;var R=!1!==i&&!J,L=qi(D),F=n._enterCb=z((function(){R&&(_i(n,W),_i(n,P)),F.cancelled?(R&&_i(n,E),j&&j(n)):O&&O(n),n._enterCb=null}));e.data.show||Ve(e,"insert",(function(){var t=n.parentNode,o=t&&t._pending&&t._pending[e.key];o&&o.tag===e.tag&&o.elm._leaveCb&&o.elm._leaveCb(),D&&D(n,F)})),q&&q(n),R&&(xi(n,E),xi(n,P),ki((function(){_i(n,E),F.cancelled||(xi(n,W),L||(Wi(N)?setTimeout(F,N):Ti(n,s,F)))}))),e.data.show&&(t&&t(),D&&D(n,F)),R||L||F()}}}function Pi(e,t){var n=e.elm;r(n._enterCb)&&(n._enterCb.cancelled=!0,n._enterCb());var o=pi(e.data.transition);if(a(o)||1!==n.nodeType)return t();if(!r(n._leaveCb)){var i=o.css,s=o.type,c=o.leaveClass,l=o.leaveToClass,u=o.leaveActiveClass,h=o.beforeLeave,p=o.leave,m=o.afterLeave,f=o.leaveCancelled,w=o.delayLeave,g=o.duration,v=!1!==i&&!J,b=qi(p),k=y(d(g)?g.leave:g);0;var x=n._leaveCb=z((function(){n.parentNode&&n.parentNode._pending&&(n.parentNode._pending[e.key]=null),v&&(_i(n,l),_i(n,u)),x.cancelled?(v&&_i(n,c),f&&f(n)):(t(),m&&m(n)),n._leaveCb=null}));w?w(_):_()}function _(){x.cancelled||(!e.data.show&&n.parentNode&&((n.parentNode._pending||(n.parentNode._pending={}))[e.key]=e),h&&h(n),v&&(xi(n,c),xi(n,u),ki((function(){_i(n,c),x.cancelled||(xi(n,l),b||(Wi(k)?setTimeout(x,k):Ti(n,s,x)))}))),p&&p(n,x),v||b||x())}}function Wi(e){return"number"==typeof e&&!isNaN(e)}function qi(e){if(a(e))return!1;var t=e.fns;return r(t)?qi(Array.isArray(t)?t[0]:t):(e._length||e.length)>1}function Di(e,t){!0!==t.data.show&&Ei(t)}var Oi=function(e){var t,n,o={},l=e.modules,d=e.nodeOps;for(t=0;t<Co.length;++t)for(o[Co[t]]=[],n=0;n<l.length;++n)r(l[n][Co[t]])&&o[Co[t]].push(l[n][Co[t]]);function u(e){var t=d.parentNode(e);r(t)&&d.removeChild(t,e)}function h(e,t,n,i,a,c,l){if(r(e.elm)&&r(c)&&(e=c[l]=we(e)),e.isRootInsert=!a,!function(e,t,n,i){var a=e.data;if(r(a)){var c=r(e.componentInstance)&&a.keepAlive;if(r(a=a.hook)&&r(a=a.init)&&a(e,!1),r(e.componentInstance))return p(e,t),m(n,e.elm,i),s(c)&&function(e,t,n,i){var a,s=e;for(;s.componentInstance;)if(s=s.componentInstance._vnode,r(a=s.data)&&r(a=a.transition)){for(a=0;a<o.activate.length;++a)o.activate[a](So,s);t.push(s);break}m(n,e.elm,i)}(e,t,n,i),!0}}(e,t,n,i)){var u=e.data,h=e.children,w=e.tag;r(w)?(e.elm=e.ns?d.createElementNS(e.ns,w):d.createElement(w,e),y(e),f(e,h,t),r(u)&&g(e,t),m(n,e.elm,i)):s(e.isComment)?(e.elm=d.createComment(e.text),m(n,e.elm,i)):(e.elm=d.createTextNode(e.text),m(n,e.elm,i))}}function p(e,t){r(e.data.pendingInsert)&&(t.push.apply(t,e.data.pendingInsert),e.data.pendingInsert=null),e.elm=e.componentInstance.$el,w(e)?(g(e,t),y(e)):(_o(e),t.push(e))}function m(e,t,n){r(e)&&(r(n)?d.parentNode(n)===e&&d.insertBefore(e,t,n):d.appendChild(e,t))}function f(e,t,n){if(i(t)){0;for(var o=0;o<t.length;++o)h(t[o],n,e.elm,null,!0,t,o)}else c(e.text)&&d.appendChild(e.elm,d.createTextNode(String(e.text)))}function w(e){for(;e.componentInstance;)e=e.componentInstance._vnode;return r(e.tag)}function g(e,n){for(var i=0;i<o.create.length;++i)o.create[i](So,e);r(t=e.data.hook)&&(r(t.create)&&t.create(So,e),r(t.insert)&&n.push(e))}function y(e){var t;if(r(t=e.fnScopeId))d.setStyleScope(e.elm,t);else for(var n=e;n;)r(t=n.context)&&r(t=t.$options._scopeId)&&d.setStyleScope(e.elm,t),n=n.parent;r(t=Xt)&&t!==e.context&&t!==e.fnContext&&r(t=t.$options._scopeId)&&d.setStyleScope(e.elm,t)}function b(e,t,n,o,i,a){for(;o<=i;++o)h(n[o],a,e,t,!1,n,o)}function k(e){var t,n,i=e.data;if(r(i))for(r(t=i.hook)&&r(t=t.destroy)&&t(e),t=0;t<o.destroy.length;++t)o.destroy[t](e);if(r(t=e.children))for(n=0;n<e.children.length;++n)k(e.children[n])}function x(e,t,n){for(;t<=n;++t){var o=e[t];r(o)&&(r(o.tag)?(_(o),k(o)):u(o.elm))}}function _(e,t){if(r(t)||r(e.data)){var n,i=o.remove.length+1;for(r(t)?t.listeners+=i:t=function(e,t){function n(){0==--n.listeners&&u(e)}return n.listeners=t,n}(e.elm,i),r(n=e.componentInstance)&&r(n=n._vnode)&&r(n.data)&&_(n,t),n=0;n<o.remove.length;++n)o.remove[n](e,t);r(n=e.data.hook)&&r(n=n.remove)?n(e,t):t()}else u(e.elm)}function T(e,t,n,o){for(var i=n;i<o;i++){var a=t[i];if(r(a)&&Io(e,a))return i}}function S(e,t,n,i,c,l){if(e!==t){r(t.elm)&&r(i)&&(t=i[c]=we(t));var u=t.elm=e.elm;if(s(e.isAsyncPlaceholder))r(t.asyncFactory.resolved)?A(e.elm,t,n):t.isAsyncPlaceholder=!0;else if(s(t.isStatic)&&s(e.isStatic)&&t.key===e.key&&(s(t.isCloned)||s(t.isOnce)))t.componentInstance=e.componentInstance;else{var p,m=t.data;r(m)&&r(p=m.hook)&&r(p=p.prepatch)&&p(e,t);var f=e.children,g=t.children;if(r(m)&&w(t)){for(p=0;p<o.update.length;++p)o.update[p](e,t);r(p=m.hook)&&r(p=p.update)&&p(e,t)}a(t.text)?r(f)&&r(g)?f!==g&&function(e,t,n,o,i){var s,c,l,u=0,p=0,m=t.length-1,f=t[0],w=t[m],g=n.length-1,y=n[0],v=n[g],k=!i;for(0;u<=m&&p<=g;)a(f)?f=t[++u]:a(w)?w=t[--m]:Io(f,y)?(S(f,y,o,n,p),f=t[++u],y=n[++p]):Io(w,v)?(S(w,v,o,n,g),w=t[--m],v=n[--g]):Io(f,v)?(S(f,v,o,n,g),k&&d.insertBefore(e,f.elm,d.nextSibling(w.elm)),f=t[++u],v=n[--g]):Io(w,y)?(S(w,y,o,n,p),k&&d.insertBefore(e,w.elm,f.elm),w=t[--m],y=n[++p]):(a(s)&&(s=Ao(t,u,m)),a(c=r(y.key)?s[y.key]:T(y,t,u,m))?h(y,o,e,f.elm,!1,n,p):Io(l=t[c],y)?(S(l,y,o,n,p),t[c]=void 0,k&&d.insertBefore(e,l.elm,f.elm)):h(y,o,e,f.elm,!1,n,p),y=n[++p]);u>m?b(e,a(n[g+1])?null:n[g+1].elm,n,p,g,o):p>g&&x(t,u,m)}(u,f,g,n,l):r(g)?(r(e.text)&&d.setTextContent(u,""),b(u,null,g,0,g.length-1,n)):r(f)?x(f,0,f.length-1):r(e.text)&&d.setTextContent(u,""):e.text!==t.text&&d.setTextContent(u,t.text),r(m)&&r(p=m.hook)&&r(p=p.postpatch)&&p(e,t)}}}function C(e,t,n){if(s(n)&&r(e.parent))e.parent.data.pendingInsert=t;else for(var o=0;o<t.length;++o)t[o].data.hook.insert(t[o])}var I=v("attrs,class,staticClass,staticStyle,key");function A(e,t,n,o){var i,a=t.tag,c=t.data,l=t.children;if(o=o||c&&c.pre,t.elm=e,s(t.isComment)&&r(t.asyncFactory))return t.isAsyncPlaceholder=!0,!0;if(r(c)&&(r(i=c.hook)&&r(i=i.init)&&i(t,!0),r(i=t.componentInstance)))return p(t,n),!0;if(r(a)){if(r(l))if(e.hasChildNodes())if(r(i=c)&&r(i=i.domProps)&&r(i=i.innerHTML)){if(i!==e.innerHTML)return!1}else{for(var d=!0,u=e.firstChild,h=0;h<l.length;h++){if(!u||!A(u,l[h],n,o)){d=!1;break}u=u.nextSibling}if(!d||u)return!1}else f(t,l,n);if(r(c)){var m=!1;for(var w in c)if(!I(w)){m=!0,g(t,n);break}!m&&c.class&&Ht(c.class)}}else e.data!==t.text&&(e.data=t.text);return!0}return function(e,t,n,i){if(!a(t)){var c,l=!1,u=[];if(a(e))l=!0,h(t,u);else{var p=r(e.nodeType);if(!p&&Io(e,t))S(e,t,u,null,null,i);else{if(p){if(1===e.nodeType&&e.hasAttribute("data-server-rendered")&&(e.removeAttribute("data-server-rendered"),n=!0),s(n)&&A(e,t,u))return C(t,u,!0),e;c=e,e=new pe(d.tagName(c).toLowerCase(),{},[],void 0,c)}var m=e.elm,f=d.parentNode(m);if(h(t,u,m._leaveCb?null:f,d.nextSibling(m)),r(t.parent))for(var g=t.parent,y=w(t);g;){for(var v=0;v<o.destroy.length;++v)o.destroy[v](g);if(g.elm=t.elm,y){for(var b=0;b<o.create.length;++b)o.create[b](So,g);var _=g.data.hook.insert;if(_.merged)for(var T=_.fns.slice(1),I=0;I<T.length;I++)T[I]()}else _o(g);g=g.parent}r(f)?x([e],0,0):r(e.tag)&&k(e)}}return C(t,u,l),t.elm}r(e)&&k(e)}}({nodeOps:ko,modules:[zo,Ho,Ko,Jo,li,K?{create:Di,activate:Di,remove:function(e,t){!0!==e.data.show?Pi(e,t):t()}}:{}].concat(jo)});J&&document.addEventListener("selectionchange",(function(){var e=document.activeElement;e&&e.vmodel&&Hi(e,"input")}));var ji={inserted:function(e,t,n,o){"select"===n.tag?(o.elm&&!o.elm._vOptions?Ve(n,"postpatch",(function(){ji.componentUpdated(e,t,n)})):Ni(e,t,n.context),e._vOptions=[].map.call(e.options,zi)):("textarea"===n.tag||bo(e.type))&&(e._vModifiers=t.modifiers,t.modifiers.lazy||(e.addEventListener("compositionstart",Fi),e.addEventListener("compositionend",Mi),e.addEventListener("change",Mi),J&&(e.vmodel=!0)))},componentUpdated:function(e,t,n){if("select"===n.tag){Ni(e,t,n.context);var o=e._vOptions,i=e._vOptions=[].map.call(e.options,zi);if(i.some((function(e,t){return!R(e,o[t])})))(e.multiple?t.value.some((function(e){return Li(e,i)})):t.value!==t.oldValue&&Li(t.value,i))&&Hi(e,"change")}}};function Ni(e,t,n){Ri(e,t,n),(Q||Z)&&setTimeout((function(){Ri(e,t,n)}),0)}function Ri(e,t,n){var o=t.value,i=e.multiple;if(!i||Array.isArray(o)){for(var a,r,s=0,c=e.options.length;s<c;s++)if(r=e.options[s],i)a=L(o,zi(r))>-1,r.selected!==a&&(r.selected=a);else if(R(zi(r),o))return void(e.selectedIndex!==s&&(e.selectedIndex=s));i||(e.selectedIndex=-1)}}function Li(e,t){return t.every((function(t){return!R(t,e)}))}function zi(e){return"_value"in e?e._value:e.value}function Fi(e){e.target.composing=!0}function Mi(e){e.target.composing&&(e.target.composing=!1,Hi(e.target,"input"))}function Hi(e,t){var n=document.createEvent("HTMLEvents");n.initEvent(t,!0,!0),e.dispatchEvent(n)}function $i(e){return!e.componentInstance||e.data&&e.data.transition?e:$i(e.componentInstance._vnode)}var Ui={model:ji,show:{bind:function(e,t,n){var o=t.value,i=(n=$i(n)).data&&n.data.transition,a=e.__vOriginalDisplay="none"===e.style.display?"":e.style.display;o&&i?(n.data.show=!0,Ei(n,(function(){e.style.display=a}))):e.style.display=o?a:"none"},update:function(e,t,n){var o=t.value;!o!=!t.oldValue&&((n=$i(n)).data&&n.data.transition?(n.data.show=!0,o?Ei(n,(function(){e.style.display=e.__vOriginalDisplay})):Pi(n,(function(){e.style.display="none"}))):e.style.display=o?e.__vOriginalDisplay:"none")},unbind:function(e,t,n,o,i){i||(e.style.display=e.__vOriginalDisplay)}}},Gi={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function Bi(e){var t=e&&e.componentOptions;return t&&t.Ctor.options.abstract?Bi(Tt(t.children)):e}function Vi(e){var t={},n=e.$options;for(var o in n.propsData)t[o]=e[o];var i=n._parentListeners;for(var o in i)t[C(o)]=i[o];return t}function Yi(e,t){if(/\d-keep-alive$/.test(t.tag))return e("keep-alive",{props:t.componentOptions.propsData})}var Ki=function(e){return e.tag||mt(e)},Xi=function(e){return"show"===e.name},Qi={name:"transition",props:Gi,abstract:!0,render:function(e){var t=this,n=this.$slots.default;if(n&&(n=n.filter(Ki)).length){0;var o=this.mode;0;var i=n[0];if(function(e){for(;e=e.parent;)if(e.data.transition)return!0}(this.$vnode))return i;var a=Bi(i);if(!a)return i;if(this._leaving)return Yi(e,i);var r="__transition-".concat(this._uid,"-");a.key=null==a.key?a.isComment?r+"comment":r+a.tag:c(a.key)?0===String(a.key).indexOf(r)?a.key:r+a.key:a.key;var s=(a.data||(a.data={})).transition=Vi(this),l=this._vnode,d=Bi(l);if(a.data.directives&&a.data.directives.some(Xi)&&(a.data.show=!0),d&&d.data&&!function(e,t){return t.key===e.key&&t.tag===e.tag}(a,d)&&!mt(d)&&(!d.componentInstance||!d.componentInstance._vnode.isComment)){var u=d.data.transition=q({},s);if("out-in"===o)return this._leaving=!0,Ve(u,"afterLeave",(function(){t._leaving=!1,t.$forceUpdate()})),Yi(e,i);if("in-out"===o){if(mt(a))return l;var h,p=function(){h()};Ve(s,"afterEnter",p),Ve(s,"enterCancelled",p),Ve(u,"delayLeave",(function(e){h=e}))}}return i}}},Ji=q({tag:String,moveClass:String},Gi);function Zi(e){e.elm._moveCb&&e.elm._moveCb(),e.elm._enterCb&&e.elm._enterCb()}function ea(e){e.data.newPos=e.elm.getBoundingClientRect()}function ta(e){var t=e.data.pos,n=e.data.newPos,o=t.left-n.left,i=t.top-n.top;if(o||i){e.data.moved=!0;var a=e.elm.style;a.transform=a.WebkitTransform="translate(".concat(o,"px,").concat(i,"px)"),a.transitionDuration="0s"}}delete Ji.mode;var na={Transition:Qi,TransitionGroup:{props:Ji,beforeMount:function(){var e=this,t=this._update;this._update=function(n,o){var i=Qt(e);e.__patch__(e._vnode,e.kept,!1,!0),e._vnode=e.kept,i(),t.call(e,n,o)}},render:function(e){for(var t=this.tag||this.$vnode.data.tag||"span",n=Object.create(null),o=this.prevChildren=this.children,i=this.$slots.default||[],a=this.children=[],r=Vi(this),s=0;s<i.length;s++){if((d=i[s]).tag)if(null!=d.key&&0!==String(d.key).indexOf("__vlist"))a.push(d),n[d.key]=d,(d.data||(d.data={})).transition=r;else;}if(o){var c=[],l=[];for(s=0;s<o.length;s++){var d;(d=o[s]).data.transition=r,d.data.pos=d.elm.getBoundingClientRect(),n[d.key]?c.push(d):l.push(d)}this.kept=e(t,null,c),this.removed=l}return e(t,null,a)},updated:function(){var e=this.prevChildren,t=this.moveClass||(this.name||"v")+"-move";e.length&&this.hasMove(e[0].elm,t)&&(e.forEach(Zi),e.forEach(ea),e.forEach(ta),this._reflow=document.body.offsetHeight,e.forEach((function(e){if(e.data.moved){var n=e.elm,o=n.style;xi(n,t),o.transform=o.WebkitTransform=o.transitionDuration="",n.addEventListener(gi,n._moveCb=function e(o){o&&o.target!==n||o&&!/transform$/.test(o.propertyName)||(n.removeEventListener(gi,e),n._moveCb=null,_i(n,t))})}})))},methods:{hasMove:function(e,t){if(!fi)return!1;if(this._hasMove)return this._hasMove;var n=e.cloneNode();e._transitionClasses&&e._transitionClasses.forEach((function(e){hi(n,e)})),ui(n,t),n.style.display="none",this.$el.appendChild(n);var o=Ci(n);return this.$el.removeChild(n),this._hasMove=o.hasTransform}}}};function oa(e,t){for(var n in t)e[n]=t[n];return e}Vn.config.mustUseProp=function(e,t,n){return"value"===n&&no(e)&&"button"!==t||"selected"===n&&"option"===e||"checked"===n&&"input"===e||"muted"===n&&"video"===e},Vn.config.isReservedTag=yo,Vn.config.isReservedAttr=to,Vn.config.getTagNamespace=function(e){return go(e)?"svg":"math"===e?"math":void 0},Vn.config.isUnknownElement=function(e){if(!K)return!0;if(yo(e))return!1;if(e=e.toLowerCase(),null!=vo[e])return vo[e];var t=document.createElement(e);return e.indexOf("-")>-1?vo[e]=t.constructor===window.HTMLUnknownElement||t.constructor===window.HTMLElement:vo[e]=/HTMLUnknownElement/.test(t.toString())},q(Vn.options.directives,Ui),q(Vn.options.components,na),Vn.prototype.__patch__=K?Oi:O,Vn.prototype.$mount=function(e,t){return function(e,t,n){var o;e.$el=t,e.$options.render||(e.$options.render=me),en(e,"beforeMount"),o=function(){e._update(e._render(),n)},new Gt(e,o,O,{before:function(){e._isMounted&&!e._isDestroyed&&en(e,"beforeUpdate")}},!0),n=!1;var i=e._preWatchers;if(i)for(var a=0;a<i.length;a++)i[a].run();return null==e.$vnode&&(e._isMounted=!0,en(e,"mounted")),e}(this,e=e&&K?function(e){if("string"==typeof e){var t=document.querySelector(e);return t||document.createElement("div")}return e}(e):void 0,t)},K&&setTimeout((function(){$.devtools&&se&&se.emit("init",Vn)}),0);var ia=/[!'()*]/g,aa=function(e){return"%"+e.charCodeAt(0).toString(16)},ra=/%2C/g,sa=function(e){return encodeURIComponent(e).replace(ia,aa).replace(ra,",")};function ca(e){try{return decodeURIComponent(e)}catch(e){0}return e}var la=function(e){return null==e||"object"==typeof e?e:String(e)};function da(e){var t={};return(e=e.trim().replace(/^(\?|#|&)/,""))?(e.split("&").forEach((function(e){var n=e.replace(/\+/g," ").split("="),o=ca(n.shift()),i=n.length>0?ca(n.join("=")):null;void 0===t[o]?t[o]=i:Array.isArray(t[o])?t[o].push(i):t[o]=[t[o],i]})),t):t}function ua(e){var t=e?Object.keys(e).map((function(t){var n=e[t];if(void 0===n)return"";if(null===n)return sa(t);if(Array.isArray(n)){var o=[];return n.forEach((function(e){void 0!==e&&(null===e?o.push(sa(t)):o.push(sa(t)+"="+sa(e)))})),o.join("&")}return sa(t)+"="+sa(n)})).filter((function(e){return e.length>0})).join("&"):null;return t?"?"+t:""}var ha=/\/?$/;function pa(e,t,n,o){var i=o&&o.options.stringifyQuery,a=t.query||{};try{a=ma(a)}catch(e){}var r={name:t.name||e&&e.name,meta:e&&e.meta||{},path:t.path||"/",hash:t.hash||"",query:a,params:t.params||{},fullPath:ga(t,i),matched:e?wa(e):[]};return n&&(r.redirectedFrom=ga(n,i)),Object.freeze(r)}function ma(e){if(Array.isArray(e))return e.map(ma);if(e&&"object"==typeof e){var t={};for(var n in e)t[n]=ma(e[n]);return t}return e}var fa=pa(null,{path:"/"});function wa(e){for(var t=[];e;)t.unshift(e),e=e.parent;return t}function ga(e,t){var n=e.path,o=e.query;void 0===o&&(o={});var i=e.hash;return void 0===i&&(i=""),(n||"/")+(t||ua)(o)+i}function ya(e,t,n){return t===fa?e===t:!!t&&(e.path&&t.path?e.path.replace(ha,"")===t.path.replace(ha,"")&&(n||e.hash===t.hash&&va(e.query,t.query)):!(!e.name||!t.name)&&(e.name===t.name&&(n||e.hash===t.hash&&va(e.query,t.query)&&va(e.params,t.params))))}function va(e,t){if(void 0===e&&(e={}),void 0===t&&(t={}),!e||!t)return e===t;var n=Object.keys(e).sort(),o=Object.keys(t).sort();return n.length===o.length&&n.every((function(n,i){var a=e[n];if(o[i]!==n)return!1;var r=t[n];return null==a||null==r?a===r:"object"==typeof a&&"object"==typeof r?va(a,r):String(a)===String(r)}))}function ba(e){for(var t=0;t<e.matched.length;t++){var n=e.matched[t];for(var o in n.instances){var i=n.instances[o],a=n.enteredCbs[o];if(i&&a){delete n.enteredCbs[o];for(var r=0;r<a.length;r++)i._isBeingDestroyed||a[r](i)}}}}var ka={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(e,t){var n=t.props,o=t.children,i=t.parent,a=t.data;a.routerView=!0;for(var r=i.$createElement,s=n.name,c=i.$route,l=i._routerViewCache||(i._routerViewCache={}),d=0,u=!1;i&&i._routerRoot!==i;){var h=i.$vnode?i.$vnode.data:{};h.routerView&&d++,h.keepAlive&&i._directInactive&&i._inactive&&(u=!0),i=i.$parent}if(a.routerViewDepth=d,u){var p=l[s],m=p&&p.component;return m?(p.configProps&&xa(m,a,p.route,p.configProps),r(m,a,o)):r()}var f=c.matched[d],w=f&&f.components[s];if(!f||!w)return l[s]=null,r();l[s]={component:w},a.registerRouteInstance=function(e,t){var n=f.instances[s];(t&&n!==e||!t&&n===e)&&(f.instances[s]=t)},(a.hook||(a.hook={})).prepatch=function(e,t){f.instances[s]=t.componentInstance},a.hook.init=function(e){e.data.keepAlive&&e.componentInstance&&e.componentInstance!==f.instances[s]&&(f.instances[s]=e.componentInstance),ba(c)};var g=f.props&&f.props[s];return g&&(oa(l[s],{route:c,configProps:g}),xa(w,a,c,g)),r(w,a,o)}};function xa(e,t,n,o){var i=t.props=function(e,t){switch(typeof t){case"undefined":return;case"object":return t;case"function":return t(e);case"boolean":return t?e.params:void 0;default:0}}(n,o);if(i){i=t.props=oa({},i);var a=t.attrs=t.attrs||{};for(var r in i)e.props&&r in e.props||(a[r]=i[r],delete i[r])}}function _a(e,t,n){var o=e.charAt(0);if("/"===o)return e;if("?"===o||"#"===o)return t+e;var i=t.split("/");n&&i[i.length-1]||i.pop();for(var a=e.replace(/^\//,"").split("/"),r=0;r<a.length;r++){var s=a[r];".."===s?i.pop():"."!==s&&i.push(s)}return""!==i[0]&&i.unshift(""),i.join("/")}function Ta(e){return e.replace(/\/(?:\s*\/)+/g,"/")}var Sa=Array.isArray||function(e){return"[object Array]"==Object.prototype.toString.call(e)},Ca=Fa,Ia=qa,Aa=function(e,t){return Oa(qa(e,t),t)},Ea=Oa,Pa=za,Wa=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function qa(e,t){for(var n,o=[],i=0,a=0,r="",s=t&&t.delimiter||"/";null!=(n=Wa.exec(e));){var c=n[0],l=n[1],d=n.index;if(r+=e.slice(a,d),a=d+c.length,l)r+=l[1];else{var u=e[a],h=n[2],p=n[3],m=n[4],f=n[5],w=n[6],g=n[7];r&&(o.push(r),r="");var y=null!=h&&null!=u&&u!==h,v="+"===w||"*"===w,b="?"===w||"*"===w,k=n[2]||s,x=m||f;o.push({name:p||i++,prefix:h||"",delimiter:k,optional:b,repeat:v,partial:y,asterisk:!!g,pattern:x?Na(x):g?".*":"[^"+ja(k)+"]+?"})}}return a<e.length&&(r+=e.substr(a)),r&&o.push(r),o}function Da(e){return encodeURI(e).replace(/[\/?#]/g,(function(e){return"%"+e.charCodeAt(0).toString(16).toUpperCase()}))}function Oa(e,t){for(var n=new Array(e.length),o=0;o<e.length;o++)"object"==typeof e[o]&&(n[o]=new RegExp("^(?:"+e[o].pattern+")$",La(t)));return function(t,o){for(var i="",a=t||{},r=(o||{}).pretty?Da:encodeURIComponent,s=0;s<e.length;s++){var c=e[s];if("string"!=typeof c){var l,d=a[c.name];if(null==d){if(c.optional){c.partial&&(i+=c.prefix);continue}throw new TypeError('Expected "'+c.name+'" to be defined')}if(Sa(d)){if(!c.repeat)throw new TypeError('Expected "'+c.name+'" to not repeat, but received `'+JSON.stringify(d)+"`");if(0===d.length){if(c.optional)continue;throw new TypeError('Expected "'+c.name+'" to not be empty')}for(var u=0;u<d.length;u++){if(l=r(d[u]),!n[s].test(l))throw new TypeError('Expected all "'+c.name+'" to match "'+c.pattern+'", but received `'+JSON.stringify(l)+"`");i+=(0===u?c.prefix:c.delimiter)+l}}else{if(l=c.asterisk?encodeURI(d).replace(/[?#]/g,(function(e){return"%"+e.charCodeAt(0).toString(16).toUpperCase()})):r(d),!n[s].test(l))throw new TypeError('Expected "'+c.name+'" to match "'+c.pattern+'", but received "'+l+'"');i+=c.prefix+l}}else i+=c}return i}}function ja(e){return e.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function Na(e){return e.replace(/([=!:$\/()])/g,"\\$1")}function Ra(e,t){return e.keys=t,e}function La(e){return e&&e.sensitive?"":"i"}function za(e,t,n){Sa(t)||(n=t||n,t=[]);for(var o=(n=n||{}).strict,i=!1!==n.end,a="",r=0;r<e.length;r++){var s=e[r];if("string"==typeof s)a+=ja(s);else{var c=ja(s.prefix),l="(?:"+s.pattern+")";t.push(s),s.repeat&&(l+="(?:"+c+l+")*"),a+=l=s.optional?s.partial?c+"("+l+")?":"(?:"+c+"("+l+"))?":c+"("+l+")"}}var d=ja(n.delimiter||"/"),u=a.slice(-d.length)===d;return o||(a=(u?a.slice(0,-d.length):a)+"(?:"+d+"(?=$))?"),a+=i?"$":o&&u?"":"(?="+d+"|$)",Ra(new RegExp("^"+a,La(n)),t)}function Fa(e,t,n){return Sa(t)||(n=t||n,t=[]),n=n||{},e instanceof RegExp?function(e,t){var n=e.source.match(/\((?!\?)/g);if(n)for(var o=0;o<n.length;o++)t.push({name:o,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return Ra(e,t)}(e,t):Sa(e)?function(e,t,n){for(var o=[],i=0;i<e.length;i++)o.push(Fa(e[i],t,n).source);return Ra(new RegExp("(?:"+o.join("|")+")",La(n)),t)}(e,t,n):function(e,t,n){return za(qa(e,n),t,n)}(e,t,n)}Ca.parse=Ia,Ca.compile=Aa,Ca.tokensToFunction=Ea,Ca.tokensToRegExp=Pa;var Ma=Object.create(null);function Ha(e,t,n){t=t||{};try{var o=Ma[e]||(Ma[e]=Ca.compile(e));return"string"==typeof t.pathMatch&&(t[0]=t.pathMatch),o(t,{pretty:!0})}catch(e){return""}finally{delete t[0]}}function $a(e,t,n,o){var i="string"==typeof e?{path:e}:e;if(i._normalized)return i;if(i.name){var a=(i=oa({},e)).params;return a&&"object"==typeof a&&(i.params=oa({},a)),i}if(!i.path&&i.params&&t){(i=oa({},i))._normalized=!0;var r=oa(oa({},t.params),i.params);if(t.name)i.name=t.name,i.params=r;else if(t.matched.length){var s=t.matched[t.matched.length-1].path;i.path=Ha(s,r,t.path)}else 0;return i}var c=function(e){var t="",n="",o=e.indexOf("#");o>=0&&(t=e.slice(o),e=e.slice(0,o));var i=e.indexOf("?");return i>=0&&(n=e.slice(i+1),e=e.slice(0,i)),{path:e,query:n,hash:t}}(i.path||""),l=t&&t.path||"/",d=c.path?_a(c.path,l,n||i.append):l,u=function(e,t,n){void 0===t&&(t={});var o,i=n||da;try{o=i(e||"")}catch(e){o={}}for(var a in t){var r=t[a];o[a]=Array.isArray(r)?r.map(la):la(r)}return o}(c.query,i.query,o&&o.options.parseQuery),h=i.hash||c.hash;return h&&"#"!==h.charAt(0)&&(h="#"+h),{_normalized:!0,path:d,query:u,hash:h}}var Ua,Ga=function(){},Ba={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(e){var t=this,n=this.$router,o=this.$route,i=n.resolve(this.to,o,this.append),a=i.location,r=i.route,s=i.href,c={},l=n.options.linkActiveClass,d=n.options.linkExactActiveClass,u=null==l?"router-link-active":l,h=null==d?"router-link-exact-active":d,p=null==this.activeClass?u:this.activeClass,m=null==this.exactActiveClass?h:this.exactActiveClass,f=r.redirectedFrom?pa(null,$a(r.redirectedFrom),null,n):r;c[m]=ya(o,f,this.exactPath),c[p]=this.exact||this.exactPath?c[m]:function(e,t){return 0===e.path.replace(ha,"/").indexOf(t.path.replace(ha,"/"))&&(!t.hash||e.hash===t.hash)&&function(e,t){for(var n in t)if(!(n in e))return!1;return!0}(e.query,t.query)}(o,f);var w=c[m]?this.ariaCurrentValue:null,g=function(e){Va(e)&&(t.replace?n.replace(a,Ga):n.push(a,Ga))},y={click:Va};Array.isArray(this.event)?this.event.forEach((function(e){y[e]=g})):y[this.event]=g;var v={class:c},b=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:s,route:r,navigate:g,isActive:c[p],isExactActive:c[m]});if(b){if(1===b.length)return b[0];if(b.length>1||!b.length)return 0===b.length?e():e("span",{},b)}if("a"===this.tag)v.on=y,v.attrs={href:s,"aria-current":w};else{var k=function e(t){var n;if(t)for(var o=0;o<t.length;o++){if("a"===(n=t[o]).tag)return n;if(n.children&&(n=e(n.children)))return n}}(this.$slots.default);if(k){k.isStatic=!1;var x=k.data=oa({},k.data);for(var _ in x.on=x.on||{},x.on){var T=x.on[_];_ in y&&(x.on[_]=Array.isArray(T)?T:[T])}for(var S in y)S in x.on?x.on[S].push(y[S]):x.on[S]=g;var C=k.data.attrs=oa({},k.data.attrs);C.href=s,C["aria-current"]=w}else v.on=y}return e(this.tag,v,this.$slots.default)}};function Va(e){if(!(e.metaKey||e.altKey||e.ctrlKey||e.shiftKey||e.defaultPrevented||void 0!==e.button&&0!==e.button)){if(e.currentTarget&&e.currentTarget.getAttribute){var t=e.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(t))return}return e.preventDefault&&e.preventDefault(),!0}}var Ya="undefined"!=typeof window;function Ka(e,t,n,o,i){var a=t||[],r=n||Object.create(null),s=o||Object.create(null);e.forEach((function(e){!function e(t,n,o,i,a,r){var s=i.path,c=i.name;0;var l=i.pathToRegexpOptions||{},d=function(e,t,n){n||(e=e.replace(/\/$/,""));if("/"===e[0])return e;if(null==t)return e;return Ta(t.path+"/"+e)}(s,a,l.strict);"boolean"==typeof i.caseSensitive&&(l.sensitive=i.caseSensitive);var u={path:d,regex:Xa(d,l),components:i.components||{default:i.component},alias:i.alias?"string"==typeof i.alias?[i.alias]:i.alias:[],instances:{},enteredCbs:{},name:c,parent:a,matchAs:r,redirect:i.redirect,beforeEnter:i.beforeEnter,meta:i.meta||{},props:null==i.props?{}:i.components?i.props:{default:i.props}};i.children&&i.children.forEach((function(i){var a=r?Ta(r+"/"+i.path):void 0;e(t,n,o,i,u,a)}));n[u.path]||(t.push(u.path),n[u.path]=u);if(void 0!==i.alias)for(var h=Array.isArray(i.alias)?i.alias:[i.alias],p=0;p<h.length;++p){0;var m={path:h[p],children:i.children};e(t,n,o,m,a,u.path||"/")}c&&(o[c]||(o[c]=u))}(a,r,s,e,i)}));for(var c=0,l=a.length;c<l;c++)"*"===a[c]&&(a.push(a.splice(c,1)[0]),l--,c--);return{pathList:a,pathMap:r,nameMap:s}}function Xa(e,t){return Ca(e,[],t)}function Qa(e,t){var n=Ka(e),o=n.pathList,i=n.pathMap,a=n.nameMap;function r(e,n,r){var s=$a(e,n,!1,t),l=s.name;if(l){var d=a[l];if(!d)return c(null,s);var u=d.regex.keys.filter((function(e){return!e.optional})).map((function(e){return e.name}));if("object"!=typeof s.params&&(s.params={}),n&&"object"==typeof n.params)for(var h in n.params)!(h in s.params)&&u.indexOf(h)>-1&&(s.params[h]=n.params[h]);return s.path=Ha(d.path,s.params),c(d,s,r)}if(s.path){s.params={};for(var p=0;p<o.length;p++){var m=o[p],f=i[m];if(Ja(f.regex,s.path,s.params))return c(f,s,r)}}return c(null,s)}function s(e,n){var o=e.redirect,i="function"==typeof o?o(pa(e,n,null,t)):o;if("string"==typeof i&&(i={path:i}),!i||"object"!=typeof i)return c(null,n);var s=i,l=s.name,d=s.path,u=n.query,h=n.hash,p=n.params;if(u=s.hasOwnProperty("query")?s.query:u,h=s.hasOwnProperty("hash")?s.hash:h,p=s.hasOwnProperty("params")?s.params:p,l){a[l];return r({_normalized:!0,name:l,query:u,hash:h,params:p},void 0,n)}if(d){var m=function(e,t){return _a(e,t.parent?t.parent.path:"/",!0)}(d,e);return r({_normalized:!0,path:Ha(m,p),query:u,hash:h},void 0,n)}return c(null,n)}function c(e,n,o){return e&&e.redirect?s(e,o||n):e&&e.matchAs?function(e,t,n){var o=r({_normalized:!0,path:Ha(n,t.params)});if(o){var i=o.matched,a=i[i.length-1];return t.params=o.params,c(a,t)}return c(null,t)}(0,n,e.matchAs):pa(e,n,o,t)}return{match:r,addRoute:function(e,t){var n="object"!=typeof e?a[e]:void 0;Ka([t||e],o,i,a,n),n&&n.alias.length&&Ka(n.alias.map((function(e){return{path:e,children:[t]}})),o,i,a,n)},getRoutes:function(){return o.map((function(e){return i[e]}))},addRoutes:function(e){Ka(e,o,i,a)}}}function Ja(e,t,n){var o=t.match(e);if(!o)return!1;if(!n)return!0;for(var i=1,a=o.length;i<a;++i){var r=e.keys[i-1];r&&(n[r.name||"pathMatch"]="string"==typeof o[i]?ca(o[i]):o[i])}return!0}var Za=Ya&&window.performance&&window.performance.now?window.performance:Date;function er(){return Za.now().toFixed(3)}var tr=er();function nr(){return tr}function or(e){return tr=e}var ir=Object.create(null);function ar(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var e=window.location.protocol+"//"+window.location.host,t=window.location.href.replace(e,""),n=oa({},window.history.state);return n.key=nr(),window.history.replaceState(n,"",t),window.addEventListener("popstate",cr),function(){window.removeEventListener("popstate",cr)}}function rr(e,t,n,o){if(e.app){var i=e.options.scrollBehavior;i&&e.app.$nextTick((function(){var a=function(){var e=nr();if(e)return ir[e]}(),r=i.call(e,t,n,o?a:null);r&&("function"==typeof r.then?r.then((function(e){pr(e,a)})).catch((function(e){0})):pr(r,a))}))}}function sr(){var e=nr();e&&(ir[e]={x:window.pageXOffset,y:window.pageYOffset})}function cr(e){sr(),e.state&&e.state.key&&or(e.state.key)}function lr(e){return ur(e.x)||ur(e.y)}function dr(e){return{x:ur(e.x)?e.x:window.pageXOffset,y:ur(e.y)?e.y:window.pageYOffset}}function ur(e){return"number"==typeof e}var hr=/^#\d/;function pr(e,t){var n,o="object"==typeof e;if(o&&"string"==typeof e.selector){var i=hr.test(e.selector)?document.getElementById(e.selector.slice(1)):document.querySelector(e.selector);if(i){var a=e.offset&&"object"==typeof e.offset?e.offset:{};t=function(e,t){var n=document.documentElement.getBoundingClientRect(),o=e.getBoundingClientRect();return{x:o.left-n.left-t.x,y:o.top-n.top-t.y}}(i,a={x:ur((n=a).x)?n.x:0,y:ur(n.y)?n.y:0})}else lr(e)&&(t=dr(e))}else o&&lr(e)&&(t=dr(e));t&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:t.x,top:t.y,behavior:e.behavior}):window.scrollTo(t.x,t.y))}var mr,fr=Ya&&((-1===(mr=window.navigator.userAgent).indexOf("Android 2.")&&-1===mr.indexOf("Android 4.0")||-1===mr.indexOf("Mobile Safari")||-1!==mr.indexOf("Chrome")||-1!==mr.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function wr(e,t){sr();var n=window.history;try{if(t){var o=oa({},n.state);o.key=nr(),n.replaceState(o,"",e)}else n.pushState({key:or(er())},"",e)}catch(n){window.location[t?"replace":"assign"](e)}}function gr(e){wr(e,!0)}var yr={redirected:2,aborted:4,cancelled:8,duplicated:16};function vr(e,t){return kr(e,t,yr.redirected,'Redirected when going from "'+e.fullPath+'" to "'+function(e){if("string"==typeof e)return e;if("path"in e)return e.path;var t={};return xr.forEach((function(n){n in e&&(t[n]=e[n])})),JSON.stringify(t,null,2)}(t)+'" via a navigation guard.')}function br(e,t){return kr(e,t,yr.cancelled,'Navigation cancelled from "'+e.fullPath+'" to "'+t.fullPath+'" with a new navigation.')}function kr(e,t,n,o){var i=new Error(o);return i._isRouter=!0,i.from=e,i.to=t,i.type=n,i}var xr=["params","query","hash"];function _r(e){return Object.prototype.toString.call(e).indexOf("Error")>-1}function Tr(e,t){return _r(e)&&e._isRouter&&(null==t||e.type===t)}function Sr(e,t,n){var o=function(i){i>=e.length?n():e[i]?t(e[i],(function(){o(i+1)})):o(i+1)};o(0)}function Cr(e){return function(t,n,o){var i=!1,a=0,r=null;Ir(e,(function(e,t,n,s){if("function"==typeof e&&void 0===e.cid){i=!0,a++;var c,l=Pr((function(t){var i;((i=t).__esModule||Er&&"Module"===i[Symbol.toStringTag])&&(t=t.default),e.resolved="function"==typeof t?t:Ua.extend(t),n.components[s]=t,--a<=0&&o()})),d=Pr((function(e){var t="Failed to resolve async component "+s+": "+e;r||(r=_r(e)?e:new Error(t),o(r))}));try{c=e(l,d)}catch(e){d(e)}if(c)if("function"==typeof c.then)c.then(l,d);else{var u=c.component;u&&"function"==typeof u.then&&u.then(l,d)}}})),i||o()}}function Ir(e,t){return Ar(e.map((function(e){return Object.keys(e.components).map((function(n){return t(e.components[n],e.instances[n],e,n)}))})))}function Ar(e){return Array.prototype.concat.apply([],e)}var Er="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Pr(e){var t=!1;return function(){for(var n=[],o=arguments.length;o--;)n[o]=arguments[o];if(!t)return t=!0,e.apply(this,n)}}var Wr=function(e,t){this.router=e,this.base=function(e){if(!e)if(Ya){var t=document.querySelector("base");e=(e=t&&t.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else e="/";"/"!==e.charAt(0)&&(e="/"+e);return e.replace(/\/$/,"")}(t),this.current=fa,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function qr(e,t,n,o){var i=Ir(e,(function(e,o,i,a){var r=function(e,t){"function"!=typeof e&&(e=Ua.extend(e));return e.options[t]}(e,t);if(r)return Array.isArray(r)?r.map((function(e){return n(e,o,i,a)})):n(r,o,i,a)}));return Ar(o?i.reverse():i)}function Dr(e,t){if(t)return function(){return e.apply(t,arguments)}}Wr.prototype.listen=function(e){this.cb=e},Wr.prototype.onReady=function(e,t){this.ready?e():(this.readyCbs.push(e),t&&this.readyErrorCbs.push(t))},Wr.prototype.onError=function(e){this.errorCbs.push(e)},Wr.prototype.transitionTo=function(e,t,n){var o,i=this;try{o=this.router.match(e,this.current)}catch(e){throw this.errorCbs.forEach((function(t){t(e)})),e}var a=this.current;this.confirmTransition(o,(function(){i.updateRoute(o),t&&t(o),i.ensureURL(),i.router.afterHooks.forEach((function(e){e&&e(o,a)})),i.ready||(i.ready=!0,i.readyCbs.forEach((function(e){e(o)})))}),(function(e){n&&n(e),e&&!i.ready&&(Tr(e,yr.redirected)&&a===fa||(i.ready=!0,i.readyErrorCbs.forEach((function(t){t(e)}))))}))},Wr.prototype.confirmTransition=function(e,t,n){var o=this,i=this.current;this.pending=e;var a,r,s=function(e){!Tr(e)&&_r(e)&&(o.errorCbs.length?o.errorCbs.forEach((function(t){t(e)})):console.error(e)),n&&n(e)},c=e.matched.length-1,l=i.matched.length-1;if(ya(e,i)&&c===l&&e.matched[c]===i.matched[l])return this.ensureURL(),e.hash&&rr(this.router,i,e,!1),s(((r=kr(a=i,e,yr.duplicated,'Avoided redundant navigation to current location: "'+a.fullPath+'".')).name="NavigationDuplicated",r));var d=function(e,t){var n,o=Math.max(e.length,t.length);for(n=0;n<o&&e[n]===t[n];n++);return{updated:t.slice(0,n),activated:t.slice(n),deactivated:e.slice(n)}}(this.current.matched,e.matched),u=d.updated,h=d.deactivated,p=d.activated,m=[].concat(function(e){return qr(e,"beforeRouteLeave",Dr,!0)}(h),this.router.beforeHooks,function(e){return qr(e,"beforeRouteUpdate",Dr)}(u),p.map((function(e){return e.beforeEnter})),Cr(p)),f=function(t,n){if(o.pending!==e)return s(br(i,e));try{t(e,i,(function(t){!1===t?(o.ensureURL(!0),s(function(e,t){return kr(e,t,yr.aborted,'Navigation aborted from "'+e.fullPath+'" to "'+t.fullPath+'" via a navigation guard.')}(i,e))):_r(t)?(o.ensureURL(!0),s(t)):"string"==typeof t||"object"==typeof t&&("string"==typeof t.path||"string"==typeof t.name)?(s(vr(i,e)),"object"==typeof t&&t.replace?o.replace(t):o.push(t)):n(t)}))}catch(e){s(e)}};Sr(m,f,(function(){Sr(function(e){return qr(e,"beforeRouteEnter",(function(e,t,n,o){return function(e,t,n){return function(o,i,a){return e(o,i,(function(e){"function"==typeof e&&(t.enteredCbs[n]||(t.enteredCbs[n]=[]),t.enteredCbs[n].push(e)),a(e)}))}}(e,n,o)}))}(p).concat(o.router.resolveHooks),f,(function(){if(o.pending!==e)return s(br(i,e));o.pending=null,t(e),o.router.app&&o.router.app.$nextTick((function(){ba(e)}))}))}))},Wr.prototype.updateRoute=function(e){this.current=e,this.cb&&this.cb(e)},Wr.prototype.setupListeners=function(){},Wr.prototype.teardown=function(){this.listeners.forEach((function(e){e()})),this.listeners=[],this.current=fa,this.pending=null};var Or=function(e){function t(t,n){e.call(this,t,n),this._startLocation=jr(this.base)}return e&&(t.__proto__=e),t.prototype=Object.create(e&&e.prototype),t.prototype.constructor=t,t.prototype.setupListeners=function(){var e=this;if(!(this.listeners.length>0)){var t=this.router,n=t.options.scrollBehavior,o=fr&&n;o&&this.listeners.push(ar());var i=function(){var n=e.current,i=jr(e.base);e.current===fa&&i===e._startLocation||e.transitionTo(i,(function(e){o&&rr(t,e,n,!0)}))};window.addEventListener("popstate",i),this.listeners.push((function(){window.removeEventListener("popstate",i)}))}},t.prototype.go=function(e){window.history.go(e)},t.prototype.push=function(e,t,n){var o=this,i=this.current;this.transitionTo(e,(function(e){wr(Ta(o.base+e.fullPath)),rr(o.router,e,i,!1),t&&t(e)}),n)},t.prototype.replace=function(e,t,n){var o=this,i=this.current;this.transitionTo(e,(function(e){gr(Ta(o.base+e.fullPath)),rr(o.router,e,i,!1),t&&t(e)}),n)},t.prototype.ensureURL=function(e){if(jr(this.base)!==this.current.fullPath){var t=Ta(this.base+this.current.fullPath);e?wr(t):gr(t)}},t.prototype.getCurrentLocation=function(){return jr(this.base)},t}(Wr);function jr(e){var t=window.location.pathname,n=t.toLowerCase(),o=e.toLowerCase();return!e||n!==o&&0!==n.indexOf(Ta(o+"/"))||(t=t.slice(e.length)),(t||"/")+window.location.search+window.location.hash}var Nr=function(e){function t(t,n,o){e.call(this,t,n),o&&function(e){var t=jr(e);if(!/^\/#/.test(t))return window.location.replace(Ta(e+"/#"+t)),!0}(this.base)||Rr()}return e&&(t.__proto__=e),t.prototype=Object.create(e&&e.prototype),t.prototype.constructor=t,t.prototype.setupListeners=function(){var e=this;if(!(this.listeners.length>0)){var t=this.router.options.scrollBehavior,n=fr&&t;n&&this.listeners.push(ar());var o=function(){var t=e.current;Rr()&&e.transitionTo(Lr(),(function(o){n&&rr(e.router,o,t,!0),fr||Mr(o.fullPath)}))},i=fr?"popstate":"hashchange";window.addEventListener(i,o),this.listeners.push((function(){window.removeEventListener(i,o)}))}},t.prototype.push=function(e,t,n){var o=this,i=this.current;this.transitionTo(e,(function(e){Fr(e.fullPath),rr(o.router,e,i,!1),t&&t(e)}),n)},t.prototype.replace=function(e,t,n){var o=this,i=this.current;this.transitionTo(e,(function(e){Mr(e.fullPath),rr(o.router,e,i,!1),t&&t(e)}),n)},t.prototype.go=function(e){window.history.go(e)},t.prototype.ensureURL=function(e){var t=this.current.fullPath;Lr()!==t&&(e?Fr(t):Mr(t))},t.prototype.getCurrentLocation=function(){return Lr()},t}(Wr);function Rr(){var e=Lr();return"/"===e.charAt(0)||(Mr("/"+e),!1)}function Lr(){var e=window.location.href,t=e.indexOf("#");return t<0?"":e=e.slice(t+1)}function zr(e){var t=window.location.href,n=t.indexOf("#");return(n>=0?t.slice(0,n):t)+"#"+e}function Fr(e){fr?wr(zr(e)):window.location.hash=e}function Mr(e){fr?gr(zr(e)):window.location.replace(zr(e))}var Hr=function(e){function t(t,n){e.call(this,t,n),this.stack=[],this.index=-1}return e&&(t.__proto__=e),t.prototype=Object.create(e&&e.prototype),t.prototype.constructor=t,t.prototype.push=function(e,t,n){var o=this;this.transitionTo(e,(function(e){o.stack=o.stack.slice(0,o.index+1).concat(e),o.index++,t&&t(e)}),n)},t.prototype.replace=function(e,t,n){var o=this;this.transitionTo(e,(function(e){o.stack=o.stack.slice(0,o.index).concat(e),t&&t(e)}),n)},t.prototype.go=function(e){var t=this,n=this.index+e;if(!(n<0||n>=this.stack.length)){var o=this.stack[n];this.confirmTransition(o,(function(){var e=t.current;t.index=n,t.updateRoute(o),t.router.afterHooks.forEach((function(t){t&&t(o,e)}))}),(function(e){Tr(e,yr.duplicated)&&(t.index=n)}))}},t.prototype.getCurrentLocation=function(){var e=this.stack[this.stack.length-1];return e?e.fullPath:"/"},t.prototype.ensureURL=function(){},t}(Wr),$r=function(e){void 0===e&&(e={}),this.app=null,this.apps=[],this.options=e,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Qa(e.routes||[],this);var t=e.mode||"hash";switch(this.fallback="history"===t&&!fr&&!1!==e.fallback,this.fallback&&(t="hash"),Ya||(t="abstract"),this.mode=t,t){case"history":this.history=new Or(this,e.base);break;case"hash":this.history=new Nr(this,e.base,this.fallback);break;case"abstract":this.history=new Hr(this,e.base);break;default:0}},Ur={currentRoute:{configurable:!0}};$r.prototype.match=function(e,t,n){return this.matcher.match(e,t,n)},Ur.currentRoute.get=function(){return this.history&&this.history.current},$r.prototype.init=function(e){var t=this;if(this.apps.push(e),e.$once("hook:destroyed",(function(){var n=t.apps.indexOf(e);n>-1&&t.apps.splice(n,1),t.app===e&&(t.app=t.apps[0]||null),t.app||t.history.teardown()})),!this.app){this.app=e;var n=this.history;if(n instanceof Or||n instanceof Nr){var o=function(e){n.setupListeners(),function(e){var o=n.current,i=t.options.scrollBehavior;fr&&i&&"fullPath"in e&&rr(t,e,o,!1)}(e)};n.transitionTo(n.getCurrentLocation(),o,o)}n.listen((function(e){t.apps.forEach((function(t){t._route=e}))}))}},$r.prototype.beforeEach=function(e){return Br(this.beforeHooks,e)},$r.prototype.beforeResolve=function(e){return Br(this.resolveHooks,e)},$r.prototype.afterEach=function(e){return Br(this.afterHooks,e)},$r.prototype.onReady=function(e,t){this.history.onReady(e,t)},$r.prototype.onError=function(e){this.history.onError(e)},$r.prototype.push=function(e,t,n){var o=this;if(!t&&!n&&"undefined"!=typeof Promise)return new Promise((function(t,n){o.history.push(e,t,n)}));this.history.push(e,t,n)},$r.prototype.replace=function(e,t,n){var o=this;if(!t&&!n&&"undefined"!=typeof Promise)return new Promise((function(t,n){o.history.replace(e,t,n)}));this.history.replace(e,t,n)},$r.prototype.go=function(e){this.history.go(e)},$r.prototype.back=function(){this.go(-1)},$r.prototype.forward=function(){this.go(1)},$r.prototype.getMatchedComponents=function(e){var t=e?e.matched?e:this.resolve(e).route:this.currentRoute;return t?[].concat.apply([],t.matched.map((function(e){return Object.keys(e.components).map((function(t){return e.components[t]}))}))):[]},$r.prototype.resolve=function(e,t,n){var o=$a(e,t=t||this.history.current,n,this),i=this.match(o,t),a=i.redirectedFrom||i.fullPath;return{location:o,route:i,href:function(e,t,n){var o="hash"===n?"#"+t:t;return e?Ta(e+"/"+o):o}(this.history.base,a,this.mode),normalizedTo:o,resolved:i}},$r.prototype.getRoutes=function(){return this.matcher.getRoutes()},$r.prototype.addRoute=function(e,t){this.matcher.addRoute(e,t),this.history.current!==fa&&this.history.transitionTo(this.history.getCurrentLocation())},$r.prototype.addRoutes=function(e){this.matcher.addRoutes(e),this.history.current!==fa&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties($r.prototype,Ur);var Gr=$r;function Br(e,t){return e.push(t),function(){var n=e.indexOf(t);n>-1&&e.splice(n,1)}}$r.install=function e(t){if(!e.installed||Ua!==t){e.installed=!0,Ua=t;var n=function(e){return void 0!==e},o=function(e,t){var o=e.$options._parentVnode;n(o)&&n(o=o.data)&&n(o=o.registerRouteInstance)&&o(e,t)};t.mixin({beforeCreate:function(){n(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),t.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,o(this,this)},destroyed:function(){o(this)}}),Object.defineProperty(t.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(t.prototype,"$route",{get:function(){return this._routerRoot._route}}),t.component("RouterView",ka),t.component("RouterLink",Ba);var i=t.config.optionMergeStrategies;i.beforeRouteEnter=i.beforeRouteLeave=i.beforeRouteUpdate=i.created}},$r.version="3.6.5",$r.isNavigationFailure=Tr,$r.NavigationFailureType=yr,$r.START_LOCATION=fa,Ya&&window.Vue&&window.Vue.use($r);n(106);n(104),n(94);var Vr={"components/AlgoliaSearchBox":()=>Promise.all([n.e(0),n.e(13)]).then(n.bind(null,323)),"components/DropdownLink":()=>Promise.all([n.e(0),n.e(14)]).then(n.bind(null,265)),"components/DropdownTransition":()=>Promise.all([n.e(0),n.e(19)]).then(n.bind(null,253)),"components/Home":()=>Promise.all([n.e(0),n.e(16)]).then(n.bind(null,295)),"components/NavLink":()=>n.e(22).then(n.bind(null,252)),"components/NavLinks":()=>Promise.all([n.e(0),n.e(12)]).then(n.bind(null,277)),"components/Navbar":()=>Promise.all([n.e(0),n.e(1)]).then(n.bind(null,320)),"components/Page":()=>Promise.all([n.e(0),n.e(11)]).then(n.bind(null,296)),"components/PageEdit":()=>Promise.all([n.e(0),n.e(17)]).then(n.bind(null,279)),"components/PageNav":()=>Promise.all([n.e(0),n.e(15)]).then(n.bind(null,280)),"components/Sidebar":()=>Promise.all([n.e(0),n.e(10)]).then(n.bind(null,297)),"components/SidebarButton":()=>Promise.all([n.e(0),n.e(20)]).then(n.bind(null,298)),"components/SidebarGroup":()=>Promise.all([n.e(0),n.e(3)]).then(n.bind(null,278)),"components/SidebarLink":()=>Promise.all([n.e(0),n.e(18)]).then(n.bind(null,266)),"components/SidebarLinks":()=>Promise.all([n.e(0),n.e(3)]).then(n.bind(null,264)),"global-components/Badge":()=>Promise.all([n.e(0),n.e(4)]).then(n.bind(null,330)),"global-components/CodeBlock":()=>Promise.all([n.e(0),n.e(5)]).then(n.bind(null,324)),"global-components/CodeGroup":()=>Promise.all([n.e(0),n.e(6)]).then(n.bind(null,325)),"layouts/404":()=>n.e(7).then(n.bind(null,326)),"layouts/Layout":()=>Promise.all([n.e(0),n.e(1),n.e(2)]).then(n.bind(null,327)),NotFound:()=>n.e(7).then(n.bind(null,326)),Layout:()=>Promise.all([n.e(0),n.e(1),n.e(2)]).then(n.bind(null,327))},Yr={"v-9cd9f09c":()=>n.e(26).then(n.bind(null,331)),"v-40447742":()=>n.e(28).then(n.bind(null,332)),"v-5261e03c":()=>n.e(21).then(n.bind(null,333)),"v-4bb753c4":()=>n.e(27).then(n.bind(null,334)),"v-696d6f80":()=>n.e(29).then(n.bind(null,335)),"v-5ab4294a":()=>n.e(30).then(n.bind(null,336)),"v-c2f362bc":()=>n.e(31).then(n.bind(null,337)),"v-d5dcd2a0":()=>n.e(32).then(n.bind(null,338)),"v-88def7ac":()=>n.e(33).then(n.bind(null,339)),"v-7a5c92a2":()=>n.e(34).then(n.bind(null,340)),"v-1bc7fd02":()=>n.e(35).then(n.bind(null,341)),"v-a14b6054":()=>n.e(36).then(n.bind(null,342)),"v-c99e5abc":()=>n.e(38).then(n.bind(null,343)),"v-28bf3ec2":()=>n.e(37).then(n.bind(null,344)),"v-36ed9422":()=>n.e(39).then(n.bind(null,345)),"v-6b66fa18":()=>n.e(40).then(n.bind(null,346)),"v-611b8c3c":()=>n.e(41).then(n.bind(null,347)),"v-163bae3c":()=>n.e(42).then(n.bind(null,348)),"v-13d0c1ca":()=>n.e(43).then(n.bind(null,349)),"v-8d905b7c":()=>n.e(44).then(n.bind(null,350)),"v-e240404c":()=>n.e(45).then(n.bind(null,351)),"v-2d8e6278":()=>n.e(46).then(n.bind(null,352)),"v-7b43cf3c":()=>n.e(47).then(n.bind(null,353)),"v-78a9ec22":()=>n.e(49).then(n.bind(null,354)),"v-eec246bc":()=>n.e(50).then(n.bind(null,355)),"v-5d616cea":()=>n.e(51).then(n.bind(null,356)),"v-3c665d38":()=>n.e(52).then(n.bind(null,357)),"v-1c104a48":()=>n.e(48).then(n.bind(null,358)),"v-c2670478":()=>n.e(53).then(n.bind(null,359)),"v-347319df":()=>n.e(54).then(n.bind(null,360)),"v-2f3b4398":()=>n.e(55).then(n.bind(null,361)),"v-44a96002":()=>n.e(56).then(n.bind(null,362)),"v-73f5d8c2":()=>n.e(57).then(n.bind(null,363)),"v-7106a8e2":()=>n.e(58).then(n.bind(null,364)),"v-b64a802c":()=>n.e(60).then(n.bind(null,365)),"v-3c541bc2":()=>n.e(61).then(n.bind(null,366)),"v-423a333c":()=>n.e(62).then(n.bind(null,367)),"v-4af1f23c":()=>n.e(59).then(n.bind(null,368)),"v-65cef250":()=>n.e(64).then(n.bind(null,369)),"v-47638d30":()=>n.e(63).then(n.bind(null,370)),"v-47e211a0":()=>n.e(65).then(n.bind(null,371)),"v-2ef7ad44":()=>n.e(66).then(n.bind(null,372)),"v-d965e2bc":()=>n.e(68).then(n.bind(null,373)),"v-272408a2":()=>n.e(67).then(n.bind(null,374)),"v-68ae0de4":()=>n.e(69).then(n.bind(null,375)),"v-53d65f58":()=>n.e(70).then(n.bind(null,376)),"v-56629f80":()=>n.e(71).then(n.bind(null,377)),"v-861efabc":()=>n.e(75).then(n.bind(null,378)),"v-c1687e0a":()=>n.e(73).then(n.bind(null,379)),"v-7a33750a":()=>n.e(72).then(n.bind(null,380)),"v-76c4aa02":()=>n.e(76).then(n.bind(null,381)),"v-e5936714":()=>n.e(74).then(n.bind(null,382)),"v-43760982":()=>n.e(77).then(n.bind(null,383)),"v-caeda73c":()=>n.e(78).then(n.bind(null,384)),"v-0327ca12":()=>n.e(79).then(n.bind(null,385)),"v-5fac5e6c":()=>n.e(80).then(n.bind(null,386)),"v-595589a2":()=>n.e(81).then(n.bind(null,387)),"v-7732347a":()=>n.e(83).then(n.bind(null,388)),"v-67f3ae7c":()=>n.e(82).then(n.bind(null,389)),"v-a1460e54":()=>n.e(85).then(n.bind(null,390)),"v-d0383dd4":()=>n.e(84).then(n.bind(null,391)),"v-0a1dd2ec":()=>n.e(86).then(n.bind(null,392)),"v-c8a8f07c":()=>n.e(87).then(n.bind(null,393)),"v-0b9844ac":()=>n.e(88).then(n.bind(null,394)),"v-edf882bc":()=>n.e(89).then(n.bind(null,395)),"v-35913a62":()=>n.e(90).then(n.bind(null,396)),"v-9d2716dc":()=>n.e(91).then(n.bind(null,397)),"v-d043b980":()=>n.e(92).then(n.bind(null,398)),"v-6fa6d57b":()=>n.e(94).then(n.bind(null,399)),"v-740be4db":()=>n.e(93).then(n.bind(null,400)),"v-5df8103c":()=>n.e(24).then(n.bind(null,401)),"v-6be5daf6":()=>n.e(95).then(n.bind(null,402)),"v-c3677d3c":()=>n.e(96).then(n.bind(null,403)),"v-1a836dbc":()=>n.e(97).then(n.bind(null,404)),"v-6f38e6b6":()=>n.e(98).then(n.bind(null,405)),"v-fc381aca":()=>n.e(100).then(n.bind(null,406)),"v-3569388c":()=>n.e(99).then(n.bind(null,407)),"v-00ee1f44":()=>n.e(101).then(n.bind(null,408)),"v-fa725f4a":()=>n.e(102).then(n.bind(null,409)),"v-7256933b":()=>n.e(103).then(n.bind(null,410))};function Kr(e){const t=Object.create(null);return function(n){return t[n]||(t[n]=e(n))}}const Xr=/-(\w)/g,Qr=Kr(e=>e.replace(Xr,(e,t)=>t?t.toUpperCase():"")),Jr=/\B([A-Z])/g,Zr=Kr(e=>e.replace(Jr,"-$1").toLowerCase()),es=Kr(e=>e.charAt(0).toUpperCase()+e.slice(1));function ts(e,t){if(!t)return;if(e(t))return e(t);return t.includes("-")?e(es(Qr(t))):e(es(t))||e(Zr(t))}const ns=Object.assign({},Vr,Yr),os=e=>ns[e],is=e=>Yr[e],as=e=>Vr[e],rs=e=>Vn.component(e);function ss(e){return ts(is,e)}function cs(e){return ts(as,e)}function ls(e){return ts(os,e)}function ds(e){return ts(rs,e)}function us(...e){return Promise.all(e.filter(e=>e).map(async e=>{if(!ds(e)&&ls(e)){const t=await ls(e)();Vn.component(e,t.default)}}))}function hs(e,t){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[e]=t)}var ps=n(92),ms=n.n(ps),fs=n(93),ws=n.n(fs),gs={created(){if(this.siteMeta=this.$site.headTags.filter(([e])=>"meta"===e).map(([e,t])=>t),this.$ssrContext){const t=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(e=t)?e.map(e=>{let t="<meta";return Object.keys(e).forEach(n=>{t+=` ${n}="${ws()(e[n])}"`}),t+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=vs(this.$canonicalUrl)}var e},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const e=this.getMergedMetaTags();this.currentMetaTags=bs(e,this.currentMetaTags)},getMergedMetaTags(){const e=this.$page.frontmatter.meta||[];return ms()([{name:"description",content:this.$description}],e,this.siteMeta,ks)},updateCanonicalLink(){ys(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",vs(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){bs(null,this.currentMetaTags),ys()}};function ys(){const e=document.querySelector("link[rel='canonical']");e&&e.remove()}function vs(e=""){return e?`<link href="${e}" rel="canonical" />`:""}function bs(e,t){if(t&&[...t].filter(e=>e.parentNode===document.head).forEach(e=>document.head.removeChild(e)),e)return e.map(e=>{const t=document.createElement("meta");return Object.keys(e).forEach(n=>{t.setAttribute(n,e[n])}),document.head.appendChild(t),t})}function ks(e){for(const t of["name","property","itemprop"])if(e.hasOwnProperty(t))return e[t]+t;return JSON.stringify(e)}var xs=n(22),_s=n.n(xs),Ts={mounted(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:_s()((function(){this.setActiveHash()}),300),setActiveHash(){const e=[].slice.call(document.querySelectorAll(".sidebar-link")),t=[].slice.call(document.querySelectorAll(".header-anchor")).filter(t=>e.some(e=>e.hash===t.hash)),n=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),o=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),i=window.innerHeight+n;for(let e=0;e<t.length;e++){const a=t[e],r=t[e+1],s=0===e&&0===n||n>=a.parentElement.offsetTop+10&&(!r||n<r.parentElement.offsetTop-10),c=decodeURIComponent(this.$route.hash);if(s&&c!==decodeURIComponent(a.hash)){const n=a;if(i===o)for(let n=e+1;n<t.length;n++)if(c===decodeURIComponent(t[n].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(n.hash),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})}}}},beforeDestroy(){window.removeEventListener("scroll",this.onScroll)}},Ss=n(23),Cs=n.n(Ss),Is={mounted(){Cs.a.configure({showSpinner:!1}),this.$router.beforeEach((e,t,n)=>{e.path===t.path||Vn.component(e.name)||Cs.a.start(),n()}),this.$router.afterEach(()=>{Cs.a.done(),this.isSidebarOpen=!1})}},As={props:{parent:Object,code:String,options:{align:String,color:String,backgroundTransition:Boolean,backgroundColor:String,successText:String,staticIcon:Boolean}},data:()=>({success:!1,originalBackground:null,originalTransition:null}),computed:{alignStyle(){let e={};return e[this.options.align]="7.5px",e},iconClass(){return this.options.staticIcon?"":"hover"}},mounted(){this.originalTransition=this.parent.style.transition,this.originalBackground=this.parent.style.background},beforeDestroy(){this.parent.style.transition=this.originalTransition,this.parent.style.background=this.originalBackground},methods:{hexToRgb(e){let t=/^#?([a-f\d]{2})([a-f\d]{2})([a-f\d]{2})$/i.exec(e);return t?{r:parseInt(t[1],16),g:parseInt(t[2],16),b:parseInt(t[3],16)}:null},copyToClipboard(e){if(navigator.clipboard)navigator.clipboard.writeText(this.code).then(()=>{this.setSuccessTransitions()},()=>{});else{let e=document.createElement("textarea");document.body.appendChild(e),e.value=this.code,e.select(),document.execCommand("Copy"),e.remove(),this.setSuccessTransitions()}},setSuccessTransitions(){if(clearTimeout(this.successTimeout),this.options.backgroundTransition){this.parent.style.transition="background 350ms";let e=this.hexToRgb(this.options.backgroundColor);this.parent.style.background=`rgba(${e.r}, ${e.g}, ${e.b}, 0.1)`}this.success=!0,this.successTimeout=setTimeout(()=>{this.options.backgroundTransition&&(this.parent.style.background=this.originalBackground,this.parent.style.transition=this.originalTransition),this.success=!1},500)}}},Es=(n(239),n(0)),Ps=Object(Es.a)(As,(function(){var e=this,t=e._self._c;return t("div",{staticClass:"code-copy"},[t("svg",{class:e.iconClass,style:e.alignStyle,attrs:{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 24 24"},on:{click:e.copyToClipboard}},[t("path",{attrs:{fill:"none",d:"M0 0h24v24H0z"}}),e._v(" "),t("path",{attrs:{fill:e.options.color,d:"M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm-1 4l6 6v10c0 1.1-.9 2-2 2H7.99C6.89 23 6 22.1 6 21l.01-14c0-1.1.89-2 1.99-2h7zm-1 7h5.5L14 6.5V12z"}})]),e._v(" "),t("span",{class:e.success?"success":"",style:e.alignStyle},[e._v("\n        "+e._s(e.options.successText)+"\n    ")])])}),[],!1,null,"49140617",null).exports,Ws=(n(240),[gs,Ts,Is,{updated(){this.update()},methods:{update(){setTimeout(()=>{document.querySelectorAll('div[class*="language-"] pre').forEach(e=>{if(e.classList.contains("code-copy-added"))return;let t=new(Vn.extend(Ps));t.options={align:"bottom",color:"#27b1ff",backgroundTransition:!0,backgroundColor:"#0075b8",successText:"Copied!",staticIcon:!1},t.code=e.innerText,t.parent=e,t.$mount(),e.classList.add("code-copy-added"),e.appendChild(t.$el)})},100)}}}]),qs={name:"GlobalLayout",computed:{layout(){const e=this.getLayout();return hs("layout",e),Vn.component(e)}},methods:{getLayout(){if(this.$page.path){const e=this.$page.frontmatter.layout;return e&&(this.$vuepress.getLayoutAsyncComponent(e)||this.$vuepress.getVueComponent(e))?e:"Layout"}return"NotFound"}}},Ds=Object(Es.a)(qs,(function(){return(0,this._self._c)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(e,t,n){switch(t){case"components":e[t]||(e[t]={}),Object.assign(e[t],n);break;case"mixins":e[t]||(e[t]=[]),e[t].push(...n);break;default:throw new Error("Unknown option name.")}}(Ds,"mixins",Ws);const Os=[{name:"v-9cd9f09c",path:"/GLOSSARY.html",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-9cd9f09c").then(n)}},{name:"v-40447742",path:"/docs/get-started/java-hello-world/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-40447742").then(n)}},{path:"/docs/get-started/java-hello-world/index.html",redirect:"/docs/get-started/java-hello-world/"},{path:"/docs/01-get-started/02-java-hello-world.html",redirect:"/docs/get-started/java-hello-world/"},{name:"v-5261e03c",path:"/docs/get-started/golang-hello-world/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-5261e03c").then(n)}},{path:"/docs/get-started/golang-hello-world/index.html",redirect:"/docs/get-started/golang-hello-world/"},{path:"/docs/01-get-started/03-golang-hello-world.html",redirect:"/docs/get-started/golang-hello-world/"},{name:"v-4bb753c4",path:"/docs/get-started/installation/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-4bb753c4").then(n)}},{path:"/docs/get-started/installation/index.html",redirect:"/docs/get-started/installation/"},{path:"/docs/01-get-started/01-server-installation.html",redirect:"/docs/get-started/installation/"},{name:"v-696d6f80",path:"/docs/get-started/video-tutorials/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-696d6f80").then(n)}},{path:"/docs/get-started/video-tutorials/index.html",redirect:"/docs/get-started/video-tutorials/"},{path:"/docs/01-get-started/04-video-tutorials.html",redirect:"/docs/get-started/video-tutorials/"},{name:"v-5ab4294a",path:"/docs/get-started/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-5ab4294a").then(n)}},{path:"/docs/get-started/index.html",redirect:"/docs/get-started/"},{path:"/docs/01-get-started/",redirect:"/docs/get-started/"},{name:"v-c2f362bc",path:"/docs/use-cases/periodic-execution/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-c2f362bc").then(n)}},{path:"/docs/use-cases/periodic-execution/index.html",redirect:"/docs/use-cases/periodic-execution/"},{path:"/docs/02-use-cases/01-periodic-execution.html",redirect:"/docs/use-cases/periodic-execution/"},{name:"v-d5dcd2a0",path:"/docs/use-cases/orchestration/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-d5dcd2a0").then(n)}},{path:"/docs/use-cases/orchestration/index.html",redirect:"/docs/use-cases/orchestration/"},{path:"/docs/02-use-cases/02-orchestration.html",redirect:"/docs/use-cases/orchestration/"},{name:"v-88def7ac",path:"/docs/use-cases/polling/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-88def7ac").then(n)}},{path:"/docs/use-cases/polling/index.html",redirect:"/docs/use-cases/polling/"},{path:"/docs/02-use-cases/03-polling.html",redirect:"/docs/use-cases/polling/"},{name:"v-7a5c92a2",path:"/docs/use-cases/event-driven/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-7a5c92a2").then(n)}},{path:"/docs/use-cases/event-driven/index.html",redirect:"/docs/use-cases/event-driven/"},{path:"/docs/02-use-cases/04-event-driven.html",redirect:"/docs/use-cases/event-driven/"},{name:"v-1bc7fd02",path:"/docs/use-cases/partitioned-scan/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-1bc7fd02").then(n)}},{path:"/docs/use-cases/partitioned-scan/index.html",redirect:"/docs/use-cases/partitioned-scan/"},{path:"/docs/02-use-cases/05-partitioned-scan.html",redirect:"/docs/use-cases/partitioned-scan/"},{name:"v-a14b6054",path:"/docs/use-cases/batch-job/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-a14b6054").then(n)}},{path:"/docs/use-cases/batch-job/index.html",redirect:"/docs/use-cases/batch-job/"},{path:"/docs/02-use-cases/06-batch-job.html",redirect:"/docs/use-cases/batch-job/"},{name:"v-c99e5abc",path:"/docs/use-cases/deployment/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-c99e5abc").then(n)}},{path:"/docs/use-cases/deployment/index.html",redirect:"/docs/use-cases/deployment/"},{path:"/docs/02-use-cases/08-deployment.html",redirect:"/docs/use-cases/deployment/"},{name:"v-28bf3ec2",path:"/docs/use-cases/provisioning/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-28bf3ec2").then(n)}},{path:"/docs/use-cases/provisioning/index.html",redirect:"/docs/use-cases/provisioning/"},{path:"/docs/02-use-cases/07-provisioning.html",redirect:"/docs/use-cases/provisioning/"},{name:"v-36ed9422",path:"/docs/use-cases/operational-management/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-36ed9422").then(n)}},{path:"/docs/use-cases/operational-management/index.html",redirect:"/docs/use-cases/operational-management/"},{path:"/docs/02-use-cases/09-operational-management.html",redirect:"/docs/use-cases/operational-management/"},{name:"v-6b66fa18",path:"/docs/use-cases/interactive/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-6b66fa18").then(n)}},{path:"/docs/use-cases/interactive/index.html",redirect:"/docs/use-cases/interactive/"},{path:"/docs/02-use-cases/10-interactive.html",redirect:"/docs/use-cases/interactive/"},{name:"v-611b8c3c",path:"/docs/use-cases/dsl/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-611b8c3c").then(n)}},{path:"/docs/use-cases/dsl/index.html",redirect:"/docs/use-cases/dsl/"},{path:"/docs/02-use-cases/11-dsl.html",redirect:"/docs/use-cases/dsl/"},{name:"v-163bae3c",path:"/docs/use-cases/big-ml/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-163bae3c").then(n)}},{path:"/docs/use-cases/big-ml/index.html",redirect:"/docs/use-cases/big-ml/"},{path:"/docs/02-use-cases/12-big-ml.html",redirect:"/docs/use-cases/big-ml/"},{name:"v-13d0c1ca",path:"/docs/use-cases/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-13d0c1ca").then(n)}},{path:"/docs/use-cases/index.html",redirect:"/docs/use-cases/"},{path:"/docs/02-use-cases/",redirect:"/docs/use-cases/"},{name:"v-8d905b7c",path:"/docs/concepts/workflows/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-8d905b7c").then(n)}},{path:"/docs/concepts/workflows/index.html",redirect:"/docs/concepts/workflows/"},{path:"/docs/03-concepts/01-workflows.html",redirect:"/docs/concepts/workflows/"},{name:"v-e240404c",path:"/docs/concepts/activities/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-e240404c").then(n)}},{path:"/docs/concepts/activities/index.html",redirect:"/docs/concepts/activities/"},{path:"/docs/03-concepts/02-activities.html",redirect:"/docs/concepts/activities/"},{name:"v-2d8e6278",path:"/docs/concepts/events/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-2d8e6278").then(n)}},{path:"/docs/concepts/events/index.html",redirect:"/docs/concepts/events/"},{path:"/docs/03-concepts/03-events.html",redirect:"/docs/concepts/events/"},{name:"v-7b43cf3c",path:"/docs/concepts/queries/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-7b43cf3c").then(n)}},{path:"/docs/concepts/queries/index.html",redirect:"/docs/concepts/queries/"},{path:"/docs/03-concepts/04-queries.html",redirect:"/docs/concepts/queries/"},{name:"v-78a9ec22",path:"/docs/concepts/task-lists/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-78a9ec22").then(n)}},{path:"/docs/concepts/task-lists/index.html",redirect:"/docs/concepts/task-lists/"},{path:"/docs/03-concepts/06-task-lists.html",redirect:"/docs/concepts/task-lists/"},{name:"v-eec246bc",path:"/docs/concepts/archival/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-eec246bc").then(n)}},{path:"/docs/concepts/archival/index.html",redirect:"/docs/concepts/archival/"},{path:"/docs/03-concepts/07-archival.html",redirect:"/docs/concepts/archival/"},{name:"v-5d616cea",path:"/docs/concepts/cross-dc-replication/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-5d616cea").then(n)}},{path:"/docs/concepts/cross-dc-replication/index.html",redirect:"/docs/concepts/cross-dc-replication/"},{path:"/docs/03-concepts/08-cross-dc-replication.html",redirect:"/docs/concepts/cross-dc-replication/"},{name:"v-3c665d38",path:"/docs/concepts/search-workflows/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-3c665d38").then(n)}},{path:"/docs/concepts/search-workflows/index.html",redirect:"/docs/concepts/search-workflows/"},{path:"/docs/03-concepts/09-search-workflows.html",redirect:"/docs/concepts/search-workflows/"},{name:"v-1c104a48",path:"/docs/concepts/topology/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-1c104a48").then(n)}},{path:"/docs/concepts/topology/index.html",redirect:"/docs/concepts/topology/"},{path:"/docs/03-concepts/05-topology.html",redirect:"/docs/concepts/topology/"},{name:"v-c2670478",path:"/docs/concepts/http-api/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-c2670478").then(n)}},{path:"/docs/concepts/http-api/index.html",redirect:"/docs/concepts/http-api/"},{path:"/docs/03-concepts/10-http-api.html",redirect:"/docs/concepts/http-api/"},{name:"v-347319df",path:"/docs/concepts/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-347319df").then(n)}},{path:"/docs/concepts/index.html",redirect:"/docs/concepts/"},{path:"/docs/03-concepts/",redirect:"/docs/concepts/"},{name:"v-2f3b4398",path:"/docs/java-client/client-overview/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-2f3b4398").then(n)}},{path:"/docs/java-client/client-overview/index.html",redirect:"/docs/java-client/client-overview/"},{path:"/docs/04-java-client/01-client-overview.html",redirect:"/docs/java-client/client-overview/"},{name:"v-44a96002",path:"/docs/java-client/workflow-interface/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-44a96002").then(n)}},{path:"/docs/java-client/workflow-interface/index.html",redirect:"/docs/java-client/workflow-interface/"},{path:"/docs/04-java-client/02-workflow-interface.html",redirect:"/docs/java-client/workflow-interface/"},{name:"v-73f5d8c2",path:"/docs/java-client/implementing-workflows/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-73f5d8c2").then(n)}},{path:"/docs/java-client/implementing-workflows/index.html",redirect:"/docs/java-client/implementing-workflows/"},{path:"/docs/04-java-client/03-implementing-workflows.html",redirect:"/docs/java-client/implementing-workflows/"},{name:"v-7106a8e2",path:"/docs/java-client/starting-workflow-executions/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-7106a8e2").then(n)}},{path:"/docs/java-client/starting-workflow-executions/index.html",redirect:"/docs/java-client/starting-workflow-executions/"},{path:"/docs/04-java-client/04-starting-workflow-executions.html",redirect:"/docs/java-client/starting-workflow-executions/"},{name:"v-b64a802c",path:"/docs/java-client/implementing-activities/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-b64a802c").then(n)}},{path:"/docs/java-client/implementing-activities/index.html",redirect:"/docs/java-client/implementing-activities/"},{path:"/docs/04-java-client/06-implementing-activities.html",redirect:"/docs/java-client/implementing-activities/"},{name:"v-3c541bc2",path:"/docs/java-client/versioning/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-3c541bc2").then(n)}},{path:"/docs/java-client/versioning/index.html",redirect:"/docs/java-client/versioning/"},{path:"/docs/04-java-client/07-versioning.html",redirect:"/docs/java-client/versioning/"},{name:"v-423a333c",path:"/docs/java-client/distributed-cron/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-423a333c").then(n)}},{path:"/docs/java-client/distributed-cron/index.html",redirect:"/docs/java-client/distributed-cron/"},{path:"/docs/04-java-client/08-distributed-cron.html",redirect:"/docs/java-client/distributed-cron/"},{name:"v-4af1f23c",path:"/docs/java-client/activity-interface/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-4af1f23c").then(n)}},{path:"/docs/java-client/activity-interface/index.html",redirect:"/docs/java-client/activity-interface/"},{path:"/docs/04-java-client/05-activity-interface.html",redirect:"/docs/java-client/activity-interface/"},{name:"v-65cef250",path:"/docs/java-client/signals/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-65cef250").then(n)}},{path:"/docs/java-client/signals/index.html",redirect:"/docs/java-client/signals/"},{path:"/docs/04-java-client/10-signals.html",redirect:"/docs/java-client/signals/"},{name:"v-47638d30",path:"/docs/java-client/workers/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-47638d30").then(n)}},{path:"/docs/java-client/workers/index.html",redirect:"/docs/java-client/workers/"},{path:"/docs/04-java-client/09-workers.html",redirect:"/docs/java-client/workers/"},{name:"v-47e211a0",path:"/docs/java-client/queries/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-47e211a0").then(n)}},{path:"/docs/java-client/queries/index.html",redirect:"/docs/java-client/queries/"},{path:"/docs/04-java-client/11-queries.html",redirect:"/docs/java-client/queries/"},{name:"v-2ef7ad44",path:"/docs/java-client/retries/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-2ef7ad44").then(n)}},{path:"/docs/java-client/retries/index.html",redirect:"/docs/java-client/retries/"},{path:"/docs/04-java-client/12-retries.html",redirect:"/docs/java-client/retries/"},{name:"v-d965e2bc",path:"/docs/java-client/exception-handling/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-d965e2bc").then(n)}},{path:"/docs/java-client/exception-handling/index.html",redirect:"/docs/java-client/exception-handling/"},{path:"/docs/04-java-client/14-exception-handling.html",redirect:"/docs/java-client/exception-handling/"},{name:"v-272408a2",path:"/docs/java-client/child-workflows/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-272408a2").then(n)}},{path:"/docs/java-client/child-workflows/index.html",redirect:"/docs/java-client/child-workflows/"},{path:"/docs/04-java-client/13-child-workflows.html",redirect:"/docs/java-client/child-workflows/"},{name:"v-68ae0de4",path:"/docs/java-client/continue-as-new/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-68ae0de4").then(n)}},{path:"/docs/java-client/continue-as-new/index.html",redirect:"/docs/java-client/continue-as-new/"},{path:"/docs/04-java-client/15-continue-as-new.html",redirect:"/docs/java-client/continue-as-new/"},{name:"v-53d65f58",path:"/docs/java-client/side-effect/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-53d65f58").then(n)}},{path:"/docs/java-client/side-effect/index.html",redirect:"/docs/java-client/side-effect/"},{path:"/docs/04-java-client/16-side-effect.html",redirect:"/docs/java-client/side-effect/"},{name:"v-56629f80",path:"/docs/java-client/testing/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-56629f80").then(n)}},{path:"/docs/java-client/testing/index.html",redirect:"/docs/java-client/testing/"},{path:"/docs/04-java-client/17-testing.html",redirect:"/docs/java-client/testing/"},{name:"v-861efabc",path:"/docs/go-client/create-workflows/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-861efabc").then(n)}},{path:"/docs/go-client/create-workflows/index.html",redirect:"/docs/go-client/create-workflows/"},{path:"/docs/05-go-client/02-create-workflows.html",redirect:"/docs/go-client/create-workflows/"},{name:"v-c1687e0a",path:"/docs/java-client/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-c1687e0a").then(n)}},{path:"/docs/java-client/index.html",redirect:"/docs/java-client/"},{path:"/docs/04-java-client/",redirect:"/docs/java-client/"},{name:"v-7a33750a",path:"/docs/java-client/workflow-replay-shadowing/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-7a33750a").then(n)}},{path:"/docs/java-client/workflow-replay-shadowing/index.html",redirect:"/docs/java-client/workflow-replay-shadowing/"},{path:"/docs/04-java-client/18-workflow-replay-shadowing.html",redirect:"/docs/java-client/workflow-replay-shadowing/"},{name:"v-76c4aa02",path:"/docs/go-client/start-workflows/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-76c4aa02").then(n)}},{path:"/docs/go-client/start-workflows/index.html",redirect:"/docs/go-client/start-workflows/"},{path:"/docs/05-go-client/02.5-starting-workflows.html",redirect:"/docs/go-client/start-workflows/"},{name:"v-e5936714",path:"/docs/go-client/workers/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-e5936714").then(n)}},{path:"/docs/go-client/workers/index.html",redirect:"/docs/go-client/workers/"},{path:"/docs/05-go-client/01-workers.html",redirect:"/docs/go-client/workers/"},{name:"v-43760982",path:"/docs/go-client/activities/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-43760982").then(n)}},{path:"/docs/go-client/activities/index.html",redirect:"/docs/go-client/activities/"},{path:"/docs/05-go-client/03-activities.html",redirect:"/docs/go-client/activities/"},{name:"v-caeda73c",path:"/docs/go-client/execute-activity/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-caeda73c").then(n)}},{path:"/docs/go-client/execute-activity/index.html",redirect:"/docs/go-client/execute-activity/"},{path:"/docs/05-go-client/04-execute-activity.html",redirect:"/docs/go-client/execute-activity/"},{name:"v-0327ca12",path:"/docs/go-client/child-workflows/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-0327ca12").then(n)}},{path:"/docs/go-client/child-workflows/index.html",redirect:"/docs/go-client/child-workflows/"},{path:"/docs/05-go-client/05-child-workflows.html",redirect:"/docs/go-client/child-workflows/"},{name:"v-5fac5e6c",path:"/docs/go-client/retries/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-5fac5e6c").then(n)}},{path:"/docs/go-client/retries/index.html",redirect:"/docs/go-client/retries/"},{path:"/docs/05-go-client/06-retries.html",redirect:"/docs/go-client/retries/"},{name:"v-595589a2",path:"/docs/go-client/error-handling/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-595589a2").then(n)}},{path:"/docs/go-client/error-handling/index.html",redirect:"/docs/go-client/error-handling/"},{path:"/docs/05-go-client/07-error-handling.html",redirect:"/docs/go-client/error-handling/"},{name:"v-7732347a",path:"/docs/go-client/continue-as-new/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-7732347a").then(n)}},{path:"/docs/go-client/continue-as-new/index.html",redirect:"/docs/go-client/continue-as-new/"},{path:"/docs/05-go-client/09-continue-as-new.html",redirect:"/docs/go-client/continue-as-new/"},{name:"v-67f3ae7c",path:"/docs/go-client/signals/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-67f3ae7c").then(n)}},{path:"/docs/go-client/signals/index.html",redirect:"/docs/go-client/signals/"},{path:"/docs/05-go-client/08-signals.html",redirect:"/docs/go-client/signals/"},{name:"v-a1460e54",path:"/docs/go-client/queries/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-a1460e54").then(n)}},{path:"/docs/go-client/queries/index.html",redirect:"/docs/go-client/queries/"},{path:"/docs/05-go-client/11-queries.html",redirect:"/docs/go-client/queries/"},{name:"v-d0383dd4",path:"/docs/go-client/side-effect/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-d0383dd4").then(n)}},{path:"/docs/go-client/side-effect/index.html",redirect:"/docs/go-client/side-effect/"},{path:"/docs/05-go-client/10-side-effect.html",redirect:"/docs/go-client/side-effect/"},{name:"v-0a1dd2ec",path:"/docs/go-client/activity-async-completion/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-0a1dd2ec").then(n)}},{path:"/docs/go-client/activity-async-completion/index.html",redirect:"/docs/go-client/activity-async-completion/"},{path:"/docs/05-go-client/12-activity-async-completion.html",redirect:"/docs/go-client/activity-async-completion/"},{name:"v-c8a8f07c",path:"/docs/go-client/workflow-testing/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-c8a8f07c").then(n)}},{path:"/docs/go-client/workflow-testing/index.html",redirect:"/docs/go-client/workflow-testing/"},{path:"/docs/05-go-client/13-workflow-testing.html",redirect:"/docs/go-client/workflow-testing/"},{name:"v-0b9844ac",path:"/docs/go-client/workflow-versioning/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-0b9844ac").then(n)}},{path:"/docs/go-client/workflow-versioning/index.html",redirect:"/docs/go-client/workflow-versioning/"},{path:"/docs/05-go-client/14-workflow-versioning.html",redirect:"/docs/go-client/workflow-versioning/"},{name:"v-edf882bc",path:"/docs/go-client/sessions/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-edf882bc").then(n)}},{path:"/docs/go-client/sessions/index.html",redirect:"/docs/go-client/sessions/"},{path:"/docs/05-go-client/15-sessions.html",redirect:"/docs/go-client/sessions/"},{name:"v-35913a62",path:"/docs/go-client/distributed-cron/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-35913a62").then(n)}},{path:"/docs/go-client/distributed-cron/index.html",redirect:"/docs/go-client/distributed-cron/"},{path:"/docs/05-go-client/16-distributed-cron.html",redirect:"/docs/go-client/distributed-cron/"},{name:"v-9d2716dc",path:"/docs/go-client/tracing/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-9d2716dc").then(n)}},{path:"/docs/go-client/tracing/index.html",redirect:"/docs/go-client/tracing/"},{path:"/docs/05-go-client/17-tracing.html",redirect:"/docs/go-client/tracing/"},{name:"v-d043b980",path:"/docs/go-client/workflow-replay-shadowing/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-d043b980").then(n)}},{path:"/docs/go-client/workflow-replay-shadowing/index.html",redirect:"/docs/go-client/workflow-replay-shadowing/"},{path:"/docs/05-go-client/18-workflow-replay-shadowing.html",redirect:"/docs/go-client/workflow-replay-shadowing/"},{name:"v-6fa6d57b",path:"/docs/cli/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-6fa6d57b").then(n)}},{path:"/docs/cli/index.html",redirect:"/docs/cli/"},{path:"/docs/06-cli/",redirect:"/docs/cli/"},{name:"v-740be4db",path:"/docs/go-client/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-740be4db").then(n)}},{path:"/docs/go-client/index.html",redirect:"/docs/go-client/"},{path:"/docs/05-go-client/",redirect:"/docs/go-client/"},{name:"v-5df8103c",path:"/docs/go-client/workflow-non-deterministic-errors/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-5df8103c").then(n)}},{path:"/docs/go-client/workflow-non-deterministic-errors/index.html",redirect:"/docs/go-client/workflow-non-deterministic-errors/"},{path:"/docs/05-go-client/19-workflow-non-deterministic-error.html",redirect:"/docs/go-client/workflow-non-deterministic-errors/"},{name:"v-6be5daf6",path:"/docs/operation-guide/setup/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-6be5daf6").then(n)}},{path:"/docs/operation-guide/setup/index.html",redirect:"/docs/operation-guide/setup/"},{path:"/docs/07-operation-guide/01-setup.html",redirect:"/docs/operation-guide/setup/"},{name:"v-c3677d3c",path:"/docs/operation-guide/maintain/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-c3677d3c").then(n)}},{path:"/docs/operation-guide/maintain/index.html",redirect:"/docs/operation-guide/maintain/"},{path:"/docs/07-operation-guide/02-maintain.html",redirect:"/docs/operation-guide/maintain/"},{name:"v-1a836dbc",path:"/docs/operation-guide/monitor/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-1a836dbc").then(n)}},{path:"/docs/operation-guide/monitor/index.html",redirect:"/docs/operation-guide/monitor/"},{path:"/docs/07-operation-guide/03-monitoring.html",redirect:"/docs/operation-guide/monitor/"},{name:"v-6f38e6b6",path:"/docs/operation-guide/troubleshooting/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-6f38e6b6").then(n)}},{path:"/docs/operation-guide/troubleshooting/index.html",redirect:"/docs/operation-guide/troubleshooting/"},{path:"/docs/07-operation-guide/04-troubleshooting.html",redirect:"/docs/operation-guide/troubleshooting/"},{name:"v-fc381aca",path:"/docs/operation-guide/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-fc381aca").then(n)}},{path:"/docs/operation-guide/index.html",redirect:"/docs/operation-guide/"},{path:"/docs/07-operation-guide/",redirect:"/docs/operation-guide/"},{name:"v-3569388c",path:"/docs/operation-guide/migration/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-3569388c").then(n)}},{path:"/docs/operation-guide/migration/index.html",redirect:"/docs/operation-guide/migration/"},{path:"/docs/07-operation-guide/05-migration.html",redirect:"/docs/operation-guide/migration/"},{name:"v-00ee1f44",path:"/docs/about/license/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-00ee1f44").then(n)}},{path:"/docs/about/license/index.html",redirect:"/docs/about/license/"},{path:"/docs/08-about/01-license.html",redirect:"/docs/about/license/"},{name:"v-fa725f4a",path:"/docs/about/",component:Ds,beforeEnter:(e,t,n)=>{us("default","v-fa725f4a").then(n)}},{path:"/docs/about/index.html",redirect:"/docs/about/"},{path:"/docs/08-about/",redirect:"/docs/about/"},{name:"v-7256933b",path:"/",component:Ds,beforeEnter:(e,t,n)=>{us("Layout","v-7256933b").then(n)}},{path:"/index.html",redirect:"/"},{path:"*",component:Ds}],js={title:"Cadence",description:"",base:"/",headTags:[["link",{rel:"icon",href:"/img/favicon.ico"}]],pages:[{title:"Glossary",frontmatter:{layout:"default",title:"Glossary",terms:{activity:"A business-level function that implements your application logic such as calling a service or transcoding a media file. An activity usually implements a single well-defined action; it can be short or long running. An activity can be implemented as a synchronous method or fully asynchronously involving multiple processes. An activity can be retried indefinitely according to the provided exponential retry policy. If for any reason an activity is not completed within the specified timeout, an error is reported to the workflow and the workflow decides how to handle it. There is no limit on potential activity duration.","activity task":"A task that contains an activity invocation information that is delivered to an activity worker through and an  activity task list. An activity worker upon receiving activity task executes a correponding activity","activity task list":"Task list that is used to deliver activity task to activity worker","activity worker":"An object that is executed in the client application and receives activity task from an  activity task list it is subscribed to. Once task is received it invokes a correspondent activity.",archival:"Archival is a feature that automatically moves event history from persistence to a blobstore after the workflow retention period. The purpose of archival is to be able to keep histories as long as needed while not overwhelming the persistence store. There are two reasons you may want to keep the histories after the retention period has passed: 1. Compliance: For legal reasons, histories may need to be stored for a long period of time. 2. Debugging: Old histories can still be accessed for debugging.",CLI:"Cadence command-line interface.","client stub":"A client-side proxy used to make remote invocations to an entity that it represents. For example, to start a workflow, a stub object that represents this workflow is created through a special API. Then this stub is used to start, query, or signal the corresponding workflow.\nThe Go client doesn't use this.",decision:"Any action taken by the workflow durable function is called a decision. For example: scheduling an activity, canceling a child workflow, or starting a timer. A decision task contains an optional list of decisions. Every decision is recorded in the event history as an event. See also [1] for more explanation","decision task":"Every time a new external event that might affect a workflow state is recorded, a decision task that contains it is added to a decision task list and then picked up by a workflow worker. After the new event is handled, the decision task is completed with a list of decision. Note that handling of a decision task is usually very fast and is not related to duration of operations that the workflow invokes. See also [1] for more explanation","decision task list":"Task list that is used to deliver decision task to workflow worker. From user's point of view, it can be viewed as a worker pool. It defines a pool of worker executing workflow or activity tasks.",domain:"Cadence is backed by a multitenant service. The unit of isolation is called a domain. Each domain acts as a namespace for task list names as well as workflow IDs. For example, when a workflow is started, it is started in a specific domain. Cadence guarantees a unique workflow ID within a domain, and supports running workflow executions to use the same workflow ID if they are in different domains. Various configuration options like retention period or archival destination are configured per domain as well through a special CRUD API or through the Cadence CLI. In the multi-cluster deployment, domain is a unit of fail-over. Each domain can only be active on a single Cadence cluster at a time. However, different domains can be active in different clusters and can fail-over independently.",event:"An indivisible operation performed by your application. For example, activity_task_started, task_failed, or timer_canceled. Events are recorded in the event history.","event history":"An append log of events for your application. History is durably persisted by the Cadence service, enabling seamless recovery of your application state from crashes or failures. It also serves as an audit log for debugging.","local activity":"A local activity is an activity that is invoked directly in the same process by a workflow code. It consumes much less resources than a normal activity, but imposes a lot of limitations like low duration and lack of rate limiting.",query:"A synchronous (from the caller's point of view) operation that is used to report a workflow state. Note that a query is inherently read only and cannot affect a workflow state.","run ID":"A UUID that a Cadence service assigns to each workflow run. If allowed by a configured policy, you might be able to re-execute a workflow, after it has closed or failed, with the same workflow id. Each such re-execution is called a run. run id is used to uniquely identify a run even if it shares a workflow id with others.",signal:"An external asynchronous request to a workflow. It can be used to deliver notifications or updates to a running workflow at any point in its existence.",task:"The context needed to execute a specific activity or workflow state transition. There are two types of tasks: an activity task and a decision task (aka workflow task). Note that a single activity execution corresponds to a single activity task, while a workflow execution employs multiple decision tasks.","task list":"Common name for activity task list and decision task list","task token":"A unique correlation ID for a Cadence activity. Activity completion calls take either task token or DomainName, WorkflowID, ActivityID arguments.",worker:"Also known as a worker service. A service that hosts the workflow and activity implementations. The worker polls the Cadence service for tasks, performs those tasks, and communicates task execution results back to the Cadence service. Worker services are developed, deployed, and operated by Cadence customers.",workflow:"A fault-oblivious stateful function that orchestrates activities. A workflow has full control over which activities are executed, and in which order. A workflow must not affect the external world directly, only through activities. What makes workflow code a workflow is that its state is preserved by Cadence. Therefore any failure of a worker process that hosts the workflow code does not affect the workflow execution. The workflow continues as if these failures did not happen. At the same time, activities can fail any moment for any reason. Because workflow code is fully fault-oblivious, it is guaranteed to get notifications about activity failures or timeouts and act accordingly. There is no limit on potential workflow duration.","workflow execution":"An instance of a workflow. The instance can be in the process of executing or it could have already completed execution.","workflow ID":"A unique identifier for a workflow execution. Cadence guarantees the uniqueness of an ID within a domain. An attempt to start a workflow with a duplicate ID results in an already started error.","workflow task":"Synonym of the decision task.","workflow worker":"An object that is executed in the client application and receives decision task from an  decision task list it is subscribed to. Once task is received it is handled by a correponding workflow."},readingShow:"top"},regularPath:"/GLOSSARY.html",relativePath:"GLOSSARY.md",key:"v-9cd9f09c",path:"/GLOSSARY.html",codeSwitcherOptions:{},headersStr:null,content:"# Glossary\n\n1 What exactly is a Cadence decision task?",normalizedContent:"# glossary\n\n1 what exactly is a cadence decision task?",charsets:{}},{title:"Java hello world",frontmatter:{layout:"default",title:"Java hello world",permalink:"/docs/get-started/java-hello-world",readingShow:"top"},regularPath:"/docs/01-get-started/02-java-hello-world.html",relativePath:"docs/01-get-started/02-java-hello-world.md",key:"v-40447742",path:"/docs/get-started/java-hello-world/",headers:[{level:2,title:"Include Cadence Java Client Dependency",slug:"include-cadence-java-client-dependency",normalizedTitle:"include cadence java client dependency",charIndex:295},{level:2,title:"Implement Hello World Workflow",slug:"implement-hello-world-workflow",normalizedTitle:"implement hello world workflow",charIndex:1932},{level:2,title:"Execute Hello World Workflow using the CLI",slug:"execute-hello-world-workflow-using-the-cli",normalizedTitle:"execute hello world workflow using the cli",charIndex:3650},{level:2,title:"List Workflows and Workflow History",slug:"list-workflows-and-workflow-history",normalizedTitle:"list workflows and workflow history",charIndex:7725},{level:2,title:"What is Next",slug:"what-is-next",normalizedTitle:"what is next",charIndex:10214}],codeSwitcherOptions:{},headersStr:"Include Cadence Java Client Dependency Implement Hello World Workflow Execute Hello World Workflow using the CLI List Workflows and Workflow History What is Next",content:'# Java Hello World\n\nThis section provides step by step instructions on how to write and run a HelloWorld with Java.\n\nFor complete, ready to build samples covering all the key Cadence concepts go to Cadence-Java-Samples.\n\nYou can also review Java-Client and java-docs for more documentation.\n\n\n# Include Cadence Java Client Dependency\n\nGo to the Maven Repository Uber Cadence Java Client Page and find the latest version of the library. Include it as a dependency into your Java project. For example if you are using Gradle the dependency looks like:\n\ncompile group: \'com.uber.cadence\', name: \'cadence-client\', version: \'<latest_version>\'\n\n\nAlso add the following dependencies that cadence-client relies on:\n\ncompile group: \'commons-configuration\', name: \'commons-configuration\', version: \'1.9\'\ncompile group: \'ch.qos.logback\', name: \'logback-classic\', version: \'1.2.3\'\n\n\nMake sure that the following code compiles:\n\nimport com.uber.cadence.workflow.Workflow;\nimport com.uber.cadence.workflow.WorkflowMethod;\nimport org.slf4j.Logger;\n\npublic class GettingStarted {\n\n    private static Logger logger = Workflow.getLogger(GettingStarted.class);\n\n    public interface HelloWorld {\n        @WorkflowMethod\n        void sayHello(String name);\n    }\n\n}\n\n\nIf you are having problems setting up the build files use the Cadence Java Samples GitHub repository as a reference.\n\nAlso add the following logback config file somewhere in your classpath:\n\n<configuration>\n    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">\n        \x3c!-- encoders are assigned the type\n             ch.qos.logback.classic.encoder.PatternLayoutEncoder by default --\x3e\n        <encoder>\n            <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>\n        </encoder>\n    </appender>\n    <logger name="io.netty" level="INFO"/>\n    <root level="INFO">\n        <appender-ref ref="STDOUT" />\n    </root>\n</configuration>\n\n\n\n# Implement Hello World Workflow\n\nLet\'s add HelloWorldImpl with the sayHello method that just logs the "Hello ..." and returns.\n\nimport com.uber.cadence.worker.Worker;\nimport com.uber.cadence.workflow.Workflow;\nimport com.uber.cadence.workflow.WorkflowMethod;\nimport org.slf4j.Logger;\n\npublic class GettingStarted {\n\n    private static Logger logger = Workflow.getLogger(GettingStarted.class);\n\n    public interface HelloWorld {\n        @WorkflowMethod\n        void sayHello(String name);\n    }\n\n    public static class HelloWorldImpl implements HelloWorld {\n\n        @Override\n        public void sayHello(String name) {\n            logger.info("Hello " + name + "!");\n        }\n    }\n}\n\n\nTo link the implementation to the Cadence framework, it should be registered with a that connects to a Cadence Service. By default the connects to the locally running Cadence service.\n\npublic static void main(String[] args) {\n  WorkflowClient workflowClient =\n      WorkflowClient.newInstance(\n          new WorkflowServiceTChannel(ClientOptions.defaultInstance()),\n          WorkflowClientOptions.newBuilder().setDomain(DOMAIN).build());\n  // Get worker to poll the task list.\n  WorkerFactory factory = WorkerFactory.newInstance(workflowClient);\n  Worker worker = factory.newWorker(TASK_LIST);\n  worker.registerWorkflowImplementationTypes(HelloWorldImpl.class);\n  factory.start();\n}\n\n\nThe code is slightly different if you are using client version prior to 3.0.0:\n\npublic static void main(String[] args) {\n    Worker.Factory factory = new Worker.Factory("test-domain");\n    Worker worker = factory.newWorker("HelloWorldTaskList");\n    worker.registerWorkflowImplementationTypes(HelloWorldImpl.class);\n    factory.start();\n}\n\n\n\n# Execute Hello World Workflow using the CLI\n\nNow run the program. Following is an example log:\n\n13:35:02.575 [main] INFO  c.u.c.s.WorkflowServiceTChannel - Initialized TChannel for service cadence-frontend, LibraryVersion: 2.2.0, FeatureVersion: 1.0.0\n13:35:02.671 [main] INFO  c.u.cadence.internal.worker.Poller - start(): Poller{options=PollerOptions{maximumPollRateIntervalMilliseconds=1000, maximumPollRatePerSecond=0.0, pollBackoffCoefficient=2.0, pollBackoffInitialInterval=PT0.2S, pollBackoffMaximumInterval=PT20S, pollThreadCount=1, pollThreadNamePrefix=\'Workflow Poller taskList="HelloWorldTaskList", domain="test-domain", type="workflow"\'}, identity=45937@maxim-C02XD0AAJGH6}\n13:35:02.673 [main] INFO  c.u.cadence.internal.worker.Poller - start(): Poller{options=PollerOptions{maximumPollRateIntervalMilliseconds=1000, maximumPollRatePerSecond=0.0, pollBackoffCoefficient=2.0, pollBackoffInitialInterval=PT0.2S, pollBackoffMaximumInterval=PT20S, pollThreadCount=1, pollThreadNamePrefix=\'null\'}, identity=81b8d0ac-ff89-47e8-b842-3dd26337feea}\n\n\nNo Hello printed. This is expected because a is just a code host. The has to be started to execute. Let\'s use Cadence to start the workflow:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start --tasklist HelloWorldTaskList --workflow_type HelloWorld::sayHello --execution_timeout 3600 --input \\"World\\"\nStarted Workflow Id: bcacfabd-9f9a-46ac-9b25-83bcea5d7fd7, run Id: e7c40431-8e23-485b-9649-e8f161219efe\n\n\nThe output of the program should change to:\n\n13:35:02.575 [main] INFO  c.u.c.s.WorkflowServiceTChannel - Initialized TChannel for service cadence-frontend, LibraryVersion: 2.2.0, FeatureVersion: 1.0.0\n13:35:02.671 [main] INFO  c.u.cadence.internal.worker.Poller - start(): Poller{options=PollerOptions{maximumPollRateIntervalMilliseconds=1000, maximumPollRatePerSecond=0.0, pollBackoffCoefficient=2.0, pollBackoffInitialInterval=PT0.2S, pollBackoffMaximumInterval=PT20S, pollThreadCount=1, pollThreadNamePrefix=\'Workflow Poller taskList="HelloWorldTaskList", domain="test-domain", type="workflow"\'}, identity=45937@maxim-C02XD0AAJGH6}\n13:35:02.673 [main] INFO  c.u.cadence.internal.worker.Poller - start(): Poller{options=PollerOptions{maximumPollRateIntervalMilliseconds=1000, maximumPollRatePerSecond=0.0, pollBackoffCoefficient=2.0, pollBackoffInitialInterval=PT0.2S, pollBackoffMaximumInterval=PT20S, pollThreadCount=1, pollThreadNamePrefix=\'null\'}, identity=81b8d0ac-ff89-47e8-b842-3dd26337feea}\n13:40:28.308 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - Hello World!\n\n\nLet\'s start another\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start --tasklist HelloWorldTaskList --workflow_type HelloWorld::sayHello --execution_timeout 3600 --input \\"Cadence\\"\nStarted Workflow Id: d2083532-9c68-49ab-90e1-d960175377a7, run Id: 331bfa04-834b-45a7-861e-bcb9f6ddae3e\n\n\nAnd the output changed to:\n\n13:35:02.575 [main] INFO  c.u.c.s.WorkflowServiceTChannel - Initialized TChannel for service cadence-frontend, LibraryVersion: 2.2.0, FeatureVersion: 1.0.0\n13:35:02.671 [main] INFO  c.u.cadence.internal.worker.Poller - start(): Poller{options=PollerOptions{maximumPollRateIntervalMilliseconds=1000, maximumPollRatePerSecond=0.0, pollBackoffCoefficient=2.0, pollBackoffInitialInterval=PT0.2S, pollBackoffMaximumInterval=PT20S, pollThreadCount=1, pollThreadNamePrefix=\'Workflow Poller taskList="HelloWorldTaskList", domain="test-domain", type="workflow"\'}, identity=45937@maxim-C02XD0AAJGH6}\n13:35:02.673 [main] INFO  c.u.cadence.internal.worker.Poller - start(): Poller{options=PollerOptions{maximumPollRateIntervalMilliseconds=1000, maximumPollRatePerSecond=0.0, pollBackoffCoefficient=2.0, pollBackoffInitialInterval=PT0.2S, pollBackoffMaximumInterval=PT20S, pollThreadCount=1, pollThreadNamePrefix=\'null\'}, identity=81b8d0ac-ff89-47e8-b842-3dd26337feea}\n13:40:28.308 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - Hello World!\n13:42:34.994 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - Hello Cadence!\n\n\n\n# List Workflows and Workflow History\n\nLet\'s list our in the\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow list\n             WORKFLOW TYPE            |             WORKFLOW ID              |                RUN ID                | START TIME | EXECUTION TIME | END TIME\n  HelloWorld::sayHello                | d2083532-9c68-49ab-90e1-d960175377a7 | 331bfa04-834b-45a7-861e-bcb9f6ddae3e | 20:42:34   | 20:42:34       | 20:42:35\n  HelloWorld::sayHello                | bcacfabd-9f9a-46ac-9b25-83bcea5d7fd7 | e7c40431-8e23-485b-9649-e8f161219efe | 20:40:28   | 20:40:28       | 20:40:29\n\n\nNow let\'s look at the history:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow showid 1965109f-607f-4b14-a5f2-24399a7b8fa7\n  1  WorkflowExecutionStarted    {WorkflowType:{Name:HelloWorld::sayHello},\n                                  TaskList:{Name:HelloWorldTaskList},\n                                  Input:["World"],\n                                  ExecutionStartToCloseTimeoutSeconds:3600,\n                                  TaskStartToCloseTimeoutSeconds:10,\n                                  ContinuedFailureDetails:[],\n                                  LastCompletionResult:[],\n                                  Identity:cadence-cli@linuxkit-025000000001,\n                                  Attempt:0,\n                                  FirstDecisionTaskBackoffSeconds:0}\n  2  DecisionTaskScheduled       {TaskList:{Name:HelloWorldTaskList},\n                                  StartToCloseTimeoutSeconds:10,\n                                  Attempt:0}\n  3  DecisionTaskStarted         {ScheduledEventId:2,\n                                  Identity:45937@maxim-C02XD0AAJGH6,\n                                  RequestId:481a14e5-67a4-436e-9a23-7f7fb7f87ef3}\n  4  DecisionTaskCompleted       {ExecutionContext:[],\n                                  ScheduledEventId:2,\n                                  StartedEventId:3,\n                                  Identity:45937@maxim-C02XD0AAJGH6}\n  5  WorkflowExecutionCompleted  {Result:[],\n                                  DecisionTaskCompletedEventId:4}\n\n\nEven for such a trivial , the history gives a lot of useful information. For complex this is a really useful tool for production and development troubleshooting. History can be automatically archived to a long-term blob store (for example Amazon S3) upon completion for compliance, analytical, and troubleshooting purposes.\n\n\n# What is Next\n\nNow you have completed the tutorials. You can continue to explore the key concepts in Cadence, and also how to use them with Java Client',normalizedContent:'# java hello world\n\nthis section provides step by step instructions on how to write and run a helloworld with java.\n\nfor complete, ready to build samples covering all the key cadence concepts go to cadence-java-samples.\n\nyou can also review java-client and java-docs for more documentation.\n\n\n# include cadence java client dependency\n\ngo to the maven repository uber cadence java client page and find the latest version of the library. include it as a dependency into your java project. for example if you are using gradle the dependency looks like:\n\ncompile group: \'com.uber.cadence\', name: \'cadence-client\', version: \'<latest_version>\'\n\n\nalso add the following dependencies that cadence-client relies on:\n\ncompile group: \'commons-configuration\', name: \'commons-configuration\', version: \'1.9\'\ncompile group: \'ch.qos.logback\', name: \'logback-classic\', version: \'1.2.3\'\n\n\nmake sure that the following code compiles:\n\nimport com.uber.cadence.workflow.workflow;\nimport com.uber.cadence.workflow.workflowmethod;\nimport org.slf4j.logger;\n\npublic class gettingstarted {\n\n    private static logger logger = workflow.getlogger(gettingstarted.class);\n\n    public interface helloworld {\n        @workflowmethod\n        void sayhello(string name);\n    }\n\n}\n\n\nif you are having problems setting up the build files use the cadence java samples github repository as a reference.\n\nalso add the following logback config file somewhere in your classpath:\n\n<configuration>\n    <appender name="stdout" class="ch.qos.logback.core.consoleappender">\n        \x3c!-- encoders are assigned the type\n             ch.qos.logback.classic.encoder.patternlayoutencoder by default --\x3e\n        <encoder>\n            <pattern>%d{hh:mm:ss.sss} [%thread] %-5level %logger{36} - %msg%n</pattern>\n        </encoder>\n    </appender>\n    <logger name="io.netty" level="info"/>\n    <root level="info">\n        <appender-ref ref="stdout" />\n    </root>\n</configuration>\n\n\n\n# implement hello world workflow\n\nlet\'s add helloworldimpl with the sayhello method that just logs the "hello ..." and returns.\n\nimport com.uber.cadence.worker.worker;\nimport com.uber.cadence.workflow.workflow;\nimport com.uber.cadence.workflow.workflowmethod;\nimport org.slf4j.logger;\n\npublic class gettingstarted {\n\n    private static logger logger = workflow.getlogger(gettingstarted.class);\n\n    public interface helloworld {\n        @workflowmethod\n        void sayhello(string name);\n    }\n\n    public static class helloworldimpl implements helloworld {\n\n        @override\n        public void sayhello(string name) {\n            logger.info("hello " + name + "!");\n        }\n    }\n}\n\n\nto link the implementation to the cadence framework, it should be registered with a that connects to a cadence service. by default the connects to the locally running cadence service.\n\npublic static void main(string[] args) {\n  workflowclient workflowclient =\n      workflowclient.newinstance(\n          new workflowservicetchannel(clientoptions.defaultinstance()),\n          workflowclientoptions.newbuilder().setdomain(domain).build());\n  // get worker to poll the task list.\n  workerfactory factory = workerfactory.newinstance(workflowclient);\n  worker worker = factory.newworker(task_list);\n  worker.registerworkflowimplementationtypes(helloworldimpl.class);\n  factory.start();\n}\n\n\nthe code is slightly different if you are using client version prior to 3.0.0:\n\npublic static void main(string[] args) {\n    worker.factory factory = new worker.factory("test-domain");\n    worker worker = factory.newworker("helloworldtasklist");\n    worker.registerworkflowimplementationtypes(helloworldimpl.class);\n    factory.start();\n}\n\n\n\n# execute hello world workflow using the cli\n\nnow run the program. following is an example log:\n\n13:35:02.575 [main] info  c.u.c.s.workflowservicetchannel - initialized tchannel for service cadence-frontend, libraryversion: 2.2.0, featureversion: 1.0.0\n13:35:02.671 [main] info  c.u.cadence.internal.worker.poller - start(): poller{options=polleroptions{maximumpollrateintervalmilliseconds=1000, maximumpollratepersecond=0.0, pollbackoffcoefficient=2.0, pollbackoffinitialinterval=pt0.2s, pollbackoffmaximuminterval=pt20s, pollthreadcount=1, pollthreadnameprefix=\'workflow poller tasklist="helloworldtasklist", domain="test-domain", type="workflow"\'}, identity=45937@maxim-c02xd0aajgh6}\n13:35:02.673 [main] info  c.u.cadence.internal.worker.poller - start(): poller{options=polleroptions{maximumpollrateintervalmilliseconds=1000, maximumpollratepersecond=0.0, pollbackoffcoefficient=2.0, pollbackoffinitialinterval=pt0.2s, pollbackoffmaximuminterval=pt20s, pollthreadcount=1, pollthreadnameprefix=\'null\'}, identity=81b8d0ac-ff89-47e8-b842-3dd26337feea}\n\n\nno hello printed. this is expected because a is just a code host. the has to be started to execute. let\'s use cadence to start the workflow:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start --tasklist helloworldtasklist --workflow_type helloworld::sayhello --execution_timeout 3600 --input \\"world\\"\nstarted workflow id: bcacfabd-9f9a-46ac-9b25-83bcea5d7fd7, run id: e7c40431-8e23-485b-9649-e8f161219efe\n\n\nthe output of the program should change to:\n\n13:35:02.575 [main] info  c.u.c.s.workflowservicetchannel - initialized tchannel for service cadence-frontend, libraryversion: 2.2.0, featureversion: 1.0.0\n13:35:02.671 [main] info  c.u.cadence.internal.worker.poller - start(): poller{options=polleroptions{maximumpollrateintervalmilliseconds=1000, maximumpollratepersecond=0.0, pollbackoffcoefficient=2.0, pollbackoffinitialinterval=pt0.2s, pollbackoffmaximuminterval=pt20s, pollthreadcount=1, pollthreadnameprefix=\'workflow poller tasklist="helloworldtasklist", domain="test-domain", type="workflow"\'}, identity=45937@maxim-c02xd0aajgh6}\n13:35:02.673 [main] info  c.u.cadence.internal.worker.poller - start(): poller{options=polleroptions{maximumpollrateintervalmilliseconds=1000, maximumpollratepersecond=0.0, pollbackoffcoefficient=2.0, pollbackoffinitialinterval=pt0.2s, pollbackoffmaximuminterval=pt20s, pollthreadcount=1, pollthreadnameprefix=\'null\'}, identity=81b8d0ac-ff89-47e8-b842-3dd26337feea}\n13:40:28.308 [workflow-root] info  c.u.c.samples.hello.gettingstarted - hello world!\n\n\nlet\'s start another\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start --tasklist helloworldtasklist --workflow_type helloworld::sayhello --execution_timeout 3600 --input \\"cadence\\"\nstarted workflow id: d2083532-9c68-49ab-90e1-d960175377a7, run id: 331bfa04-834b-45a7-861e-bcb9f6ddae3e\n\n\nand the output changed to:\n\n13:35:02.575 [main] info  c.u.c.s.workflowservicetchannel - initialized tchannel for service cadence-frontend, libraryversion: 2.2.0, featureversion: 1.0.0\n13:35:02.671 [main] info  c.u.cadence.internal.worker.poller - start(): poller{options=polleroptions{maximumpollrateintervalmilliseconds=1000, maximumpollratepersecond=0.0, pollbackoffcoefficient=2.0, pollbackoffinitialinterval=pt0.2s, pollbackoffmaximuminterval=pt20s, pollthreadcount=1, pollthreadnameprefix=\'workflow poller tasklist="helloworldtasklist", domain="test-domain", type="workflow"\'}, identity=45937@maxim-c02xd0aajgh6}\n13:35:02.673 [main] info  c.u.cadence.internal.worker.poller - start(): poller{options=polleroptions{maximumpollrateintervalmilliseconds=1000, maximumpollratepersecond=0.0, pollbackoffcoefficient=2.0, pollbackoffinitialinterval=pt0.2s, pollbackoffmaximuminterval=pt20s, pollthreadcount=1, pollthreadnameprefix=\'null\'}, identity=81b8d0ac-ff89-47e8-b842-3dd26337feea}\n13:40:28.308 [workflow-root] info  c.u.c.samples.hello.gettingstarted - hello world!\n13:42:34.994 [workflow-root] info  c.u.c.samples.hello.gettingstarted - hello cadence!\n\n\n\n# list workflows and workflow history\n\nlet\'s list our in the\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow list\n             workflow type            |             workflow id              |                run id                | start time | execution time | end time\n  helloworld::sayhello                | d2083532-9c68-49ab-90e1-d960175377a7 | 331bfa04-834b-45a7-861e-bcb9f6ddae3e | 20:42:34   | 20:42:34       | 20:42:35\n  helloworld::sayhello                | bcacfabd-9f9a-46ac-9b25-83bcea5d7fd7 | e7c40431-8e23-485b-9649-e8f161219efe | 20:40:28   | 20:40:28       | 20:40:29\n\n\nnow let\'s look at the history:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow showid 1965109f-607f-4b14-a5f2-24399a7b8fa7\n  1  workflowexecutionstarted    {workflowtype:{name:helloworld::sayhello},\n                                  tasklist:{name:helloworldtasklist},\n                                  input:["world"],\n                                  executionstarttoclosetimeoutseconds:3600,\n                                  taskstarttoclosetimeoutseconds:10,\n                                  continuedfailuredetails:[],\n                                  lastcompletionresult:[],\n                                  identity:cadence-cli@linuxkit-025000000001,\n                                  attempt:0,\n                                  firstdecisiontaskbackoffseconds:0}\n  2  decisiontaskscheduled       {tasklist:{name:helloworldtasklist},\n                                  starttoclosetimeoutseconds:10,\n                                  attempt:0}\n  3  decisiontaskstarted         {scheduledeventid:2,\n                                  identity:45937@maxim-c02xd0aajgh6,\n                                  requestid:481a14e5-67a4-436e-9a23-7f7fb7f87ef3}\n  4  decisiontaskcompleted       {executioncontext:[],\n                                  scheduledeventid:2,\n                                  startedeventid:3,\n                                  identity:45937@maxim-c02xd0aajgh6}\n  5  workflowexecutioncompleted  {result:[],\n                                  decisiontaskcompletedeventid:4}\n\n\neven for such a trivial , the history gives a lot of useful information. for complex this is a really useful tool for production and development troubleshooting. history can be automatically archived to a long-term blob store (for example amazon s3) upon completion for compliance, analytical, and troubleshooting purposes.\n\n\n# what is next\n\nnow you have completed the tutorials. you can continue to explore the key concepts in cadence, and also how to use them with java client',charsets:{cjk:!0}},{title:"Golang hello world",frontmatter:{layout:"default",title:"Golang hello world",permalink:"/docs/get-started/golang-hello-world",readingShow:"top"},regularPath:"/docs/01-get-started/03-golang-hello-world.html",relativePath:"docs/01-get-started/03-golang-hello-world.md",key:"v-5261e03c",path:"/docs/get-started/golang-hello-world/",headers:[{level:2,title:"Prerequisite",slug:"prerequisite",normalizedTitle:"prerequisite",charIndex:388},{level:2,title:"Step 1. Implement A Cadence Worker Service",slug:"step-1-implement-a-cadence-worker-service",normalizedTitle:"step 1. implement a cadence worker service",charIndex:922},{level:2,title:"Step 2. Write a simple Cadence hello world activity and workflow",slug:"step-2-write-a-simple-cadence-hello-world-activity-and-workflow",normalizedTitle:"step 2. write a simple cadence hello world activity and workflow",charIndex:4615},{level:2,title:"Step 3. Run the workflow with Cadence CLI",slug:"step-3-run-the-workflow-with-cadence-cli",normalizedTitle:"step 3. run the workflow with cadence cli",charIndex:5904},{level:2,title:"(Optional) Step 4. Monitor Cadence workflow with Cadence web UI",slug:"optional-step-4-monitor-cadence-workflow-with-cadence-web-ui",normalizedTitle:"(optional) step 4. monitor cadence workflow with cadence web ui",charIndex:6701},{level:2,title:"What is Next",slug:"what-is-next",normalizedTitle:"what is next",charIndex:7153}],codeSwitcherOptions:{},headersStr:"Prerequisite Step 1. Implement A Cadence Worker Service Step 2. Write a simple Cadence hello world activity and workflow Step 3. Run the workflow with Cadence CLI (Optional) Step 4. Monitor Cadence workflow with Cadence web UI What is Next",content:'# Golang Hello World\n\nThis section provides step-by-step instructions on how to write and run a HelloWorld workflow in Cadence with Golang. You will learn two critical building blocks of Cadence: activities and workflows. First, you will write an activity function that prints a "Hello World!" message in the log. Then, you will write a workflow function that executes this activity.\n\n\n# Prerequisite\n\nTo successfully run this hello world sample, follow this checklist of setting up Cadence environment\n\n 1. Your worker is running properly and you have registered the hello world activity and workflow to the worker\n 2. Your Cadence server is running (check your background docker container process)\n 3. You have successfully registered a domain for this workflow\n\nYou must finish part 2 and 3 by following the first section to proceed the next steps. We are using domain called test-domain for this tutorial project.\n\n\n# Step 1. Implement A Cadence Worker Service\n\nCreate a new main.go file in your local directory and paste the basic worker service layout.\n\npackage main\n\nimport (\n    "net/http"\n    "go.uber.org/cadence/.gen/go/cadence/workflowserviceclient"\n    "go.uber.org/cadence/compatibility"\n    "go.uber.org/cadence/worker"\n\n    apiv1 "github.com/uber/cadence-idl/go/proto/api/v1"\n    "github.com/uber-go/tally"\n    "go.uber.org/zap"\n    "go.uber.org/zap/zapcore"\n    "go.uber.org/yarpc"\n    "go.uber.org/yarpc/transport/grpc"\n)\n\nvar HostPort = "127.0.0.1:7833"\nvar Domain = "test-domain"\nvar TaskListName = "test-worker"\nvar ClientName = "test-worker"\nvar CadenceService = "cadence-frontend"\n\nfunc main() {\n    startWorker(buildLogger(), buildCadenceClient())\n    err := http.ListenAndServe(":8080", nil)\n    if err != nil {\n        panic(err)\n    }\n}\n\nfunc buildLogger() *zap.Logger {\n    config := zap.NewDevelopmentConfig()\n    config.Level.SetLevel(zapcore.InfoLevel)\n\n    var err error\n    logger, err := config.Build()\n    if err != nil {\n        panic("Failed to setup logger")\n    }\n\n    return logger\n}\n\nfunc buildCadenceClient() workflowserviceclient.Interface {\n    dispatcher := yarpc.NewDispatcher(yarpc.Config{\n\t\tName: ClientName,\n\t\tOutbounds: yarpc.Outbounds{\n\t\t  CadenceService: {Unary: grpc.NewTransport().NewSingleOutbound(HostPort)},\n\t\t},\n\t  })\n\t  if err := dispatcher.Start(); err != nil {\n\t\tpanic("Failed to start dispatcher")\n\t  }\n  \n\t  clientConfig := dispatcher.ClientConfig(CadenceService)\n  \n\t  return compatibility.NewThrift2ProtoAdapter(\n\t\tapiv1.NewDomainAPIYARPCClient(clientConfig),\n\t\tapiv1.NewWorkflowAPIYARPCClient(clientConfig),\n\t\tapiv1.NewWorkerAPIYARPCClient(clientConfig),\n\t\tapiv1.NewVisibilityAPIYARPCClient(clientConfig),\n\t  )\n}\n\nfunc startWorker(logger *zap.Logger, service workflowserviceclient.Interface) {\n    // TaskListName identifies set of client workflows, activities, and workers.\n    // It could be your group or client or application name.\n    workerOptions := worker.Options{\n        Logger:       logger,\n        MetricsScope: tally.NewTestScope(TaskListName, map[string]string{}),\n    }\n\n    worker := worker.New(\n        service,\n        Domain,\n        TaskListName,\n        workerOptions)\n    err := worker.Start()\n    if err != nil {\n        panic("Failed to start worker")\n    }\n\n    logger.Info("Started Worker.", zap.String("worker", TaskListName))\n}\n\n\nIn this worker service, we start a HTTP server and create a new Cadence client running continuously at the background. Then start the server on your local, you may see logs such like\n\n2023-07-03T11:46:46.266-0700    INFO    internal/internal_worker.go:826 Worker has no workflows registered, so workflow worker will not be started.     {"Domain": "test-domain", "TaskList": "test-worker", "WorkerID": "35987@uber-C02F18EQMD6R@test-worker@90c0260e-ba5c-4652-9f10-c6d1f9e29c1d"}\n2023-07-03T11:46:46.267-0700    INFO    internal/internal_worker.go:834 Started Workflow Worker {"Domain": "test-domain", "TaskList": "test-worker", "WorkerID": "35987@uber-C02F18EQMD6R@test-worker@90c0260e-ba5c-4652-9f10-c6d1f9e29c1d"}\n2023-07-03T11:46:46.267-0700    INFO    internal/internal_worker.go:838 Worker has no activities registered, so activity worker will not be started.    {"Domain": "test-domain", "TaskList": "test-worker", "WorkerID": "35987@uber-C02F18EQMD6R@test-worker@90c0260e-ba5c-4652-9f10-c6d1f9e29c1d"}\n2023-07-03T11:46:46.267-0700    INFO    cadence-worker/main.go:75       Started Worker. {"worker": "test-worker"}\n\n\nYou may see this because there are no activities and workflows registered to the worker. Let\'s proceed to next steps to write a hello world activity and workflow.\n\n\n# Step 2. Write a simple Cadence hello world activity and workflow\n\nLet\'s write a hello world activity, which take a single input called name and greet us after the workflow is finished.\n\nfunc helloWorldWorkflow(ctx workflow.Context, name string) error {\n\tao := workflow.ActivityOptions{\n\t\tScheduleToStartTimeout: time.Minute,\n\t\tStartToCloseTimeout:    time.Minute,\n\t\tHeartbeatTimeout:       time.Second * 20,\n\t}\n\tctx = workflow.WithActivityOptions(ctx, ao)\n\n\tlogger := workflow.GetLogger(ctx)\n\tlogger.Info("helloworld workflow started")\n\tvar helloworldResult string\n\terr := workflow.ExecuteActivity(ctx, helloWorldActivity, name).Get(ctx, &helloworldResult)\n\tif err != nil {\n\t\tlogger.Error("Activity failed.", zap.Error(err))\n\t\treturn err\n\t}\n\n\tlogger.Info("Workflow completed.", zap.String("Result", helloworldResult))\n\n\treturn nil\n}\n\nfunc helloWorldActivity(ctx context.Context, name string) (string, error) {\n\tlogger := activity.GetLogger(ctx)\n\tlogger.Info("helloworld activity started")\n\treturn "Hello " + name + "!", nil\n}\n\n\nDon\'t forget to register the workflow and activity to the worker.\n\nfunc init() {\n    workflow.Register(helloWorldWorkflow)\n    activity.Register(helloWorldActivity)\n}\n\n\nImport the context module if it was not automatically added.\n\nimport (\n    "context"\n)\n\n\n\n# Step 3. Run the workflow with Cadence CLI\n\nRestart your worker and run the following command to interact with your workflow.\n\ncadence --domain test-domain workflow start --et 60 --tl test-worker --workflow_type main.helloWorldWorkflow --input \'"World"\'\n\n\nYou should see logs in your worker terminal like\n\n2023-07-16T11:30:02.717-0700    INFO    cadence-worker/code.go:104      Workflow completed. {"Domain": "test-domain", "TaskList": "test-worker", "WorkerID": "11294@uber-C02F18EQMD6R@test-worker@5829c68e-ace0-472f-b5f3-6ccfc7903dd5", "WorkflowType": "main.helloWorldWorkflow", "WorkflowID": "8acbda3c-d240-4f27-8388-97c866b8bfb5", "RunID": "4b91341f-056f-4f0b-ab64-83bcc3a53e5a", "Result": "Hello World!"}\n\n\nCongratulations! You just launched your very first Cadence workflow from scratch\n\n\n# (Optional) Step 4. Monitor Cadence workflow with Cadence web UI\n\nWhen you start the Cadence backend server, it also automatically starts a front end portal for your workflow. Open you browser and go to\n\nhttp://localhost:8088\n\nYou may see a dashboard below\n\nType the domain you used for the tutorial, in this case, we type test-domain and hit enter. Then you can see a complete history of the workflows you have triggered associated to this domain.\n\n\n# What is Next\n\nNow you have completed the tutorials. You can continue to explore the key concepts in Cadence, and also how to use them with Go Client\n\nFor complete, ready to build samples covering all the key Cadence concepts go to Cadence-Samples for more examples.\n\nYou can also review Cadence-Client and go-docs for more documentation.',normalizedContent:'# golang hello world\n\nthis section provides step-by-step instructions on how to write and run a helloworld workflow in cadence with golang. you will learn two critical building blocks of cadence: activities and workflows. first, you will write an activity function that prints a "hello world!" message in the log. then, you will write a workflow function that executes this activity.\n\n\n# prerequisite\n\nto successfully run this hello world sample, follow this checklist of setting up cadence environment\n\n 1. your worker is running properly and you have registered the hello world activity and workflow to the worker\n 2. your cadence server is running (check your background docker container process)\n 3. you have successfully registered a domain for this workflow\n\nyou must finish part 2 and 3 by following the first section to proceed the next steps. we are using domain called test-domain for this tutorial project.\n\n\n# step 1. implement a cadence worker service\n\ncreate a new main.go file in your local directory and paste the basic worker service layout.\n\npackage main\n\nimport (\n    "net/http"\n    "go.uber.org/cadence/.gen/go/cadence/workflowserviceclient"\n    "go.uber.org/cadence/compatibility"\n    "go.uber.org/cadence/worker"\n\n    apiv1 "github.com/uber/cadence-idl/go/proto/api/v1"\n    "github.com/uber-go/tally"\n    "go.uber.org/zap"\n    "go.uber.org/zap/zapcore"\n    "go.uber.org/yarpc"\n    "go.uber.org/yarpc/transport/grpc"\n)\n\nvar hostport = "127.0.0.1:7833"\nvar domain = "test-domain"\nvar tasklistname = "test-worker"\nvar clientname = "test-worker"\nvar cadenceservice = "cadence-frontend"\n\nfunc main() {\n    startworker(buildlogger(), buildcadenceclient())\n    err := http.listenandserve(":8080", nil)\n    if err != nil {\n        panic(err)\n    }\n}\n\nfunc buildlogger() *zap.logger {\n    config := zap.newdevelopmentconfig()\n    config.level.setlevel(zapcore.infolevel)\n\n    var err error\n    logger, err := config.build()\n    if err != nil {\n        panic("failed to setup logger")\n    }\n\n    return logger\n}\n\nfunc buildcadenceclient() workflowserviceclient.interface {\n    dispatcher := yarpc.newdispatcher(yarpc.config{\n\t\tname: clientname,\n\t\toutbounds: yarpc.outbounds{\n\t\t  cadenceservice: {unary: grpc.newtransport().newsingleoutbound(hostport)},\n\t\t},\n\t  })\n\t  if err := dispatcher.start(); err != nil {\n\t\tpanic("failed to start dispatcher")\n\t  }\n  \n\t  clientconfig := dispatcher.clientconfig(cadenceservice)\n  \n\t  return compatibility.newthrift2protoadapter(\n\t\tapiv1.newdomainapiyarpcclient(clientconfig),\n\t\tapiv1.newworkflowapiyarpcclient(clientconfig),\n\t\tapiv1.newworkerapiyarpcclient(clientconfig),\n\t\tapiv1.newvisibilityapiyarpcclient(clientconfig),\n\t  )\n}\n\nfunc startworker(logger *zap.logger, service workflowserviceclient.interface) {\n    // tasklistname identifies set of client workflows, activities, and workers.\n    // it could be your group or client or application name.\n    workeroptions := worker.options{\n        logger:       logger,\n        metricsscope: tally.newtestscope(tasklistname, map[string]string{}),\n    }\n\n    worker := worker.new(\n        service,\n        domain,\n        tasklistname,\n        workeroptions)\n    err := worker.start()\n    if err != nil {\n        panic("failed to start worker")\n    }\n\n    logger.info("started worker.", zap.string("worker", tasklistname))\n}\n\n\nin this worker service, we start a http server and create a new cadence client running continuously at the background. then start the server on your local, you may see logs such like\n\n2023-07-03t11:46:46.266-0700    info    internal/internal_worker.go:826 worker has no workflows registered, so workflow worker will not be started.     {"domain": "test-domain", "tasklist": "test-worker", "workerid": "35987@uber-c02f18eqmd6r@test-worker@90c0260e-ba5c-4652-9f10-c6d1f9e29c1d"}\n2023-07-03t11:46:46.267-0700    info    internal/internal_worker.go:834 started workflow worker {"domain": "test-domain", "tasklist": "test-worker", "workerid": "35987@uber-c02f18eqmd6r@test-worker@90c0260e-ba5c-4652-9f10-c6d1f9e29c1d"}\n2023-07-03t11:46:46.267-0700    info    internal/internal_worker.go:838 worker has no activities registered, so activity worker will not be started.    {"domain": "test-domain", "tasklist": "test-worker", "workerid": "35987@uber-c02f18eqmd6r@test-worker@90c0260e-ba5c-4652-9f10-c6d1f9e29c1d"}\n2023-07-03t11:46:46.267-0700    info    cadence-worker/main.go:75       started worker. {"worker": "test-worker"}\n\n\nyou may see this because there are no activities and workflows registered to the worker. let\'s proceed to next steps to write a hello world activity and workflow.\n\n\n# step 2. write a simple cadence hello world activity and workflow\n\nlet\'s write a hello world activity, which take a single input called name and greet us after the workflow is finished.\n\nfunc helloworldworkflow(ctx workflow.context, name string) error {\n\tao := workflow.activityoptions{\n\t\tscheduletostarttimeout: time.minute,\n\t\tstarttoclosetimeout:    time.minute,\n\t\theartbeattimeout:       time.second * 20,\n\t}\n\tctx = workflow.withactivityoptions(ctx, ao)\n\n\tlogger := workflow.getlogger(ctx)\n\tlogger.info("helloworld workflow started")\n\tvar helloworldresult string\n\terr := workflow.executeactivity(ctx, helloworldactivity, name).get(ctx, &helloworldresult)\n\tif err != nil {\n\t\tlogger.error("activity failed.", zap.error(err))\n\t\treturn err\n\t}\n\n\tlogger.info("workflow completed.", zap.string("result", helloworldresult))\n\n\treturn nil\n}\n\nfunc helloworldactivity(ctx context.context, name string) (string, error) {\n\tlogger := activity.getlogger(ctx)\n\tlogger.info("helloworld activity started")\n\treturn "hello " + name + "!", nil\n}\n\n\ndon\'t forget to register the workflow and activity to the worker.\n\nfunc init() {\n    workflow.register(helloworldworkflow)\n    activity.register(helloworldactivity)\n}\n\n\nimport the context module if it was not automatically added.\n\nimport (\n    "context"\n)\n\n\n\n# step 3. run the workflow with cadence cli\n\nrestart your worker and run the following command to interact with your workflow.\n\ncadence --domain test-domain workflow start --et 60 --tl test-worker --workflow_type main.helloworldworkflow --input \'"world"\'\n\n\nyou should see logs in your worker terminal like\n\n2023-07-16t11:30:02.717-0700    info    cadence-worker/code.go:104      workflow completed. {"domain": "test-domain", "tasklist": "test-worker", "workerid": "11294@uber-c02f18eqmd6r@test-worker@5829c68e-ace0-472f-b5f3-6ccfc7903dd5", "workflowtype": "main.helloworldworkflow", "workflowid": "8acbda3c-d240-4f27-8388-97c866b8bfb5", "runid": "4b91341f-056f-4f0b-ab64-83bcc3a53e5a", "result": "hello world!"}\n\n\ncongratulations! you just launched your very first cadence workflow from scratch\n\n\n# (optional) step 4. monitor cadence workflow with cadence web ui\n\nwhen you start the cadence backend server, it also automatically starts a front end portal for your workflow. open you browser and go to\n\nhttp://localhost:8088\n\nyou may see a dashboard below\n\ntype the domain you used for the tutorial, in this case, we type test-domain and hit enter. then you can see a complete history of the workflows you have triggered associated to this domain.\n\n\n# what is next\n\nnow you have completed the tutorials. you can continue to explore the key concepts in cadence, and also how to use them with go client\n\nfor complete, ready to build samples covering all the key cadence concepts go to cadence-samples for more examples.\n\nyou can also review cadence-client and go-docs for more documentation.',charsets:{}},{title:"Server Installation",frontmatter:{layout:"default",title:"Server Installation",permalink:"/docs/get-started/installation",readingShow:"top"},regularPath:"/docs/01-get-started/01-server-installation.html",relativePath:"docs/01-get-started/01-server-installation.md",key:"v-4bb753c4",path:"/docs/get-started/installation/",headers:[{level:2,title:"0. Prerequisite - Install docker",slug:"_0-prerequisite-install-docker",normalizedTitle:"0. prerequisite - install docker",charIndex:322},{level:2,title:"1. Run Cadence Server Using Docker Compose",slug:"_1-run-cadence-server-using-docker-compose",normalizedTitle:"1. run cadence server using docker compose",charIndex:461},{level:2,title:"2. Register a Domain Using the CLI",slug:"_2-register-a-domain-using-the-cli",normalizedTitle:"2. register a domain using the cli",charIndex:849},{level:2,title:"What's Next",slug:"what-s-next",normalizedTitle:"what's next",charIndex:1771},{level:2,title:"Troubleshooting",slug:"troubleshooting",normalizedTitle:"troubleshooting",charIndex:2055}],codeSwitcherOptions:{},headersStr:"0. Prerequisite - Install docker 1. Run Cadence Server Using Docker Compose 2. Register a Domain Using the CLI What's Next Troubleshooting",content:"# Install Cadence Service Locally\n\nTo get started with Cadence, you need to set up three components successfully.\n\n * A Cadence server hosting dependencies that Cadence relies on such as Cassandra, Elastic Search, etc\n * A Cadence domain for you workflow application\n * A Cadence worker service hosting your workflows\n\n\n# 0. Prerequisite - Install docker\n\nFollow the Docker installation instructions found here: https://docs.docker.com/engine/installation/\n\n\n# 1. Run Cadence Server Using Docker Compose\n\nDownload the Cadence docker-compose file:\n\n\ncurl -O https://raw.githubusercontent.com/uber/cadence/master/docker/docker-compose.yml && curl -O https://raw.githubusercontent.com/uber/cadence/master/docker/prometheus/prometheus.yml\n\n\nThen start Cadence Service by running:\n\ndocker-compose up\n\n\nPlease keep this process running at background.\n\n\n# 2. Register a Domain Using the CLI\n\nIn a new terminal, create a new domain called test-domain (or choose whatever name you like) by running:\n\ndocker run --network=host --rm ubercadence/cli:master --do test-domain domain register -rd 1\n\n\nCheck that the domain is indeed registered:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain domain describe\nName: test-domain\nDescription:\nOwnerEmail:\nDomainData: map[]\nStatus: REGISTERED\nRetentionInDays: 1\nEmitMetrics: false\nActiveClusterName: active\nClusters: active\nArchivalStatus: DISABLED\nBad binaries to reset:\n+-----------------+----------+------------+--------+\n| BINARY CHECKSUM | OPERATOR | START TIME | REASON |\n+-----------------+----------+------------+--------+\n+-----------------+----------+------------+--------+\n>\n\n\nPlease remember the domains you created because they will be used in your worker implementation and Cadence CLI commands.\n\n\n# What's Next\n\nSo far you've successfully finished two prerequisites to your Cadence application. The next steps are to implement a simple worker service that hosts your workflows and to run your very first hello world Cadence workflow.\n\nGo to Java HelloWorld or Golang HelloWorld.\n\n\n# Troubleshooting\n\nThere can be various reasons that docker-compose up cannot succeed:\n\n * In case of the image being too old, update the docker image by docker pull ubercadence/server:master-auto-setup and retry\n * In case of the local docker env is messed up: docker system prune --all and retry (see details about it )\n * See logs of different container:\n   * If Cassandra is not able to get up: docker logs -f docker_cassandra_1\n   * If Cadence is not able to get up: docker logs -f docker_cadence_1\n   * If Cadence Web is not able to get up: docker logs -f docker_cadence-web_1\n\nIf the above is still not working, open an issue in Server(main) repo.",normalizedContent:"# install cadence service locally\n\nto get started with cadence, you need to set up three components successfully.\n\n * a cadence server hosting dependencies that cadence relies on such as cassandra, elastic search, etc\n * a cadence domain for you workflow application\n * a cadence worker service hosting your workflows\n\n\n# 0. prerequisite - install docker\n\nfollow the docker installation instructions found here: https://docs.docker.com/engine/installation/\n\n\n# 1. run cadence server using docker compose\n\ndownload the cadence docker-compose file:\n\n\ncurl -o https://raw.githubusercontent.com/uber/cadence/master/docker/docker-compose.yml && curl -o https://raw.githubusercontent.com/uber/cadence/master/docker/prometheus/prometheus.yml\n\n\nthen start cadence service by running:\n\ndocker-compose up\n\n\nplease keep this process running at background.\n\n\n# 2. register a domain using the cli\n\nin a new terminal, create a new domain called test-domain (or choose whatever name you like) by running:\n\ndocker run --network=host --rm ubercadence/cli:master --do test-domain domain register -rd 1\n\n\ncheck that the domain is indeed registered:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain domain describe\nname: test-domain\ndescription:\nowneremail:\ndomaindata: map[]\nstatus: registered\nretentionindays: 1\nemitmetrics: false\nactiveclustername: active\nclusters: active\narchivalstatus: disabled\nbad binaries to reset:\n+-----------------+----------+------------+--------+\n| binary checksum | operator | start time | reason |\n+-----------------+----------+------------+--------+\n+-----------------+----------+------------+--------+\n>\n\n\nplease remember the domains you created because they will be used in your worker implementation and cadence cli commands.\n\n\n# what's next\n\nso far you've successfully finished two prerequisites to your cadence application. the next steps are to implement a simple worker service that hosts your workflows and to run your very first hello world cadence workflow.\n\ngo to java helloworld or golang helloworld.\n\n\n# troubleshooting\n\nthere can be various reasons that docker-compose up cannot succeed:\n\n * in case of the image being too old, update the docker image by docker pull ubercadence/server:master-auto-setup and retry\n * in case of the local docker env is messed up: docker system prune --all and retry (see details about it )\n * see logs of different container:\n   * if cassandra is not able to get up: docker logs -f docker_cassandra_1\n   * if cadence is not able to get up: docker logs -f docker_cadence_1\n   * if cadence web is not able to get up: docker logs -f docker_cadence-web_1\n\nif the above is still not working, open an issue in server(main) repo.",charsets:{cjk:!0}},{title:"Video Tutorials",frontmatter:{layout:"default",title:"Video Tutorials",permalink:"/docs/get-started/video-tutorials",readingShow:"top"},regularPath:"/docs/01-get-started/04-video-tutorials.html",relativePath:"docs/01-get-started/04-video-tutorials.md",key:"v-696d6f80",path:"/docs/get-started/video-tutorials/",headers:[{level:2,title:"HelloWorld",slug:"helloworld",normalizedTitle:"helloworld",charIndex:88}],codeSwitcherOptions:{},headersStr:"HelloWorld",content:"# Overview\n\nAn Introduction to the Cadence programming model and value proposition.\n\n\n# HelloWorld\n\nA step-by-step video tutorial about how to install and run HellowWorld(Java).\n\n",normalizedContent:"# overview\n\nan introduction to the cadence programming model and value proposition.\n\n\n# helloworld\n\na step-by-step video tutorial about how to install and run hellowworld(java).\n\n",charsets:{}},{title:"Overview",frontmatter:{layout:"default",title:"Overview",description:"A large number of use cases span beyond a single request-reply, require tracking of a complex state, respond to asynchronous events, and communicate to external unreliable dependencies.",permalink:"/docs/get-started/",readingShow:"top"},regularPath:"/docs/01-get-started/",relativePath:"docs/01-get-started/index.md",key:"v-5ab4294a",path:"/docs/get-started/",headers:[{level:2,title:"What's Next",slug:"what-s-next",normalizedTitle:"what's next",charIndex:2059}],codeSwitcherOptions:{},headersStr:"What's Next",content:"# Overview\n\nA large number of use cases span beyond a single request-reply, require tracking of a complex state, respond to asynchronous , and communicate to external unreliable dependencies. The usual approach to building such applications is a hodgepodge of stateless services, databases, cron jobs, and queuing systems. This negatively impacts the developer productivity as most of the code is dedicated to plumbing, obscuring the actual business logic behind a myriad of low-level details. Such systems frequently have availability problems as it is hard to keep all the components healthy.\n\nThe Cadence solution is a fault-oblivious stateful programming model that obscures most of the complexities of building scalable distributed applications. In essence, Cadence provides a durable virtual memory that is not linked to a specific process, and preserves the full application state, including function stacks, with local variables across all sorts of host and software failures. This allows you to write code using the full power of a programming language while Cadence takes care of durability, availability, and scalability of the application.\n\nCadence consists of a programming framework (or client library) and a managed service (or backend). The framework enables developers to author and coordinate in familiar languages (Go and Java are supported officially, and Python and Ruby by the community).\n\nYou can also use iWF as a DSL framework on top of Cadence.\n\nThe Cadence backend service is stateless and relies on a persistent store. Currently, Cassandra and MySQL/Postgres storages are supported. An adapter to any other database that provides multi-row single shard transactions can be added. There are different service deployment models. At Uber, our team operates multitenant clusters that are shared by hundreds of applications. See service topology to understand the overall architecture. The GitHub repo for the Cadence server is uber/cadence. The docker image for the Cadence server is available on Docker Hub at ubercadence/server.\n\n\n# What's Next\n\nLet's try with some sample workflows. To start with, go to server installation to install cadence locally, and run a HelloWorld sample with Java or Golang.\n\nWhen you have any trouble with the instructions, you can watch the video tutorials, and reach out to us on Slack Channel, or raise any question on StackOverflow or open an Github issue.",normalizedContent:"# overview\n\na large number of use cases span beyond a single request-reply, require tracking of a complex state, respond to asynchronous , and communicate to external unreliable dependencies. the usual approach to building such applications is a hodgepodge of stateless services, databases, cron jobs, and queuing systems. this negatively impacts the developer productivity as most of the code is dedicated to plumbing, obscuring the actual business logic behind a myriad of low-level details. such systems frequently have availability problems as it is hard to keep all the components healthy.\n\nthe cadence solution is a fault-oblivious stateful programming model that obscures most of the complexities of building scalable distributed applications. in essence, cadence provides a durable virtual memory that is not linked to a specific process, and preserves the full application state, including function stacks, with local variables across all sorts of host and software failures. this allows you to write code using the full power of a programming language while cadence takes care of durability, availability, and scalability of the application.\n\ncadence consists of a programming framework (or client library) and a managed service (or backend). the framework enables developers to author and coordinate in familiar languages (go and java are supported officially, and python and ruby by the community).\n\nyou can also use iwf as a dsl framework on top of cadence.\n\nthe cadence backend service is stateless and relies on a persistent store. currently, cassandra and mysql/postgres storages are supported. an adapter to any other database that provides multi-row single shard transactions can be added. there are different service deployment models. at uber, our team operates multitenant clusters that are shared by hundreds of applications. see service topology to understand the overall architecture. the github repo for the cadence server is uber/cadence. the docker image for the cadence server is available on docker hub at ubercadence/server.\n\n\n# what's next\n\nlet's try with some sample workflows. to start with, go to server installation to install cadence locally, and run a helloworld sample with java or golang.\n\nwhen you have any trouble with the instructions, you can watch the video tutorials, and reach out to us on slack channel, or raise any question on stackoverflow or open an github issue.",charsets:{}},{title:"Periodic execution",frontmatter:{layout:"default",title:"Periodic execution",permalink:"/docs/use-cases/periodic-execution",readingShow:"top"},regularPath:"/docs/02-use-cases/01-periodic-execution.html",relativePath:"docs/02-use-cases/01-periodic-execution.md",key:"v-c2f362bc",path:"/docs/use-cases/periodic-execution/",codeSwitcherOptions:{},headersStr:null,content:"# Periodic execution (aka Distributed Cron)\n\nPeriodic execution, frequently referred to as distributed cron, is when you execute business logic periodically. The advantage of Cadence for these scenarios is that it guarantees execution, sophisticated error handling, retry policies, and visibility into execution history.\n\nAnother important dimension is scale. Some use cases require periodic execution for a large number of entities. At Uber, there are applications that create periodic per customer. Imagine 100+ million parallel cron jobs that don't require a separate batch processing framework.\n\nPeriodic execution is often part of other use cases. For example, once a month report generation is a periodic service orchestration. Or an event-driven that accumulates loyalty points for a customer and applies those points once a month.\n\nThere are many real-world examples of Cadence periodic executions. Such as the following:\n\n * An Uber backend service that recalculates various statistics for each hex in each city once a minute.\n * Monthly Uber for Business report generation.",normalizedContent:"# periodic execution (aka distributed cron)\n\nperiodic execution, frequently referred to as distributed cron, is when you execute business logic periodically. the advantage of cadence for these scenarios is that it guarantees execution, sophisticated error handling, retry policies, and visibility into execution history.\n\nanother important dimension is scale. some use cases require periodic execution for a large number of entities. at uber, there are applications that create periodic per customer. imagine 100+ million parallel cron jobs that don't require a separate batch processing framework.\n\nperiodic execution is often part of other use cases. for example, once a month report generation is a periodic service orchestration. or an event-driven that accumulates loyalty points for a customer and applies those points once a month.\n\nthere are many real-world examples of cadence periodic executions. such as the following:\n\n * an uber backend service that recalculates various statistics for each hex in each city once a minute.\n * monthly uber for business report generation.",charsets:{}},{title:"Orchestration",frontmatter:{layout:"default",title:"Orchestration",permalink:"/docs/use-cases/orchestration",readingShow:"top"},regularPath:"/docs/02-use-cases/02-orchestration.html",relativePath:"docs/02-use-cases/02-orchestration.md",key:"v-d5dcd2a0",path:"/docs/use-cases/orchestration/",codeSwitcherOptions:{},headersStr:null,content:"# Microservice Orchestration and Saga\n\nIt is common that some business processes are implemented as multiple microservice calls. And the implementation must guarantee that all of the calls must eventually succeed even with the occurrence of prolonged downstream service failures. In some cases, instead of trying to complete the process by retrying for a long time, compensation rollback logic should be executed. Saga Pattern is one way to standardize on compensation APIs.\n\nCadence is a perfect fit for such scenarios. It guarantees that code eventually completes, has built-in support for unlimited exponential retries and simplifies coding of the compensation logic. It also gives full visibility into the state of each , in contrast to an orchestration based on queues where getting a current status of each individual request is practically impossible.\n\nFollowing are some real-world examples of Cadence-based service orchestration scenarios:\n\n * Using Cadence workflows to spin up Kubernetes (Banzai Cloud Fork)\n * Improving the User Experience with Uber’s Customer Obsession Ticket Routing Workflow and Orchestration Engine\n * Enabling Faster Financial Partnership Integrations Using Cadence",normalizedContent:"# microservice orchestration and saga\n\nit is common that some business processes are implemented as multiple microservice calls. and the implementation must guarantee that all of the calls must eventually succeed even with the occurrence of prolonged downstream service failures. in some cases, instead of trying to complete the process by retrying for a long time, compensation rollback logic should be executed. saga pattern is one way to standardize on compensation apis.\n\ncadence is a perfect fit for such scenarios. it guarantees that code eventually completes, has built-in support for unlimited exponential retries and simplifies coding of the compensation logic. it also gives full visibility into the state of each , in contrast to an orchestration based on queues where getting a current status of each individual request is practically impossible.\n\nfollowing are some real-world examples of cadence-based service orchestration scenarios:\n\n * using cadence workflows to spin up kubernetes (banzai cloud fork)\n * improving the user experience with uber’s customer obsession ticket routing workflow and orchestration engine\n * enabling faster financial partnership integrations using cadence",charsets:{}},{title:"Polling",frontmatter:{layout:"default",title:"Polling",permalink:"/docs/use-cases/polling",readingShow:"top"},regularPath:"/docs/02-use-cases/03-polling.html",relativePath:"docs/02-use-cases/03-polling.md",key:"v-88def7ac",path:"/docs/use-cases/polling/",codeSwitcherOptions:{},headersStr:null,content:"# Polling\n\nPolling is executing a periodic action checking for a state change. Examples are pinging a host, calling a REST API, or listing an Amazon S3 bucket for newly uploaded files.\n\nCadence support for long running and unlimited retries makes it a good fit.\n\nSome real-world use cases:\n\n * Network, host and service monitoring\n * Processing files uploaded to FTP or S3\n * Cadence Polling Cookbook by Instaclustr: Polling an external API for a specific resource to become available:",normalizedContent:"# polling\n\npolling is executing a periodic action checking for a state change. examples are pinging a host, calling a rest api, or listing an amazon s3 bucket for newly uploaded files.\n\ncadence support for long running and unlimited retries makes it a good fit.\n\nsome real-world use cases:\n\n * network, host and service monitoring\n * processing files uploaded to ftp or s3\n * cadence polling cookbook by instaclustr: polling an external api for a specific resource to become available:",charsets:{}},{title:"Event driven application",frontmatter:{layout:"default",title:"Event driven application",permalink:"/docs/use-cases/event-driven",readingShow:"top"},regularPath:"/docs/02-use-cases/04-event-driven.html",relativePath:"docs/02-use-cases/04-event-driven.md",key:"v-7a5c92a2",path:"/docs/use-cases/event-driven/",codeSwitcherOptions:{},headersStr:null,content:"# Event driven application\n\nMany applications listen to multiple sources, update the state of correspondent business entities, and have to execute actions if some state is reached. Cadence is a good fit for many of these. It has direct support for asynchronous (aka ), has a simple programming model that obscures a lot of complexity around state persistence, and ensures external action execution through built-in retries.\n\nReal-world examples:\n\n * Fraud detection where reacts to generated by consumer behavior\n * Customer loyalty program where the accumulates reward points and applies them when requested",normalizedContent:"# event driven application\n\nmany applications listen to multiple sources, update the state of correspondent business entities, and have to execute actions if some state is reached. cadence is a good fit for many of these. it has direct support for asynchronous (aka ), has a simple programming model that obscures a lot of complexity around state persistence, and ensures external action execution through built-in retries.\n\nreal-world examples:\n\n * fraud detection where reacts to generated by consumer behavior\n * customer loyalty program where the accumulates reward points and applies them when requested",charsets:{}},{title:"Storage scan",frontmatter:{layout:"default",title:"Storage scan",permalink:"/docs/use-cases/partitioned-scan",readingShow:"top"},regularPath:"/docs/02-use-cases/05-partitioned-scan.html",relativePath:"docs/02-use-cases/05-partitioned-scan.md",key:"v-1bc7fd02",path:"/docs/use-cases/partitioned-scan/",codeSwitcherOptions:{},headersStr:null,content:"# Storage scan\n\nIt is common to have large data sets partitioned across a large number of hosts or databases, or having billions of files in an Amazon S3 bucket. Cadence is an ideal solution for implementing the full scan of such data in a scalable and resilient way. The standard pattern is to run an (or multiple parallel for partitioned data sets) that performs the scan and heartbeats its progress back to Cadence. In the case of a host failure, the is retried on a different host and continues execution from the last reported progress.\n\nA real-world example:\n\n * Cadence internal system that performs periodic scan of all records",normalizedContent:"# storage scan\n\nit is common to have large data sets partitioned across a large number of hosts or databases, or having billions of files in an amazon s3 bucket. cadence is an ideal solution for implementing the full scan of such data in a scalable and resilient way. the standard pattern is to run an (or multiple parallel for partitioned data sets) that performs the scan and heartbeats its progress back to cadence. in the case of a host failure, the is retried on a different host and continues execution from the last reported progress.\n\na real-world example:\n\n * cadence internal system that performs periodic scan of all records",charsets:{}},{title:"Batch job",frontmatter:{layout:"default",title:"Batch job",permalink:"/docs/use-cases/batch-job",readingShow:"top"},regularPath:"/docs/02-use-cases/06-batch-job.html",relativePath:"docs/02-use-cases/06-batch-job.md",key:"v-a14b6054",path:"/docs/use-cases/batch-job/",codeSwitcherOptions:{},headersStr:null,content:"# Batch job\n\nA lot of batch jobs are not pure data manipulation programs. For those, the existing big data frameworks are the best fit. But if processing a record requires external API calls that might fail and potentially take a long time, Cadence might be preferable.\n\nOne of our internal Uber customer uses Cadence for end of month statement generation. Each statement requires calls to multiple microservices and some statements can be really large. Cadence was chosen because it provides hard guarantees around durability of the financial data and seamlessly deals with long running operations, retries, and intermittent failures.",normalizedContent:"# batch job\n\na lot of batch jobs are not pure data manipulation programs. for those, the existing big data frameworks are the best fit. but if processing a record requires external api calls that might fail and potentially take a long time, cadence might be preferable.\n\none of our internal uber customer uses cadence for end of month statement generation. each statement requires calls to multiple microservices and some statements can be really large. cadence was chosen because it provides hard guarantees around durability of the financial data and seamlessly deals with long running operations, retries, and intermittent failures.",charsets:{}},{title:"Deployment",frontmatter:{layout:"default",title:"Deployment",permalink:"/docs/use-cases/deployment",readingShow:"top"},regularPath:"/docs/02-use-cases/08-deployment.html",relativePath:"docs/02-use-cases/08-deployment.md",key:"v-c99e5abc",path:"/docs/use-cases/deployment/",codeSwitcherOptions:{},headersStr:null,content:"# CI/CD and Deployment\n\nImplementing CI/CD pipelines and deployment of applications to containers or virtual or physical machines is a non-trivial process. Its business logic has to deal with complex requirements around rolling upgrades, canary deployments, and rollbacks. Cadence is a perfect platform for building a deployment solution because it provides all the necessary guarantees and abstractions allowing developers to focus on the business logic.\n\nExample production systems:\n\n * Uber internal deployment infrastructure\n * Update push to IoT devices",normalizedContent:"# ci/cd and deployment\n\nimplementing ci/cd pipelines and deployment of applications to containers or virtual or physical machines is a non-trivial process. its business logic has to deal with complex requirements around rolling upgrades, canary deployments, and rollbacks. cadence is a perfect platform for building a deployment solution because it provides all the necessary guarantees and abstractions allowing developers to focus on the business logic.\n\nexample production systems:\n\n * uber internal deployment infrastructure\n * update push to iot devices",charsets:{}},{title:"Infrastructure provisioning",frontmatter:{layout:"default",title:"Infrastructure provisioning",permalink:"/docs/use-cases/provisioning",readingShow:"top"},regularPath:"/docs/02-use-cases/07-provisioning.html",relativePath:"docs/02-use-cases/07-provisioning.md",key:"v-28bf3ec2",path:"/docs/use-cases/provisioning/",codeSwitcherOptions:{},headersStr:null,content:"# Infrastructure provisioning\n\nProvisioning a new datacenter or a pool of machines in a public cloud is a potentially long running operation with a lot of possibilities for intermittent failures. The scale is also a concern when tens or even hundreds of thousands of resources should be provisioned and configured. One useful feature for provisioning scenarios is Cadence support for routing execution to a specific process or host.\n\nA lot of operations require some sort of locking to ensure that no more than one mutation is executed on a resource at a time. Cadence provides strong guarantees of uniqueness by business ID. This can be used to implement such locking behavior in a fault tolerant and scalable manner.\n\nSome real-world use cases:\n\n * Using Cadence workflows to spin up Kubernetes, by Banzai Cloud\n * Using Cadence to orchestrate cluster life cycle in HashiCorp Consul, by HashiCorp",normalizedContent:"# infrastructure provisioning\n\nprovisioning a new datacenter or a pool of machines in a public cloud is a potentially long running operation with a lot of possibilities for intermittent failures. the scale is also a concern when tens or even hundreds of thousands of resources should be provisioned and configured. one useful feature for provisioning scenarios is cadence support for routing execution to a specific process or host.\n\na lot of operations require some sort of locking to ensure that no more than one mutation is executed on a resource at a time. cadence provides strong guarantees of uniqueness by business id. this can be used to implement such locking behavior in a fault tolerant and scalable manner.\n\nsome real-world use cases:\n\n * using cadence workflows to spin up kubernetes, by banzai cloud\n * using cadence to orchestrate cluster life cycle in hashicorp consul, by hashicorp",charsets:{}},{title:"Operational management",frontmatter:{layout:"default",title:"Operational management",permalink:"/docs/use-cases/operational-management",readingShow:"top"},regularPath:"/docs/02-use-cases/09-operational-management.html",relativePath:"docs/02-use-cases/09-operational-management.md",key:"v-36ed9422",path:"/docs/use-cases/operational-management/",codeSwitcherOptions:{},headersStr:null,content:"# Operational management\n\nImagine that you have to create a self operating database similar to Amazon RDS. Cadence is used in multiple projects that automate managing and automatic recovery of various products like MySQL, Elasticsearch and Apache Cassandra.\n\nSuch systems are usually a mixture of different use cases. They need to monitor the status of resources using polling. They have to execute orchestration API calls to administrative interfaces of a database. They have to provision new hardware or Docker instances if necessary. They need to push configuration updates and perform other actions like backups periodically.",normalizedContent:"# operational management\n\nimagine that you have to create a self operating database similar to amazon rds. cadence is used in multiple projects that automate managing and automatic recovery of various products like mysql, elasticsearch and apache cassandra.\n\nsuch systems are usually a mixture of different use cases. they need to monitor the status of resources using polling. they have to execute orchestration api calls to administrative interfaces of a database. they have to provision new hardware or docker instances if necessary. they need to push configuration updates and perform other actions like backups periodically.",charsets:{}},{title:"Interactive application",frontmatter:{layout:"default",title:"Interactive application",permalink:"/docs/use-cases/interactive",readingShow:"top"},regularPath:"/docs/02-use-cases/10-interactive.html",relativePath:"docs/02-use-cases/10-interactive.md",key:"v-6b66fa18",path:"/docs/use-cases/interactive/",codeSwitcherOptions:{},headersStr:null,content:"# Interactive application\n\nCadence is performant and scalable enough to support interactive applications. It can be used to track UI session state and at the same time execute background operations. For example, while placing an order a customer might need to go through several screens while a background evaluates the customer for fraudulent .",normalizedContent:"# interactive application\n\ncadence is performant and scalable enough to support interactive applications. it can be used to track ui session state and at the same time execute background operations. for example, while placing an order a customer might need to go through several screens while a background evaluates the customer for fraudulent .",charsets:{}},{title:"DSL workflows",frontmatter:{layout:"default",title:"DSL workflows",permalink:"/docs/use-cases/dsl",readingShow:"top"},regularPath:"/docs/02-use-cases/11-dsl.html",relativePath:"docs/02-use-cases/11-dsl.md",key:"v-611b8c3c",path:"/docs/use-cases/dsl/",codeSwitcherOptions:{},headersStr:null,content:'# DSL workflows\n\nCadence supports implementing business logic directly in programming languages like Java and Go. But there are cases when using a domain-specific language is more appropriate. Or there might be a legacy system that uses some form of DSL for process definition but it is not operationally stable and scalable. This also applies to more recent systems like Apache Airflow, various BPMN engines and AWS Step Functions.\n\nAn application that interprets the DSL definition can be written using the Cadence SDK. It automatically becomes highly fault tolerant, scalable, and durable when running on Cadence. Cadence has been used to deprecate several Uber internal DSL engines. The customers continue to use existing process definitions, but Cadence is used as an execution engine.\n\nThere are multiple benefits of unifying all company engines on top of Cadence. The most obvious one is that it is more efficient to support a single product instead of many. It is also difficult to beat the scalability and stability of Cadence which each of the integrations it comes with. Additionally, the ability to share across "engines" might be a huge benefit in some cases.',normalizedContent:'# dsl workflows\n\ncadence supports implementing business logic directly in programming languages like java and go. but there are cases when using a domain-specific language is more appropriate. or there might be a legacy system that uses some form of dsl for process definition but it is not operationally stable and scalable. this also applies to more recent systems like apache airflow, various bpmn engines and aws step functions.\n\nan application that interprets the dsl definition can be written using the cadence sdk. it automatically becomes highly fault tolerant, scalable, and durable when running on cadence. cadence has been used to deprecate several uber internal dsl engines. the customers continue to use existing process definitions, but cadence is used as an execution engine.\n\nthere are multiple benefits of unifying all company engines on top of cadence. the most obvious one is that it is more efficient to support a single product instead of many. it is also difficult to beat the scalability and stability of cadence which each of the integrations it comes with. additionally, the ability to share across "engines" might be a huge benefit in some cases.',charsets:{}},{title:"Big data and ML",frontmatter:{layout:"default",title:"Big data and ML",permalink:"/docs/use-cases/big-ml",readingShow:"top"},regularPath:"/docs/02-use-cases/12-big-ml.html",relativePath:"docs/02-use-cases/12-big-ml.md",key:"v-163bae3c",path:"/docs/use-cases/big-ml/",codeSwitcherOptions:{},headersStr:null,content:"# Big data and ML\n\nA lot of companies build custom ETL and ML training and deployment solutions. Cadence is a good fit for a control plane for such applications.\n\nOne important feature of Cadence is its ability to route execution to a specific process or host. It is useful to control how ML models and other large files are allocated to hosts. For example, if an ML model is partitioned by city, the requests should be routed to hosts that contain the corresponding city model.",normalizedContent:"# big data and ml\n\na lot of companies build custom etl and ml training and deployment solutions. cadence is a good fit for a control plane for such applications.\n\none important feature of cadence is its ability to route execution to a specific process or host. it is useful to control how ml models and other large files are allocated to hosts. for example, if an ml model is partitioned by city, the requests should be routed to hosts that contain the corresponding city model.",charsets:{}},{title:"Introduction",frontmatter:{layout:"default",title:"Introduction",permalink:"/docs/use-cases/",readingShow:"top"},regularPath:"/docs/02-use-cases/",relativePath:"docs/02-use-cases/index.md",key:"v-13d0c1ca",path:"/docs/use-cases/",codeSwitcherOptions:{},headersStr:null,content:'# Use cases\n\nAs Cadence developers, we face a difficult non-technical problem: How to position and describe the Cadence platform.\n\nWe call it workflow. But when most people hear the word "workflow" they think about low-code and UIs. While these might be useful for non technical users, they frequently bring more pain than value to software engineers. Most UIs and low-code DSLs are awesome for "hello world" demo applications, but any diagram with 100+ elements or a few thousand lines of JSON DSL is completely impractical. So positioning Cadence as a is not ideal as it turns away developers that would enjoy its code-only approach.\n\nWe call it orchestrator. But this term is pretty narrow and turns away customers that want to implement business process automation solutions.\n\nWe call it durable function platform. It is technically a correct term. But most developers outside of the Microsoft ecosystem have never heard of Durable Functions.\n\nWe believe that problem in naming comes from the fact that Cadence is indeed a new way to write distributed applications. It is generic enough that it can be applied to practically any use case that goes beyond a single request reply. It can be used to build applications that are in traditional areas of or orchestration platforms. But it is also huge developer productivity boost for multiple use cases that traditionally rely on databases and/or queues.\n\nThis section represents a far from complete list of use cases where Cadence is a good fit. All of them have been used by real production services inside and outside of Uber.\n\nDon\'t think of this list as exhaustive. It is common to employ multiple use types in a single application. For example, an operational management use case might need periodic execution, service orchestration, polling, driven, as well as interactive parts.',normalizedContent:'# use cases\n\nas cadence developers, we face a difficult non-technical problem: how to position and describe the cadence platform.\n\nwe call it workflow. but when most people hear the word "workflow" they think about low-code and uis. while these might be useful for non technical users, they frequently bring more pain than value to software engineers. most uis and low-code dsls are awesome for "hello world" demo applications, but any diagram with 100+ elements or a few thousand lines of json dsl is completely impractical. so positioning cadence as a is not ideal as it turns away developers that would enjoy its code-only approach.\n\nwe call it orchestrator. but this term is pretty narrow and turns away customers that want to implement business process automation solutions.\n\nwe call it durable function platform. it is technically a correct term. but most developers outside of the microsoft ecosystem have never heard of durable functions.\n\nwe believe that problem in naming comes from the fact that cadence is indeed a new way to write distributed applications. it is generic enough that it can be applied to practically any use case that goes beyond a single request reply. it can be used to build applications that are in traditional areas of or orchestration platforms. but it is also huge developer productivity boost for multiple use cases that traditionally rely on databases and/or queues.\n\nthis section represents a far from complete list of use cases where cadence is a good fit. all of them have been used by real production services inside and outside of uber.\n\ndon\'t think of this list as exhaustive. it is common to employ multiple use types in a single application. for example, an operational management use case might need periodic execution, service orchestration, polling, driven, as well as interactive parts.',charsets:{}},{title:"Workflows",frontmatter:{layout:"default",title:"Workflows",permalink:"/docs/concepts/workflows",readingShow:"top"},regularPath:"/docs/03-concepts/01-workflows.html",relativePath:"docs/03-concepts/01-workflows.md",key:"v-8d905b7c",path:"/docs/concepts/workflows/",headers:[{level:2,title:"Overview",slug:"overview",normalizedTitle:"overview",charIndex:45},{level:2,title:"Example",slug:"example",normalizedTitle:"example",charIndex:347},{level:2,title:"State Recovery and Determinism",slug:"state-recovery-and-determinism",normalizedTitle:"state recovery and determinism",charIndex:7821},{level:2,title:"ID Uniqueness",slug:"id-uniqueness",normalizedTitle:"id uniqueness",charIndex:8556},{level:2,title:"Child Workflow",slug:"child-workflow",normalizedTitle:"child workflow",charIndex:9681},{level:2,title:"Workflow Retries",slug:"workflow-retries",normalizedTitle:"workflow retries",charIndex:11254},{level:2,title:"How does workflow run",slug:"how-does-workflow-run",normalizedTitle:"how does workflow run",charIndex:12798}],codeSwitcherOptions:{},headersStr:"Overview Example State Recovery and Determinism ID Uniqueness Child Workflow Workflow Retries How does workflow run",content:"# Fault-oblivious stateful workflow code\n\n\n# Overview\n\nCadence core abstraction is a fault-oblivious stateful . The state of the code, including local variables and threads it creates, is immune to process and Cadence service failures. This is a very powerful concept as it encapsulates state, processing threads, durable timers and handlers.\n\n\n# Example\n\nLet's look at a use case. A customer signs up for an application with a trial period. After the period, if the customer has not cancelled, he should be charged once a month for the renewal. The customer has to be notified by email about the charges and should be able to cancel the subscription at any time.\n\nThe business logic of this use case is not very complicated and can be expressed in a few dozen lines of code. But any practical implementation has to ensure that the business process is fault tolerant and scalable. There are various ways to approach the design of such a system.\n\nOne approach is to center it around a database. An application process would periodically scan database tables for customers in specific states, execute necessary actions, and update the state to reflect that. While feasible, this approach has various drawbacks. The most obvious is that the state machine of the customer state quickly becomes extremely complicated. For example, charging a credit card or sending emails can fail due to a downstream system unavailability. The failed calls might need to be retried for a long time, ideally using an exponential retry policy. These calls should be throttled to not overload external systems. There should be support for poison pills to avoid blocking the whole process if a single customer record cannot be processed for whatever reason. The database-based approach also usually has performance problems. Databases are not efficient for scenarios that require constant polling for records in a specific state.\n\nAnother commonly employed approach is to use a timer service and queues. Any update is pushed to a queue and then a that consumes from it updates a database and possibly pushes more messages in downstream queues. For operations that require scheduling, an external timer service can be used. This approach usually scales much better because a database is not constantly polled for changes. But it makes the programming model more complex and error prone as usually there is no transactional update between a queuing system and a database.\n\nWith Cadence, the entire logic can be encapsulated in a simple durable function that directly implements the business logic. Because the function is stateful, the implementer doesn't need to employ any additional systems to ensure durability and fault tolerance.\n\nHere is an example that implements the subscription management use case. It is in Java, but Go is also supported. The Python and .NET libraries are under active development.\n\n// This SubscriptionWorkflow interface is an example of defining a workflow in Cadence\npublic interface SubscriptionWorkflow {\n    @WorkflowMethod\n    void manageSubscription(String customerId);\n    @SignalMethod\n    void cancelSubscription();\n    @SignalMethod    \n    void updateBillingPeriodChargeAmount(int billingPeriodChargeAmount);\n    @QueryMethod    \n    String queryCustomerId();\n    @QueryMethod        \n    int queryBillingPeriodNumber();\n    @QueryMethod        \n    int queryBillingPeriodChargeAmount();\n}\n\n// Workflow implementation is independent from interface. That way, application that start/signal/query workflows only need to know the interface\npublic class SubscriptionWorkflowImpl implements SubscriptionWorkflow {\n\n    private int billingPeriodNum;\n    private boolean subscriptionCancelled;\n    private Customer customer;\n    \n    private final SubscriptionActivities activities =\n            Workflow.newActivityStub(SubscriptionActivities.class);\n\n    // This manageSubscription function is an example of a workflow using Cadence\n    @Override\n    public void manageSubscription(Customer customer) {\n        // Set the Workflow customer to class properties so that it can be used by other methods like Query/Signal\n        this.customer = customer;\n\n        // sendWelcomeEmail is an activity in Cadence. It is implemented in user code and Cadence executes this activity on a worker node when needed.\n        activities.sendWelcomeEmail(customer);\n\n        // for this example, there are a fixed number of periods in the subscription\n        // Cadence supports indefinitely running workflow but some advanced techniques are needed\n        while (billingPeriodNum < customer.getSubscription().getPeriodsInSubcription()) {\n\n            // Workflow.await tells Cadence to pause the workflow at this stage (saving it's state to the database)\n            // Execution restarts when the billing period time has passed or the subscriptionCancelled event is received , whichever comes first\n            Workflow.await(customer.getSubscription().getBillingPeriod(), () -> subscriptionCancelled);\n\n            if (subscriptionCancelled) {\n                activities.sendCancellationEmailDuringActiveSubscription(customer);\n                break;\n            }\n            \n            // chargeCustomerForBillingPeriod is another activity\n            // Cadence will automatically handle issues such as your billing service being unavailable at the time\n            // this activity is invoked\n            activities.chargeCustomerForBillingPeriod(customer, billingPeriodNum);\n\n            billingPeriodNum++;\n        }\n\n        if (!subscriptionCancelled) {\n            activities.sendSubscriptionOverEmail(customer);\n        }\n        \n        // the workflow is finished once this function returns\n    }\n\n    @Override\n    public void cancelSubscription() {\n        subscriptionCancelled = true;\n    }\n\n    @Override\n    public void updateBillingPeriodChargeAmount(int billingPeriodChargeAmount) {\n        customer.getSubscription().setBillingPeriodCharge(billingPeriodChargeAmount);\n    }\n\n    @Override\n    public String queryCustomerId() {\n        return customer.getId();\n    }\n\n    @Override\n    public int queryBillingPeriodNumber() {\n        return billingPeriodNum;\n    }\n\n    @Override\n    public int queryBillingPeriodChargeAmount() {\n        return customer.getSubscription().getBillingPeriodCharge();\n    }\n}\n\n\n\nAgain, note that this code directly implements the business logic. If any of the invoked operations (aka ) takes a long time, the code is not going to change. It is okay to block on chargeCustomerForBillingPeriod for a day if the downstream processing service is down that long. The same way that blocking sleep for a billing period like 30 days is a normal operation inside the code.\n\nCadence has practically no scalability limits on the number of open instances. So even if your site has hundreds of millions of consumers, the above code is not going to change.\n\nThe commonly asked question by developers that learn Cadence is \"How do I handle process failure/restart in my \"? The answer is that you do not. The code is completely oblivious to any failures and downtime of or even the Cadence service itself. As soon as they are recovered and the needs to handle some , like timer or an completion, the current state of the is fully restored and the execution is continued. The only reason for a failure is the business code throwing an exception, not underlying infrastructure outages.\n\nAnother commonly asked question is whether a can handle more instances than its cache size or number of threads it can support. The answer is that a , when in a blocked state, can be safely removed from a . Later it can be resurrected on a different or the same when the need (in the form of an external ) arises. So a single can handle millions of open , assuming it can handle the update rate.\n\n\n# State Recovery and Determinism\n\nThe state recovery utilizes sourcing which puts a few restrictions on how the code is written. The main restriction is that the code must be deterministic which means that it must produce exactly the same result if executed multiple times. This rules out any external API calls from the code as external calls can fail intermittently or change its output any time. That is why all communication with the external world should happen through . For the same reason, code must use Cadence APIs to get current time, sleep, and create new threads.\n\nTo understand the Cadence execution model as well as the recovery mechanism, watch the following webcast. The animation covering recovery starts at 15:50.\n\n\n# ID Uniqueness\n\nis assigned by a client when starting a . It is usually a business level ID like customer ID or order ID.\n\nCadence guarantees that there could be only one (across all types) with a given ID open per at any time. An attempt to start a with the same ID is going to fail with WorkflowExecutionAlreadyStarted error.\n\nAn attempt to start a if there is a completed with the same ID depends on a WorkflowIdReusePolicy option:\n\n * AllowDuplicateFailedOnly means that it is allowed to start a only if a previously executed with the same ID failed.\n * AllowDuplicate means that it is allowed to start independently of the previous completion status.\n * RejectDuplicate means that it is not allowed to start a using the same at all.\n * TerminateIfRunning means terminating the current running workflow if one exists, and start a new one.\n\nThe default is AllowDuplicateFailedOnly.\n\nTo distinguish multiple runs of a with the same , Cadence identifies a with two IDs: Workflow ID and Run ID. Run ID is a service-assigned UUID. To be precise, any is uniquely identified by a triple: Domain Name, Workflow ID and Run ID.\n\n\n# Child Workflow\n\nA can execute other as child :workflow:workflows:. A child completion or failure is reported to its parent.\n\nSome reasons to use child are:\n\n * A child can be hosted by a separate set of which don't contain the parent code. So it would act as a separate service that can be invoked from multiple other .\n * A single has a limited size. For example, it cannot execute 100k . Child can be used to partition the problem into smaller chunks. One parent with 1000 children each executing 1000 is 1 million executed .\n * A child can be used to manage some resource using its ID to guarantee uniqueness. For example, a that manages host upgrades can have a child per host (host name being a ) and use them to ensure that all operations on the host are serialized.\n * A child can be used to execute some periodic logic without blowing up the parent history size. When a parent starts a child, it executes periodic logic calling that continues as many times as needed, then completes. From the parent point if view, it is just a single child invocation.\n\nThe main limitation of a child versus collocating all the application logic in a single is lack of the shared state. Parent and child can communicate only through asynchronous . But if there is a tight coupling between them, it might be simpler to use a single and just rely on a shared object state.\n\nWe recommended starting from a single implementation if your problem has bounded size in terms of number of executed and processed . It is more straightforward than multiple asynchronously communicating .\n\n\n# Workflow Retries\n\ncode is unaffected by infrastructure level downtime and failures. But it still can fail due to business logic level failures. For example, an can fail due to exceeding the retry interval and the error is not handled by application code, or the code having a bug.\n\nSome require a guarantee that they keep running even in presence of such failures. To support such use cases, an optional exponential retry policy can be specified when starting a . When it is specified, a failure restarts a from the beginning after the calculated retry interval. Following are the retry policy parameters:\n\n * InitialInterval is a delay before the first retry.\n * BackoffCoefficient. Retry policies are exponential. The coefficient specifies how fast the retry interval is growing. The coefficient of 1 means that the retry interval is always equal to the InitialInterval.\n * MaximumInterval specifies the maximum interval between retries. Useful for coefficients of more than 1.\n * MaximumAttempts specifies how many times to attempt to execute a in the presence of failures. If this limit is exceeded, the fails without retry. Not required if ExpirationInterval is specified.\n * ExpirationInterval specifies for how long to attempt executing a in the presence of failures. If this interval is exceeded, the fails without retry. Not required if MaximumAttempts is specified.\n * NonRetryableErrorReasons allows to specify errors that shouldn't be retried. For example, retrying invalid arguments error doesn't make sense in some scenarios.\n\n\n# How does workflow run\n\nYou may wonder how it works. Behind the scenes, workflow decision is driving the whole workflow running. It's the internal entities for client and server to run your workflows. If this is interesting to you, read this stack Overflow QA.",normalizedContent:"# fault-oblivious stateful workflow code\n\n\n# overview\n\ncadence core abstraction is a fault-oblivious stateful . the state of the code, including local variables and threads it creates, is immune to process and cadence service failures. this is a very powerful concept as it encapsulates state, processing threads, durable timers and handlers.\n\n\n# example\n\nlet's look at a use case. a customer signs up for an application with a trial period. after the period, if the customer has not cancelled, he should be charged once a month for the renewal. the customer has to be notified by email about the charges and should be able to cancel the subscription at any time.\n\nthe business logic of this use case is not very complicated and can be expressed in a few dozen lines of code. but any practical implementation has to ensure that the business process is fault tolerant and scalable. there are various ways to approach the design of such a system.\n\none approach is to center it around a database. an application process would periodically scan database tables for customers in specific states, execute necessary actions, and update the state to reflect that. while feasible, this approach has various drawbacks. the most obvious is that the state machine of the customer state quickly becomes extremely complicated. for example, charging a credit card or sending emails can fail due to a downstream system unavailability. the failed calls might need to be retried for a long time, ideally using an exponential retry policy. these calls should be throttled to not overload external systems. there should be support for poison pills to avoid blocking the whole process if a single customer record cannot be processed for whatever reason. the database-based approach also usually has performance problems. databases are not efficient for scenarios that require constant polling for records in a specific state.\n\nanother commonly employed approach is to use a timer service and queues. any update is pushed to a queue and then a that consumes from it updates a database and possibly pushes more messages in downstream queues. for operations that require scheduling, an external timer service can be used. this approach usually scales much better because a database is not constantly polled for changes. but it makes the programming model more complex and error prone as usually there is no transactional update between a queuing system and a database.\n\nwith cadence, the entire logic can be encapsulated in a simple durable function that directly implements the business logic. because the function is stateful, the implementer doesn't need to employ any additional systems to ensure durability and fault tolerance.\n\nhere is an example that implements the subscription management use case. it is in java, but go is also supported. the python and .net libraries are under active development.\n\n// this subscriptionworkflow interface is an example of defining a workflow in cadence\npublic interface subscriptionworkflow {\n    @workflowmethod\n    void managesubscription(string customerid);\n    @signalmethod\n    void cancelsubscription();\n    @signalmethod    \n    void updatebillingperiodchargeamount(int billingperiodchargeamount);\n    @querymethod    \n    string querycustomerid();\n    @querymethod        \n    int querybillingperiodnumber();\n    @querymethod        \n    int querybillingperiodchargeamount();\n}\n\n// workflow implementation is independent from interface. that way, application that start/signal/query workflows only need to know the interface\npublic class subscriptionworkflowimpl implements subscriptionworkflow {\n\n    private int billingperiodnum;\n    private boolean subscriptioncancelled;\n    private customer customer;\n    \n    private final subscriptionactivities activities =\n            workflow.newactivitystub(subscriptionactivities.class);\n\n    // this managesubscription function is an example of a workflow using cadence\n    @override\n    public void managesubscription(customer customer) {\n        // set the workflow customer to class properties so that it can be used by other methods like query/signal\n        this.customer = customer;\n\n        // sendwelcomeemail is an activity in cadence. it is implemented in user code and cadence executes this activity on a worker node when needed.\n        activities.sendwelcomeemail(customer);\n\n        // for this example, there are a fixed number of periods in the subscription\n        // cadence supports indefinitely running workflow but some advanced techniques are needed\n        while (billingperiodnum < customer.getsubscription().getperiodsinsubcription()) {\n\n            // workflow.await tells cadence to pause the workflow at this stage (saving it's state to the database)\n            // execution restarts when the billing period time has passed or the subscriptioncancelled event is received , whichever comes first\n            workflow.await(customer.getsubscription().getbillingperiod(), () -> subscriptioncancelled);\n\n            if (subscriptioncancelled) {\n                activities.sendcancellationemailduringactivesubscription(customer);\n                break;\n            }\n            \n            // chargecustomerforbillingperiod is another activity\n            // cadence will automatically handle issues such as your billing service being unavailable at the time\n            // this activity is invoked\n            activities.chargecustomerforbillingperiod(customer, billingperiodnum);\n\n            billingperiodnum++;\n        }\n\n        if (!subscriptioncancelled) {\n            activities.sendsubscriptionoveremail(customer);\n        }\n        \n        // the workflow is finished once this function returns\n    }\n\n    @override\n    public void cancelsubscription() {\n        subscriptioncancelled = true;\n    }\n\n    @override\n    public void updatebillingperiodchargeamount(int billingperiodchargeamount) {\n        customer.getsubscription().setbillingperiodcharge(billingperiodchargeamount);\n    }\n\n    @override\n    public string querycustomerid() {\n        return customer.getid();\n    }\n\n    @override\n    public int querybillingperiodnumber() {\n        return billingperiodnum;\n    }\n\n    @override\n    public int querybillingperiodchargeamount() {\n        return customer.getsubscription().getbillingperiodcharge();\n    }\n}\n\n\n\nagain, note that this code directly implements the business logic. if any of the invoked operations (aka ) takes a long time, the code is not going to change. it is okay to block on chargecustomerforbillingperiod for a day if the downstream processing service is down that long. the same way that blocking sleep for a billing period like 30 days is a normal operation inside the code.\n\ncadence has practically no scalability limits on the number of open instances. so even if your site has hundreds of millions of consumers, the above code is not going to change.\n\nthe commonly asked question by developers that learn cadence is \"how do i handle process failure/restart in my \"? the answer is that you do not. the code is completely oblivious to any failures and downtime of or even the cadence service itself. as soon as they are recovered and the needs to handle some , like timer or an completion, the current state of the is fully restored and the execution is continued. the only reason for a failure is the business code throwing an exception, not underlying infrastructure outages.\n\nanother commonly asked question is whether a can handle more instances than its cache size or number of threads it can support. the answer is that a , when in a blocked state, can be safely removed from a . later it can be resurrected on a different or the same when the need (in the form of an external ) arises. so a single can handle millions of open , assuming it can handle the update rate.\n\n\n# state recovery and determinism\n\nthe state recovery utilizes sourcing which puts a few restrictions on how the code is written. the main restriction is that the code must be deterministic which means that it must produce exactly the same result if executed multiple times. this rules out any external api calls from the code as external calls can fail intermittently or change its output any time. that is why all communication with the external world should happen through . for the same reason, code must use cadence apis to get current time, sleep, and create new threads.\n\nto understand the cadence execution model as well as the recovery mechanism, watch the following webcast. the animation covering recovery starts at 15:50.\n\n\n# id uniqueness\n\nis assigned by a client when starting a . it is usually a business level id like customer id or order id.\n\ncadence guarantees that there could be only one (across all types) with a given id open per at any time. an attempt to start a with the same id is going to fail with workflowexecutionalreadystarted error.\n\nan attempt to start a if there is a completed with the same id depends on a workflowidreusepolicy option:\n\n * allowduplicatefailedonly means that it is allowed to start a only if a previously executed with the same id failed.\n * allowduplicate means that it is allowed to start independently of the previous completion status.\n * rejectduplicate means that it is not allowed to start a using the same at all.\n * terminateifrunning means terminating the current running workflow if one exists, and start a new one.\n\nthe default is allowduplicatefailedonly.\n\nto distinguish multiple runs of a with the same , cadence identifies a with two ids: workflow id and run id. run id is a service-assigned uuid. to be precise, any is uniquely identified by a triple: domain name, workflow id and run id.\n\n\n# child workflow\n\na can execute other as child :workflow:workflows:. a child completion or failure is reported to its parent.\n\nsome reasons to use child are:\n\n * a child can be hosted by a separate set of which don't contain the parent code. so it would act as a separate service that can be invoked from multiple other .\n * a single has a limited size. for example, it cannot execute 100k . child can be used to partition the problem into smaller chunks. one parent with 1000 children each executing 1000 is 1 million executed .\n * a child can be used to manage some resource using its id to guarantee uniqueness. for example, a that manages host upgrades can have a child per host (host name being a ) and use them to ensure that all operations on the host are serialized.\n * a child can be used to execute some periodic logic without blowing up the parent history size. when a parent starts a child, it executes periodic logic calling that continues as many times as needed, then completes. from the parent point if view, it is just a single child invocation.\n\nthe main limitation of a child versus collocating all the application logic in a single is lack of the shared state. parent and child can communicate only through asynchronous . but if there is a tight coupling between them, it might be simpler to use a single and just rely on a shared object state.\n\nwe recommended starting from a single implementation if your problem has bounded size in terms of number of executed and processed . it is more straightforward than multiple asynchronously communicating .\n\n\n# workflow retries\n\ncode is unaffected by infrastructure level downtime and failures. but it still can fail due to business logic level failures. for example, an can fail due to exceeding the retry interval and the error is not handled by application code, or the code having a bug.\n\nsome require a guarantee that they keep running even in presence of such failures. to support such use cases, an optional exponential retry policy can be specified when starting a . when it is specified, a failure restarts a from the beginning after the calculated retry interval. following are the retry policy parameters:\n\n * initialinterval is a delay before the first retry.\n * backoffcoefficient. retry policies are exponential. the coefficient specifies how fast the retry interval is growing. the coefficient of 1 means that the retry interval is always equal to the initialinterval.\n * maximuminterval specifies the maximum interval between retries. useful for coefficients of more than 1.\n * maximumattempts specifies how many times to attempt to execute a in the presence of failures. if this limit is exceeded, the fails without retry. not required if expirationinterval is specified.\n * expirationinterval specifies for how long to attempt executing a in the presence of failures. if this interval is exceeded, the fails without retry. not required if maximumattempts is specified.\n * nonretryableerrorreasons allows to specify errors that shouldn't be retried. for example, retrying invalid arguments error doesn't make sense in some scenarios.\n\n\n# how does workflow run\n\nyou may wonder how it works. behind the scenes, workflow decision is driving the whole workflow running. it's the internal entities for client and server to run your workflows. if this is interesting to you, read this stack overflow qa.",charsets:{}},{title:"Activities",frontmatter:{layout:"default",title:"Activities",permalink:"/docs/concepts/activities",readingShow:"top"},regularPath:"/docs/03-concepts/02-activities.html",relativePath:"docs/03-concepts/02-activities.md",key:"v-e240404c",path:"/docs/concepts/activities/",headers:[{level:2,title:"Timeouts",slug:"timeouts",normalizedTitle:"timeouts",charIndex:854},{level:2,title:"Retries",slug:"retries",normalizedTitle:"retries",charIndex:1835},{level:2,title:"Long Running Activities",slug:"long-running-activities",normalizedTitle:"long running activities",charIndex:1601},{level:2,title:"Cancellation",slug:"cancellation",normalizedTitle:"cancellation",charIndex:4826},{level:2,title:"Activity Task Routing through Task Lists",slug:"activity-task-routing-through-task-lists",normalizedTitle:"activity task routing through task lists",charIndex:5435},{level:2,title:"Asynchronous Activity Completion",slug:"asynchronous-activity-completion",normalizedTitle:"asynchronous activity completion",charIndex:7240},{level:2,title:"Local Activities",slug:"local-activities",normalizedTitle:"local activities",charIndex:7860}],codeSwitcherOptions:{},headersStr:"Timeouts Retries Long Running Activities Cancellation Activity Task Routing through Task Lists Asynchronous Activity Completion Local Activities",content:"# Activities\n\nFault-oblivious stateful code is the core abstraction of Cadence. But, due to deterministic execution requirements, they are not allowed to call any external API directly. Instead they orchestrate execution of . In its simplest form, a Cadence is a function or an object method in one of the supported languages. Cadence does not recover state in case of failures. Therefore an function is allowed to contain any code without restrictions.\n\nare invoked asynchronously through . A is essentially a queue used to store an until it is picked up by an available . The processes an by invoking its implementation function. When the function returns, the reports the result back to the Cadence service which in turn notifies the about completion. It is possible to implement an fully asynchronously by completing it from a different process.\n\n\n# Timeouts\n\nCadence does not impose any system limit on duration. It is up to the application to choose the timeouts for its execution. These are the configurable timeouts:\n\n * ScheduleToStart is the maximum time from a requesting execution to a starting its execution. The usual reason for this timeout to fire is all being down or not being able to keep up with the request rate. We recommend setting this timeout to the maximum time a is willing to wait for an execution in the presence of all possible outages.\n * StartToClose is the maximum time an can execute after it was picked by a .\n * ScheduleToClose is the maximum time from the requesting an execution to its completion.\n * Heartbeat is the maximum time between heartbeat requests. See Long Running Activities.\n\nEither ScheduleToClose or both ScheduleToStart and StartToClose timeouts are required.\n\nTimeouts are the key to manage activities. For more tips of how to set proper timeout, read this Stack Overflow QA.\n\n\n# Retries\n\nAs Cadence doesn't recover an 's state and they can communicate to any external system, failures are expected. Therefore, Cadence supports automatic retries. Any when invoked can have an associated retry policy. Here are the retry policy parameters:\n\n * InitialInterval is a delay before the first retry.\n * BackoffCoefficient. Retry policies are exponential. The coefficient specifies how fast the retry interval is growing. The coefficient of 1 means that the retry interval is always equal to the InitialInterval.\n * MaximumInterval specifies the maximum interval between retries. Useful for coefficients more than 1.\n * MaximumAttempts specifies how many times to attempt to execute an in the presence of failures. If this limit is exceeded, the error is returned back to the that invoked the . Not required if ExpirationInterval is specified.\n * ExpirationInterval specifies for how long to attempt executing an in the presence of failures. If this interval is exceeded, the error is returned back to the that invoked the . Not required if MaximumAttempts is specified.\n * NonRetryableErrorReasons allows you to specify errors that shouldn't be retried. For example retrying invalid arguments error doesn't make sense in some scenarios.\n\nThere are scenarios when not a single but rather the whole part of a should be retried on failure. For example, a media encoding that downloads a file to a host, processes it, and then uploads the result back to storage. In this , if the host that hosts the dies, all three should be retried on a different host. Such retries should be handled by the code as they are very use case specific.\n\n\n# Long Running Activities\n\nFor long running , we recommended that you specify a relatively short heartbeat timeout and constantly heartbeat. This way failures for even very long running can be handled in a timely manner. An that specifies the heartbeat timeout is expected to call the heartbeat method periodically from its implementation.\n\nA heartbeat request can include application specific payload. This is useful to save execution progress. If an times out due to a missed heartbeat, the next attempt to execute it can access that progress and continue its execution from that point.\n\nLong running can be used as a special case of leader election. Cadence timeouts use second resolution. So it is not a solution for realtime applications. But if it is okay to react to the process failure within a few seconds, then a Cadence heartbeat is a good fit.\n\nOne common use case for such leader election is monitoring. An executes an internal loop that periodically polls some API and checks for some condition. It also heartbeats on every iteration. If the condition is satisfied, the completes which lets its to handle it. If the dies, the times out after the heartbeat interval is exceeded and is retried on a different . The same pattern works for polling for new files in Amazon S3 buckets or responses in REST or other synchronous APIs.\n\n\n# Cancellation\n\nA can request an cancellation. Currently the only way for an to learn that it was cancelled is through heart beating. The heartbeat request fails with a special error indicating that the was cancelled. Then it is up to the implementation to perform all the necessary cleanup and report that it is done with it. It is up to the implementation to decide if it wants to wait for the cancellation confirmation or just proceed without waiting.\n\nAnother common case for heartbeat failure is that the that invoked it is in a completed state. In this case an is expected to perform cleanup as well.\n\n\n# Activity Task Routing through Task Lists\n\nare dispatched to through . are queues that listen on. are highly dynamic and lightweight. They don't need to be explicitly registered. And it is okay to have one per process. It is normal to have more than one type to be invoked through a single . And it is normal in some cases (like host routing) to invoke the same type on multiple .\n\nHere are some use cases for employing multiple in a single workflow:\n\n * Flow control. A that consumes from a asks for an only when it has available capacity. So are never overloaded by request spikes. If executions are requested faster than can process them, they are backlogged in the .\n * Throttling. Each can specify the maximum rate it is allowed to processes on a . It does not exceed this limit even if it has spare capacity. There is also support for global rate limiting. This limit works across all for the given . It is frequently used to limit load on a downstream service that an calls into.\n * Deploying a set of independently. Think about a service that hosts and can be deployed independently from other and . To send to this service, a separate is needed.\n * with different capabilities. For example, on GPU boxes vs non GPU boxes. Having two separate in this case allows to pick which one to send an execution request to.\n * Routing to a specific host. For example, in the media encoding case the transform and upload have to run on the same host as the download one.\n * Routing to a specific process. For example, some load large data sets and caches it in the process. The that rely on this data set should be routed to the same process.\n * Multiple priorities. One per priority and having a pool per priority.\n * Versioning. A new backwards incompatible implementation of an might use a different .\n\n\n# Asynchronous Activity Completion\n\nBy default an is a function or a method depending on a client side library language. As soon as the function returns, an completes. But in some cases an implementation is asynchronous. For example it is forwarded to an external system through a message queue. And the reply comes through a different queue.\n\nTo support such use cases, Cadence allows implementations that do not complete upon function completions. A separate API should be used in this case to complete the . This API can be called from any process, even in a different programming language, that the original used.\n\n\n# Local Activities\n\nSome of the are very short lived and do not need the queing semantic, flow control, rate limiting and routing capabilities. For these Cadence supports so called feature. are executed in the same process as the that invoked them.\n\nWhat you will trade off by using local activities\n\n * Less Debuggability: There is no ActivityTaskScheduled and ActivityTaskStarted events. So you would not able to see the input.\n * No tasklist dispatching: The worker is always the same as the workflow decision worker. You don't have a choice of using activity workers.\n * More possibility of duplicated execution. Though regular activity could also execute multiple times when using retry policy, local activity has more chance of ocurring. Because local activity result is not recorded into history until DecisionTaskCompleted. Also when executing multiple local activities in a row, SDK(Java+Golang) would optimize recording in a way that only recording by interval(before current decision task timeout).\n * No long running capability with record heartbeat\n * No Tasklist global ratelimiting\n\nConsider using for functions that are:\n\n * idempotent\n * no longer than a few seconds\n * do not require global rate limiting\n * do not require routing to specific or pools of\n * can be implemented in the same binary as the that invokes them\n * non business critical so that losing some debuggability is okay(e.g. logging, loading config)\n * when you really need optimization. For example, if there are many timers firing at the same time to invoke activities, it could overload Cadence's server. Using local activities can help save the server capacity.\n\nThe main benefit of is that they are much more efficient in utilizing Cadence service resources and have much lower latency overhead comparing to the usual invocation.",normalizedContent:"# activities\n\nfault-oblivious stateful code is the core abstraction of cadence. but, due to deterministic execution requirements, they are not allowed to call any external api directly. instead they orchestrate execution of . in its simplest form, a cadence is a function or an object method in one of the supported languages. cadence does not recover state in case of failures. therefore an function is allowed to contain any code without restrictions.\n\nare invoked asynchronously through . a is essentially a queue used to store an until it is picked up by an available . the processes an by invoking its implementation function. when the function returns, the reports the result back to the cadence service which in turn notifies the about completion. it is possible to implement an fully asynchronously by completing it from a different process.\n\n\n# timeouts\n\ncadence does not impose any system limit on duration. it is up to the application to choose the timeouts for its execution. these are the configurable timeouts:\n\n * scheduletostart is the maximum time from a requesting execution to a starting its execution. the usual reason for this timeout to fire is all being down or not being able to keep up with the request rate. we recommend setting this timeout to the maximum time a is willing to wait for an execution in the presence of all possible outages.\n * starttoclose is the maximum time an can execute after it was picked by a .\n * scheduletoclose is the maximum time from the requesting an execution to its completion.\n * heartbeat is the maximum time between heartbeat requests. see long running activities.\n\neither scheduletoclose or both scheduletostart and starttoclose timeouts are required.\n\ntimeouts are the key to manage activities. for more tips of how to set proper timeout, read this stack overflow qa.\n\n\n# retries\n\nas cadence doesn't recover an 's state and they can communicate to any external system, failures are expected. therefore, cadence supports automatic retries. any when invoked can have an associated retry policy. here are the retry policy parameters:\n\n * initialinterval is a delay before the first retry.\n * backoffcoefficient. retry policies are exponential. the coefficient specifies how fast the retry interval is growing. the coefficient of 1 means that the retry interval is always equal to the initialinterval.\n * maximuminterval specifies the maximum interval between retries. useful for coefficients more than 1.\n * maximumattempts specifies how many times to attempt to execute an in the presence of failures. if this limit is exceeded, the error is returned back to the that invoked the . not required if expirationinterval is specified.\n * expirationinterval specifies for how long to attempt executing an in the presence of failures. if this interval is exceeded, the error is returned back to the that invoked the . not required if maximumattempts is specified.\n * nonretryableerrorreasons allows you to specify errors that shouldn't be retried. for example retrying invalid arguments error doesn't make sense in some scenarios.\n\nthere are scenarios when not a single but rather the whole part of a should be retried on failure. for example, a media encoding that downloads a file to a host, processes it, and then uploads the result back to storage. in this , if the host that hosts the dies, all three should be retried on a different host. such retries should be handled by the code as they are very use case specific.\n\n\n# long running activities\n\nfor long running , we recommended that you specify a relatively short heartbeat timeout and constantly heartbeat. this way failures for even very long running can be handled in a timely manner. an that specifies the heartbeat timeout is expected to call the heartbeat method periodically from its implementation.\n\na heartbeat request can include application specific payload. this is useful to save execution progress. if an times out due to a missed heartbeat, the next attempt to execute it can access that progress and continue its execution from that point.\n\nlong running can be used as a special case of leader election. cadence timeouts use second resolution. so it is not a solution for realtime applications. but if it is okay to react to the process failure within a few seconds, then a cadence heartbeat is a good fit.\n\none common use case for such leader election is monitoring. an executes an internal loop that periodically polls some api and checks for some condition. it also heartbeats on every iteration. if the condition is satisfied, the completes which lets its to handle it. if the dies, the times out after the heartbeat interval is exceeded and is retried on a different . the same pattern works for polling for new files in amazon s3 buckets or responses in rest or other synchronous apis.\n\n\n# cancellation\n\na can request an cancellation. currently the only way for an to learn that it was cancelled is through heart beating. the heartbeat request fails with a special error indicating that the was cancelled. then it is up to the implementation to perform all the necessary cleanup and report that it is done with it. it is up to the implementation to decide if it wants to wait for the cancellation confirmation or just proceed without waiting.\n\nanother common case for heartbeat failure is that the that invoked it is in a completed state. in this case an is expected to perform cleanup as well.\n\n\n# activity task routing through task lists\n\nare dispatched to through . are queues that listen on. are highly dynamic and lightweight. they don't need to be explicitly registered. and it is okay to have one per process. it is normal to have more than one type to be invoked through a single . and it is normal in some cases (like host routing) to invoke the same type on multiple .\n\nhere are some use cases for employing multiple in a single workflow:\n\n * flow control. a that consumes from a asks for an only when it has available capacity. so are never overloaded by request spikes. if executions are requested faster than can process them, they are backlogged in the .\n * throttling. each can specify the maximum rate it is allowed to processes on a . it does not exceed this limit even if it has spare capacity. there is also support for global rate limiting. this limit works across all for the given . it is frequently used to limit load on a downstream service that an calls into.\n * deploying a set of independently. think about a service that hosts and can be deployed independently from other and . to send to this service, a separate is needed.\n * with different capabilities. for example, on gpu boxes vs non gpu boxes. having two separate in this case allows to pick which one to send an execution request to.\n * routing to a specific host. for example, in the media encoding case the transform and upload have to run on the same host as the download one.\n * routing to a specific process. for example, some load large data sets and caches it in the process. the that rely on this data set should be routed to the same process.\n * multiple priorities. one per priority and having a pool per priority.\n * versioning. a new backwards incompatible implementation of an might use a different .\n\n\n# asynchronous activity completion\n\nby default an is a function or a method depending on a client side library language. as soon as the function returns, an completes. but in some cases an implementation is asynchronous. for example it is forwarded to an external system through a message queue. and the reply comes through a different queue.\n\nto support such use cases, cadence allows implementations that do not complete upon function completions. a separate api should be used in this case to complete the . this api can be called from any process, even in a different programming language, that the original used.\n\n\n# local activities\n\nsome of the are very short lived and do not need the queing semantic, flow control, rate limiting and routing capabilities. for these cadence supports so called feature. are executed in the same process as the that invoked them.\n\nwhat you will trade off by using local activities\n\n * less debuggability: there is no activitytaskscheduled and activitytaskstarted events. so you would not able to see the input.\n * no tasklist dispatching: the worker is always the same as the workflow decision worker. you don't have a choice of using activity workers.\n * more possibility of duplicated execution. though regular activity could also execute multiple times when using retry policy, local activity has more chance of ocurring. because local activity result is not recorded into history until decisiontaskcompleted. also when executing multiple local activities in a row, sdk(java+golang) would optimize recording in a way that only recording by interval(before current decision task timeout).\n * no long running capability with record heartbeat\n * no tasklist global ratelimiting\n\nconsider using for functions that are:\n\n * idempotent\n * no longer than a few seconds\n * do not require global rate limiting\n * do not require routing to specific or pools of\n * can be implemented in the same binary as the that invokes them\n * non business critical so that losing some debuggability is okay(e.g. logging, loading config)\n * when you really need optimization. for example, if there are many timers firing at the same time to invoke activities, it could overload cadence's server. using local activities can help save the server capacity.\n\nthe main benefit of is that they are much more efficient in utilizing cadence service resources and have much lower latency overhead comparing to the usual invocation.",charsets:{}},{title:"Event handling",frontmatter:{layout:"default",title:"Event handling",permalink:"/docs/concepts/events",readingShow:"top"},regularPath:"/docs/03-concepts/03-events.html",relativePath:"docs/03-concepts/03-events.md",key:"v-2d8e6278",path:"/docs/concepts/events/",headers:[{level:2,title:"Event Aggregation and Correlation",slug:"event-aggregation-and-correlation",normalizedTitle:"event aggregation and correlation",charIndex:248},{level:2,title:"Human Tasks",slug:"human-tasks",normalizedTitle:"human tasks",charIndex:1865},{level:2,title:"Process Execution Alteration",slug:"process-execution-alteration",normalizedTitle:"process execution alteration",charIndex:2447},{level:2,title:"Synchronization",slug:"synchronization",normalizedTitle:"synchronization",charIndex:2966}],codeSwitcherOptions:{},headersStr:"Event Aggregation and Correlation Human Tasks Process Execution Alteration Synchronization",content:"# Event handling\n\nFault-oblivious stateful can be about an external . A is always point to point destined to a specific instance. are always processed in the order in which they are received.\n\nThere are multiple scenarios for which are useful.\n\n\n# Event Aggregation and Correlation\n\nCadence is not a replacement for generic stream processing engines like Apache Flink or Apache Spark. But in certain scenarios it is a better fit. For example, when all that should be aggregated and correlated are always applied to some business entity with a clear ID. And then when a certain condition is met, actions should be executed.\n\nThe main limitation is that a single Cadence has a pretty limited throughput, while the number of is practically unlimited. So if you need to aggregate per customer, and your application has 100 million customers and each customer doesn't generate more than 20 per second, then Cadence would work fine. But if you want to aggregate all for US customers then the rate of these would be beyond the single capacity.\n\nFor example, an IoT device generates and a certain sequence of indicates that the device should be reprovisioned. A instance per device would be created and each instance would manage the state machine of the device and execute reprovision when necessary.\n\nAnother use case is a customer loyalty program. Every time a customer makes a purchase, an is generated into Apache Kafka for downstream systems to process. A loyalty service Kafka consumer receives the and a customer about the purchase using the Cadence signalWorkflowExecution API. The accumulates the count of the purchases. If a specified threshold is achieved, the executes an that notifies some external service that the customer has reached the next level of loyalty program. The also executes to periodically message the customer about their current status.\n\n\n# Human Tasks\n\nA lot of business processes involve human participants. The standard Cadence pattern for implementing an external interaction is to execute an that creates a human in an external system. It can be an email with a form, or a record in some external database, or a mobile app notification. When a user changes the status of the , a is sent to the corresponding . For example, when the form is submitted, or a mobile app notification is acknowledged. Some have multiple possible actions like claim, return, complete, reject. So multiple can be sent in relation to it.\n\n\n# Process Execution Alteration\n\nSome business processes should change their behavior if some external has happened. For example, while executing an order shipment , any change in item quantity could be delivered in a form of a .\n\nAnother example is a service deployment . While rolling out new software version to a Kubernetes cluster some problem was identified. A can be used to ask the to pause while the problem is investigated. Then either a continue or a rollback can be used to execute the appropriate action.\n\n\n# Synchronization\n\nCadence are strongly consistent so they can be used as a synchronization point for executing actions. For example, there is a requirement that all messages for a single user are processed sequentially but the underlying messaging infrastructure can deliver them in parallel. The Cadence solution would be to have a per user and it when an is received. Then the would buffer all in an internal data structure and then call an for every received. See the following Stack Overflow answer for an example.",normalizedContent:"# event handling\n\nfault-oblivious stateful can be about an external . a is always point to point destined to a specific instance. are always processed in the order in which they are received.\n\nthere are multiple scenarios for which are useful.\n\n\n# event aggregation and correlation\n\ncadence is not a replacement for generic stream processing engines like apache flink or apache spark. but in certain scenarios it is a better fit. for example, when all that should be aggregated and correlated are always applied to some business entity with a clear id. and then when a certain condition is met, actions should be executed.\n\nthe main limitation is that a single cadence has a pretty limited throughput, while the number of is practically unlimited. so if you need to aggregate per customer, and your application has 100 million customers and each customer doesn't generate more than 20 per second, then cadence would work fine. but if you want to aggregate all for us customers then the rate of these would be beyond the single capacity.\n\nfor example, an iot device generates and a certain sequence of indicates that the device should be reprovisioned. a instance per device would be created and each instance would manage the state machine of the device and execute reprovision when necessary.\n\nanother use case is a customer loyalty program. every time a customer makes a purchase, an is generated into apache kafka for downstream systems to process. a loyalty service kafka consumer receives the and a customer about the purchase using the cadence signalworkflowexecution api. the accumulates the count of the purchases. if a specified threshold is achieved, the executes an that notifies some external service that the customer has reached the next level of loyalty program. the also executes to periodically message the customer about their current status.\n\n\n# human tasks\n\na lot of business processes involve human participants. the standard cadence pattern for implementing an external interaction is to execute an that creates a human in an external system. it can be an email with a form, or a record in some external database, or a mobile app notification. when a user changes the status of the , a is sent to the corresponding . for example, when the form is submitted, or a mobile app notification is acknowledged. some have multiple possible actions like claim, return, complete, reject. so multiple can be sent in relation to it.\n\n\n# process execution alteration\n\nsome business processes should change their behavior if some external has happened. for example, while executing an order shipment , any change in item quantity could be delivered in a form of a .\n\nanother example is a service deployment . while rolling out new software version to a kubernetes cluster some problem was identified. a can be used to ask the to pause while the problem is investigated. then either a continue or a rollback can be used to execute the appropriate action.\n\n\n# synchronization\n\ncadence are strongly consistent so they can be used as a synchronization point for executing actions. for example, there is a requirement that all messages for a single user are processed sequentially but the underlying messaging infrastructure can deliver them in parallel. the cadence solution would be to have a per user and it when an is received. then the would buffer all in an internal data structure and then call an for every received. see the following stack overflow answer for an example.",charsets:{}},{title:"Synchronous query",frontmatter:{layout:"default",title:"Synchronous query",permalink:"/docs/concepts/queries",readingShow:"top"},regularPath:"/docs/03-concepts/04-queries.html",relativePath:"docs/03-concepts/04-queries.md",key:"v-7b43cf3c",path:"/docs/concepts/queries/",headers:[{level:2,title:"Stack Trace Query",slug:"stack-trace-query",normalizedTitle:"stack trace query",charIndex:1119}],codeSwitcherOptions:{},headersStr:"Stack Trace Query",content:'# Synchronous query\n\ncode is stateful with the Cadence framework preserving it over various software and hardware failures. The state is constantly mutated during . To expose this internal state to the external world Cadence provides a synchronous feature. From the implementer point of view the is exposed as a synchronous callback that is invoked by external entities. Multiple such callbacks can be provided per type exposing different information to different external systems.\n\nTo execute a an external client calls a synchronous Cadence API providing , workflowID, name and optional arguments.\n\ncallbacks must be read-only not mutating the state in any way. The other limitation is that the callback cannot contain any blocking code. Both above limitations rule out ability to invoke from the handlers.\n\nCadence team is currently working on implementing update feature that would be similar to in the way it is invoked, but would support state mutation and invocations. From user\'s point of view, update is similar to signal + strong consistent query, but implemented in a much less expensive way in Cadence.\n\n\n# Stack Trace Query\n\nThe Cadence client libraries expose some predefined out of the box. Currently the only supported built-in is stack_trace. This returns stacks of all owned threads. This is a great way to troubleshoot any in production.\n\nExample\n\n$cadence --do samples-domain wf query -w <workflowID> -qt __stack_trace\n"coroutine 1 [blocked on selector-1.Select]:\\nmain.sampleSignalCounterWorkflow(0x1a99ae8, 0xc00009d700, 0x0, 0x0, 0x0)\\n\\t/Users/qlong/indeed/cadence-samples/cmd/samples/recipes/signalcounter/signal_counter_workflow.go:38 +0x1be\\nreflect.Value.call(0x1852ac0, 0x19cb608, 0x13, 0x1979180, 0x4, 0xc00045aa80, 0x2, 0x2, 0x2, 0x18, ...)\\n\\t/usr/local/Cellar/go/1.16.3/libexec/src/reflect/value.go:476 +0x8e7\\nreflect.Value.Call(0x1852ac0, 0x19cb608, 0x13, 0xc00045aa80, 0x2, 0x2, 0x1, 0x2, 0xc00045a720)\\n\\t/usr/local/Cellar/go/1.16.3/libexec/src/reflect/value.go:337 +0xb9\\ngo.uber.org/cadence/internal.(*workflowEnvironmentInterceptor).ExecuteWorkflow(0xc00045a720, 0x1a99ae8, 0xc00009d700, 0xc0001ca820, 0x20, 0xc00007fad0, 0x1, 0x1, 0x1, 0x1, ...)\\n\\t/Users/qlong/go/pkg/mod/go.uber.org/cadence@v0.17.1-0.20210708064625-c4a7e032cc13/internal/workflow.go:372 +0x2cb\\ngo.uber.org/cadence/internal.(*workflowExecutor).Execute(0xc000098d80, 0x1a99ae8, 0xc00009d700, 0xc0001b127e, 0x2, 0x2, 0xc00044cb01, 0xc000070101, 0xc000073738, 0x1729f25, ...)\\n\\t/Users/qlong/go/pkg/mod/go.uber.org/cadence@v0.17.1-0.20210708064625-c4a7e032cc13/internal/internal_worker.go:699 +0x28d\\ngo.uber.org/cadence/internal.(*syncWorkflowDefinition).Execute.func1(0x1a99ce0, 0xc00045a9f0)\\n\\t/Users/qlong/go/pkg/mod/go.uber.org/cadence@v0.17.1-0.20210708064625-c4a7e032cc13/internal/internal_workflow.go:466 +0x106"\n',normalizedContent:'# synchronous query\n\ncode is stateful with the cadence framework preserving it over various software and hardware failures. the state is constantly mutated during . to expose this internal state to the external world cadence provides a synchronous feature. from the implementer point of view the is exposed as a synchronous callback that is invoked by external entities. multiple such callbacks can be provided per type exposing different information to different external systems.\n\nto execute a an external client calls a synchronous cadence api providing , workflowid, name and optional arguments.\n\ncallbacks must be read-only not mutating the state in any way. the other limitation is that the callback cannot contain any blocking code. both above limitations rule out ability to invoke from the handlers.\n\ncadence team is currently working on implementing update feature that would be similar to in the way it is invoked, but would support state mutation and invocations. from user\'s point of view, update is similar to signal + strong consistent query, but implemented in a much less expensive way in cadence.\n\n\n# stack trace query\n\nthe cadence client libraries expose some predefined out of the box. currently the only supported built-in is stack_trace. this returns stacks of all owned threads. this is a great way to troubleshoot any in production.\n\nexample\n\n$cadence --do samples-domain wf query -w <workflowid> -qt __stack_trace\n"coroutine 1 [blocked on selector-1.select]:\\nmain.samplesignalcounterworkflow(0x1a99ae8, 0xc00009d700, 0x0, 0x0, 0x0)\\n\\t/users/qlong/indeed/cadence-samples/cmd/samples/recipes/signalcounter/signal_counter_workflow.go:38 +0x1be\\nreflect.value.call(0x1852ac0, 0x19cb608, 0x13, 0x1979180, 0x4, 0xc00045aa80, 0x2, 0x2, 0x2, 0x18, ...)\\n\\t/usr/local/cellar/go/1.16.3/libexec/src/reflect/value.go:476 +0x8e7\\nreflect.value.call(0x1852ac0, 0x19cb608, 0x13, 0xc00045aa80, 0x2, 0x2, 0x1, 0x2, 0xc00045a720)\\n\\t/usr/local/cellar/go/1.16.3/libexec/src/reflect/value.go:337 +0xb9\\ngo.uber.org/cadence/internal.(*workflowenvironmentinterceptor).executeworkflow(0xc00045a720, 0x1a99ae8, 0xc00009d700, 0xc0001ca820, 0x20, 0xc00007fad0, 0x1, 0x1, 0x1, 0x1, ...)\\n\\t/users/qlong/go/pkg/mod/go.uber.org/cadence@v0.17.1-0.20210708064625-c4a7e032cc13/internal/workflow.go:372 +0x2cb\\ngo.uber.org/cadence/internal.(*workflowexecutor).execute(0xc000098d80, 0x1a99ae8, 0xc00009d700, 0xc0001b127e, 0x2, 0x2, 0xc00044cb01, 0xc000070101, 0xc000073738, 0x1729f25, ...)\\n\\t/users/qlong/go/pkg/mod/go.uber.org/cadence@v0.17.1-0.20210708064625-c4a7e032cc13/internal/internal_worker.go:699 +0x28d\\ngo.uber.org/cadence/internal.(*syncworkflowdefinition).execute.func1(0x1a99ce0, 0xc00045a9f0)\\n\\t/users/qlong/go/pkg/mod/go.uber.org/cadence@v0.17.1-0.20210708064625-c4a7e032cc13/internal/internal_workflow.go:466 +0x106"\n',charsets:{}},{title:"Task lists",frontmatter:{layout:"default",title:"Task lists",permalink:"/docs/concepts/task-lists",readingShow:"top"},regularPath:"/docs/03-concepts/06-task-lists.html",relativePath:"docs/03-concepts/06-task-lists.md",key:"v-78a9ec22",path:"/docs/concepts/task-lists/",codeSwitcherOptions:{},headersStr:null,content:"# Task lists\n\nWhen a invokes an , it sends the ScheduleActivityTask to the Cadence service. As a result, the service updates the state and dispatches an to a that implements the . Instead of calling the directly, an intermediate queue is used. So the service adds an to this queue and a receives the using a long poll request. Cadence calls this queue used to dispatch an .\n\nSimilarly, when a needs to handle an external , a is created. A is used to deliver it to the (also called decider).\n\nWhile Cadence are queues, they have some differences from commonly used queuing technologies. The main one is that they do not require explicit registration and are created on demand. The number of is not limited. A common use case is to have a per process and use it to deliver to the process. Another use case is to have a per pool of .\n\nThere are multiple advantages of using a to deliver instead of invoking an through a synchronous RPC:\n\n * doesn't need to have any open ports, which is more secure.\n * doesn't need to advertise itself through DNS or any other network discovery mechanism.\n * When all are down, messages are persisted in a waiting for the to recover.\n * A polls for a message only when it has spare capacity, so it never gets overloaded.\n * Automatic load balancing across a large number of .\n * support server side throttling. This allows you to limit the dispatch rate to the pool of and still supports adding a with a higher rate when spikes happen.\n * can be used to route a request to specific pools of or even a specific process.",normalizedContent:"# task lists\n\nwhen a invokes an , it sends the scheduleactivitytask to the cadence service. as a result, the service updates the state and dispatches an to a that implements the . instead of calling the directly, an intermediate queue is used. so the service adds an to this queue and a receives the using a long poll request. cadence calls this queue used to dispatch an .\n\nsimilarly, when a needs to handle an external , a is created. a is used to deliver it to the (also called decider).\n\nwhile cadence are queues, they have some differences from commonly used queuing technologies. the main one is that they do not require explicit registration and are created on demand. the number of is not limited. a common use case is to have a per process and use it to deliver to the process. another use case is to have a per pool of .\n\nthere are multiple advantages of using a to deliver instead of invoking an through a synchronous rpc:\n\n * doesn't need to have any open ports, which is more secure.\n * doesn't need to advertise itself through dns or any other network discovery mechanism.\n * when all are down, messages are persisted in a waiting for the to recover.\n * a polls for a message only when it has spare capacity, so it never gets overloaded.\n * automatic load balancing across a large number of .\n * support server side throttling. this allows you to limit the dispatch rate to the pool of and still supports adding a with a higher rate when spikes happen.\n * can be used to route a request to specific pools of or even a specific process.",charsets:{}},{title:"Archival",frontmatter:{layout:"default",title:"Archival",permalink:"/docs/concepts/archival",readingShow:"top"},regularPath:"/docs/03-concepts/07-archival.html",relativePath:"docs/03-concepts/07-archival.md",key:"v-eec246bc",path:"/docs/concepts/archival/",headers:[{level:2,title:"Concepts",slug:"concepts",normalizedTitle:"concepts",charIndex:1029},{level:2,title:"Configuring Archival",slug:"configuring-archival",normalizedTitle:"configuring archival",charIndex:1530},{level:3,title:"Cluster Level Archival Config",slug:"cluster-level-archival-config",normalizedTitle:"cluster level archival config",charIndex:1720},{level:3,title:"Domain Level Archival Config",slug:"domain-level-archival-config",normalizedTitle:"domain level archival config",charIndex:2401},{level:2,title:"Running Locally",slug:"running-locally",normalizedTitle:"running locally",charIndex:2837},{level:2,title:"Running in Production",slug:"running-in-production",normalizedTitle:"running in production",charIndex:3996},{level:2,title:"FAQ",slug:"faq",normalizedTitle:"faq",charIndex:970},{level:3,title:"When does archival happen?",slug:"when-does-archival-happen",normalizedTitle:"when does archival happen?",charIndex:4755},{level:3,title:"What's the query syntax for visibility archival?",slug:"what-s-the-query-syntax-for-visibility-archival",normalizedTitle:"what's the query syntax for visibility archival?",charIndex:5315},{level:3,title:"How does archival interact with global domains?",slug:"how-does-archival-interact-with-global-domains",normalizedTitle:"how does archival interact with global domains?",charIndex:5832},{level:3,title:"Can I specify multiple archival URIs?",slug:"can-i-specify-multiple-archival-uris",normalizedTitle:"can i specify multiple archival uris?",charIndex:6409},{level:3,title:"How does archival work with PII?",slug:"how-does-archival-work-with-pii",normalizedTitle:"how does archival work with pii?",charIndex:6591},{level:2,title:"Planned Future Work",slug:"planned-future-work",normalizedTitle:"planned future work",charIndex:6895}],codeSwitcherOptions:{},headersStr:"Concepts Configuring Archival Cluster Level Archival Config Domain Level Archival Config Running Locally Running in Production FAQ When does archival happen? What's the query syntax for visibility archival? How does archival interact with global domains? Can I specify multiple archival URIs? How does archival work with PII? Planned Future Work",content:'# Archival\n\nis a feature that automatically moves histories (history archival) and visibility records (visibility archival) from persistence to a secondary data store after the retention period, thus allowing users to keep workflow history and visibility records as long as necessary without overwhelming Cadence primary data store. There are two reasons you may consider turning on archival for your domain:\n\n 1. Compliance: For legal reasons histories may need to be stored for a long period of time.\n 2. Debugging: Old histories can still be accessed for debugging.\n\nThe current implementation of the feature has two limitations:\n\n 1. RunID Required: In order to retrieve an archived workflow history, both workflowID and runID are required.\n 2. Best Effort: It is possible that a history or visibility record is deleted from Cadence primary persistence without being archived first. These cases are rare but are possible with the current state of . Please check the FAQ section for how to get notified when this happens.\n\n\n# Concepts\n\n * Archiver: Archiver is the component that is responsible for archiving and retrieving histories and visibility records. Its interface is generic and supports different kinds of locations: local file system, S3, Kafka, etc. Check this README if you would like to add a new archiver implementation for your data store.\n * URI: An URI is used to specify the location. Based on the scheme part of an URI, the corresponding archiver will be selected by the system to perform the operation.\n\n\n# Configuring Archival\n\nis controlled by both level config and cluster level config. History and visibility archival have separate domain/cluster configs, but they share the same purpose.\n\n\n# Cluster Level Archival Config\n\nA Cadence cluster can be in one of three states:\n\n * Disabled: No will occur and the archivers will be not initialized on service startup.\n * Paused: This state is not yet implemented. Currently setting cluster to paused is the same as setting it to disabled.\n * Enabled: will occur.\n\nEnabling the cluster for simply means workflow histories will be archived. There is another config which controls whether archived histories or visibility records can be accessed. Both configs have defaults defined in the static yaml and can be overwritten via dynamic config. Note, however, dynamic config will take effect only when is enabled in static yaml.\n\n\n# Domain Level Archival Config\n\nA includes two pieces of related config:\n\n * Status: Either enabled or disabled. If a is in the disabled state, no will occur for that .\n * URI: The scheme and location where histories or visibility records will be archived to. When a enables for the first time URI is set and can never be changed. If URI is not specified when first enabling a for , a default URI from the static config will be used.\n\n\n# Running Locally\n\nYou can follow the steps below to run and test the feature locally:\n\n 1. ./cadence-server start\n 2. ./cadence --do samples-domain domain register --gd false --history_archival_status enabled --visibility_archival_status enabled --retention 0\n 3. Run the helloworld cadence-sample by following the README\n 4. Copy the workflowID the completed from log output\n 5. Retrieve runID through archived visibility record ./cadence --do samples-domain wf listarchived -q \'WorkflowID = "<workflowID>"\'\n 6. Retrieve archived history ./cadence --do samples-domain wf show --wid <workflowID> --rid <runID>\n\nIn step 2, we registered a new and enabled both history and visibility feature for that . Since we didn\'t provide an URI when registering the new , the default URI specified in config/development.yaml is used. The default URI is file:///tmp/cadence_archival/development for history archival and "file:///tmp/cadence_vis_archival/development" for visibility archival. You can find the archived history under the /tmp/cadence_archival/development directory and archived visibility record under the /tmp/cadence_vis_archival/development directory.\n\n\n# Running in Production\n\nCadence supports uploading workflow histories to Google Cloud and Amazon S3 for archival in production. Check documentation in GCloud archival component and S3 archival component.\n\nBelow is an example of Amazon S3 archival configuration:\n\narchival:\n  history:\n    status: "enabled"\n    enableRead: true\n    provider:\n      s3store:\n        region: "us-east-2"\n  visibility:\n    status: "enabled"\n    enableRead: true\n    provider:\n      s3store:\n        region: "us-east-2"\ndomainDefaults:\n  archival:\n    history:\n      status: "enabled"\n      URI: "s3://put-name-of-your-s3-bucket-here"\n    visibility:\n      status: "enabled"\n      URI: "s3://put-name-of-your-s3-bucket-here" # most proably the same as the previous URI\n\n\n\n# FAQ\n\n\n# When does archival happen?\n\nIn theory, we would like both history and visibility archival happen after workflow closes and retention period passes. However, due to some limitations in the implementation, only history archival happens after the retention period, while visibility archival happens immediately after workflow closes. Please treat this as an implementation details inside Cadence and do not relay on this fact. Archived data should only be checked after the retention period, and we may change the way we do visibility archival in the future.\n\n\n# What\'s the query syntax for visibility archival?\n\nThe listArchived CLI command and API accept a SQL-like query for retrieving archived visibility records, similar to how the listWorkflow command works. Unfortunately, since different Archiver implementations have very different capability, there\'s currently no universal query syntax that works for all Archiver implementations. Please check the README (for example, S3 and GCP) of the Archiver used by your domain for the supported query syntax and limitations.\n\n\n# How does archival interact with global domains?\n\nIf you have a global domain, when occurs it will first run on the active cluster and some time later it will run on the standby cluster when replication happens. For history archival, Cadence will check if upload operation has been performed and skip duplicate efforts. For visibility archival, there\'s no such check and duplicated visibility records will be uploaded. Depending on the Archiver implementation, those duplicated upload may consume more space in the underlying storage and duplicated entries may be returned.\n\n\n# Can I specify multiple archival URIs?\n\nEach can only have one URI for history and one URI for visibility . Different , however, can have different URIs (with different schemes).\n\n\n# How does archival work with PII?\n\nNo cadence should ever operate on clear text PII. Cadence can be thought of as a database and just as one would not store PII in a database PII should not be stored in Cadence. This is even more important when is enabled because these histories can be kept forever.\n\n\n# Planned Future Work\n\n * Support retriving archived workflow histories without providing runID.\n * Provide guarantee that no history or visibility record is deleted from primary persistence before being archived.\n * Implement Paused state. In this state no will occur but histories or visibility record also will not be deleted from persistence. Once enabled again from paused state, all skipped will occur.',normalizedContent:'# archival\n\nis a feature that automatically moves histories (history archival) and visibility records (visibility archival) from persistence to a secondary data store after the retention period, thus allowing users to keep workflow history and visibility records as long as necessary without overwhelming cadence primary data store. there are two reasons you may consider turning on archival for your domain:\n\n 1. compliance: for legal reasons histories may need to be stored for a long period of time.\n 2. debugging: old histories can still be accessed for debugging.\n\nthe current implementation of the feature has two limitations:\n\n 1. runid required: in order to retrieve an archived workflow history, both workflowid and runid are required.\n 2. best effort: it is possible that a history or visibility record is deleted from cadence primary persistence without being archived first. these cases are rare but are possible with the current state of . please check the faq section for how to get notified when this happens.\n\n\n# concepts\n\n * archiver: archiver is the component that is responsible for archiving and retrieving histories and visibility records. its interface is generic and supports different kinds of locations: local file system, s3, kafka, etc. check this readme if you would like to add a new archiver implementation for your data store.\n * uri: an uri is used to specify the location. based on the scheme part of an uri, the corresponding archiver will be selected by the system to perform the operation.\n\n\n# configuring archival\n\nis controlled by both level config and cluster level config. history and visibility archival have separate domain/cluster configs, but they share the same purpose.\n\n\n# cluster level archival config\n\na cadence cluster can be in one of three states:\n\n * disabled: no will occur and the archivers will be not initialized on service startup.\n * paused: this state is not yet implemented. currently setting cluster to paused is the same as setting it to disabled.\n * enabled: will occur.\n\nenabling the cluster for simply means workflow histories will be archived. there is another config which controls whether archived histories or visibility records can be accessed. both configs have defaults defined in the static yaml and can be overwritten via dynamic config. note, however, dynamic config will take effect only when is enabled in static yaml.\n\n\n# domain level archival config\n\na includes two pieces of related config:\n\n * status: either enabled or disabled. if a is in the disabled state, no will occur for that .\n * uri: the scheme and location where histories or visibility records will be archived to. when a enables for the first time uri is set and can never be changed. if uri is not specified when first enabling a for , a default uri from the static config will be used.\n\n\n# running locally\n\nyou can follow the steps below to run and test the feature locally:\n\n 1. ./cadence-server start\n 2. ./cadence --do samples-domain domain register --gd false --history_archival_status enabled --visibility_archival_status enabled --retention 0\n 3. run the helloworld cadence-sample by following the readme\n 4. copy the workflowid the completed from log output\n 5. retrieve runid through archived visibility record ./cadence --do samples-domain wf listarchived -q \'workflowid = "<workflowid>"\'\n 6. retrieve archived history ./cadence --do samples-domain wf show --wid <workflowid> --rid <runid>\n\nin step 2, we registered a new and enabled both history and visibility feature for that . since we didn\'t provide an uri when registering the new , the default uri specified in config/development.yaml is used. the default uri is file:///tmp/cadence_archival/development for history archival and "file:///tmp/cadence_vis_archival/development" for visibility archival. you can find the archived history under the /tmp/cadence_archival/development directory and archived visibility record under the /tmp/cadence_vis_archival/development directory.\n\n\n# running in production\n\ncadence supports uploading workflow histories to google cloud and amazon s3 for archival in production. check documentation in gcloud archival component and s3 archival component.\n\nbelow is an example of amazon s3 archival configuration:\n\narchival:\n  history:\n    status: "enabled"\n    enableread: true\n    provider:\n      s3store:\n        region: "us-east-2"\n  visibility:\n    status: "enabled"\n    enableread: true\n    provider:\n      s3store:\n        region: "us-east-2"\ndomaindefaults:\n  archival:\n    history:\n      status: "enabled"\n      uri: "s3://put-name-of-your-s3-bucket-here"\n    visibility:\n      status: "enabled"\n      uri: "s3://put-name-of-your-s3-bucket-here" # most proably the same as the previous uri\n\n\n\n# faq\n\n\n# when does archival happen?\n\nin theory, we would like both history and visibility archival happen after workflow closes and retention period passes. however, due to some limitations in the implementation, only history archival happens after the retention period, while visibility archival happens immediately after workflow closes. please treat this as an implementation details inside cadence and do not relay on this fact. archived data should only be checked after the retention period, and we may change the way we do visibility archival in the future.\n\n\n# what\'s the query syntax for visibility archival?\n\nthe listarchived cli command and api accept a sql-like query for retrieving archived visibility records, similar to how the listworkflow command works. unfortunately, since different archiver implementations have very different capability, there\'s currently no universal query syntax that works for all archiver implementations. please check the readme (for example, s3 and gcp) of the archiver used by your domain for the supported query syntax and limitations.\n\n\n# how does archival interact with global domains?\n\nif you have a global domain, when occurs it will first run on the active cluster and some time later it will run on the standby cluster when replication happens. for history archival, cadence will check if upload operation has been performed and skip duplicate efforts. for visibility archival, there\'s no such check and duplicated visibility records will be uploaded. depending on the archiver implementation, those duplicated upload may consume more space in the underlying storage and duplicated entries may be returned.\n\n\n# can i specify multiple archival uris?\n\neach can only have one uri for history and one uri for visibility . different , however, can have different uris (with different schemes).\n\n\n# how does archival work with pii?\n\nno cadence should ever operate on clear text pii. cadence can be thought of as a database and just as one would not store pii in a database pii should not be stored in cadence. this is even more important when is enabled because these histories can be kept forever.\n\n\n# planned future work\n\n * support retriving archived workflow histories without providing runid.\n * provide guarantee that no history or visibility record is deleted from primary persistence before being archived.\n * implement paused state. in this state no will occur but histories or visibility record also will not be deleted from persistence. once enabled again from paused state, all skipped will occur.',charsets:{}},{title:"Cross DC replication",frontmatter:{layout:"default",title:"Cross DC replication",permalink:"/docs/concepts/cross-dc-replication",readingShow:"top"},regularPath:"/docs/03-concepts/08-cross-dc-replication.html",relativePath:"docs/03-concepts/08-cross-dc-replication.md",key:"v-5d616cea",path:"/docs/concepts/cross-dc-replication/",headers:[{level:2,title:"Global Domains Architecture",slug:"global-domains-architecture",normalizedTitle:"global domains architecture",charIndex:300},{level:3,title:"Conflict Resolution",slug:"conflict-resolution",normalizedTitle:"conflict resolution",charIndex:2309},{level:2,title:"Global Domain Concepts, Configuration and Operation",slug:"global-domain-concepts-configuration-and-operation",normalizedTitle:"global domain concepts, configuration and operation",charIndex:3148},{level:3,title:"Concepts",slug:"concepts",normalizedTitle:"concepts",charIndex:3162},{level:3,title:"Operate by CLI",slug:"operate-by-cli",normalizedTitle:"operate by cli",charIndex:4221},{level:2,title:"Running Locally",slug:"running-locally",normalizedTitle:"running locally",charIndex:5743},{level:2,title:"Running in Production",slug:"running-in-production",normalizedTitle:"running in production",charIndex:5865}],codeSwitcherOptions:{},headersStr:"Global Domains Architecture Conflict Resolution Global Domain Concepts, Configuration and Operation Concepts Operate by CLI Running Locally Running in Production",content:'# Cross-DC replication\n\nThe Cadence Global feature provides clients with the capability to continue their from another cluster in the event of a datacenter failover. Although you can configure a Global to be replicated to any number of clusters, it is only considered active in a single cluster.\n\n\n# Global Domains Architecture\n\nCadence has introduced a new top level entity, Global , which provides support for replication of execution across clusters. A global domain can be configured with more than one clusters, but can only be active in one of the clusters at any point of time. We call it passive or standby when not active in other clusters.\n\nThe number of standby clusters can be zero, if a global domain only configured to one cluster. This is preferred/recommended.\n\nAny workflow of a global domain can only make make progress in its active cluster. And the workflow progress is replicated to other standby clusters. For example, starting workflow by calling StartWorkflow, or starting activity(by PollForActivityTask API), can only be processed in its active cluster. After active cluster made progress, standby clusters (if any) will poll the history from active to replicate the workflow states.\n\nHowever, standby clusters can also receive the requests, e.g. for starting workflows or starting activities. They know which cluster the domain is active at. So the requests can be routed to the active clusters. This is called api-forwarding in Cadence. api-forwarding makes it possible to have no downtime during failover. There are two api-forwarding policy: selected-api-forwarding and all-domain-api-forwarding policy.\n\nWhen using selected-api-forwarding, applications need to run different set of activity & workflow polling on every cluster. Cadence will only dispatch tasks on the current active cluster; on the standby cluster will sit idle until the Global is failed over. This is recommended if XDC is being used in multiple clusters running in very remote data centers(regions), which forwarding is expensive to do.\n\nWhen using all-domain-api-forwarding, applications only need to run activity & workflow polling on one cluster. This makes it easier for the application setup. This is recommended when clusters are all in local or nearby datacenters. See more details in discussion.\n\n\n# Conflict Resolution\n\nUnlike local which provide at-most-once semantics for execution, Global can only support at-least-once semantics. Cadence global domain relies on asynchronous replication of across clusters, so in the event of a failover it is possible that gets dispatched again on the new active cluster due to a replication lag. This also means that whenever is updated after a failover by the new cluster, any previous replication for that execution cannot be applied. This results in loss of some progress made by the in the previous active cluster. During such conflict resolution, Cadence re-injects any external like to the new history before discarding replication . Even though some progress could rollback during failovers, Cadence provides the guarantee that won’t get stuck and will continue to make forward progress.\n\n\n# Global Domain Concepts, Configuration and Operation\n\n\n# Concepts\n\n# IsGlobal\n\nThis config is used to distinguish local to the cluster from the global . It controls the creation of replication on updates allowing the state to be replicated across clusters. This is a read-only setting that can only be set when the is provisioned.\n\n# Clusters\n\nA list of clusters where the can fail over to, including the current active cluster. This is also a read-only setting that can only be set when the is provisioned. A re-replication feature on the roadmap will allow updating this config to add/remove clusters in the future.\n\n# Active Cluster Name\n\nName of the current active cluster for the Global . This config is updated each time the Global is failed over to another cluster.\n\n# Failover Version\n\nUnique failover version which also represents the current active cluster for Global . Cadence allows failover to be triggered from any cluster, so failover version is designed in a way to not allow conflicts if failover is mistakenly triggered simultaneously on two clusters.\n\n\n# Operate by CLI\n\nThe Cadence can also be used to the config or perform failovers. Here are some useful commands.\n\n# Describe Global Domain\n\nThe following command can be used to describe Global metadata:\n\n$ cadence --do cadence-canary-xdc d desc\nName: cadence-canary-xdc\nDescription: cadence canary cross dc testing domain\nOwnerEmail: cadence-dev@cadenceworkflow.io\nDomainData:\nStatus: REGISTERED\nRetentionInDays: 7\nEmitMetrics: true\nActiveClusterName: dc1\nClusters: dc1, dc2\n\n\n# Failover Global Domain using domain update command(being deprecated in favor of managed graceful failover)\n\nThe following command can be used to failover Global my-domain-global to the dc2 cluster:\n\n$ cadence --do my-domain-global d up --ac dc2\n\n\n# Failover Global Domain using Managed Graceful Failover\n\nFirst of all, update the domain to enable this feature for the domain\n\n$ cadence --do test-global-domain-0 d update --domain_data IsManagedByCadence:true\n$ cadence --do test-global-domain-1 d update --domain_data IsManagedByCadence:true\n$ cadence --do test-global-domain-2 d update --domain_data IsManagedByCadence:true\n...\n\n\nThen you can start failover the those global domains using managed failover:\n\ncadence admin cluster failover start --source_cluster dc1 --target_cluster dc2\n\n\nThis will failover all the domains with IsManagedByCadence:true from dc1 to dc2.\n\nYou can provide more detailed options when using the command, and also watch the progress of the failover. Feel free to explore the cadence admin cluster failover tab.\n\n\n# Running Locally\n\nThe best way is to use Cadence docker-compose: docker-compose -f docker-compose-multiclusters.yml up\n\n\n# Running in Production\n\nEnable global domain feature needs to be enabled in static config.\n\nHere we use clusterDCA and clusterDCB as an example. We pick clusterDCA as the primary(used to called "master") cluster. The only difference of being a primary cluster is that it is responsible for domain registration. Primary can be changed later but it needs to be the same across all clusters.\n\nThe ClusterMeta config of clusterDCA should be\n\ndcRedirectionPolicy:\n  policy: "selected-apis-forwarding"\n\nclusterMetadata:\n  enableGlobalDomain: true\n  failoverVersionIncrement: 10\n  masterClusterName: "clusterDCA"\n  currentClusterName: "clusterDCA"\n  clusterInformation:\n    clusterDCA:\n      enabled: true\n      initialFailoverVersion: 1\n      rpcName: "cadence-frontend"\n      rpcAddress: "<>:<>"\n    clusterDCB:\n      enabled: true\n      initialFailoverVersion: 0\n      rpcName: "cadence-frontend"\n      rpcAddress: "<>:<>"\n\n\nAnd ClusterMeta config of clusterDCB should be\n\ndcRedirectionPolicy:\n  policy: "selected-apis-forwarding"\n\nclusterMetadata:\n  enableGlobalDomain: true\n  failoverVersionIncrement: 10\n  masterClusterName: "clusterDCA"\n  currentClusterName: "clusterDCB"\n  clusterInformation:\n    clusterDCA:\n      enabled: true\n      initialFailoverVersion: 1\n      rpcName: "cadence-frontend"\n      rpcAddress: "<>:<>"\n    clusterDCB:\n      enabled: true\n      initialFailoverVersion: 0\n\n      rpcName: "cadence-frontend"\n      rpcAddress: "<>:<>"\n\n\nAfter the configuration is deployed:\n\n 1. Register a global domain cadence --do <domain_name> domain register --global_domain true --clusters clusterDCA clusterDCB --active_cluster clusterDCA\n\n 2. Run some workflow and failover domain from one to another cadence --do <domain_name> domain update --active_cluster clusterDCB\n\nThen the domain should be failed over to clusterDCB. Now worklfows are read-only in clusterDCA. So your workers polling tasks from clusterDCA will become idle.\n\nNote 1: that even though clusterDCA is standy/read-only for this domain, it can be active for another domain. So being active/standy is per domain basis not per clusters. In other words, for example if you use XDC in case of DC failure of clusterDCA, you need to failover all domains from clusterDCA to clusterDCB.\n\nNote 2: even though a domain is standy/read-only in a cluster, say clusterDCA, sending write requests(startWF, signalWF, etc) could still work because there is a forwarding component in the Frontend service. It will try to re-route the requests to an active cluster for the domain.',normalizedContent:'# cross-dc replication\n\nthe cadence global feature provides clients with the capability to continue their from another cluster in the event of a datacenter failover. although you can configure a global to be replicated to any number of clusters, it is only considered active in a single cluster.\n\n\n# global domains architecture\n\ncadence has introduced a new top level entity, global , which provides support for replication of execution across clusters. a global domain can be configured with more than one clusters, but can only be active in one of the clusters at any point of time. we call it passive or standby when not active in other clusters.\n\nthe number of standby clusters can be zero, if a global domain only configured to one cluster. this is preferred/recommended.\n\nany workflow of a global domain can only make make progress in its active cluster. and the workflow progress is replicated to other standby clusters. for example, starting workflow by calling startworkflow, or starting activity(by pollforactivitytask api), can only be processed in its active cluster. after active cluster made progress, standby clusters (if any) will poll the history from active to replicate the workflow states.\n\nhowever, standby clusters can also receive the requests, e.g. for starting workflows or starting activities. they know which cluster the domain is active at. so the requests can be routed to the active clusters. this is called api-forwarding in cadence. api-forwarding makes it possible to have no downtime during failover. there are two api-forwarding policy: selected-api-forwarding and all-domain-api-forwarding policy.\n\nwhen using selected-api-forwarding, applications need to run different set of activity & workflow polling on every cluster. cadence will only dispatch tasks on the current active cluster; on the standby cluster will sit idle until the global is failed over. this is recommended if xdc is being used in multiple clusters running in very remote data centers(regions), which forwarding is expensive to do.\n\nwhen using all-domain-api-forwarding, applications only need to run activity & workflow polling on one cluster. this makes it easier for the application setup. this is recommended when clusters are all in local or nearby datacenters. see more details in discussion.\n\n\n# conflict resolution\n\nunlike local which provide at-most-once semantics for execution, global can only support at-least-once semantics. cadence global domain relies on asynchronous replication of across clusters, so in the event of a failover it is possible that gets dispatched again on the new active cluster due to a replication lag. this also means that whenever is updated after a failover by the new cluster, any previous replication for that execution cannot be applied. this results in loss of some progress made by the in the previous active cluster. during such conflict resolution, cadence re-injects any external like to the new history before discarding replication . even though some progress could rollback during failovers, cadence provides the guarantee that won’t get stuck and will continue to make forward progress.\n\n\n# global domain concepts, configuration and operation\n\n\n# concepts\n\n# isglobal\n\nthis config is used to distinguish local to the cluster from the global . it controls the creation of replication on updates allowing the state to be replicated across clusters. this is a read-only setting that can only be set when the is provisioned.\n\n# clusters\n\na list of clusters where the can fail over to, including the current active cluster. this is also a read-only setting that can only be set when the is provisioned. a re-replication feature on the roadmap will allow updating this config to add/remove clusters in the future.\n\n# active cluster name\n\nname of the current active cluster for the global . this config is updated each time the global is failed over to another cluster.\n\n# failover version\n\nunique failover version which also represents the current active cluster for global . cadence allows failover to be triggered from any cluster, so failover version is designed in a way to not allow conflicts if failover is mistakenly triggered simultaneously on two clusters.\n\n\n# operate by cli\n\nthe cadence can also be used to the config or perform failovers. here are some useful commands.\n\n# describe global domain\n\nthe following command can be used to describe global metadata:\n\n$ cadence --do cadence-canary-xdc d desc\nname: cadence-canary-xdc\ndescription: cadence canary cross dc testing domain\nowneremail: cadence-dev@cadenceworkflow.io\ndomaindata:\nstatus: registered\nretentionindays: 7\nemitmetrics: true\nactiveclustername: dc1\nclusters: dc1, dc2\n\n\n# failover global domain using domain update command(being deprecated in favor of managed graceful failover)\n\nthe following command can be used to failover global my-domain-global to the dc2 cluster:\n\n$ cadence --do my-domain-global d up --ac dc2\n\n\n# failover global domain using managed graceful failover\n\nfirst of all, update the domain to enable this feature for the domain\n\n$ cadence --do test-global-domain-0 d update --domain_data ismanagedbycadence:true\n$ cadence --do test-global-domain-1 d update --domain_data ismanagedbycadence:true\n$ cadence --do test-global-domain-2 d update --domain_data ismanagedbycadence:true\n...\n\n\nthen you can start failover the those global domains using managed failover:\n\ncadence admin cluster failover start --source_cluster dc1 --target_cluster dc2\n\n\nthis will failover all the domains with ismanagedbycadence:true from dc1 to dc2.\n\nyou can provide more detailed options when using the command, and also watch the progress of the failover. feel free to explore the cadence admin cluster failover tab.\n\n\n# running locally\n\nthe best way is to use cadence docker-compose: docker-compose -f docker-compose-multiclusters.yml up\n\n\n# running in production\n\nenable global domain feature needs to be enabled in static config.\n\nhere we use clusterdca and clusterdcb as an example. we pick clusterdca as the primary(used to called "master") cluster. the only difference of being a primary cluster is that it is responsible for domain registration. primary can be changed later but it needs to be the same across all clusters.\n\nthe clustermeta config of clusterdca should be\n\ndcredirectionpolicy:\n  policy: "selected-apis-forwarding"\n\nclustermetadata:\n  enableglobaldomain: true\n  failoverversionincrement: 10\n  masterclustername: "clusterdca"\n  currentclustername: "clusterdca"\n  clusterinformation:\n    clusterdca:\n      enabled: true\n      initialfailoverversion: 1\n      rpcname: "cadence-frontend"\n      rpcaddress: "<>:<>"\n    clusterdcb:\n      enabled: true\n      initialfailoverversion: 0\n      rpcname: "cadence-frontend"\n      rpcaddress: "<>:<>"\n\n\nand clustermeta config of clusterdcb should be\n\ndcredirectionpolicy:\n  policy: "selected-apis-forwarding"\n\nclustermetadata:\n  enableglobaldomain: true\n  failoverversionincrement: 10\n  masterclustername: "clusterdca"\n  currentclustername: "clusterdcb"\n  clusterinformation:\n    clusterdca:\n      enabled: true\n      initialfailoverversion: 1\n      rpcname: "cadence-frontend"\n      rpcaddress: "<>:<>"\n    clusterdcb:\n      enabled: true\n      initialfailoverversion: 0\n\n      rpcname: "cadence-frontend"\n      rpcaddress: "<>:<>"\n\n\nafter the configuration is deployed:\n\n 1. register a global domain cadence --do <domain_name> domain register --global_domain true --clusters clusterdca clusterdcb --active_cluster clusterdca\n\n 2. run some workflow and failover domain from one to another cadence --do <domain_name> domain update --active_cluster clusterdcb\n\nthen the domain should be failed over to clusterdcb. now worklfows are read-only in clusterdca. so your workers polling tasks from clusterdca will become idle.\n\nnote 1: that even though clusterdca is standy/read-only for this domain, it can be active for another domain. so being active/standy is per domain basis not per clusters. in other words, for example if you use xdc in case of dc failure of clusterdca, you need to failover all domains from clusterdca to clusterdcb.\n\nnote 2: even though a domain is standy/read-only in a cluster, say clusterdca, sending write requests(startwf, signalwf, etc) could still work because there is a forwarding component in the frontend service. it will try to re-route the requests to an active cluster for the domain.',charsets:{}},{title:"Search workflows(Advanced visibility)",frontmatter:{layout:"default",title:"Search workflows(Advanced visibility)",permalink:"/docs/concepts/search-workflows",readingShow:"top"},regularPath:"/docs/03-concepts/09-search-workflows.html",relativePath:"docs/03-concepts/09-search-workflows.md",key:"v-3c665d38",path:"/docs/concepts/search-workflows/",headers:[{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:47},{level:2,title:"Memo vs Search Attributes",slug:"memo-vs-search-attributes",normalizedTitle:"memo vs search attributes",charIndex:843},{level:2,title:"Search Attributes (Go Client Usage)",slug:"search-attributes-go-client-usage",normalizedTitle:"search attributes (go client usage)",charIndex:2531},{level:3,title:"Allow Listing Search Attributes",slug:"allow-listing-search-attributes",normalizedTitle:"allow listing search attributes",charIndex:2885},{level:3,title:"Value Types",slug:"value-types",normalizedTitle:"value types",charIndex:5087},{level:3,title:"Limit",slug:"limit",normalizedTitle:"limit",charIndex:5298},{level:3,title:"Upsert Search Attributes in Workflow",slug:"upsert-search-attributes-in-workflow",normalizedTitle:"upsert search attributes in workflow",charIndex:5631},{level:3,title:"ContinueAsNew and Cron",slug:"continueasnew-and-cron",normalizedTitle:"continueasnew and cron",charIndex:6932},{level:2,title:"Query Capabilities",slug:"query-capabilities",normalizedTitle:"query capabilities",charIndex:7084},{level:3,title:"Supported Operators",slug:"supported-operators",normalizedTitle:"supported operators",charIndex:7264},{level:3,title:"Default Attributes",slug:"default-attributes",normalizedTitle:"default attributes",charIndex:7364},{level:3,title:"General Notes About Queries",slug:"general-notes-about-queries",normalizedTitle:"general notes about queries",charIndex:9280},{level:2,title:"Tools Support",slug:"tools-support",normalizedTitle:"tools support",charIndex:9802},{level:3,title:"CLI",slug:"cli",normalizedTitle:"cli",charIndex:470},{level:3,title:"Web UI Support",slug:"web-ui-support",normalizedTitle:"web ui support",charIndex:11655},{level:3,title:"TLS Support for connecting to Elasticsearch",slug:"tls-support-for-connecting-to-elasticsearch",normalizedTitle:"tls support for connecting to elasticsearch",charIndex:11818},{level:2,title:"Running Locally",slug:"running-locally",normalizedTitle:"running locally",charIndex:12432},{level:2,title:"Running in Production",slug:"running-in-production",normalizedTitle:"running in production",charIndex:13237}],codeSwitcherOptions:{},headersStr:"Introduction Memo vs Search Attributes Search Attributes (Go Client Usage) Allow Listing Search Attributes Value Types Limit Upsert Search Attributes in Workflow ContinueAsNew and Cron Query Capabilities Supported Operators Default Attributes General Notes About Queries Tools Support CLI Web UI Support TLS Support for connecting to Elasticsearch Running Locally Running in Production",content:'# Searching Workflows(Advanced visibility)\n\n\n# Introduction\n\nCadence supports creating with customized key-value pairs, updating the information within the code, and then listing/searching with a SQL-like . For example, you can create with keys city and age, then search all with city = seattle and age > 22.\n\nAlso note that normal properties like start time and type can be queried as well. For example, the following could be specified when listing workflows from the CLI or using the list APIs (Go, Java):\n\nWorkflowType = "main.Workflow" AND CloseStatus != "completed" AND (StartTime > \n   "2019-06-07T16:46:34-08:00" OR CloseTime > "2019-06-07T16:46:34-08:00") \n   ORDER BY StartTime DESC \n\n\nIn other places, this is also called as advanced visibility. While basic visibility is referred to basic listing without being able to search.\n\n\n# Memo vs Search Attributes\n\nCadence offers two methods for creating with key-value pairs: memo and search attributes. Memo can only be provided on start. Also, memo data are not indexed, and are therefore not searchable. Memo data are visible when listing using the list APIs. Search attributes data are indexed so you can search by on these attributes. However, search attributes require the use of Elasticsearch.\n\nMemo and search attributes are available in the Go client in StartWorkflowOptions.\n\ntype StartWorkflowOptions struct {\n    // ...\n\n    // Memo - Optional non-indexed info that will be shown in list workflow.\n    Memo map[string]interface{}\n\n    // SearchAttributes - Optional indexed info that can be used in query of List/Scan/Count workflow APIs (only\n    // supported when Cadence server is using Elasticsearch). The key and value type must be registered on Cadence server side.\n    // Use GetSearchAttributes API to get valid key and corresponding value type.\n    SearchAttributes map[string]interface{}\n}\n\n\nIn the Java client, the WorkflowOptions.Builder has similar methods for memo and search attributes.\n\nSome important distinctions between memo and search attributes:\n\n * Memo can support all data types because it is not indexed. Search attributes only support basic data types (including String(aka Text), Int, Float, Bool, Datetime) because it is indexed by Elasticsearch.\n * Memo does not restrict on key names. Search attributes require that keys are allowlisted before using them because Elasticsearch has a limit on indexed keys.\n * Memo doesn\'t require Cadence clusters to depend on Elasticsearch while search attributes only works with Elasticsearch.\n\n\n# Search Attributes (Go Client Usage)\n\nWhen using the Cadence Go client, provide key-value pairs as SearchAttributes in StartWorkflowOptions.\n\nSearchAttributes is map[string]interface{} where the keys need to be allowlisted so that Cadence knows the attribute key name and value type. The value provided in the map must be the same type as registered.\n\n\n# Allow Listing Search Attributes\n\nStart by the list of search attributes using the\n\n$ cadence --domain samples-domain cl get-search-attr\n+---------------------+------------+\n|         KEY         | VALUE TYPE |\n+---------------------+------------+\n| CloseStatus         | INT        |\n| CloseTime           | INT        |\n| CustomBoolField     | DOUBLE     |\n| CustomDatetimeField | DATETIME   |\n| CustomDomain        | KEYWORD    |\n| CustomDoubleField   | BOOL       |\n| CustomIntField      | INT        |\n| CustomKeywordField  | KEYWORD    |\n| CustomStringField   | STRING     |\n| DomainID            | KEYWORD    |\n| ExecutionTime       | INT        |\n| HistoryLength       | INT        |\n| RunID               | KEYWORD    |\n| StartTime           | INT        |\n| WorkflowID          | KEYWORD    |\n| WorkflowType        | KEYWORD    |\n+---------------------+------------+\n\n\nUse the admin to add a new search attribute:\n\ncadence --domain samples-domain adm cl asa --search_attr_key NewKey --search_attr_type 1\n\n\nThe numbers for the attribute types map as follows:\n\n * 0 = String(Text)\n * 1 = Keyword\n * 2 = Int\n * 3 = Double\n * 4 = Bool\n * 5 = DateTime\n\n# Keyword vs String(Text)\n\nNote 1: String has been renamed to Text in ElasticSearch. Cadence is also planning to rename it.\n\nNote 2: Keyword and String(Text) are concepts taken from Elasticsearch. Each word in a String(Text) is considered a searchable keyword. For a UUID, that can be problematic as Elasticsearch will index each portion of the UUID separately. To have the whole string considered as a searchable keyword, use the Keyword type.\n\nFor example, key RunID with value "2dd29ab7-2dd8-4668-83e0-89cae261cfb1"\n\n * as a Keyword will only be matched by RunID = "2dd29ab7-2dd8-4668-83e0-89cae261cfb1" (or in the future with regular expressions)\n * as a String(Text) will be matched by RunID = "2dd8", which may cause unwanted matches\n\nNote: String(Text) type can not be used in Order By .\n\nThere are some pre-allowlisted search attributes that are handy for testing:\n\n * CustomKeywordField\n * CustomIntField\n * CustomDoubleField\n * CustomBoolField\n * CustomDatetimeField\n * CustomStringField\n\nTheir types are indicated in their names.\n\n\n# Value Types\n\nHere are the Search Attribute value types and their correspondent Golang types:\n\n * Keyword = string\n * Int = int64\n * Double = float64\n * Bool = bool\n * Datetime = time.Time\n * String = string\n\n\n# Limit\n\nWe recommend limiting the number of Elasticsearch indexes by enforcing limits on the following:\n\n * Number of keys: 100 per\n * Size of value: 2kb per value\n * Total size of key and values: 40kb per\n\nCadence reserves keys like DomainID, WorkflowID, and RunID. These can only be used in list . The values are not updatable.\n\n\n# Upsert Search Attributes in Workflow\n\nUpsertSearchAttributes is used to add or update search attributes from within the code.\n\nGo samples for search attributes can be found at github.com/uber-common/cadence-samples.\n\nUpsertSearchAttributes will merge attributes to the existing map in the . Consider this example code:\n\nfunc MyWorkflow(ctx workflow.Context, input string) error {\n\n    attr1 := map[string]interface{}{\n        "CustomIntField": 1,\n        "CustomBoolField": true,\n    }\n    workflow.UpsertSearchAttributes(ctx, attr1)\n\n    attr2 := map[string]interface{}{\n        "CustomIntField": 2,\n        "CustomKeywordField": "seattle",\n    }\n    workflow.UpsertSearchAttributes(ctx, attr2)\n}\n\n\nAfter the second call to UpsertSearchAttributes, the map will contain:\n\nmap[string]interface{}{\n    "CustomIntField": 2,\n    "CustomBoolField": true,\n    "CustomKeywordField": "seattle",\n}\n\n\nThere is no support for removing a field. To achieve a similar effect, set the field to a sentinel value. For example, to remove “CustomKeywordField”, update it to “impossibleVal”. Then searching CustomKeywordField != ‘impossibleVal’ will match with CustomKeywordField not equal to "impossibleVal", which includes without the CustomKeywordField set.\n\nUse workflow.GetInfo to get current search attributes.\n\n\n# ContinueAsNew and Cron\n\nWhen performing a ContinueAsNew or using Cron, search attributes (and memo) will be carried over to the new run by default.\n\n\n# Query Capabilities\n\nby using a SQL-like where clause when listing workflows from the CLI or using the list APIs (Go, Java).\n\nNote that you will only see from one domain when .\n\n\n# Supported Operators\n\n * AND, OR, ()\n * =, !=, >, >=, <, <=\n * IN\n * BETWEEN ... AND\n * ORDER BY\n\n\n# Default Attributes\n\nMore and more default attributes are added in newer versions. Please get the by using the get-search-attr command or the GetSearchAttributes API. Some names and types are as follows:\n\nKEY                   VALUE TYPE\nCloseStatus           INT\nCloseTime             INT\nCustomBoolField       DOUBLE\nCustomDatetimeField   DATETIME\nCustomDomain          KEYWORD\nCustomDoubleField     BOOL\nCustomIntField        INT\nCustomKeywordField    KEYWORD\nCustomStringField     STRING\nDomainID              KEYWORD\nExecutionTime         INT\nHistoryLength         INT\nRunID                 KEYWORD\nStartTime             INT\nWorkflowID            KEYWORD\nWorkflowType          KEYWORD\nTasklist              KEYWORD\n\nThere are some special considerations for these attributes:\n\n * CloseStatus, CloseTime, DomainID, ExecutionTime, HistoryLength, RunID, StartTime, WorkflowID, WorkflowType are reserved by Cadence and are read-only\n * Starting from v0.18.0, Cadence automatically maps(case insensitive) string to CloseStatus so that you don\'t need to use integer in the query, to make it easier to use.\n   * 0 = "completed"\n   * 1 = "failed"\n   * 2 = "canceled"\n   * 3 = "terminated"\n   * 4 = "continued_as_new"\n   * 5 = "timed_out"\n * StartTime, CloseTime and ExecutionTime are stored as INT, but support using both EpochTime in nanoseconds, and string in RFC3339 format (ex. "2006-01-02T15:04:05+07:00")\n * CloseTime, CloseStatus, HistoryLength are only present in closed\n * ExecutionTime is for Retry/Cron user to a that will run in the future\n * To list only open , add CloseTime = missing to the end of the .\n\nIf you use retry or the cron feature to that will start execution in a certain time range, you can add predicates on ExecutionTime. For example: ExecutionTime > 2019-01-01T10:00:00-07:00. Note that if predicates on ExecutionTime are included, only cron or a that needs to retry will be returned.\n\n\n# General Notes About Queries\n\n * Pagesize default is 1000, and cannot be larger than 10k\n * Range on Cadence timestamp (StartTime, CloseTime, ExecutionTime) cannot be larger than 9223372036854775807 (maxInt64 - 1001)\n * by time range will have 1ms resolution\n * column names are case sensitive\n * ListWorkflow may take longer when retrieving a large number of (10M+)\n * To retrieve a large number of without caring about order, use the ScanWorkflow API\n * To efficiently count the number of , use the CountWorkflow API\n\n\n# Tools Support\n\n\n# CLI\n\nSupport for search attributes is available as of version 0.6.0 of the Cadence server. You can also use the from the latest CLI Docker image (supported on 0.6.4 or later).\n\n# Start Workflow with Search Attributes\n\ncadence --do samples-domain workflow start --tl helloWorldGroup --wt main.Workflow --et 60 --dt 10 -i \'"vancexu"\' -search_attr_key \'CustomIntField | CustomKeywordField | CustomStringField |  CustomBoolField | CustomDatetimeField\' -search_attr_value \'5 | keyword1 | vancexu test | true | 2019-06-07T16:16:36-08:00\'\n\n\n# Search Workflows with List API/Command\n\ncadence --do samples-domain wf list -q \'(CustomKeywordField = "keyword1" and CustomIntField >= 5) or CustomKeywordField = "keyword2"\' -psa\n\n\ncadence --do samples-domain wf list -q \'CustomKeywordField in ("keyword2", "keyword1") and CustomIntField >= 5 and CloseTime between "2018-06-07T16:16:36-08:00" and "2019-06-07T16:46:34-08:00" order by CustomDatetimeField desc\' -psa\n\n\nTo list only open , add CloseTime = missing to the end of the .\n\nNote that can support more than one type of filter:\n\ncadence --do samples-domain wf list -q \'WorkflowType = "main.Workflow" and (WorkflowID = "1645a588-4772-4dab-b276-5f9db108b3a8" or RunID = "be66519b-5f09-40cd-b2e8-20e4106244dc")\'\n\n\ncadence --do samples-domain wf list -q \'WorkflowType = "main.Workflow" StartTime > "2019-06-07T16:46:34-08:00" and CloseTime = missing\'\n\n\nAll above command can be done with ListWorkflowExecutions API.\n\n# Count Workflows with Count API/Command\n\ncadence --do samples-domain wf count -q \'(CustomKeywordField = "keyword1" and CustomIntField >= 5) or CustomKeywordField = "keyword2"\'\n\n\ncadence --do samples-domain wf count -q \'CloseStatus="failed"\'\n\n\ncadence --do samples-domain wf count -q \'CloseStatus!="completed"\'\n\n\nAll above command can be done with CountWorkflowExecutions API.\n\n\n# Web UI Support\n\nare supported in Cadence Web as of release 3.4.0. Use the "Basic/Advanced" button to switch to "Advanced" mode and type the in the search box.\n\n\n# TLS Support for connecting to Elasticsearch\n\nIf your elasticsearch deployment requires TLS to connect to it, you can add the following to your config template. The TLS config is optional and when not provided it defaults to tls.enabled to false\n\nelasticsearch:\n  url:\n    scheme: "https"\n    host: "127.0.0.1:9200"\n  indices:\n    visibility: cadence-visibility-dev\n  tls:\n    enabled: true\n    caFile: /secrets/cadence/elasticsearch_cert.pem\n    enableHostVerification: true\n    serverName: myServerName\n    certFile: /secrets/cadence/certfile.crt\n    keyFile: /secrets/cadence/keyfile.key\n    sslmode: false\n\n\n\n# Running Locally\n\n 1. Increase Docker memory to higher than 6GB. Navigate to Docker -> Preferences -> Advanced -> Memory\n 2. Get the Cadence Docker compose file. Run curl -O https://raw.githubusercontent.com/uber/cadence/master/docker/docker-compose-es.yml\n 3. Start Cadence Docker (which contains Apache Kafka, Apache Zookeeper, and Elasticsearch) using docker-compose -f docker-compose-es.yml up\n 4. From the Docker output log, make sure Elasticsearch and Cadence started correctly. If you encounter an insufficient disk space error, try docker system prune -a --volumes\n 5. Register a local domain and start using it. cadence --do samples-domain d re\n 6. Add the key to ElasticSearch And also allowlist search attributes. cadence --do domain adm cl asa --search_attr_key NewKey --search_attr_type 1\n\n\n# Running in Production\n\nTo enable this feature in a Cadence cluster:\n\n * Register index schema on ElasticSearch. Run two CURL commands following this script.\n   * Create a index template by using the schema , choose v6/v7 based on your ElasticSearch version\n   * Create an index follow the index template, remember the name\n * Register topic on Kafka, and remember the name\n   * Set up the right number of partitions based on your expected throughput(can be scaled up later)\n * Configure Cadence for ElasticSearch + Kafka like this documentation Based on the full static config, you may add some other fields like AuthN. Similarly for Kafka.\n\nTo add new search attributes:\n\n 1. Add the key to ElasticSearch cadence --do domain adm cl asa --search_attr_key NewKey --search_attr_type 1\n 2. Update the dynamic configuration to allowlist the new attribute\n\nNote: starting a with search attributes but without advanced visibility feature will succeed as normal, but will not be searchable and will not be shown in list results.',normalizedContent:'# searching workflows(advanced visibility)\n\n\n# introduction\n\ncadence supports creating with customized key-value pairs, updating the information within the code, and then listing/searching with a sql-like . for example, you can create with keys city and age, then search all with city = seattle and age > 22.\n\nalso note that normal properties like start time and type can be queried as well. for example, the following could be specified when listing workflows from the cli or using the list apis (go, java):\n\nworkflowtype = "main.workflow" and closestatus != "completed" and (starttime > \n   "2019-06-07t16:46:34-08:00" or closetime > "2019-06-07t16:46:34-08:00") \n   order by starttime desc \n\n\nin other places, this is also called as advanced visibility. while basic visibility is referred to basic listing without being able to search.\n\n\n# memo vs search attributes\n\ncadence offers two methods for creating with key-value pairs: memo and search attributes. memo can only be provided on start. also, memo data are not indexed, and are therefore not searchable. memo data are visible when listing using the list apis. search attributes data are indexed so you can search by on these attributes. however, search attributes require the use of elasticsearch.\n\nmemo and search attributes are available in the go client in startworkflowoptions.\n\ntype startworkflowoptions struct {\n    // ...\n\n    // memo - optional non-indexed info that will be shown in list workflow.\n    memo map[string]interface{}\n\n    // searchattributes - optional indexed info that can be used in query of list/scan/count workflow apis (only\n    // supported when cadence server is using elasticsearch). the key and value type must be registered on cadence server side.\n    // use getsearchattributes api to get valid key and corresponding value type.\n    searchattributes map[string]interface{}\n}\n\n\nin the java client, the workflowoptions.builder has similar methods for memo and search attributes.\n\nsome important distinctions between memo and search attributes:\n\n * memo can support all data types because it is not indexed. search attributes only support basic data types (including string(aka text), int, float, bool, datetime) because it is indexed by elasticsearch.\n * memo does not restrict on key names. search attributes require that keys are allowlisted before using them because elasticsearch has a limit on indexed keys.\n * memo doesn\'t require cadence clusters to depend on elasticsearch while search attributes only works with elasticsearch.\n\n\n# search attributes (go client usage)\n\nwhen using the cadence go client, provide key-value pairs as searchattributes in startworkflowoptions.\n\nsearchattributes is map[string]interface{} where the keys need to be allowlisted so that cadence knows the attribute key name and value type. the value provided in the map must be the same type as registered.\n\n\n# allow listing search attributes\n\nstart by the list of search attributes using the\n\n$ cadence --domain samples-domain cl get-search-attr\n+---------------------+------------+\n|         key         | value type |\n+---------------------+------------+\n| closestatus         | int        |\n| closetime           | int        |\n| customboolfield     | double     |\n| customdatetimefield | datetime   |\n| customdomain        | keyword    |\n| customdoublefield   | bool       |\n| customintfield      | int        |\n| customkeywordfield  | keyword    |\n| customstringfield   | string     |\n| domainid            | keyword    |\n| executiontime       | int        |\n| historylength       | int        |\n| runid               | keyword    |\n| starttime           | int        |\n| workflowid          | keyword    |\n| workflowtype        | keyword    |\n+---------------------+------------+\n\n\nuse the admin to add a new search attribute:\n\ncadence --domain samples-domain adm cl asa --search_attr_key newkey --search_attr_type 1\n\n\nthe numbers for the attribute types map as follows:\n\n * 0 = string(text)\n * 1 = keyword\n * 2 = int\n * 3 = double\n * 4 = bool\n * 5 = datetime\n\n# keyword vs string(text)\n\nnote 1: string has been renamed to text in elasticsearch. cadence is also planning to rename it.\n\nnote 2: keyword and string(text) are concepts taken from elasticsearch. each word in a string(text) is considered a searchable keyword. for a uuid, that can be problematic as elasticsearch will index each portion of the uuid separately. to have the whole string considered as a searchable keyword, use the keyword type.\n\nfor example, key runid with value "2dd29ab7-2dd8-4668-83e0-89cae261cfb1"\n\n * as a keyword will only be matched by runid = "2dd29ab7-2dd8-4668-83e0-89cae261cfb1" (or in the future with regular expressions)\n * as a string(text) will be matched by runid = "2dd8", which may cause unwanted matches\n\nnote: string(text) type can not be used in order by .\n\nthere are some pre-allowlisted search attributes that are handy for testing:\n\n * customkeywordfield\n * customintfield\n * customdoublefield\n * customboolfield\n * customdatetimefield\n * customstringfield\n\ntheir types are indicated in their names.\n\n\n# value types\n\nhere are the search attribute value types and their correspondent golang types:\n\n * keyword = string\n * int = int64\n * double = float64\n * bool = bool\n * datetime = time.time\n * string = string\n\n\n# limit\n\nwe recommend limiting the number of elasticsearch indexes by enforcing limits on the following:\n\n * number of keys: 100 per\n * size of value: 2kb per value\n * total size of key and values: 40kb per\n\ncadence reserves keys like domainid, workflowid, and runid. these can only be used in list . the values are not updatable.\n\n\n# upsert search attributes in workflow\n\nupsertsearchattributes is used to add or update search attributes from within the code.\n\ngo samples for search attributes can be found at github.com/uber-common/cadence-samples.\n\nupsertsearchattributes will merge attributes to the existing map in the . consider this example code:\n\nfunc myworkflow(ctx workflow.context, input string) error {\n\n    attr1 := map[string]interface{}{\n        "customintfield": 1,\n        "customboolfield": true,\n    }\n    workflow.upsertsearchattributes(ctx, attr1)\n\n    attr2 := map[string]interface{}{\n        "customintfield": 2,\n        "customkeywordfield": "seattle",\n    }\n    workflow.upsertsearchattributes(ctx, attr2)\n}\n\n\nafter the second call to upsertsearchattributes, the map will contain:\n\nmap[string]interface{}{\n    "customintfield": 2,\n    "customboolfield": true,\n    "customkeywordfield": "seattle",\n}\n\n\nthere is no support for removing a field. to achieve a similar effect, set the field to a sentinel value. for example, to remove “customkeywordfield”, update it to “impossibleval”. then searching customkeywordfield != ‘impossibleval’ will match with customkeywordfield not equal to "impossibleval", which includes without the customkeywordfield set.\n\nuse workflow.getinfo to get current search attributes.\n\n\n# continueasnew and cron\n\nwhen performing a continueasnew or using cron, search attributes (and memo) will be carried over to the new run by default.\n\n\n# query capabilities\n\nby using a sql-like where clause when listing workflows from the cli or using the list apis (go, java).\n\nnote that you will only see from one domain when .\n\n\n# supported operators\n\n * and, or, ()\n * =, !=, >, >=, <, <=\n * in\n * between ... and\n * order by\n\n\n# default attributes\n\nmore and more default attributes are added in newer versions. please get the by using the get-search-attr command or the getsearchattributes api. some names and types are as follows:\n\nkey                   value type\nclosestatus           int\nclosetime             int\ncustomboolfield       double\ncustomdatetimefield   datetime\ncustomdomain          keyword\ncustomdoublefield     bool\ncustomintfield        int\ncustomkeywordfield    keyword\ncustomstringfield     string\ndomainid              keyword\nexecutiontime         int\nhistorylength         int\nrunid                 keyword\nstarttime             int\nworkflowid            keyword\nworkflowtype          keyword\ntasklist              keyword\n\nthere are some special considerations for these attributes:\n\n * closestatus, closetime, domainid, executiontime, historylength, runid, starttime, workflowid, workflowtype are reserved by cadence and are read-only\n * starting from v0.18.0, cadence automatically maps(case insensitive) string to closestatus so that you don\'t need to use integer in the query, to make it easier to use.\n   * 0 = "completed"\n   * 1 = "failed"\n   * 2 = "canceled"\n   * 3 = "terminated"\n   * 4 = "continued_as_new"\n   * 5 = "timed_out"\n * starttime, closetime and executiontime are stored as int, but support using both epochtime in nanoseconds, and string in rfc3339 format (ex. "2006-01-02t15:04:05+07:00")\n * closetime, closestatus, historylength are only present in closed\n * executiontime is for retry/cron user to a that will run in the future\n * to list only open , add closetime = missing to the end of the .\n\nif you use retry or the cron feature to that will start execution in a certain time range, you can add predicates on executiontime. for example: executiontime > 2019-01-01t10:00:00-07:00. note that if predicates on executiontime are included, only cron or a that needs to retry will be returned.\n\n\n# general notes about queries\n\n * pagesize default is 1000, and cannot be larger than 10k\n * range on cadence timestamp (starttime, closetime, executiontime) cannot be larger than 9223372036854775807 (maxint64 - 1001)\n * by time range will have 1ms resolution\n * column names are case sensitive\n * listworkflow may take longer when retrieving a large number of (10m+)\n * to retrieve a large number of without caring about order, use the scanworkflow api\n * to efficiently count the number of , use the countworkflow api\n\n\n# tools support\n\n\n# cli\n\nsupport for search attributes is available as of version 0.6.0 of the cadence server. you can also use the from the latest cli docker image (supported on 0.6.4 or later).\n\n# start workflow with search attributes\n\ncadence --do samples-domain workflow start --tl helloworldgroup --wt main.workflow --et 60 --dt 10 -i \'"vancexu"\' -search_attr_key \'customintfield | customkeywordfield | customstringfield |  customboolfield | customdatetimefield\' -search_attr_value \'5 | keyword1 | vancexu test | true | 2019-06-07t16:16:36-08:00\'\n\n\n# search workflows with list api/command\n\ncadence --do samples-domain wf list -q \'(customkeywordfield = "keyword1" and customintfield >= 5) or customkeywordfield = "keyword2"\' -psa\n\n\ncadence --do samples-domain wf list -q \'customkeywordfield in ("keyword2", "keyword1") and customintfield >= 5 and closetime between "2018-06-07t16:16:36-08:00" and "2019-06-07t16:46:34-08:00" order by customdatetimefield desc\' -psa\n\n\nto list only open , add closetime = missing to the end of the .\n\nnote that can support more than one type of filter:\n\ncadence --do samples-domain wf list -q \'workflowtype = "main.workflow" and (workflowid = "1645a588-4772-4dab-b276-5f9db108b3a8" or runid = "be66519b-5f09-40cd-b2e8-20e4106244dc")\'\n\n\ncadence --do samples-domain wf list -q \'workflowtype = "main.workflow" starttime > "2019-06-07t16:46:34-08:00" and closetime = missing\'\n\n\nall above command can be done with listworkflowexecutions api.\n\n# count workflows with count api/command\n\ncadence --do samples-domain wf count -q \'(customkeywordfield = "keyword1" and customintfield >= 5) or customkeywordfield = "keyword2"\'\n\n\ncadence --do samples-domain wf count -q \'closestatus="failed"\'\n\n\ncadence --do samples-domain wf count -q \'closestatus!="completed"\'\n\n\nall above command can be done with countworkflowexecutions api.\n\n\n# web ui support\n\nare supported in cadence web as of release 3.4.0. use the "basic/advanced" button to switch to "advanced" mode and type the in the search box.\n\n\n# tls support for connecting to elasticsearch\n\nif your elasticsearch deployment requires tls to connect to it, you can add the following to your config template. the tls config is optional and when not provided it defaults to tls.enabled to false\n\nelasticsearch:\n  url:\n    scheme: "https"\n    host: "127.0.0.1:9200"\n  indices:\n    visibility: cadence-visibility-dev\n  tls:\n    enabled: true\n    cafile: /secrets/cadence/elasticsearch_cert.pem\n    enablehostverification: true\n    servername: myservername\n    certfile: /secrets/cadence/certfile.crt\n    keyfile: /secrets/cadence/keyfile.key\n    sslmode: false\n\n\n\n# running locally\n\n 1. increase docker memory to higher than 6gb. navigate to docker -> preferences -> advanced -> memory\n 2. get the cadence docker compose file. run curl -o https://raw.githubusercontent.com/uber/cadence/master/docker/docker-compose-es.yml\n 3. start cadence docker (which contains apache kafka, apache zookeeper, and elasticsearch) using docker-compose -f docker-compose-es.yml up\n 4. from the docker output log, make sure elasticsearch and cadence started correctly. if you encounter an insufficient disk space error, try docker system prune -a --volumes\n 5. register a local domain and start using it. cadence --do samples-domain d re\n 6. add the key to elasticsearch and also allowlist search attributes. cadence --do domain adm cl asa --search_attr_key newkey --search_attr_type 1\n\n\n# running in production\n\nto enable this feature in a cadence cluster:\n\n * register index schema on elasticsearch. run two curl commands following this script.\n   * create a index template by using the schema , choose v6/v7 based on your elasticsearch version\n   * create an index follow the index template, remember the name\n * register topic on kafka, and remember the name\n   * set up the right number of partitions based on your expected throughput(can be scaled up later)\n * configure cadence for elasticsearch + kafka like this documentation based on the full static config, you may add some other fields like authn. similarly for kafka.\n\nto add new search attributes:\n\n 1. add the key to elasticsearch cadence --do domain adm cl asa --search_attr_key newkey --search_attr_type 1\n 2. update the dynamic configuration to allowlist the new attribute\n\nnote: starting a with search attributes but without advanced visibility feature will succeed as normal, but will not be searchable and will not be shown in list results.',charsets:{cjk:!0}},{title:"Deployment topology",frontmatter:{layout:"default",title:"Deployment topology",permalink:"/docs/concepts/topology",readingShow:"top"},regularPath:"/docs/03-concepts/05-topology.html",relativePath:"docs/03-concepts/05-topology.md",key:"v-1c104a48",path:"/docs/concepts/topology/",headers:[{level:2,title:"Overview",slug:"overview",normalizedTitle:"overview",charIndex:26},{level:2,title:"Cadence Service",slug:"cadence-service",normalizedTitle:"cadence service",charIndex:463},{level:2,title:"Workflow Worker",slug:"workflow-worker",normalizedTitle:"workflow worker",charIndex:2374},{level:2,title:"Activity Worker",slug:"activity-worker",normalizedTitle:"activity worker",charIndex:3445},{level:2,title:"External Clients",slug:"external-clients",normalizedTitle:"external clients",charIndex:4137}],codeSwitcherOptions:{},headersStr:"Overview Cadence Service Workflow Worker Activity Worker External Clients",content:"# Deployment topology\n\n\n# Overview\n\nCadence is a highly scalable fault-oblivious stateful code platform. The fault-oblivious code is a next level of abstraction over commonly used techniques to achieve fault tolerance and durability.\n\nA common Cadence-based application consists of a Cadence service, and , and external clients. Note that both types of as well as external clients are roles and can be collocated in a single application process if necessary.\n\n\n# Cadence Service\n\n\n\nAt the core of Cadence is a highly scalable multitentant service. The service exposes all of its functionality through a strongly typed gRPC API. A Cadence cluster include multiple services, each of which may run on multiple nodes for scalability and reliablity:\n\n * Front End: which is a stateless service used to handle incoming requests from Workers. It is expected that an external load balancing mechanism is used to distribute load between Front End instances.\n * History Service: where the core logic of orchestrating workflow steps and activities is implemented\n * Matching Service: matches workflow/activity tasks that need to be executed to workflow/activity workers that are able to execute them. Matching is assigned task for execution by the history service\n * Internal Worker Service: implements Cadence workflows and activities for internal requirements such as archiving\n * Workers: are effectively the client apps for Cadence. This is where user created workflow and activity logic is executed\n\nInternally it depends on a persistent store. Currently, Apache Cassandra, MySQL, PostgreSQL, CockroachDB (PostgreSQL compatible) and TiDB (MySQL compatible) stores are supported out of the box. For listing using complex predicates, ElasticSearch and OpenSearch cluster can be used.\n\nCadence service is responsible for keeping state and associated durable timers. It maintains internal queues (called ) which are used to dispatch to external .\n\nCadence service is multitentant. Therefore it is expected that multiple pools of implementing different use cases connect to the same service instance. For example, at Uber a single service is used by more than a hundred applications. At the same time some external customers deploy an instance of Cadence service per application. For local development, a local Cadence service instance configured through docker-compose is used.\n\n\n\n\n# Workflow Worker\n\nCadence reuses terminology from workflow automation . So fault-oblivious stateful code is called .\n\nThe Cadence service does not execute code directly. The code is hosted by an external (from the service point of view) process. These processes receive that contain that the is expected to handle from the Cadence service, delivers them to the code, and communicates back to the service.\n\nAs code is external to the service, it can be implemented in any language that can talk service Thrift API. Currently Java and Go clients are production ready. While Python and C# clients are under development. Let us know if you are interested in contributing a client in your preferred language.\n\nThe Cadence service API doesn't impose any specific definition language. So a specific can be implemented to execute practically any existing specification. The model the Cadence team chose to support out of the box is based on the idea of durable function. Durable functions are as close as possible to application business logic with minimal plumbing required.\n\n\n# Activity Worker\n\nfault-oblivious code is immune to infrastructure failures. But it has to communicate with the imperfect external world where failures are common. All communication to the external world is done through . are pieces of code that can perform any application-specific action like calling a service, updating a database record, or downloading a file from Amazon S3. Cadence are very feature-rich compared to queuing systems. Example features are routing to specific processes, infinite retries, heartbeats, and unlimited execution time.\n\nare hosted by processes that receive from the Cadence service, invoke correspondent implementations and report back completion statuses.\n\n\n# External Clients\n\nand host and code. But to create a instance (an execution in Cadence terminology) the StartWorkflowExecution Cadence service API call should be used. Usually, are started by outside entities like UIs, microservices or CLIs.\n\nThese entities can also:\n\n * notify about asynchronous external in the form of\n * synchronously state\n * synchronously wait for a completion\n * cancel, terminate, restart, and reset\n * search for specific using list API",normalizedContent:"# deployment topology\n\n\n# overview\n\ncadence is a highly scalable fault-oblivious stateful code platform. the fault-oblivious code is a next level of abstraction over commonly used techniques to achieve fault tolerance and durability.\n\na common cadence-based application consists of a cadence service, and , and external clients. note that both types of as well as external clients are roles and can be collocated in a single application process if necessary.\n\n\n# cadence service\n\n\n\nat the core of cadence is a highly scalable multitentant service. the service exposes all of its functionality through a strongly typed grpc api. a cadence cluster include multiple services, each of which may run on multiple nodes for scalability and reliablity:\n\n * front end: which is a stateless service used to handle incoming requests from workers. it is expected that an external load balancing mechanism is used to distribute load between front end instances.\n * history service: where the core logic of orchestrating workflow steps and activities is implemented\n * matching service: matches workflow/activity tasks that need to be executed to workflow/activity workers that are able to execute them. matching is assigned task for execution by the history service\n * internal worker service: implements cadence workflows and activities for internal requirements such as archiving\n * workers: are effectively the client apps for cadence. this is where user created workflow and activity logic is executed\n\ninternally it depends on a persistent store. currently, apache cassandra, mysql, postgresql, cockroachdb (postgresql compatible) and tidb (mysql compatible) stores are supported out of the box. for listing using complex predicates, elasticsearch and opensearch cluster can be used.\n\ncadence service is responsible for keeping state and associated durable timers. it maintains internal queues (called ) which are used to dispatch to external .\n\ncadence service is multitentant. therefore it is expected that multiple pools of implementing different use cases connect to the same service instance. for example, at uber a single service is used by more than a hundred applications. at the same time some external customers deploy an instance of cadence service per application. for local development, a local cadence service instance configured through docker-compose is used.\n\n\n\n\n# workflow worker\n\ncadence reuses terminology from workflow automation . so fault-oblivious stateful code is called .\n\nthe cadence service does not execute code directly. the code is hosted by an external (from the service point of view) process. these processes receive that contain that the is expected to handle from the cadence service, delivers them to the code, and communicates back to the service.\n\nas code is external to the service, it can be implemented in any language that can talk service thrift api. currently java and go clients are production ready. while python and c# clients are under development. let us know if you are interested in contributing a client in your preferred language.\n\nthe cadence service api doesn't impose any specific definition language. so a specific can be implemented to execute practically any existing specification. the model the cadence team chose to support out of the box is based on the idea of durable function. durable functions are as close as possible to application business logic with minimal plumbing required.\n\n\n# activity worker\n\nfault-oblivious code is immune to infrastructure failures. but it has to communicate with the imperfect external world where failures are common. all communication to the external world is done through . are pieces of code that can perform any application-specific action like calling a service, updating a database record, or downloading a file from amazon s3. cadence are very feature-rich compared to queuing systems. example features are routing to specific processes, infinite retries, heartbeats, and unlimited execution time.\n\nare hosted by processes that receive from the cadence service, invoke correspondent implementations and report back completion statuses.\n\n\n# external clients\n\nand host and code. but to create a instance (an execution in cadence terminology) the startworkflowexecution cadence service api call should be used. usually, are started by outside entities like uis, microservices or clis.\n\nthese entities can also:\n\n * notify about asynchronous external in the form of\n * synchronously state\n * synchronously wait for a completion\n * cancel, terminate, restart, and reset\n * search for specific using list api",charsets:{}},{title:"HTTP API",frontmatter:{layout:"default",title:"HTTP API",permalink:"/docs/concepts/http-api",readingShow:"top"},regularPath:"/docs/03-concepts/10-http-api.html",relativePath:"docs/03-concepts/10-http-api.md",key:"v-c2670478",path:"/docs/concepts/http-api/",headers:[{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:21},{level:2,title:"Setup",slug:"setup",normalizedTitle:"setup",charIndex:765},{level:3,title:"Updating Cadence configuration files",slug:"updating-cadence-configuration-files",normalizedTitle:"updating cadence configuration files",charIndex:775},{level:3,title:"Using local binaries",slug:"using-local-binaries",normalizedTitle:"using local binaries",charIndex:1188},{level:3,title:"Using “docker run” command",slug:"using-docker-run-command",normalizedTitle:"using “docker run” command",charIndex:1281},{level:3,title:"Using docker-compose",slug:"using-docker-compose",normalizedTitle:"using docker-compose",charIndex:1682},{level:2,title:"Using HTTP API",slug:"using-http-api-2",normalizedTitle:"using http api",charIndex:2},{level:2,title:"HTTP API Reference",slug:"http-api-reference",normalizedTitle:"http api reference",charIndex:3184},{level:3,title:"Admin API",slug:"admin-api",normalizedTitle:"admin api",charIndex:3207},{level:3,title:"Domain API",slug:"domain-api",normalizedTitle:"domain api",charIndex:13442},{level:3,title:"Meta API",slug:"meta-api",normalizedTitle:"meta api",charIndex:18445},{level:3,title:"Visibility API",slug:"visibility-api",normalizedTitle:"visibility api",charIndex:19146},{level:3,title:"Workflow API",slug:"workflow-api",normalizedTitle:"workflow api",charIndex:25851}],codeSwitcherOptions:{},headersStr:"Introduction Setup Updating Cadence configuration files Using local binaries Using “docker run” command Using docker-compose Using HTTP API HTTP API Reference Admin API Domain API Meta API Visibility API Workflow API",content:'# Using HTTP API\n\n\n# Introduction\n\nFrom version 1.2.0 onwards, Cadence has introduced HTTP API support, which allows you to interact with the Cadence server using the HTTP protocol. To put this into perspective, HTTP/JSON communication is a flexible method for server interaction. In the context of Cadence, this implies that a range of RPC methods can be exposed and invoked using the HTTP protocol. This enhancement broadens the scope of interaction with the Cadence server, enabling the use of any programming language that supports HTTP. Consequently, you can leverage this functionality to initiate or terminate workflows from your bash scripts, monitor the status of your cluster, or execute any other operation that the Cadence RPC declaration supports.\n\n\n# Setup\n\n\n# Updating Cadence configuration files\n\nTo enable “start workflow” HTTP API, add http section to Cadence RPC configuration settings (e.g., in base.yaml or development.yaml):\n\nservices:\n  frontend:\n    rpc:\n      <...>\n      http:\n        port: 8800\n        procedures:\n          - uber.cadence.api.v1.WorkflowAPI::StartWorkflowExecution \n\n\nThen you can run Cadence server in the following ways to use HTTP API.\n\n\n# Using local binaries\n\nBuild and run ./cadence-server as described in Developing Cadence.\n\n\n# Using “docker run” command\n\nRefer to instructions described in Using docker image for production.\n\nAdditionally add two more environment variables:\n\ndocker run\n<...>\n    -e FRONTEND_HTTP_PORT=8800                          -- HTTP PORT TO LISTEN \n    -e FRONTEND_HTTP_PROCEDURES=uber.cadence.api.v1.WorkflowAPI::StartWorkflowExecution  -- List of API methods exposed\n    ubercadence/server:<tag> \n\n\n\n# Using docker-compose\n\nAdd HTTP environment variables to docker/docker-compose.yml configuration:\n\ncadence:\n  image: ubercadence/server:master-auto-setup\n  ports:\n    - "8000:8000"\n    - "8001:8001"\n    - "8002:8002"\n    - "8003:8003"\n    - "7933:7933"\n    - "7934:7934"\n    - "7935:7935"\n    - "7939:7939"\n    - "7833:7833"\n    - "8800:8800"\n  environment:\n    - "CASSANDRA_SEEDS=cassandra"\n    - "PROMETHEUS_ENDPOINT_0=0.0.0.0:8000"\n    - "PROMETHEUS_ENDPOINT_1=0.0.0.0:8001"\n    - "PROMETHEUS_ENDPOINT_2=0.0.0.0:8002"\n    - "PROMETHEUS_ENDPOINT_3=0.0.0.0:8003"\n    - "DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/development.yaml"\n    - "FRONTEND_HTTP_PORT=8800"\n    - "FRONTEND_HTTP_PROCEDURES=uber.cadence.api.v1.WorkflowAPI::StartWorkflowExecution" \n\n\n\n# Using HTTP API\n\nStart a workflow using curl command\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: rpc-client-name\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.WorkflowAPI::StartWorkflowExecution\' \\\n    -d @data.json \n\n\nWhere data.json content looks something like this:\n\n{\n  "domain": "sample-domain",\n  "workflowId": "workflowid123",\n  "execution_start_to_close_timeout": "11s",\n  "task_start_to_close_timeout": "10s",\n  "workflowType": {\n    "name": "workflow_type"\n  },\n  "taskList": {\n    "name": "tasklist-name"\n  },\n  "identity": "My custom caller identity",\n  "requestId": "4D1E4058-6FCF-4BA8-BF16-8FA8B02F9651"\n} \n\n\n\n# HTTP API Reference\n\n\n# Admin API\n\n----------------------------------------\n\nPOST uber.cadence.admin.v1.AdminAPI::AddSearchAttribute\n\n# Add search attributes to whitelist\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.admin.v1.AdminAPIAddSearchAttribute\n\n# Example payload\n\n{\n  "search_attribute": {\n    "custom_key": 1\n  }\n}\n\n\nSearch attribute types\n\nTYPE       VALUE\nString     1\nKeyword    2\nInt        3\nDouble     4\nDateTime   5\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.admin.v1.AdminAPI::AddSearchAttribute\' \\\n    -d \\\n    \'{\n      "search_attribute": {\n        "custom_key": 1\n      }\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{}\n\n\n----------------------------------------\n\nPOST uber.cadence.admin.v1.AdminAPI::CloseShard\n\n# Close a shard given a shard ID\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.admin.v1.AdminAPICloseShard\n\n# Example payload\n\n{\n  "shard_id": 0\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.admin.v1.AdminAPI::CloseShard\' \\\n    -d \\\n    \'{ \n      "shard_id": 0\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{}\n\n\n----------------------------------------\n\nPOST uber.cadence.admin.v1.AdminAPI::CountDLQMessages\n\n# Count DLQ messages\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.admin.v1.AdminAPICountDLQMessages\n\n# Example payload\n\nNone\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.admin.v1.AdminAPI::CountDLQMessages\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "history": []\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.admin.v1.AdminAPI::DescribeCluster\n\n# Describe cluster information\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.admin.v1.AdminAPIDescribeCluster\n\n# Example payload\n\nNone\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.admin.v1.AdminAPI::DescribeCluster\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "supportedClientVersions": {\n    "goSdk": "1.7.0",\n    "javaSdk": "1.5.0"\n  },\n  "membershipInfo": {\n    "currentHost": {\n      "identity": "127.0.0.1:7933"\n    },\n    "reachableMembers": [\n      "127.0.0.1:7933",\n      "127.0.0.1:7934",\n      "127.0.0.1:7935",\n      "127.0.0.1:7939"\n    ],\n    "rings": [\n      {\n        "role": "cadence-frontend",\n        "memberCount": 1,\n        "members": [\n          {\n            "identity": "127.0.0.1:7933"\n          }\n        ]\n      },\n      {\n        "role": "cadence-history",\n        "memberCount": 1,\n        "members": [\n          {\n            "identity": "127.0.0.1:7934"\n          }\n        ]\n      },\n      {\n        "role": "cadence-matching",\n        "memberCount": 1,\n        "members": [\n          {\n            "identity": "127.0.0.1:7935"\n          }\n        ]\n      },\n      {\n        "role": "cadence-worker",\n        "memberCount": 1,\n        "members": [\n          {\n            "identity": "127.0.0.1:7939"\n          }\n        ]\n      }\n    ]\n  },\n  "persistenceInfo": {\n    "historyStore": {\n      "backend": "shardedNosql"\n    },\n    "visibilityStore": {\n      "backend": "cassandra",\n      "features": [\n        {\n          "key": "advancedVisibilityEnabled"\n        }\n      ]\n    }\n  }\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.admin.v1.AdminAPI::DescribeHistoryHost\n\n# Describe internal information of history host\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.admin.v1.AdminAPIDescribeHistoryHost\n\n# Example payload\n\n{\n  "host_address": "127.0.0.1:7934"\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.admin.v1.AdminAPI::DescribeHistoryHost\' \\\n    -d \\\n    \'{\n      "host_address": "127.0.0.1:7934"\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "numberOfShards": 4,\n  "domainCache": {\n    "numOfItemsInCacheByID": 5,\n    "numOfItemsInCacheByName": 5\n  },\n  "shardControllerStatus": "started",\n  "address": "127.0.0.1:7934"\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.admin.v1.AdminAPI::DescribeShardDistribution\n\n# List shard distribution\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.admin.v1.AdminAPIDescribeShardDistribution\n\n# Example payload\n\n{\n  "page_size": 100,\n  "page_id": 0\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.admin.v1.AdminAPI::DescribeShardDistribution\' \\\n    -d \\\n    \'{\n      "page_size": 100,\n      "page_id": 0\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "numberOfShards": 4,\n  "shards": {\n    "0": "127.0.0.1:7934",\n    "1": "127.0.0.1:7934",\n    "2": "127.0.0.1:7934",\n    "3": "127.0.0.1:7934"\n  }\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.admin.v1.AdminAPI::DescribeWorkflowExecution\n\n# Describe internal information of workflow execution\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.admin.v1.AdminAPIDescribeWorkflowExecution\n\n# Example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "cc09d5dd-b2fa-46d8-b426-54c96b12d18f"\n  }\n}\n\n\nrun_id is optional and allows to describe a specific run.\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.admin.v1.AdminAPI::DescribeWorkflowExecution\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_execution": {\n        "workflow_id": "sample-workflow-id",\n        "run_id": "cc09d5dd-b2fa-46d8-b426-54c96b12d18f"\n      }\n    }\' | tr -d \'\\\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "shardId": 3,\n  "historyAddr": "127.0.0.1:7934",\n  "mutableStateInDatabase": {\n    "ActivityInfos": {},\n    "TimerInfos": {},\n    "ChildExecutionInfos": {},\n    "RequestCancelInfos": {},\n    "SignalInfos": {},\n    "SignalRequestedIDs": {},\n    "ExecutionInfo": {\n      "DomainID": "d7aff879-f524-43a8-b340-5a223a69d75b",\n      "WorkflowID": "sample-workflow-id",\n      "RunID": "cc09d5dd-b2fa-46d8-b426-54c96b12d18f",\n      "FirstExecutionRunID": "cc09d5dd-b2fa-46d8-b426-54c96b12d18f",\n      "ParentDomainID": "",\n      "ParentWorkflowID": "",\n      "ParentRunID": "",\n      "InitiatedID": -7,\n      "CompletionEventBatchID": 3,\n      "CompletionEvent": null,\n      "TaskList": "sample-task-list",\n      "WorkflowTypeName": "sample-workflow-type",\n      "WorkflowTimeout": 11,\n      "DecisionStartToCloseTimeout": 10,\n      "ExecutionContext": null,\n      "State": 2,\n      "CloseStatus": 6,\n      "LastFirstEventID": 3,\n      "LastEventTaskID": 8388614,\n      "NextEventID": 4,\n      "LastProcessedEvent": -23,\n      "StartTimestamp": "2023-09-08T05:13:04.24Z",\n      "LastUpdatedTimestamp": "2023-09-08T05:13:15.247Z",\n      "CreateRequestID": "8049b932-6c2f-415a-9bb2-241dcf4cfc9c",\n      "SignalCount": 0,\n      "DecisionVersion": 0,\n      "DecisionScheduleID": 2,\n      "DecisionStartedID": -23,\n      "DecisionRequestID": "emptyUuid",\n      "DecisionTimeout": 10,\n      "DecisionAttempt": 0,\n      "DecisionStartedTimestamp": 0,\n      "DecisionScheduledTimestamp": 1694149984240504000,\n      "DecisionOriginalScheduledTimestamp": 1694149984240503000,\n      "CancelRequested": false,\n      "CancelRequestID": "",\n      "StickyTaskList": "",\n      "StickyScheduleToStartTimeout": 0,\n      "ClientLibraryVersion": "",\n      "ClientFeatureVersion": "",\n      "ClientImpl": "",\n      "AutoResetPoints": {},\n      "Memo": null,\n      "SearchAttributes": null,\n      "PartitionConfig": null,\n      "Attempt": 0,\n      "HasRetryPolicy": false,\n      "InitialInterval": 0,\n      "BackoffCoefficient": 0,\n      "MaximumInterval": 0,\n      "ExpirationTime": "0001-01-01T00:00:00Z",\n      "MaximumAttempts": 0,\n      "NonRetriableErrors": null,\n      "BranchToken": null,\n      "CronSchedule": "",\n      "IsCron": false,\n      "ExpirationSeconds": 0\n    },\n    "ExecutionStats": null,\n    "BufferedEvents": [],\n    "VersionHistories": {\n      "CurrentVersionHistoryIndex": 0,\n      "Histories": [\n        {\n          "BranchToken": "WQsACgAAACRjYzA5ZDVkZC1iMmZhLTQ2ZDgtYjQyNi01NGM5NmIxMmQxOGYLABQAAAAkYWM5YmIwMmUtMjllYy00YWEyLTlkZGUtZWQ0YWU1NWRhMjlhDwAeDAAAAAAA",\n          "Items": [\n            {\n              "EventID": 3,\n              "Version": 0\n            }\n          ]\n        }\n      ]\n    },\n    "ReplicationState": null,\n    "Checksum": {\n      "Version": 0,\n      "Flavor": 0,\n      "Value": null\n    }\n  }\n}\n\n\n----------------------------------------\n\n\n# Domain API\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.DomainAPI::DescribeDomain\n\n# Describe existing workflow domain\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.DomainAPIDescribeDomain\n\n# Example payload\n\n{\n  "name": "sample-domain",\n  "uuid": "d7aff879-f524-43a8-b340-5a223a69d75b"\n}\n\n\nuuid of the domain is optional.\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.DomainAPI::DescribeDomain\' \\\n    -d \\\n    \'{\n      "name": "sample-domain"\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "domain": {\n    "id": "d7aff879-f524-43a8-b340-5a223a69d75b",\n    "name": "sample-domain",\n    "status": "DOMAIN_STATUS_REGISTERED",\n    "data": {},\n    "workflowExecutionRetentionPeriod": "259200s",\n    "badBinaries": {\n      "binaries": {}\n    },\n    "historyArchivalStatus": "ARCHIVAL_STATUS_ENABLED",\n    "historyArchivalUri": "file:///tmp/cadence_archival/development",\n    "visibilityArchivalStatus": "ARCHIVAL_STATUS_ENABLED",\n    "visibilityArchivalUri": "file:///tmp/cadence_vis_archival/development",\n    "activeClusterName": "cluster0",\n    "clusters": [\n      {\n        "clusterName": "cluster0"\n      }\n    ],\n    "isGlobalDomain": true,\n    "isolationGroups": {}\n  }\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.DomainAPI::ListDomains\n\n# List all domains in the cluster\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.DomainAPIListDomains\n\n# Example payload\n\n{\n  "page_size": 100\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.DomainAPI::ListDomains\' \\\n    -d \\\n    \'{\n      "page_size": 100\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "domains": [\n    {\n      "id": "3116607e-419b-4783-85fc-47726a4c3fe9",\n      "name": "cadence-batcher",\n      "status": "DOMAIN_STATUS_REGISTERED",\n      "description": "Cadence internal system domain",\n      "data": {},\n      "workflowExecutionRetentionPeriod": "604800s",\n      "badBinaries": {\n        "binaries": {}\n      },\n      "historyArchivalStatus": "ARCHIVAL_STATUS_DISABLED",\n      "visibilityArchivalStatus": "ARCHIVAL_STATUS_DISABLED",\n      "activeClusterName": "cluster0",\n      "clusters": [\n        {\n          "clusterName": "cluster0"\n        }\n      ],\n      "failoverVersion": "-24",\n      "isolationGroups": {}\n    },\n    {\n      "id": "59c51119-1b41-4a28-986d-d6e377716f82",\n      "name": "cadence-shadower",\n      "status": "DOMAIN_STATUS_REGISTERED",\n      "description": "Cadence internal system domain",\n      "data": {},\n      "workflowExecutionRetentionPeriod": "604800s",\n      "badBinaries": {\n        "binaries": {}\n      },\n      "historyArchivalStatus": "ARCHIVAL_STATUS_DISABLED",\n      "visibilityArchivalStatus": "ARCHIVAL_STATUS_DISABLED",\n      "activeClusterName": "cluster0",\n      "clusters": [\n        {\n          "clusterName": "cluster0"\n        }\n      ],\n      "failoverVersion": "-24",\n      "isolationGroups": {}\n    },\n    {\n      "id": "32049b68-7872-4094-8e63-d0dd59896a83",\n      "name": "cadence-system",\n      "status": "DOMAIN_STATUS_REGISTERED",\n      "description": "cadence system workflow domain",\n      "ownerEmail": "cadence-dev-group@uber.com",\n      "data": {},\n      "workflowExecutionRetentionPeriod": "259200s",\n      "badBinaries": {\n        "binaries": {}\n      },\n      "historyArchivalStatus": "ARCHIVAL_STATUS_DISABLED",\n      "visibilityArchivalStatus": "ARCHIVAL_STATUS_DISABLED",\n      "activeClusterName": "cluster0",\n      "clusters": [\n        {\n          "clusterName": "cluster0"\n        }\n      ],\n      "failoverVersion": "-24",\n      "isolationGroups": {}\n    },\n    {\n      "id": "d7aff879-f524-43a8-b340-5a223a69d75b",\n      "name": "sample-domain",\n      "status": "DOMAIN_STATUS_REGISTERED",\n      "data": {},\n      "workflowExecutionRetentionPeriod": "259200s",\n      "badBinaries": {\n        "binaries": {}\n      },\n      "historyArchivalStatus": "ARCHIVAL_STATUS_ENABLED",\n      "historyArchivalUri": "file:///tmp/cadence_archival/development",\n      "visibilityArchivalStatus": "ARCHIVAL_STATUS_ENABLED",\n      "visibilityArchivalUri": "file:///tmp/cadence_vis_archival/development",\n      "activeClusterName": "cluster0",\n      "clusters": [\n        {\n          "clusterName": "cluster0"\n        }\n      ],\n      "isGlobalDomain": true,\n      "isolationGroups": {}\n    }\n  ],\n  "nextPageToken": ""\n}\n\n\n----------------------------------------\n\n\n# Meta API\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.MetaAPI::Health\n\n# Health check\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.MetaAPIHealth\n\n# Example payload\n\nNone\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n  -H \'context-ttl-ms: 2000\' \\\n  -H \'rpc-caller: curl-client\' \\\n  -H \'rpc-service: cadence-frontend\' \\\n  -H \'rpc-encoding: json\' \\\n  -H \'rpc-procedure: uber.cadence.api.v1.MetaAPI::Health\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "ok": true,\n  "message": "OK"\n}\n\n\n----------------------------------------\n\n\n# Visibility API\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.VisibilityAPI::GetSearchAttributes\n\n# Get search attributes\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.VisibilityAPIGetSearchAttributes\n\n# Example payload\n\nNone\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n  -H \'context-ttl-ms: 2000\' \\\n  -H \'rpc-caller: curl-client\' \\\n  -H \'rpc-service: cadence-frontend\' \\\n  -H \'rpc-encoding: json\' \\\n  -H \'rpc-procedure: uber.cadence.api.v1.VisibilityAPI::GetSearchAttributes\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "keys": {\n    "BinaryChecksums": "INDEXED_VALUE_TYPE_KEYWORD",\n    "CadenceChangeVersion": "INDEXED_VALUE_TYPE_KEYWORD",\n    "CloseStatus": "INDEXED_VALUE_TYPE_INT",\n    "CloseTime": "INDEXED_VALUE_TYPE_INT",\n    "CustomBoolField": "INDEXED_VALUE_TYPE_BOOL",\n    "CustomDatetimeField": "INDEXED_VALUE_TYPE_DATETIME",\n    "CustomDomain": "INDEXED_VALUE_TYPE_KEYWORD",\n    "CustomDoubleField": "INDEXED_VALUE_TYPE_DOUBLE",\n    "CustomIntField": "INDEXED_VALUE_TYPE_INT",\n    "CustomKeywordField": "INDEXED_VALUE_TYPE_KEYWORD",\n    "CustomStringField": "INDEXED_VALUE_TYPE_STRING",\n    "DomainID": "INDEXED_VALUE_TYPE_KEYWORD",\n    "ExecutionTime": "INDEXED_VALUE_TYPE_INT",\n    "HistoryLength": "INDEXED_VALUE_TYPE_INT",\n    "IsCron": "INDEXED_VALUE_TYPE_KEYWORD",\n    "NewKey": "INDEXED_VALUE_TYPE_KEYWORD",\n    "NumClusters": "INDEXED_VALUE_TYPE_INT",\n    "Operator": "INDEXED_VALUE_TYPE_KEYWORD",\n    "Passed": "INDEXED_VALUE_TYPE_BOOL",\n    "RolloutID": "INDEXED_VALUE_TYPE_KEYWORD",\n    "RunID": "INDEXED_VALUE_TYPE_KEYWORD",\n    "ShardID": "INDEXED_VALUE_TYPE_INT",\n    "StartTime": "INDEXED_VALUE_TYPE_INT",\n    "TaskList": "INDEXED_VALUE_TYPE_KEYWORD",\n    "TestNewKey": "INDEXED_VALUE_TYPE_STRING",\n    "UpdateTime": "INDEXED_VALUE_TYPE_INT",\n    "WorkflowID": "INDEXED_VALUE_TYPE_KEYWORD",\n    "WorkflowType": "INDEXED_VALUE_TYPE_KEYWORD",\n    "addon": "INDEXED_VALUE_TYPE_KEYWORD",\n    "addon-type": "INDEXED_VALUE_TYPE_KEYWORD",\n    "environment": "INDEXED_VALUE_TYPE_KEYWORD",\n    "project": "INDEXED_VALUE_TYPE_KEYWORD",\n    "service": "INDEXED_VALUE_TYPE_KEYWORD",\n    "user": "INDEXED_VALUE_TYPE_KEYWORD"\n  }\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.VisibilityAPI::ListClosedWorkflowExecutions\n\n# List closed workflow executions in a domain\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.VisibilityAPIListClosedWorkflowExecutions\n\n# Example payloads\n\nstartTimeFilter is required while executionFilter and typeFilter are optional.\n\n{\n  "domain": "sample-domain",\n  "start_time_filter": {\n    "earliest_time": "2023-01-01T00:00:00Z",\n    "latest_time": "2023-12-31T00:00:00Z"\n  }\n}\n\n\n{\n  "domain": "sample-domain",\n  "start_time_filter": {\n    "earliest_time": "2023-01-01T00:00:00Z",\n    "latest_time": "2023-12-31T00:00:00Z"\n  },\n  "execution_filter": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "71c3d47b-454a-4315-97c7-15355140094b"\n  }\n}\n\n\n{\n  "domain": "sample-domain",\n  "start_time_filter": {\n    "earliest_time": "2023-01-01T00:00:00Z",\n    "latest_time": "2023-12-31T00:00:00Z"\n  },\n  "type_filter": {\n    "name": "sample-workflow-type"\n  }\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.VisibilityAPI::ListClosedWorkflowExecutions\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "start_time_filter": {\n        "earliest_time": "2023-01-01T00:00:00Z",\n        "latest_time": "2023-12-31T00:00:00Z"\n      }\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "executions": [\n    {\n      "workflowExecution": {\n        "workflowId": "sample-workflow-id",\n        "runId": "71c3d47b-454a-4315-97c7-15355140094b"\n      },\n      "type": {\n        "name": "sample-workflow-type"\n      },\n      "startTime": "2023-09-08T06:31:18.778Z",\n      "closeTime": "2023-09-08T06:32:18.782Z",\n      "closeStatus": "WORKFLOW_EXECUTION_CLOSE_STATUS_TIMED_OUT",\n      "historyLength": "5",\n      "executionTime": "2023-09-08T06:31:18.778Z",\n      "memo": {},\n      "searchAttributes": {\n        "indexedFields": {}\n      },\n      "taskList": "sample-task-list"\n    }\n  ],\n  "nextPageToken": ""\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.VisibilityAPI::ListOpenWorkflowExecutions\n\n# List open workflow executions in a domain\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.VisibilityAPIListOpenWorkflowExecutions\n\n# Example payloads\n\nstartTimeFilter is required while executionFilter and typeFilter are optional.\n\n{\n  "domain": "sample-domain",\n  "start_time_filter": {\n    "earliest_time": "2023-01-01T00:00:00Z",\n    "latest_time": "2023-12-31T00:00:00Z"\n  }\n}\n\n\n{\n  "domain": "sample-domain",\n  "start_time_filter": {\n    "earliest_time": "2023-01-01T00:00:00Z",\n    "latest_time": "2023-12-31T00:00:00Z"\n  },\n  "execution_filter": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "71c3d47b-454a-4315-97c7-15355140094b"\n  }\n}\n\n\n{\n  "domain": "sample-domain",\n  "start_time_filter": {\n    "earliest_time": "2023-01-01T00:00:00Z",\n    "latest_time": "2023-12-31T00:00:00Z"\n  },\n  "type_filter": {\n    "name": "sample-workflow-type"\n  }\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n  -H \'context-ttl-ms: 2000\' \\\n  -H \'rpc-caller: curl-client\' \\\n  -H \'rpc-service: cadence-frontend\' \\\n  -H \'rpc-encoding: json\' \\\n  -H \'rpc-procedure: uber.cadence.api.v1.VisibilityAPI::ListOpenWorkflowExecutions\' \\\n  -d \\\n  \'{\n    "domain": "sample-domain",\n    "start_time_filter": {\n      "earliest_time": "2023-01-01T00:00:00Z",\n      "latest_time": "2023-12-31T00:00:00Z"\n    }\n  }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "executions": [\n    {\n      "workflowExecution": {\n        "workflowId": "sample-workflow-id",\n        "runId": "5dbabeeb-82a2-41ed-bf55-dc732a4d46ce"\n      },\n      "type": {\n        "name": "sample-workflow-type"\n      },\n      "startTime": "2023-09-12T02:17:46.596Z",\n      "executionTime": "2023-09-12T02:17:46.596Z",\n      "memo": {},\n      "searchAttributes": {\n        "indexedFields": {}\n      },\n      "taskList": "sample-task-list"\n    }\n  ],\n  "nextPageToken": ""\n}\n\n\n----------------------------------------\n\n\n# Workflow API\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.WorkflowAPI::DescribeTaskList\n\n# Describe pollers info of tasklist\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.WorkflowAPIDescribeTaskList\n\n# Example payload\n\n{\n  "domain": "sample-domain",\n  "task_list": {\n    "name": "sample-task-list",\n    "kind": 1\n  },\n  "task_list_type": 1,\n  "include_task_list_status": true\n}\n\n\ntask_list kind is optional.\n\nTask list kinds\n\nTYPE                 VALUE\nTaskListKindNormal   1\nTaskListKindSticky   2\n\nTask list types\n\nTYPE                   VALUE\nTaskListTypeDecision   1\nTaskListTypeActivity   2\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.WorkflowAPI::DescribeTaskList\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "task_list": {\n        "name": "sample-task-list",\n        "kind": 1\n      },\n      "task_list_type": 1,\n      "include_task_list_status": true\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "taskListStatus": {\n    "readLevel": "200000",\n    "ratePerSecond": 100000,\n    "taskIdBlock": {\n      "startId": "200001",\n      "endId": "300000"\n    }\n  }\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.WorkflowAPI::DescribeWorkflowExecution\n\n# Describe a workflow execution\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.WorkflowAPIDescribeWorkflowExecution\n\n# Example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "5dbabeeb-82a2-41ed-bf55-dc732a4d46ce"\n  }\n}\n\n\nrun_id is optional and allows to describe a specific run.\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n  -H \'context-ttl-ms: 2000\' \\\n  -H \'rpc-caller: curl-client\' \\\n  -H \'rpc-service: cadence-frontend\' \\\n  -H \'rpc-encoding: json\' \\\n  -H \'rpc-procedure: uber.cadence.api.v1.WorkflowAPI::DescribeWorkflowExecution\' \\\n  -d \\\n  \'{\n    "domain": "sample-domain",\n    "workflow_execution": {\n      "workflow_id": "sample-workflow-id",\n      "run_id": "5dbabeeb-82a2-41ed-bf55-dc732a4d46ce"\n    }\n  }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "executionConfiguration": {\n    "taskList": {\n      "name": "sample-task-list"\n    },\n    "executionStartToCloseTimeout": "11s",\n    "taskStartToCloseTimeout": "10s"\n  },\n  "workflowExecutionInfo": {\n    "workflowExecution": {\n      "workflowId": "sample-workflow-id",\n      "runId": "5dbabeeb-82a2-41ed-bf55-dc732a4d46ce"\n    },\n    "type": {\n      "name": "sample-workflow-type"\n    },\n    "startTime": "2023-09-12T02:17:46.596Z",\n    "closeTime": "2023-09-12T02:17:57.602707Z",\n    "closeStatus": "WORKFLOW_EXECUTION_CLOSE_STATUS_TIMED_OUT",\n    "historyLength": "3",\n    "executionTime": "2023-09-12T02:17:46.596Z",\n    "memo": {},\n    "searchAttributes": {},\n    "autoResetPoints": {}\n  },\n  "pendingDecision": {\n    "state": "PENDING_DECISION_STATE_SCHEDULED",\n    "scheduledTime": "2023-09-12T02:17:46.596982Z",\n    "originalScheduledTime": "2023-09-12T02:17:46.596982Z"\n  }\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.WorkflowAPI::GetClusterInfo\n\n# Get supported client versions for the cluster\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.WorkflowAPIGetClusterInfo\n\n# Example payload\n\nNone\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n  -H \'context-ttl-ms: 2000\' \\\n  -H \'rpc-caller: curl-client\' \\\n  -H \'rpc-service: cadence-frontend\' \\\n  -H \'rpc-encoding: json\' \\\n  -H \'rpc-procedure: uber.cadence.api.v1.WorkflowAPI::GetClusterInfo\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "supportedClientVersions": {\n    "goSdk": "1.7.0",\n    "javaSdk": "1.5.0"\n  }\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.WorkflowAPI::GetTaskListsByDomain\n\n# Get the task lists in a domain\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.WorkflowAPIGetTaskListsByDomain\n\n# Example payload\n\n{\n  "domain": "sample-domain"\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.WorkflowAPI::GetTaskListsByDomain\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain"\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "decisionTaskListMap": {},\n  "activityTaskListMap": {}\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.WorkflowAPI::GetWorkflowExecutionHistory\n\n# Get the history of workflow executions\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.WorkflowAPIGetWorkflowExecutionHistory\n\n# Example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id"\n  }\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.WorkflowAPI::GetWorkflowExecutionHistory\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_execution": {\n        "workflow_id": "sample-workflow-id"\n      }\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "history": {\n    "events": [\n      {\n        "eventId": "1",\n        "eventTime": "2023-09-12T05:34:46.107550Z",\n        "taskId": "9437321",\n        "workflowExecutionStartedEventAttributes": {\n          "workflowType": {\n            "name": "sample-workflow-type"\n          },\n          "taskList": {\n            "name": "sample-task-list"\n          },\n          "input": {\n            "data": "IkN1cmwhIg=="\n          },\n          "executionStartToCloseTimeout": "61s",\n          "taskStartToCloseTimeout": "60s",\n          "originalExecutionRunId": "fd7c2283-79dd-458c-8306-e2d1d8217613",\n          "identity": "client-name-visible-in-history",\n          "firstExecutionRunId": "fd7c2283-79dd-458c-8306-e2d1d8217613",\n          "firstDecisionTaskBackoff": "0s"\n        }\n      },\n      {\n        "eventId": "2",\n        "eventTime": "2023-09-12T05:34:46.107565Z",\n        "taskId": "9437322",\n        "decisionTaskScheduledEventAttributes": {\n          "taskList": {\n            "name": "sample-task-list"\n          },\n          "startToCloseTimeout": "60s"\n        }\n      },\n      {\n        "eventId": "3",\n        "eventTime": "2023-09-12T05:34:59.184511Z",\n        "taskId": "9437330",\n        "workflowExecutionCancelRequestedEventAttributes": {\n          "cause": "dummy",\n          "identity": "client-name-visible-in-history"\n        }\n      },\n      {\n        "eventId": "4",\n        "eventTime": "2023-09-12T05:35:47.112156Z",\n        "taskId": "9437332",\n        "workflowExecutionTimedOutEventAttributes": {\n          "timeoutType": "TIMEOUT_TYPE_START_TO_CLOSE"\n        }\n      }\n    ]\n  }\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.WorkflowAPI::ListTaskListPartitions\n\n# List all the task list partitions and the hostname for partitions\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.WorkflowAPIListTaskListPartitions\n\n# Example payload\n\n{\n  "domain": "sample-domain",\n  "task_list": {\n    "name": "sample-task-list"\n  }\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.WorkflowAPI::ListTaskListPartitions\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "task_list": {\n        "name": "sample-task-list"\n      }\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "activityTaskListPartitions": [\n    {\n      "key": "sample-task-list",\n      "ownerHostName": "127.0.0.1:7935"\n    }\n  ],\n  "decisionTaskListPartitions": [\n    {\n      "key": "sample-task-list",\n      "ownerHostName": "127.0.0.1:7935"\n    }\n  ]\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.WorkflowAPI::RefreshWorkflowTasks\n\n# Refresh all the tasks of a workflow\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.WorkflowAPIRefreshWorkflowTasks\n\n# Example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "b7973fb8-2229-4fe7-ad70-c919c1ae8774"\n  }\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.WorkflowAPI::RefreshWorkflowTasks\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_execution": {\n        "workflow_id": "sample-workflow-id",\n        "run_id": "b7973fb8-2229-4fe7-ad70-c919c1ae8774"\n      }\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.WorkflowAPI::RequestCancelWorkflowExecution\n\n# Cancel a workflow execution\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.WorkflowAPIRequestCancelWorkflowExecution\n\n# Example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "b7973fb8-2229-4fe7-ad70-c919c1ae8774"\n  },\n  "request_id": "8049B932-6C2F-415A-9BB2-241DCF4CFC9C",\n  "cause": "dummy",\n  "identity": "client-name-visible-in-history",\n  "first_execution_run_id": "b7973fb8-2229-4fe7-ad70-c919c1ae8774"\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.WorkflowAPI::RequestCancelWorkflowExecution\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_execution": {\n        "workflow_id": "sample-workflow-id",\n        "run_id": "fd7c2283-79dd-458c-8306-e2d1d8217613"\n      },\n      "request_id": "8049B932-6C2F-415A-9BB2-241DCF4CFC9C",\n      "cause": "dummy",\n      "identity": "client-name-visible-in-history",\n      "first_execution_run_id": "fd7c2283-79dd-458c-8306-e2d1d8217613"\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.WorkflowAPI::RestartWorkflowExecution\n\n# Restart a previous workflow execution\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.WorkflowAPIRestartWorkflowExecution\n\n# Example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "0f95ad5b-03bc-4c6b-8cf0-1f3ea08eb86a"\n  },\n  "identity": "client-name-visible-in-history",\n  "reason": "dummy"\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.WorkflowAPI::RestartWorkflowExecution\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_execution": {\n        "workflow_id": "sample-workflow-id",\n        "run_id": "0f95ad5b-03bc-4c6b-8cf0-1f3ea08eb86a"\n      },\n      "identity": "client-name-visible-in-history",\n      "reason": "dummy"\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "runId": "82914458-3221-42b4-ae54-2e66dff864f7"\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.WorkflowAPI::SignalWithStartWorkflowExecution\n\n# Signal the current open workflow if exists, or attempt to start a new run based on IDResuePolicy and signals it\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.WorkflowAPISignalWithStartWorkflowExecution\n\n# Example payload\n\n{\n  "start_request": {\n    "domain": "sample-domain",\n    "workflow_id": "sample-workflow-id",\n    "execution_start_to_close_timeout": "61s",\n    "task_start_to_close_timeout": "60s",\n    "workflow_type": {\n      "name": "sample-workflow-type"\n    },\n    "task_list": {\n      "name": "sample-task-list"\n    },\n    "identity": "client-name-visible-in-history",\n    "request_id": "8049B932-6C2F-415A-9BB2-241DCF4CFC9C",\n    "input": {\n      "data": "IkN1cmwhIg=="\n    }\n  },\n  "signal_name": "channelA",\n  "signal_input": {\n    "data": "MTA="\n  }\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.WorkflowAPI::SignalWithStartWorkflowExecution\' \\\n    -d \\\n    \'{\n      "start_request": {\n        "domain": "sample-domain",\n        "workflow_id": "sample-workflow-id",\n        "execution_start_to_close_timeout": "61s",\n        "task_start_to_close_timeout": "60s",\n        "workflow_type": {\n          "name": "sample-workflow-type"\n        },\n        "task_list": {\n          "name": "sample-task-list"\n        },\n        "identity": "client-name-visible-in-history",\n        "request_id": "8049B932-6C2F-415A-9BB2-241DCF4CFC9C",\n        "input": {\n          "data": "IkN1cmwhIg=="\n        }\n      },\n      "signal_name": "channelA",\n      "signal_input": {\n        "data": "MTA="\n      }\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "runId": "cc09d5dd-b2fa-46d8-b426-54c96b12d18f"\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.WorkflowAPI::SignalWorkflowExecution\n\n# Signal a workflow execution\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.WorkflowAPISignalWorkflowExecution\n\n# Example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "cc09d5dd-b2fa-46d8-b426-54c96b12d18f"\n  },\n  "signal_name": "channelA",\n  "signal_input": {\n    "data": "MTA="\n  }\n}\n\n\nrun_id is optional and allows to signal a specific run.\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.WorkflowAPI::SignalWorkflowExecution\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_execution": {\n        "workflow_id": "sample-workflow-id"\n      },\n      "signal_name": "channelA",\n      "signal_input": {\n        "data": "MTA="\n      }\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.WorkflowAPI::StartWorkflowExecution\n\n# Start a new workflow execution\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.WorkflowAPIStartWorkflowExecution\n\n# Example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_id": "sample-workflow-id",\n  "execution_start_to_close_timeout": "61s",\n  "task_start_to_close_timeout": "60s",\n  "workflow_type": {\n    "name": "sample-workflow-type"\n  },\n  "task_list": {\n    "name": "sample-task-list"\n  },\n  "identity": "client-name-visible-in-history",\n  "request_id": "8049B932-6C2F-415A-9BB2-241DCF4CFC9C",\n  "input": {\n    "data": "IkN1cmwhIg=="\n  }\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.WorkflowAPI::StartWorkflowExecution\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_id": "sample-workflow-id",\n      "execution_start_to_close_timeout": "61s",\n      "task_start_to_close_timeout": "60s",\n      "workflow_type": {\n        "name": "sample-workflow-type"\n      },\n      "task_list": {\n        "name": "sample-task-list"\n      },\n      "identity": "client-name-visible-in-history",\n      "request_id": "8049B932-6C2F-415A-9BB2-241DCF4CFC9C",\n      "input": {\n        "data": "IkN1cmwhIg=="\n      }\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{\n  "runId": "cc09d5dd-b2fa-46d8-b426-54c96b12d18f"\n}\n\n\n----------------------------------------\n\nPOST uber.cadence.api.v1.WorkflowAPI::TerminateWorkflowExecution\n\n# Terminate a new workflow execution\n\n# Headers\n\nNAME             EXAMPLE\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.WorkflowAPITerminateWorkflowExecution\n\n# Example payloads\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id"\n  }\n}\n\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "0f95ad5b-03bc-4c6b-8cf0-1f3ea08eb86a"\n  },\n  "reason": "dummy",\n  "identity": "client-name-visible-in-history",\n  "first_execution_run_id": "0f95ad5b-03bc-4c6b-8cf0-1f3ea08eb86a"\n}\n\n\n# Example cURL\n\ncurl -X POST http://0.0.0.0:8800 \\\n    -H \'context-ttl-ms: 2000\' \\\n    -H \'rpc-caller: curl-client\' \\\n    -H \'rpc-service: cadence-frontend\' \\\n    -H \'rpc-encoding: json\' \\\n    -H \'rpc-procedure: uber.cadence.api.v1.WorkflowAPI::TerminateWorkflowExecution\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_execution": {\n        "workflow_id": "sample-workflow-id"\n      }\n    }\'\n\n\n# Example successful response\n\nHTTP code: 200\n\n{}\n\n\n----------------------------------------',normalizedContent:'# using http api\n\n\n# introduction\n\nfrom version 1.2.0 onwards, cadence has introduced http api support, which allows you to interact with the cadence server using the http protocol. to put this into perspective, http/json communication is a flexible method for server interaction. in the context of cadence, this implies that a range of rpc methods can be exposed and invoked using the http protocol. this enhancement broadens the scope of interaction with the cadence server, enabling the use of any programming language that supports http. consequently, you can leverage this functionality to initiate or terminate workflows from your bash scripts, monitor the status of your cluster, or execute any other operation that the cadence rpc declaration supports.\n\n\n# setup\n\n\n# updating cadence configuration files\n\nto enable “start workflow” http api, add http section to cadence rpc configuration settings (e.g., in base.yaml or development.yaml):\n\nservices:\n  frontend:\n    rpc:\n      <...>\n      http:\n        port: 8800\n        procedures:\n          - uber.cadence.api.v1.workflowapi::startworkflowexecution \n\n\nthen you can run cadence server in the following ways to use http api.\n\n\n# using local binaries\n\nbuild and run ./cadence-server as described in developing cadence.\n\n\n# using “docker run” command\n\nrefer to instructions described in using docker image for production.\n\nadditionally add two more environment variables:\n\ndocker run\n<...>\n    -e frontend_http_port=8800                          -- http port to listen \n    -e frontend_http_procedures=uber.cadence.api.v1.workflowapi::startworkflowexecution  -- list of api methods exposed\n    ubercadence/server:<tag> \n\n\n\n# using docker-compose\n\nadd http environment variables to docker/docker-compose.yml configuration:\n\ncadence:\n  image: ubercadence/server:master-auto-setup\n  ports:\n    - "8000:8000"\n    - "8001:8001"\n    - "8002:8002"\n    - "8003:8003"\n    - "7933:7933"\n    - "7934:7934"\n    - "7935:7935"\n    - "7939:7939"\n    - "7833:7833"\n    - "8800:8800"\n  environment:\n    - "cassandra_seeds=cassandra"\n    - "prometheus_endpoint_0=0.0.0.0:8000"\n    - "prometheus_endpoint_1=0.0.0.0:8001"\n    - "prometheus_endpoint_2=0.0.0.0:8002"\n    - "prometheus_endpoint_3=0.0.0.0:8003"\n    - "dynamic_config_file_path=config/dynamicconfig/development.yaml"\n    - "frontend_http_port=8800"\n    - "frontend_http_procedures=uber.cadence.api.v1.workflowapi::startworkflowexecution" \n\n\n\n# using http api\n\nstart a workflow using curl command\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: rpc-client-name\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.workflowapi::startworkflowexecution\' \\\n    -d @data.json \n\n\nwhere data.json content looks something like this:\n\n{\n  "domain": "sample-domain",\n  "workflowid": "workflowid123",\n  "execution_start_to_close_timeout": "11s",\n  "task_start_to_close_timeout": "10s",\n  "workflowtype": {\n    "name": "workflow_type"\n  },\n  "tasklist": {\n    "name": "tasklist-name"\n  },\n  "identity": "my custom caller identity",\n  "requestid": "4d1e4058-6fcf-4ba8-bf16-8fa8b02f9651"\n} \n\n\n\n# http api reference\n\n\n# admin api\n\n----------------------------------------\n\npost uber.cadence.admin.v1.adminapi::addsearchattribute\n\n# add search attributes to whitelist\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.admin.v1.adminapiaddsearchattribute\n\n# example payload\n\n{\n  "search_attribute": {\n    "custom_key": 1\n  }\n}\n\n\nsearch attribute types\n\ntype       value\nstring     1\nkeyword    2\nint        3\ndouble     4\ndatetime   5\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.admin.v1.adminapi::addsearchattribute\' \\\n    -d \\\n    \'{\n      "search_attribute": {\n        "custom_key": 1\n      }\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{}\n\n\n----------------------------------------\n\npost uber.cadence.admin.v1.adminapi::closeshard\n\n# close a shard given a shard id\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.admin.v1.adminapicloseshard\n\n# example payload\n\n{\n  "shard_id": 0\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.admin.v1.adminapi::closeshard\' \\\n    -d \\\n    \'{ \n      "shard_id": 0\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{}\n\n\n----------------------------------------\n\npost uber.cadence.admin.v1.adminapi::countdlqmessages\n\n# count dlq messages\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.admin.v1.adminapicountdlqmessages\n\n# example payload\n\nnone\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.admin.v1.adminapi::countdlqmessages\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "history": []\n}\n\n\n----------------------------------------\n\npost uber.cadence.admin.v1.adminapi::describecluster\n\n# describe cluster information\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.admin.v1.adminapidescribecluster\n\n# example payload\n\nnone\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.admin.v1.adminapi::describecluster\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "supportedclientversions": {\n    "gosdk": "1.7.0",\n    "javasdk": "1.5.0"\n  },\n  "membershipinfo": {\n    "currenthost": {\n      "identity": "127.0.0.1:7933"\n    },\n    "reachablemembers": [\n      "127.0.0.1:7933",\n      "127.0.0.1:7934",\n      "127.0.0.1:7935",\n      "127.0.0.1:7939"\n    ],\n    "rings": [\n      {\n        "role": "cadence-frontend",\n        "membercount": 1,\n        "members": [\n          {\n            "identity": "127.0.0.1:7933"\n          }\n        ]\n      },\n      {\n        "role": "cadence-history",\n        "membercount": 1,\n        "members": [\n          {\n            "identity": "127.0.0.1:7934"\n          }\n        ]\n      },\n      {\n        "role": "cadence-matching",\n        "membercount": 1,\n        "members": [\n          {\n            "identity": "127.0.0.1:7935"\n          }\n        ]\n      },\n      {\n        "role": "cadence-worker",\n        "membercount": 1,\n        "members": [\n          {\n            "identity": "127.0.0.1:7939"\n          }\n        ]\n      }\n    ]\n  },\n  "persistenceinfo": {\n    "historystore": {\n      "backend": "shardednosql"\n    },\n    "visibilitystore": {\n      "backend": "cassandra",\n      "features": [\n        {\n          "key": "advancedvisibilityenabled"\n        }\n      ]\n    }\n  }\n}\n\n\n----------------------------------------\n\npost uber.cadence.admin.v1.adminapi::describehistoryhost\n\n# describe internal information of history host\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.admin.v1.adminapidescribehistoryhost\n\n# example payload\n\n{\n  "host_address": "127.0.0.1:7934"\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.admin.v1.adminapi::describehistoryhost\' \\\n    -d \\\n    \'{\n      "host_address": "127.0.0.1:7934"\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "numberofshards": 4,\n  "domaincache": {\n    "numofitemsincachebyid": 5,\n    "numofitemsincachebyname": 5\n  },\n  "shardcontrollerstatus": "started",\n  "address": "127.0.0.1:7934"\n}\n\n\n----------------------------------------\n\npost uber.cadence.admin.v1.adminapi::describesharddistribution\n\n# list shard distribution\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.admin.v1.adminapidescribesharddistribution\n\n# example payload\n\n{\n  "page_size": 100,\n  "page_id": 0\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.admin.v1.adminapi::describesharddistribution\' \\\n    -d \\\n    \'{\n      "page_size": 100,\n      "page_id": 0\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "numberofshards": 4,\n  "shards": {\n    "0": "127.0.0.1:7934",\n    "1": "127.0.0.1:7934",\n    "2": "127.0.0.1:7934",\n    "3": "127.0.0.1:7934"\n  }\n}\n\n\n----------------------------------------\n\npost uber.cadence.admin.v1.adminapi::describeworkflowexecution\n\n# describe internal information of workflow execution\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.admin.v1.adminapidescribeworkflowexecution\n\n# example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "cc09d5dd-b2fa-46d8-b426-54c96b12d18f"\n  }\n}\n\n\nrun_id is optional and allows to describe a specific run.\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.admin.v1.adminapi::describeworkflowexecution\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_execution": {\n        "workflow_id": "sample-workflow-id",\n        "run_id": "cc09d5dd-b2fa-46d8-b426-54c96b12d18f"\n      }\n    }\' | tr -d \'\\\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "shardid": 3,\n  "historyaddr": "127.0.0.1:7934",\n  "mutablestateindatabase": {\n    "activityinfos": {},\n    "timerinfos": {},\n    "childexecutioninfos": {},\n    "requestcancelinfos": {},\n    "signalinfos": {},\n    "signalrequestedids": {},\n    "executioninfo": {\n      "domainid": "d7aff879-f524-43a8-b340-5a223a69d75b",\n      "workflowid": "sample-workflow-id",\n      "runid": "cc09d5dd-b2fa-46d8-b426-54c96b12d18f",\n      "firstexecutionrunid": "cc09d5dd-b2fa-46d8-b426-54c96b12d18f",\n      "parentdomainid": "",\n      "parentworkflowid": "",\n      "parentrunid": "",\n      "initiatedid": -7,\n      "completioneventbatchid": 3,\n      "completionevent": null,\n      "tasklist": "sample-task-list",\n      "workflowtypename": "sample-workflow-type",\n      "workflowtimeout": 11,\n      "decisionstarttoclosetimeout": 10,\n      "executioncontext": null,\n      "state": 2,\n      "closestatus": 6,\n      "lastfirsteventid": 3,\n      "lasteventtaskid": 8388614,\n      "nexteventid": 4,\n      "lastprocessedevent": -23,\n      "starttimestamp": "2023-09-08t05:13:04.24z",\n      "lastupdatedtimestamp": "2023-09-08t05:13:15.247z",\n      "createrequestid": "8049b932-6c2f-415a-9bb2-241dcf4cfc9c",\n      "signalcount": 0,\n      "decisionversion": 0,\n      "decisionscheduleid": 2,\n      "decisionstartedid": -23,\n      "decisionrequestid": "emptyuuid",\n      "decisiontimeout": 10,\n      "decisionattempt": 0,\n      "decisionstartedtimestamp": 0,\n      "decisionscheduledtimestamp": 1694149984240504000,\n      "decisionoriginalscheduledtimestamp": 1694149984240503000,\n      "cancelrequested": false,\n      "cancelrequestid": "",\n      "stickytasklist": "",\n      "stickyscheduletostarttimeout": 0,\n      "clientlibraryversion": "",\n      "clientfeatureversion": "",\n      "clientimpl": "",\n      "autoresetpoints": {},\n      "memo": null,\n      "searchattributes": null,\n      "partitionconfig": null,\n      "attempt": 0,\n      "hasretrypolicy": false,\n      "initialinterval": 0,\n      "backoffcoefficient": 0,\n      "maximuminterval": 0,\n      "expirationtime": "0001-01-01t00:00:00z",\n      "maximumattempts": 0,\n      "nonretriableerrors": null,\n      "branchtoken": null,\n      "cronschedule": "",\n      "iscron": false,\n      "expirationseconds": 0\n    },\n    "executionstats": null,\n    "bufferedevents": [],\n    "versionhistories": {\n      "currentversionhistoryindex": 0,\n      "histories": [\n        {\n          "branchtoken": "wqsacgaaacrjyza5zdvkzc1immzhltq2zdgtyjqyni01ngm5nmixmmqxogylabqaaaakywm5ymiwmmutmjllyy00yweyltlkzgutzwq0ywu1nwrhmjlhdwaedaaaaaaa",\n          "items": [\n            {\n              "eventid": 3,\n              "version": 0\n            }\n          ]\n        }\n      ]\n    },\n    "replicationstate": null,\n    "checksum": {\n      "version": 0,\n      "flavor": 0,\n      "value": null\n    }\n  }\n}\n\n\n----------------------------------------\n\n\n# domain api\n\n----------------------------------------\n\npost uber.cadence.api.v1.domainapi::describedomain\n\n# describe existing workflow domain\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.domainapidescribedomain\n\n# example payload\n\n{\n  "name": "sample-domain",\n  "uuid": "d7aff879-f524-43a8-b340-5a223a69d75b"\n}\n\n\nuuid of the domain is optional.\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.domainapi::describedomain\' \\\n    -d \\\n    \'{\n      "name": "sample-domain"\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "domain": {\n    "id": "d7aff879-f524-43a8-b340-5a223a69d75b",\n    "name": "sample-domain",\n    "status": "domain_status_registered",\n    "data": {},\n    "workflowexecutionretentionperiod": "259200s",\n    "badbinaries": {\n      "binaries": {}\n    },\n    "historyarchivalstatus": "archival_status_enabled",\n    "historyarchivaluri": "file:///tmp/cadence_archival/development",\n    "visibilityarchivalstatus": "archival_status_enabled",\n    "visibilityarchivaluri": "file:///tmp/cadence_vis_archival/development",\n    "activeclustername": "cluster0",\n    "clusters": [\n      {\n        "clustername": "cluster0"\n      }\n    ],\n    "isglobaldomain": true,\n    "isolationgroups": {}\n  }\n}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.domainapi::listdomains\n\n# list all domains in the cluster\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.domainapilistdomains\n\n# example payload\n\n{\n  "page_size": 100\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.domainapi::listdomains\' \\\n    -d \\\n    \'{\n      "page_size": 100\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "domains": [\n    {\n      "id": "3116607e-419b-4783-85fc-47726a4c3fe9",\n      "name": "cadence-batcher",\n      "status": "domain_status_registered",\n      "description": "cadence internal system domain",\n      "data": {},\n      "workflowexecutionretentionperiod": "604800s",\n      "badbinaries": {\n        "binaries": {}\n      },\n      "historyarchivalstatus": "archival_status_disabled",\n      "visibilityarchivalstatus": "archival_status_disabled",\n      "activeclustername": "cluster0",\n      "clusters": [\n        {\n          "clustername": "cluster0"\n        }\n      ],\n      "failoverversion": "-24",\n      "isolationgroups": {}\n    },\n    {\n      "id": "59c51119-1b41-4a28-986d-d6e377716f82",\n      "name": "cadence-shadower",\n      "status": "domain_status_registered",\n      "description": "cadence internal system domain",\n      "data": {},\n      "workflowexecutionretentionperiod": "604800s",\n      "badbinaries": {\n        "binaries": {}\n      },\n      "historyarchivalstatus": "archival_status_disabled",\n      "visibilityarchivalstatus": "archival_status_disabled",\n      "activeclustername": "cluster0",\n      "clusters": [\n        {\n          "clustername": "cluster0"\n        }\n      ],\n      "failoverversion": "-24",\n      "isolationgroups": {}\n    },\n    {\n      "id": "32049b68-7872-4094-8e63-d0dd59896a83",\n      "name": "cadence-system",\n      "status": "domain_status_registered",\n      "description": "cadence system workflow domain",\n      "owneremail": "cadence-dev-group@uber.com",\n      "data": {},\n      "workflowexecutionretentionperiod": "259200s",\n      "badbinaries": {\n        "binaries": {}\n      },\n      "historyarchivalstatus": "archival_status_disabled",\n      "visibilityarchivalstatus": "archival_status_disabled",\n      "activeclustername": "cluster0",\n      "clusters": [\n        {\n          "clustername": "cluster0"\n        }\n      ],\n      "failoverversion": "-24",\n      "isolationgroups": {}\n    },\n    {\n      "id": "d7aff879-f524-43a8-b340-5a223a69d75b",\n      "name": "sample-domain",\n      "status": "domain_status_registered",\n      "data": {},\n      "workflowexecutionretentionperiod": "259200s",\n      "badbinaries": {\n        "binaries": {}\n      },\n      "historyarchivalstatus": "archival_status_enabled",\n      "historyarchivaluri": "file:///tmp/cadence_archival/development",\n      "visibilityarchivalstatus": "archival_status_enabled",\n      "visibilityarchivaluri": "file:///tmp/cadence_vis_archival/development",\n      "activeclustername": "cluster0",\n      "clusters": [\n        {\n          "clustername": "cluster0"\n        }\n      ],\n      "isglobaldomain": true,\n      "isolationgroups": {}\n    }\n  ],\n  "nextpagetoken": ""\n}\n\n\n----------------------------------------\n\n\n# meta api\n\n----------------------------------------\n\npost uber.cadence.api.v1.metaapi::health\n\n# health check\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.metaapihealth\n\n# example payload\n\nnone\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n  -h \'context-ttl-ms: 2000\' \\\n  -h \'rpc-caller: curl-client\' \\\n  -h \'rpc-service: cadence-frontend\' \\\n  -h \'rpc-encoding: json\' \\\n  -h \'rpc-procedure: uber.cadence.api.v1.metaapi::health\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "ok": true,\n  "message": "ok"\n}\n\n\n----------------------------------------\n\n\n# visibility api\n\n----------------------------------------\n\npost uber.cadence.api.v1.visibilityapi::getsearchattributes\n\n# get search attributes\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.visibilityapigetsearchattributes\n\n# example payload\n\nnone\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n  -h \'context-ttl-ms: 2000\' \\\n  -h \'rpc-caller: curl-client\' \\\n  -h \'rpc-service: cadence-frontend\' \\\n  -h \'rpc-encoding: json\' \\\n  -h \'rpc-procedure: uber.cadence.api.v1.visibilityapi::getsearchattributes\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "keys": {\n    "binarychecksums": "indexed_value_type_keyword",\n    "cadencechangeversion": "indexed_value_type_keyword",\n    "closestatus": "indexed_value_type_int",\n    "closetime": "indexed_value_type_int",\n    "customboolfield": "indexed_value_type_bool",\n    "customdatetimefield": "indexed_value_type_datetime",\n    "customdomain": "indexed_value_type_keyword",\n    "customdoublefield": "indexed_value_type_double",\n    "customintfield": "indexed_value_type_int",\n    "customkeywordfield": "indexed_value_type_keyword",\n    "customstringfield": "indexed_value_type_string",\n    "domainid": "indexed_value_type_keyword",\n    "executiontime": "indexed_value_type_int",\n    "historylength": "indexed_value_type_int",\n    "iscron": "indexed_value_type_keyword",\n    "newkey": "indexed_value_type_keyword",\n    "numclusters": "indexed_value_type_int",\n    "operator": "indexed_value_type_keyword",\n    "passed": "indexed_value_type_bool",\n    "rolloutid": "indexed_value_type_keyword",\n    "runid": "indexed_value_type_keyword",\n    "shardid": "indexed_value_type_int",\n    "starttime": "indexed_value_type_int",\n    "tasklist": "indexed_value_type_keyword",\n    "testnewkey": "indexed_value_type_string",\n    "updatetime": "indexed_value_type_int",\n    "workflowid": "indexed_value_type_keyword",\n    "workflowtype": "indexed_value_type_keyword",\n    "addon": "indexed_value_type_keyword",\n    "addon-type": "indexed_value_type_keyword",\n    "environment": "indexed_value_type_keyword",\n    "project": "indexed_value_type_keyword",\n    "service": "indexed_value_type_keyword",\n    "user": "indexed_value_type_keyword"\n  }\n}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.visibilityapi::listclosedworkflowexecutions\n\n# list closed workflow executions in a domain\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.visibilityapilistclosedworkflowexecutions\n\n# example payloads\n\nstarttimefilter is required while executionfilter and typefilter are optional.\n\n{\n  "domain": "sample-domain",\n  "start_time_filter": {\n    "earliest_time": "2023-01-01t00:00:00z",\n    "latest_time": "2023-12-31t00:00:00z"\n  }\n}\n\n\n{\n  "domain": "sample-domain",\n  "start_time_filter": {\n    "earliest_time": "2023-01-01t00:00:00z",\n    "latest_time": "2023-12-31t00:00:00z"\n  },\n  "execution_filter": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "71c3d47b-454a-4315-97c7-15355140094b"\n  }\n}\n\n\n{\n  "domain": "sample-domain",\n  "start_time_filter": {\n    "earliest_time": "2023-01-01t00:00:00z",\n    "latest_time": "2023-12-31t00:00:00z"\n  },\n  "type_filter": {\n    "name": "sample-workflow-type"\n  }\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.visibilityapi::listclosedworkflowexecutions\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "start_time_filter": {\n        "earliest_time": "2023-01-01t00:00:00z",\n        "latest_time": "2023-12-31t00:00:00z"\n      }\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "executions": [\n    {\n      "workflowexecution": {\n        "workflowid": "sample-workflow-id",\n        "runid": "71c3d47b-454a-4315-97c7-15355140094b"\n      },\n      "type": {\n        "name": "sample-workflow-type"\n      },\n      "starttime": "2023-09-08t06:31:18.778z",\n      "closetime": "2023-09-08t06:32:18.782z",\n      "closestatus": "workflow_execution_close_status_timed_out",\n      "historylength": "5",\n      "executiontime": "2023-09-08t06:31:18.778z",\n      "memo": {},\n      "searchattributes": {\n        "indexedfields": {}\n      },\n      "tasklist": "sample-task-list"\n    }\n  ],\n  "nextpagetoken": ""\n}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.visibilityapi::listopenworkflowexecutions\n\n# list open workflow executions in a domain\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.visibilityapilistopenworkflowexecutions\n\n# example payloads\n\nstarttimefilter is required while executionfilter and typefilter are optional.\n\n{\n  "domain": "sample-domain",\n  "start_time_filter": {\n    "earliest_time": "2023-01-01t00:00:00z",\n    "latest_time": "2023-12-31t00:00:00z"\n  }\n}\n\n\n{\n  "domain": "sample-domain",\n  "start_time_filter": {\n    "earliest_time": "2023-01-01t00:00:00z",\n    "latest_time": "2023-12-31t00:00:00z"\n  },\n  "execution_filter": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "71c3d47b-454a-4315-97c7-15355140094b"\n  }\n}\n\n\n{\n  "domain": "sample-domain",\n  "start_time_filter": {\n    "earliest_time": "2023-01-01t00:00:00z",\n    "latest_time": "2023-12-31t00:00:00z"\n  },\n  "type_filter": {\n    "name": "sample-workflow-type"\n  }\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n  -h \'context-ttl-ms: 2000\' \\\n  -h \'rpc-caller: curl-client\' \\\n  -h \'rpc-service: cadence-frontend\' \\\n  -h \'rpc-encoding: json\' \\\n  -h \'rpc-procedure: uber.cadence.api.v1.visibilityapi::listopenworkflowexecutions\' \\\n  -d \\\n  \'{\n    "domain": "sample-domain",\n    "start_time_filter": {\n      "earliest_time": "2023-01-01t00:00:00z",\n      "latest_time": "2023-12-31t00:00:00z"\n    }\n  }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "executions": [\n    {\n      "workflowexecution": {\n        "workflowid": "sample-workflow-id",\n        "runid": "5dbabeeb-82a2-41ed-bf55-dc732a4d46ce"\n      },\n      "type": {\n        "name": "sample-workflow-type"\n      },\n      "starttime": "2023-09-12t02:17:46.596z",\n      "executiontime": "2023-09-12t02:17:46.596z",\n      "memo": {},\n      "searchattributes": {\n        "indexedfields": {}\n      },\n      "tasklist": "sample-task-list"\n    }\n  ],\n  "nextpagetoken": ""\n}\n\n\n----------------------------------------\n\n\n# workflow api\n\n----------------------------------------\n\npost uber.cadence.api.v1.workflowapi::describetasklist\n\n# describe pollers info of tasklist\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.workflowapidescribetasklist\n\n# example payload\n\n{\n  "domain": "sample-domain",\n  "task_list": {\n    "name": "sample-task-list",\n    "kind": 1\n  },\n  "task_list_type": 1,\n  "include_task_list_status": true\n}\n\n\ntask_list kind is optional.\n\ntask list kinds\n\ntype                 value\ntasklistkindnormal   1\ntasklistkindsticky   2\n\ntask list types\n\ntype                   value\ntasklisttypedecision   1\ntasklisttypeactivity   2\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.workflowapi::describetasklist\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "task_list": {\n        "name": "sample-task-list",\n        "kind": 1\n      },\n      "task_list_type": 1,\n      "include_task_list_status": true\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "taskliststatus": {\n    "readlevel": "200000",\n    "ratepersecond": 100000,\n    "taskidblock": {\n      "startid": "200001",\n      "endid": "300000"\n    }\n  }\n}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.workflowapi::describeworkflowexecution\n\n# describe a workflow execution\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.workflowapidescribeworkflowexecution\n\n# example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "5dbabeeb-82a2-41ed-bf55-dc732a4d46ce"\n  }\n}\n\n\nrun_id is optional and allows to describe a specific run.\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n  -h \'context-ttl-ms: 2000\' \\\n  -h \'rpc-caller: curl-client\' \\\n  -h \'rpc-service: cadence-frontend\' \\\n  -h \'rpc-encoding: json\' \\\n  -h \'rpc-procedure: uber.cadence.api.v1.workflowapi::describeworkflowexecution\' \\\n  -d \\\n  \'{\n    "domain": "sample-domain",\n    "workflow_execution": {\n      "workflow_id": "sample-workflow-id",\n      "run_id": "5dbabeeb-82a2-41ed-bf55-dc732a4d46ce"\n    }\n  }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "executionconfiguration": {\n    "tasklist": {\n      "name": "sample-task-list"\n    },\n    "executionstarttoclosetimeout": "11s",\n    "taskstarttoclosetimeout": "10s"\n  },\n  "workflowexecutioninfo": {\n    "workflowexecution": {\n      "workflowid": "sample-workflow-id",\n      "runid": "5dbabeeb-82a2-41ed-bf55-dc732a4d46ce"\n    },\n    "type": {\n      "name": "sample-workflow-type"\n    },\n    "starttime": "2023-09-12t02:17:46.596z",\n    "closetime": "2023-09-12t02:17:57.602707z",\n    "closestatus": "workflow_execution_close_status_timed_out",\n    "historylength": "3",\n    "executiontime": "2023-09-12t02:17:46.596z",\n    "memo": {},\n    "searchattributes": {},\n    "autoresetpoints": {}\n  },\n  "pendingdecision": {\n    "state": "pending_decision_state_scheduled",\n    "scheduledtime": "2023-09-12t02:17:46.596982z",\n    "originalscheduledtime": "2023-09-12t02:17:46.596982z"\n  }\n}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.workflowapi::getclusterinfo\n\n# get supported client versions for the cluster\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.workflowapigetclusterinfo\n\n# example payload\n\nnone\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n  -h \'context-ttl-ms: 2000\' \\\n  -h \'rpc-caller: curl-client\' \\\n  -h \'rpc-service: cadence-frontend\' \\\n  -h \'rpc-encoding: json\' \\\n  -h \'rpc-procedure: uber.cadence.api.v1.workflowapi::getclusterinfo\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "supportedclientversions": {\n    "gosdk": "1.7.0",\n    "javasdk": "1.5.0"\n  }\n}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.workflowapi::gettasklistsbydomain\n\n# get the task lists in a domain\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.workflowapigettasklistsbydomain\n\n# example payload\n\n{\n  "domain": "sample-domain"\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.workflowapi::gettasklistsbydomain\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain"\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "decisiontasklistmap": {},\n  "activitytasklistmap": {}\n}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.workflowapi::getworkflowexecutionhistory\n\n# get the history of workflow executions\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.workflowapigetworkflowexecutionhistory\n\n# example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id"\n  }\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.workflowapi::getworkflowexecutionhistory\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_execution": {\n        "workflow_id": "sample-workflow-id"\n      }\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "history": {\n    "events": [\n      {\n        "eventid": "1",\n        "eventtime": "2023-09-12t05:34:46.107550z",\n        "taskid": "9437321",\n        "workflowexecutionstartedeventattributes": {\n          "workflowtype": {\n            "name": "sample-workflow-type"\n          },\n          "tasklist": {\n            "name": "sample-task-list"\n          },\n          "input": {\n            "data": "ikn1cmwhig=="\n          },\n          "executionstarttoclosetimeout": "61s",\n          "taskstarttoclosetimeout": "60s",\n          "originalexecutionrunid": "fd7c2283-79dd-458c-8306-e2d1d8217613",\n          "identity": "client-name-visible-in-history",\n          "firstexecutionrunid": "fd7c2283-79dd-458c-8306-e2d1d8217613",\n          "firstdecisiontaskbackoff": "0s"\n        }\n      },\n      {\n        "eventid": "2",\n        "eventtime": "2023-09-12t05:34:46.107565z",\n        "taskid": "9437322",\n        "decisiontaskscheduledeventattributes": {\n          "tasklist": {\n            "name": "sample-task-list"\n          },\n          "starttoclosetimeout": "60s"\n        }\n      },\n      {\n        "eventid": "3",\n        "eventtime": "2023-09-12t05:34:59.184511z",\n        "taskid": "9437330",\n        "workflowexecutioncancelrequestedeventattributes": {\n          "cause": "dummy",\n          "identity": "client-name-visible-in-history"\n        }\n      },\n      {\n        "eventid": "4",\n        "eventtime": "2023-09-12t05:35:47.112156z",\n        "taskid": "9437332",\n        "workflowexecutiontimedouteventattributes": {\n          "timeouttype": "timeout_type_start_to_close"\n        }\n      }\n    ]\n  }\n}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.workflowapi::listtasklistpartitions\n\n# list all the task list partitions and the hostname for partitions\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.workflowapilisttasklistpartitions\n\n# example payload\n\n{\n  "domain": "sample-domain",\n  "task_list": {\n    "name": "sample-task-list"\n  }\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.workflowapi::listtasklistpartitions\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "task_list": {\n        "name": "sample-task-list"\n      }\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "activitytasklistpartitions": [\n    {\n      "key": "sample-task-list",\n      "ownerhostname": "127.0.0.1:7935"\n    }\n  ],\n  "decisiontasklistpartitions": [\n    {\n      "key": "sample-task-list",\n      "ownerhostname": "127.0.0.1:7935"\n    }\n  ]\n}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.workflowapi::refreshworkflowtasks\n\n# refresh all the tasks of a workflow\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.workflowapirefreshworkflowtasks\n\n# example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "b7973fb8-2229-4fe7-ad70-c919c1ae8774"\n  }\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.workflowapi::refreshworkflowtasks\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_execution": {\n        "workflow_id": "sample-workflow-id",\n        "run_id": "b7973fb8-2229-4fe7-ad70-c919c1ae8774"\n      }\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.workflowapi::requestcancelworkflowexecution\n\n# cancel a workflow execution\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.workflowapirequestcancelworkflowexecution\n\n# example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "b7973fb8-2229-4fe7-ad70-c919c1ae8774"\n  },\n  "request_id": "8049b932-6c2f-415a-9bb2-241dcf4cfc9c",\n  "cause": "dummy",\n  "identity": "client-name-visible-in-history",\n  "first_execution_run_id": "b7973fb8-2229-4fe7-ad70-c919c1ae8774"\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.workflowapi::requestcancelworkflowexecution\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_execution": {\n        "workflow_id": "sample-workflow-id",\n        "run_id": "fd7c2283-79dd-458c-8306-e2d1d8217613"\n      },\n      "request_id": "8049b932-6c2f-415a-9bb2-241dcf4cfc9c",\n      "cause": "dummy",\n      "identity": "client-name-visible-in-history",\n      "first_execution_run_id": "fd7c2283-79dd-458c-8306-e2d1d8217613"\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.workflowapi::restartworkflowexecution\n\n# restart a previous workflow execution\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.workflowapirestartworkflowexecution\n\n# example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "0f95ad5b-03bc-4c6b-8cf0-1f3ea08eb86a"\n  },\n  "identity": "client-name-visible-in-history",\n  "reason": "dummy"\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.workflowapi::restartworkflowexecution\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_execution": {\n        "workflow_id": "sample-workflow-id",\n        "run_id": "0f95ad5b-03bc-4c6b-8cf0-1f3ea08eb86a"\n      },\n      "identity": "client-name-visible-in-history",\n      "reason": "dummy"\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "runid": "82914458-3221-42b4-ae54-2e66dff864f7"\n}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.workflowapi::signalwithstartworkflowexecution\n\n# signal the current open workflow if exists, or attempt to start a new run based on idresuepolicy and signals it\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.workflowapisignalwithstartworkflowexecution\n\n# example payload\n\n{\n  "start_request": {\n    "domain": "sample-domain",\n    "workflow_id": "sample-workflow-id",\n    "execution_start_to_close_timeout": "61s",\n    "task_start_to_close_timeout": "60s",\n    "workflow_type": {\n      "name": "sample-workflow-type"\n    },\n    "task_list": {\n      "name": "sample-task-list"\n    },\n    "identity": "client-name-visible-in-history",\n    "request_id": "8049b932-6c2f-415a-9bb2-241dcf4cfc9c",\n    "input": {\n      "data": "ikn1cmwhig=="\n    }\n  },\n  "signal_name": "channela",\n  "signal_input": {\n    "data": "mta="\n  }\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.workflowapi::signalwithstartworkflowexecution\' \\\n    -d \\\n    \'{\n      "start_request": {\n        "domain": "sample-domain",\n        "workflow_id": "sample-workflow-id",\n        "execution_start_to_close_timeout": "61s",\n        "task_start_to_close_timeout": "60s",\n        "workflow_type": {\n          "name": "sample-workflow-type"\n        },\n        "task_list": {\n          "name": "sample-task-list"\n        },\n        "identity": "client-name-visible-in-history",\n        "request_id": "8049b932-6c2f-415a-9bb2-241dcf4cfc9c",\n        "input": {\n          "data": "ikn1cmwhig=="\n        }\n      },\n      "signal_name": "channela",\n      "signal_input": {\n        "data": "mta="\n      }\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "runid": "cc09d5dd-b2fa-46d8-b426-54c96b12d18f"\n}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.workflowapi::signalworkflowexecution\n\n# signal a workflow execution\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.workflowapisignalworkflowexecution\n\n# example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "cc09d5dd-b2fa-46d8-b426-54c96b12d18f"\n  },\n  "signal_name": "channela",\n  "signal_input": {\n    "data": "mta="\n  }\n}\n\n\nrun_id is optional and allows to signal a specific run.\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.workflowapi::signalworkflowexecution\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_execution": {\n        "workflow_id": "sample-workflow-id"\n      },\n      "signal_name": "channela",\n      "signal_input": {\n        "data": "mta="\n      }\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.workflowapi::startworkflowexecution\n\n# start a new workflow execution\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.workflowapistartworkflowexecution\n\n# example payload\n\n{\n  "domain": "sample-domain",\n  "workflow_id": "sample-workflow-id",\n  "execution_start_to_close_timeout": "61s",\n  "task_start_to_close_timeout": "60s",\n  "workflow_type": {\n    "name": "sample-workflow-type"\n  },\n  "task_list": {\n    "name": "sample-task-list"\n  },\n  "identity": "client-name-visible-in-history",\n  "request_id": "8049b932-6c2f-415a-9bb2-241dcf4cfc9c",\n  "input": {\n    "data": "ikn1cmwhig=="\n  }\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.workflowapi::startworkflowexecution\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_id": "sample-workflow-id",\n      "execution_start_to_close_timeout": "61s",\n      "task_start_to_close_timeout": "60s",\n      "workflow_type": {\n        "name": "sample-workflow-type"\n      },\n      "task_list": {\n        "name": "sample-task-list"\n      },\n      "identity": "client-name-visible-in-history",\n      "request_id": "8049b932-6c2f-415a-9bb2-241dcf4cfc9c",\n      "input": {\n        "data": "ikn1cmwhig=="\n      }\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{\n  "runid": "cc09d5dd-b2fa-46d8-b426-54c96b12d18f"\n}\n\n\n----------------------------------------\n\npost uber.cadence.api.v1.workflowapi::terminateworkflowexecution\n\n# terminate a new workflow execution\n\n# headers\n\nname             example\ncontext-ttl-ms   2000\nrpc-caller       curl-client\nrpc-service      cadence-frontend\nrpc-encoding     json\nrpc-procedure    uber.cadence.api.v1.workflowapiterminateworkflowexecution\n\n# example payloads\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id"\n  }\n}\n\n\n{\n  "domain": "sample-domain",\n  "workflow_execution": {\n    "workflow_id": "sample-workflow-id",\n    "run_id": "0f95ad5b-03bc-4c6b-8cf0-1f3ea08eb86a"\n  },\n  "reason": "dummy",\n  "identity": "client-name-visible-in-history",\n  "first_execution_run_id": "0f95ad5b-03bc-4c6b-8cf0-1f3ea08eb86a"\n}\n\n\n# example curl\n\ncurl -x post http://0.0.0.0:8800 \\\n    -h \'context-ttl-ms: 2000\' \\\n    -h \'rpc-caller: curl-client\' \\\n    -h \'rpc-service: cadence-frontend\' \\\n    -h \'rpc-encoding: json\' \\\n    -h \'rpc-procedure: uber.cadence.api.v1.workflowapi::terminateworkflowexecution\' \\\n    -d \\\n    \'{\n      "domain": "sample-domain",\n      "workflow_execution": {\n        "workflow_id": "sample-workflow-id"\n      }\n    }\'\n\n\n# example successful response\n\nhttp code: 200\n\n{}\n\n\n----------------------------------------',charsets:{cjk:!0}},{title:"Introduction",frontmatter:{layout:"default",title:"Introduction",permalink:"/docs/concepts",readingShow:"top"},regularPath:"/docs/03-concepts/",relativePath:"docs/03-concepts/index.md",key:"v-347319df",path:"/docs/concepts/",codeSwitcherOptions:{},headersStr:null,content:"# Concepts\n\nCadence is a new developer friendly way to develop distributed applications.\n\nIt borrows the core terminology from the workflow-automation space. So its concepts include workflows and activities. can react to events and return internal state through queries.\n\nThe deployment topology explains how all these concepts are mapped to deployable software components.\n\nThe HTTP API reference describes how to use HTTP API to interact with Cadence server.",normalizedContent:"# concepts\n\ncadence is a new developer friendly way to develop distributed applications.\n\nit borrows the core terminology from the workflow-automation space. so its concepts include workflows and activities. can react to events and return internal state through queries.\n\nthe deployment topology explains how all these concepts are mapped to deployable software components.\n\nthe http api reference describes how to use http api to interact with cadence server.",charsets:{}},{title:"Client SDK Overview",frontmatter:{layout:"default",title:"Client SDK Overview",permalink:"/docs/java-client/client-overview",readingShow:"top"},regularPath:"/docs/04-java-client/01-client-overview.html",relativePath:"docs/04-java-client/01-client-overview.md",key:"v-2f3b4398",path:"/docs/java-client/client-overview/",headers:[{level:2,title:"JavaDoc Packages",slug:"javadoc-packages",normalizedTitle:"javadoc packages",charIndex:169},{level:3,title:"com.uber.cadence.activity",slug:"com-uber-cadence-activity",normalizedTitle:"com.uber.cadence.activity",charIndex:190},{level:3,title:"com.uber.cadence.client",slug:"com-uber-cadence-client",normalizedTitle:"com.uber.cadence.client",charIndex:296},{level:3,title:"com.uber.cadence.workflow",slug:"com-uber-cadence-workflow",normalizedTitle:"com.uber.cadence.workflow",charIndex:446},{level:3,title:"com.uber.cadence.worker",slug:"com-uber-cadence-worker",normalizedTitle:"com.uber.cadence.worker",charIndex:506},{level:3,title:"com.uber.cadence.testing",slug:"com-uber-cadence-testing",normalizedTitle:"com.uber.cadence.testing",charIndex:572},{level:2,title:"Samples",slug:"samples",normalizedTitle:"samples",charIndex:26},{level:3,title:"com.uber.cadence.samples.hello",slug:"com-uber-cadence-samples-hello",normalizedTitle:"com.uber.cadence.samples.hello",charIndex:654},{level:3,title:"com.uber.cadence.samples.bookingsaga",slug:"com-uber-cadence-samples-bookingsaga",normalizedTitle:"com.uber.cadence.samples.bookingsaga",charIndex:843},{level:3,title:"com.uber.cadence.samples.fileprocessing",slug:"com-uber-cadence-samples-fileprocessing",normalizedTitle:"com.uber.cadence.samples.fileprocessing",charIndex:942}],codeSwitcherOptions:{},headersStr:"JavaDoc Packages com.uber.cadence.activity com.uber.cadence.client com.uber.cadence.workflow com.uber.cadence.worker com.uber.cadence.testing Samples com.uber.cadence.samples.hello com.uber.cadence.samples.bookingsaga com.uber.cadence.samples.fileprocessing",content:"# Client SDK Overview\n\n * Samples: https://github.com/uber/cadence-java-samples\n * JavaDoc documentation: https://www.javadoc.io/doc/com.uber.cadence/cadence-client\n\n\n# JavaDoc Packages\n\n\n# com.uber.cadence.activity\n\nAPIs to implement activity: accessing activity info, or sending heartbeat.\n\n\n# com.uber.cadence.client\n\nAPIs for external application code to interact with Cadence workflows: start workflows, send signals or query workflows.\n\n\n# com.uber.cadence.workflow\n\nAPIs to implement workflows.\n\n\n# com.uber.cadence.worker\n\nAPIs to configure and start workers.\n\n\n# com.uber.cadence.testing\n\nAPIs to write unit tests for workflows.\n\n\n# Samples\n\n\n# com.uber.cadence.samples.hello\n\nSamples of how to use the basic feature: activity, local activity, ChildWorkflow, Query, etc. This is the most important package you need to start with.\n\n\n# com.uber.cadence.samples.bookingsaga\n\nAn end-to-end example to write workflow using SAGA APIs.\n\n\n# com.uber.cadence.samples.fileprocessing\n\nAn end-to-end example to write workflows to download a file, zips it, and uploads it to a destination.\n\nAn important requirement for such a workflow is that while a first activity can run on any host, the second and third must run on the same host as the first one. This is achieved through use of a host specific task list. The first activity returns the name of the host specific task list and all other activities are dispatched using the stub that is configured with it. This assumes that FileProcessingWorker has a worker running on the same task list.",normalizedContent:"# client sdk overview\n\n * samples: https://github.com/uber/cadence-java-samples\n * javadoc documentation: https://www.javadoc.io/doc/com.uber.cadence/cadence-client\n\n\n# javadoc packages\n\n\n# com.uber.cadence.activity\n\napis to implement activity: accessing activity info, or sending heartbeat.\n\n\n# com.uber.cadence.client\n\napis for external application code to interact with cadence workflows: start workflows, send signals or query workflows.\n\n\n# com.uber.cadence.workflow\n\napis to implement workflows.\n\n\n# com.uber.cadence.worker\n\napis to configure and start workers.\n\n\n# com.uber.cadence.testing\n\napis to write unit tests for workflows.\n\n\n# samples\n\n\n# com.uber.cadence.samples.hello\n\nsamples of how to use the basic feature: activity, local activity, childworkflow, query, etc. this is the most important package you need to start with.\n\n\n# com.uber.cadence.samples.bookingsaga\n\nan end-to-end example to write workflow using saga apis.\n\n\n# com.uber.cadence.samples.fileprocessing\n\nan end-to-end example to write workflows to download a file, zips it, and uploads it to a destination.\n\nan important requirement for such a workflow is that while a first activity can run on any host, the second and third must run on the same host as the first one. this is achieved through use of a host specific task list. the first activity returns the name of the host specific task list and all other activities are dispatched using the stub that is configured with it. this assumes that fileprocessingworker has a worker running on the same task list.",charsets:{}},{title:"Workflow interface",frontmatter:{layout:"default",title:"Workflow interface",permalink:"/docs/java-client/workflow-interface",readingShow:"top"},regularPath:"/docs/04-java-client/02-workflow-interface.html",relativePath:"docs/04-java-client/02-workflow-interface.md",key:"v-44a96002",path:"/docs/java-client/workflow-interface/",codeSwitcherOptions:{},headersStr:null,content:'# Workflow interface\n\nencapsulates the orchestration of and child . It can also answer synchronous and receive external (also known as ).\n\nA must define an interface class. All of its methods must have one of the following annotations:\n\n * @WorkflowMethod indicates an entry point to a . It contains parameters such as timeouts and a . Required parameters (such as executionStartToCloseTimeoutSeconds) that are not specified through the annotation must be provided at runtime.\n * @SignalMethod indicates a method that reacts to external . It must have a void return type.\n * @QueryMethod indicates a method that reacts to synchronous requests.\n\nYou can have more than one method with the same annotation (except @WorkflowMethod). For example:\n\npublic interface FileProcessingWorkflow {\n\n    @WorkflowMethod(executionStartToCloseTimeoutSeconds = 10, taskList = "file-processing")\n    String processFile(Arguments args);\n\n    @QueryMethod(name="history")\n    List<String> getHistory();\n\n    @QueryMethod(name="status")\n    String getStatus();\n\n    @SignalMethod\n    void retryNow();\n\n    @SignalMethod\n    void abandon();\n}\n\n\nWe recommended that you use a single value type argument for methods. In this way, adding new arguments as fields to the value type is a backwards-compatible change.',normalizedContent:'# workflow interface\n\nencapsulates the orchestration of and child . it can also answer synchronous and receive external (also known as ).\n\na must define an interface class. all of its methods must have one of the following annotations:\n\n * @workflowmethod indicates an entry point to a . it contains parameters such as timeouts and a . required parameters (such as executionstarttoclosetimeoutseconds) that are not specified through the annotation must be provided at runtime.\n * @signalmethod indicates a method that reacts to external . it must have a void return type.\n * @querymethod indicates a method that reacts to synchronous requests.\n\nyou can have more than one method with the same annotation (except @workflowmethod). for example:\n\npublic interface fileprocessingworkflow {\n\n    @workflowmethod(executionstarttoclosetimeoutseconds = 10, tasklist = "file-processing")\n    string processfile(arguments args);\n\n    @querymethod(name="history")\n    list<string> gethistory();\n\n    @querymethod(name="status")\n    string getstatus();\n\n    @signalmethod\n    void retrynow();\n\n    @signalmethod\n    void abandon();\n}\n\n\nwe recommended that you use a single value type argument for methods. in this way, adding new arguments as fields to the value type is a backwards-compatible change.',charsets:{}},{title:"Implementing workflows",frontmatter:{layout:"default",title:"Implementing workflows",permalink:"/docs/java-client/implementing-workflows",readingShow:"top"},regularPath:"/docs/04-java-client/03-implementing-workflows.html",relativePath:"docs/04-java-client/03-implementing-workflows.md",key:"v-73f5d8c2",path:"/docs/java-client/implementing-workflows/",headers:[{level:2,title:"Calling Activities",slug:"calling-activities",normalizedTitle:"calling activities",charIndex:515},{level:2,title:"Calling Activities Asynchronously",slug:"calling-activities-asynchronously",normalizedTitle:"calling activities asynchronously",charIndex:2719},{level:2,title:"Workflow Implementation Constraints",slug:"workflow-implementation-constraints",normalizedTitle:"workflow implementation constraints",charIndex:5585}],codeSwitcherOptions:{},headersStr:"Calling Activities Calling Activities Asynchronously Workflow Implementation Constraints",content:"# Implementing workflows\n\nA implementation implements a interface. Each time a new is started, a new instance of the implementation object is created. Then, one of the methods (depending on which type has been started) annotated with @WorkflowMethod is invoked. As soon as this method returns, the is closed. While is open, it can receive calls to and methods. No additional calls to methods are allowed. The object is stateful, so and methods can communicate with the other parts of the through object fields.\n\n\n# Calling Activities\n\nWorkflow.newActivityStub returns a client-side stub that implements an interface. It takes type and options as arguments. options are needed only if some of the required timeouts are not specified through the @ActivityMethod annotation.\n\nCalling a method on this interface invokes an that implements this method. An invocation synchronously blocks until the completes, fails, or times out. Even if execution takes a few months, the code still sees it as a single synchronous invocation. It doesn't matter what happens to the processes that host the . The business logic code just sees a single method call.\n\npublic class FileProcessingWorkflowImpl implements FileProcessingWorkflow {\n\n    private final FileProcessingActivities activities;\n\n    public FileProcessingWorkflowImpl() {\n        this.activities = Workflow.newActivityStub(FileProcessingActivities.class);\n    }\n\n    @Override\n    public void processFile(Arguments args) {\n        String localName = null;\n        String processedName = null;\n        try {\n            localName = activities.download(args.getSourceBucketName(), args.getSourceFilename());\n            processedName = activities.processFile(localName);\n            activities.upload(args.getTargetBucketName(), args.getTargetFilename(), processedName);\n        } finally {\n            if (localName != null) { // File was downloaded.\n                activities.deleteLocalFile(localName);\n            }\n            if (processedName != null) { // File was processed.\n                activities.deleteLocalFile(processedName);\n            }\n        }\n    }\n    ...\n}\n\n\nIf different need different options, like timeouts or a , multiple client-side stubs can be created with different options.\n\npublic FileProcessingWorkflowImpl() {\n    ActivityOptions options1 = new ActivityOptions.Builder()\n             .setTaskList(\"taskList1\")\n             .build();\n    this.store1 = Workflow.newActivityStub(FileProcessingActivities.class, options1);\n\n    ActivityOptions options2 = new ActivityOptions.Builder()\n             .setTaskList(\"taskList2\")\n             .build();\n    this.store2 = Workflow.newActivityStub(FileProcessingActivities.class, options2);\n}\n\n\n\n# Calling Activities Asynchronously\n\nSometimes need to perform certain operations in parallel. The Async class static methods allow you to invoke any asynchronously. The calls return a Promise result immediately. Promise is similar to both Java Future and CompletionStage. The Promise get blocks until a result is available. It also exposes the thenApply and handle methods. See the Promise JavaDoc for technical details about differences with Future.\n\nTo convert a synchronous call:\n\nString localName = activities.download(sourceBucket, sourceFile);\n\n\nTo asynchronous style, the method reference is passed to Async.function or Async.procedure followed by arguments:\n\nPromise<String> localNamePromise = Async.function(activities::download, sourceBucket, sourceFile);\n\n\nThen to wait synchronously for the result:\n\nString localName = localNamePromise.get();\n\n\nHere is the above example rewritten to call download and upload in parallel on multiple files:\n\npublic void processFile(Arguments args) {\n    List<Promise<String>> localNamePromises = new ArrayList<>();\n    List<String> processedNames = null;\n    try {\n        // Download all files in parallel.\n        for (String sourceFilename : args.getSourceFilenames()) {\n            Promise<String> localName = Async.function(activities::download,\n                args.getSourceBucketName(), sourceFilename);\n            localNamePromises.add(localName);\n        }\n        // allOf converts a list of promises to a single promise that contains a list\n        // of each promise value.\n        Promise<List<String>> localNamesPromise = Promise.allOf(localNamePromises);\n\n        // All code until the next line wasn't blocking.\n        // The promise get is a blocking call.\n        List<String> localNames = localNamesPromise.get();\n        processedNames = activities.processFiles(localNames);\n\n        // Upload all results in parallel.\n        List<Promise<Void>> uploadedList = new ArrayList<>();\n        for (String processedName : processedNames) {\n            Promise<Void> uploaded = Async.procedure(activities::upload,\n                args.getTargetBucketName(), args.getTargetFilename(), processedName);\n            uploadedList.add(uploaded);\n        }\n        // Wait for all uploads to complete.\n        Promise<?> allUploaded = Promise.allOf(uploadedList);\n        allUploaded.get(); // blocks until all promises are ready.\n    } finally {\n        for (Promise<String> localNamePromise : localNamePromises) {\n            // Skip files that haven't completed downloading.\n            if (localNamePromise.isCompleted()) {\n                activities.deleteLocalFile(localNamePromise.get());\n            }\n        }\n        if (processedNames != null) {\n            for (String processedName : processedNames) {\n                activities.deleteLocalFile(processedName);\n            }\n        }\n    }\n}\n\n\n\n# Workflow Implementation Constraints\n\nCadence uses the Microsoft Azure Event Sourcing pattern to recover the state of a object including its threads and local variable values. In essence, every time a state has to be restored, its code is re-executed from the beginning. When replaying, side effects (such as invocations) are ignored because they are already recorded in the . When writing logic, the replay is not visible, so the code should be written since it executes only once. This design puts the following constraints on the implementation:\n\n * Do not use any mutable global variables because multiple instances of are executed in parallel.\n * Do not call any non-deterministic functions like non seeded random or UUID.randomUUID() directly from the code.\n\nAlways do the following in :\n\n * Don’t perform any IO or service calls as they are not usually deterministic. Use for this.\n * Only use Workflow.currentTimeMillis() to get the current time inside a .\n * Do not use native Java Thread or any other multi-threaded classes like ThreadPoolExecutor. Use Async.function or Async.procedure to execute code asynchronously.\n * Don't use any synchronization, locks, and other standard Java blocking concurrency-related classes besides those provided by the Workflow class. There is no need in explicit synchronization because multi-threaded code inside a is executed one thread at a time and under a global lock.\n    * Call WorkflowThread.sleep instead of Thread.sleep.\n    * Use Promise and CompletablePromise instead of Future and CompletableFuture.\n    * Use WorkflowQueue instead of BlockingQueue.\n\n * Use Workflow.getVersion when making any changes to the code. Without this, any deployment of updated code might break already open .\n * Don’t access configuration APIs directly from a because changes in the configuration might affect a path. Pass it as an argument to a function or use an to load it.\n\nmethod arguments and return values are serializable to a byte array using the provided DataConverter interface. The default implementation uses JSON serializer, but you can use any alternative serialization mechanism.\n\nThe values passed to through invocation parameters or returned through a result value are recorded in the execution history. The entire execution history is transferred from the Cadence service to with every that the logic needs to process. A large execution history can thus adversely impact the performance of your . Therefore, be mindful of the amount of data that you transfer via invocation parameters or return values. Otherwise, no additional limitations exist on implementations.",normalizedContent:"# implementing workflows\n\na implementation implements a interface. each time a new is started, a new instance of the implementation object is created. then, one of the methods (depending on which type has been started) annotated with @workflowmethod is invoked. as soon as this method returns, the is closed. while is open, it can receive calls to and methods. no additional calls to methods are allowed. the object is stateful, so and methods can communicate with the other parts of the through object fields.\n\n\n# calling activities\n\nworkflow.newactivitystub returns a client-side stub that implements an interface. it takes type and options as arguments. options are needed only if some of the required timeouts are not specified through the @activitymethod annotation.\n\ncalling a method on this interface invokes an that implements this method. an invocation synchronously blocks until the completes, fails, or times out. even if execution takes a few months, the code still sees it as a single synchronous invocation. it doesn't matter what happens to the processes that host the . the business logic code just sees a single method call.\n\npublic class fileprocessingworkflowimpl implements fileprocessingworkflow {\n\n    private final fileprocessingactivities activities;\n\n    public fileprocessingworkflowimpl() {\n        this.activities = workflow.newactivitystub(fileprocessingactivities.class);\n    }\n\n    @override\n    public void processfile(arguments args) {\n        string localname = null;\n        string processedname = null;\n        try {\n            localname = activities.download(args.getsourcebucketname(), args.getsourcefilename());\n            processedname = activities.processfile(localname);\n            activities.upload(args.gettargetbucketname(), args.gettargetfilename(), processedname);\n        } finally {\n            if (localname != null) { // file was downloaded.\n                activities.deletelocalfile(localname);\n            }\n            if (processedname != null) { // file was processed.\n                activities.deletelocalfile(processedname);\n            }\n        }\n    }\n    ...\n}\n\n\nif different need different options, like timeouts or a , multiple client-side stubs can be created with different options.\n\npublic fileprocessingworkflowimpl() {\n    activityoptions options1 = new activityoptions.builder()\n             .settasklist(\"tasklist1\")\n             .build();\n    this.store1 = workflow.newactivitystub(fileprocessingactivities.class, options1);\n\n    activityoptions options2 = new activityoptions.builder()\n             .settasklist(\"tasklist2\")\n             .build();\n    this.store2 = workflow.newactivitystub(fileprocessingactivities.class, options2);\n}\n\n\n\n# calling activities asynchronously\n\nsometimes need to perform certain operations in parallel. the async class static methods allow you to invoke any asynchronously. the calls return a promise result immediately. promise is similar to both java future and completionstage. the promise get blocks until a result is available. it also exposes the thenapply and handle methods. see the promise javadoc for technical details about differences with future.\n\nto convert a synchronous call:\n\nstring localname = activities.download(sourcebucket, sourcefile);\n\n\nto asynchronous style, the method reference is passed to async.function or async.procedure followed by arguments:\n\npromise<string> localnamepromise = async.function(activities::download, sourcebucket, sourcefile);\n\n\nthen to wait synchronously for the result:\n\nstring localname = localnamepromise.get();\n\n\nhere is the above example rewritten to call download and upload in parallel on multiple files:\n\npublic void processfile(arguments args) {\n    list<promise<string>> localnamepromises = new arraylist<>();\n    list<string> processednames = null;\n    try {\n        // download all files in parallel.\n        for (string sourcefilename : args.getsourcefilenames()) {\n            promise<string> localname = async.function(activities::download,\n                args.getsourcebucketname(), sourcefilename);\n            localnamepromises.add(localname);\n        }\n        // allof converts a list of promises to a single promise that contains a list\n        // of each promise value.\n        promise<list<string>> localnamespromise = promise.allof(localnamepromises);\n\n        // all code until the next line wasn't blocking.\n        // the promise get is a blocking call.\n        list<string> localnames = localnamespromise.get();\n        processednames = activities.processfiles(localnames);\n\n        // upload all results in parallel.\n        list<promise<void>> uploadedlist = new arraylist<>();\n        for (string processedname : processednames) {\n            promise<void> uploaded = async.procedure(activities::upload,\n                args.gettargetbucketname(), args.gettargetfilename(), processedname);\n            uploadedlist.add(uploaded);\n        }\n        // wait for all uploads to complete.\n        promise<?> alluploaded = promise.allof(uploadedlist);\n        alluploaded.get(); // blocks until all promises are ready.\n    } finally {\n        for (promise<string> localnamepromise : localnamepromises) {\n            // skip files that haven't completed downloading.\n            if (localnamepromise.iscompleted()) {\n                activities.deletelocalfile(localnamepromise.get());\n            }\n        }\n        if (processednames != null) {\n            for (string processedname : processednames) {\n                activities.deletelocalfile(processedname);\n            }\n        }\n    }\n}\n\n\n\n# workflow implementation constraints\n\ncadence uses the microsoft azure event sourcing pattern to recover the state of a object including its threads and local variable values. in essence, every time a state has to be restored, its code is re-executed from the beginning. when replaying, side effects (such as invocations) are ignored because they are already recorded in the . when writing logic, the replay is not visible, so the code should be written since it executes only once. this design puts the following constraints on the implementation:\n\n * do not use any mutable global variables because multiple instances of are executed in parallel.\n * do not call any non-deterministic functions like non seeded random or uuid.randomuuid() directly from the code.\n\nalways do the following in :\n\n * don’t perform any io or service calls as they are not usually deterministic. use for this.\n * only use workflow.currenttimemillis() to get the current time inside a .\n * do not use native java thread or any other multi-threaded classes like threadpoolexecutor. use async.function or async.procedure to execute code asynchronously.\n * don't use any synchronization, locks, and other standard java blocking concurrency-related classes besides those provided by the workflow class. there is no need in explicit synchronization because multi-threaded code inside a is executed one thread at a time and under a global lock.\n    * call workflowthread.sleep instead of thread.sleep.\n    * use promise and completablepromise instead of future and completablefuture.\n    * use workflowqueue instead of blockingqueue.\n\n * use workflow.getversion when making any changes to the code. without this, any deployment of updated code might break already open .\n * don’t access configuration apis directly from a because changes in the configuration might affect a path. pass it as an argument to a function or use an to load it.\n\nmethod arguments and return values are serializable to a byte array using the provided dataconverter interface. the default implementation uses json serializer, but you can use any alternative serialization mechanism.\n\nthe values passed to through invocation parameters or returned through a result value are recorded in the execution history. the entire execution history is transferred from the cadence service to with every that the logic needs to process. a large execution history can thus adversely impact the performance of your . therefore, be mindful of the amount of data that you transfer via invocation parameters or return values. otherwise, no additional limitations exist on implementations.",charsets:{}},{title:"Starting workflows",frontmatter:{layout:"default",title:"Starting workflows",permalink:"/docs/java-client/starting-workflow-executions",readingShow:"top"},regularPath:"/docs/04-java-client/04-starting-workflow-executions.html",relativePath:"docs/04-java-client/04-starting-workflow-executions.md",key:"v-7106a8e2",path:"/docs/java-client/starting-workflow-executions/",headers:[{level:2,title:"Creating a WorkflowClient",slug:"creating-a-workflowclient",normalizedTitle:"creating a workflowclient",charIndex:35},{level:2,title:"Executing Workflows",slug:"executing-workflows",normalizedTitle:"executing workflows",charIndex:2593}],codeSwitcherOptions:{},headersStr:"Creating a WorkflowClient Executing Workflows",content:'# Starting workflow executions\n\n\n# Creating a WorkflowClient\n\nA interface that executes a requires initializing a WorkflowClient instance, creating a client side stub to the , and then calling a method annotated with @WorkflowMethod.\n\nA simple WorkflowClient instance that utilises the communication protocol can be initialised as follows:\n\nWorkflowClient workflowClient =\n        WorkflowClient.newInstance(\n            new WorkflowServiceTChannel(\n                ClientOptions.newBuilder().setHost(cadenceServiceHost).setPort(cadenceServicePort).build()),\n            WorkflowClientOptions.newBuilder().setDomain(domain).build());\n// Create a workflow stub.\nFileProcessingWorkflow workflow = workflowClient.newWorkflowStub(FileProcessingWorkflow.class);\n\n\nAlternatively, if wishing to create a WorkflowClient that uses TLS, we can initialise a client that uses the gRPC communication protocol instead. First, additions will need to be made to the project\'s pom.xml:\n\n<dependency>\n    <groupId>io.grpc</groupId>\n    <artifactId>grpc-netty</artifactId>\n    <version>LATEST.RELEASE.VERSION</version>\n</dependency>\n<dependency>\n    <groupId>io.netty</groupId>\n    <artifactId>netty-all</artifactId>\n    <version>LATEST.RELEASE.VERSION</version>\n</dependency>\n\n\nThen, use the following client implementation; provide a TLS certificate with which the cluster has also been configured (replace "/path/to/cert/file" in the sample):\n\nWorkflowClient workflowClient =\n        WorkflowClient.newInstance(\n            new Thrift2ProtoAdapter(\n                IGrpcServiceStubs.newInstance(\n                    ClientOptions.newBuilder().setGRPCChannel(\n                        NettyChannelBuilder.forAddress(cadenceServiceHost, cadenceServicePort)\n                            .useTransportSecurity()\n                            .defaultLoadBalancingPolicy("round_robin")\n                            .sslContext(GrpcSslContexts.forClient()\n                                .trustManager(new File("/path/to/cert/file"))\n                                .build()).build()).build())),\n            WorkflowClientOptions.newBuilder().setDomain(domain).build());\n// Create a workflow stub.\nFileProcessingWorkflow workflow = workflowClient.newWorkflowStub(FileProcessingWorkflow.class);\n\n\nOr, if you are using version prior to 3.0.0, a WorkflowClient can be created as follows:\n\nWorkflowClient workflowClient = WorkflowClient.newClient(cadenceServiceHost, cadenceServicePort, domain);\n// Create a workflow stub.\nFileProcessingWorkflow workflow = workflowClient.newWorkflowStub(FileProcessingWorkflow.class);\n\n\n\n# Executing Workflows\n\nThere are two ways to start asynchronously and synchronously. Asynchronous start initiates a and immediately returns to the caller. This is the most common way to start in production code. Synchronous invocation starts a and then waits for its completion. If the process that started the crashes or stops waiting, the continues executing. Because are potentially long running, and crashes of clients happen, this is not very commonly found in production use.\n\nAsynchronous start:\n\n// Returns as soon as the workflow starts.\nWorkflowExecution workflowExecution = WorkflowClient.start(workflow::processFile, workflowArgs);\n\nSystem.out.println("Started process file workflow with workflowId=\\"" + workflowExecution.getWorkflowId()\n                    + "\\" and runId=\\"" + workflowExecution.getRunId() + "\\"");\n\n\nSynchronous start:\n\n// Start a workflow and then wait for a result.\n// Note that if the waiting process is killed, the workflow will continue execution.\nString result = workflow.processFile(workflowArgs);\n\n\nIf you need to wait for a completion after an asynchronous start, the most straightforward way is to call the blocking version again. If WorkflowOptions.WorkflowIdReusePolicy is not AllowDuplicate, then instead of throwing DuplicateWorkflowException, it reconnects to an existing and waits for its completion. The following example shows how to do this from a different process than the one that started the . All this process needs is a WorkflowID.\n\nWorkflowExecution execution = new WorkflowExecution().setWorkflowId(workflowId);\nFileProcessingWorkflow workflow = workflowClient.newWorkflowStub(execution);\n// Returns result potentially waiting for workflow to complete.\nString result = workflow.processFile(workflowArgs);\n',normalizedContent:'# starting workflow executions\n\n\n# creating a workflowclient\n\na interface that executes a requires initializing a workflowclient instance, creating a client side stub to the , and then calling a method annotated with @workflowmethod.\n\na simple workflowclient instance that utilises the communication protocol can be initialised as follows:\n\nworkflowclient workflowclient =\n        workflowclient.newinstance(\n            new workflowservicetchannel(\n                clientoptions.newbuilder().sethost(cadenceservicehost).setport(cadenceserviceport).build()),\n            workflowclientoptions.newbuilder().setdomain(domain).build());\n// create a workflow stub.\nfileprocessingworkflow workflow = workflowclient.newworkflowstub(fileprocessingworkflow.class);\n\n\nalternatively, if wishing to create a workflowclient that uses tls, we can initialise a client that uses the grpc communication protocol instead. first, additions will need to be made to the project\'s pom.xml:\n\n<dependency>\n    <groupid>io.grpc</groupid>\n    <artifactid>grpc-netty</artifactid>\n    <version>latest.release.version</version>\n</dependency>\n<dependency>\n    <groupid>io.netty</groupid>\n    <artifactid>netty-all</artifactid>\n    <version>latest.release.version</version>\n</dependency>\n\n\nthen, use the following client implementation; provide a tls certificate with which the cluster has also been configured (replace "/path/to/cert/file" in the sample):\n\nworkflowclient workflowclient =\n        workflowclient.newinstance(\n            new thrift2protoadapter(\n                igrpcservicestubs.newinstance(\n                    clientoptions.newbuilder().setgrpcchannel(\n                        nettychannelbuilder.foraddress(cadenceservicehost, cadenceserviceport)\n                            .usetransportsecurity()\n                            .defaultloadbalancingpolicy("round_robin")\n                            .sslcontext(grpcsslcontexts.forclient()\n                                .trustmanager(new file("/path/to/cert/file"))\n                                .build()).build()).build())),\n            workflowclientoptions.newbuilder().setdomain(domain).build());\n// create a workflow stub.\nfileprocessingworkflow workflow = workflowclient.newworkflowstub(fileprocessingworkflow.class);\n\n\nor, if you are using version prior to 3.0.0, a workflowclient can be created as follows:\n\nworkflowclient workflowclient = workflowclient.newclient(cadenceservicehost, cadenceserviceport, domain);\n// create a workflow stub.\nfileprocessingworkflow workflow = workflowclient.newworkflowstub(fileprocessingworkflow.class);\n\n\n\n# executing workflows\n\nthere are two ways to start asynchronously and synchronously. asynchronous start initiates a and immediately returns to the caller. this is the most common way to start in production code. synchronous invocation starts a and then waits for its completion. if the process that started the crashes or stops waiting, the continues executing. because are potentially long running, and crashes of clients happen, this is not very commonly found in production use.\n\nasynchronous start:\n\n// returns as soon as the workflow starts.\nworkflowexecution workflowexecution = workflowclient.start(workflow::processfile, workflowargs);\n\nsystem.out.println("started process file workflow with workflowid=\\"" + workflowexecution.getworkflowid()\n                    + "\\" and runid=\\"" + workflowexecution.getrunid() + "\\"");\n\n\nsynchronous start:\n\n// start a workflow and then wait for a result.\n// note that if the waiting process is killed, the workflow will continue execution.\nstring result = workflow.processfile(workflowargs);\n\n\nif you need to wait for a completion after an asynchronous start, the most straightforward way is to call the blocking version again. if workflowoptions.workflowidreusepolicy is not allowduplicate, then instead of throwing duplicateworkflowexception, it reconnects to an existing and waits for its completion. the following example shows how to do this from a different process than the one that started the . all this process needs is a workflowid.\n\nworkflowexecution execution = new workflowexecution().setworkflowid(workflowid);\nfileprocessingworkflow workflow = workflowclient.newworkflowstub(execution);\n// returns result potentially waiting for workflow to complete.\nstring result = workflow.processfile(workflowargs);\n',charsets:{}},{title:"Implementing activities",frontmatter:{layout:"default",title:"Implementing activities",permalink:"/docs/java-client/implementing-activities",readingShow:"top"},regularPath:"/docs/04-java-client/06-implementing-activities.html",relativePath:"docs/04-java-client/06-implementing-activities.md",key:"v-b64a802c",path:"/docs/java-client/implementing-activities/",headers:[{level:2,title:"Accessing Activity Info",slug:"accessing-activity-info",normalizedTitle:"accessing activity info",charIndex:1518},{level:2,title:"Asynchronous Activity Completion",slug:"asynchronous-activity-completion",normalizedTitle:"asynchronous activity completion",charIndex:2514},{level:2,title:"Activity Heart Beating",slug:"activity-heart-beating",normalizedTitle:"activity heart beating",charIndex:3930}],codeSwitcherOptions:{},headersStr:"Accessing Activity Info Asynchronous Activity Completion Activity Heart Beating",content:'# Implementing activities\n\nimplementation is an implementation of an interface. A single instance of the implementation is shared across multiple simultaneous invocations. Therefore, the implementation code must be thread safe.\n\nThe values passed to through invocation parameters or returned through a result value are recorded in the execution history. The entire execution history is transferred from the Cadence service to when a state needs to recover. A large execution history can thus adversely impact the performance of your . Therefore, be mindful of the amount of data you transfer via invocation parameters or return values. Otherwise, no additional limitations exist on implementations.\n\npublic class FileProcessingActivitiesImpl implements FileProcessingActivities {\n\n    private final AmazonS3 s3Client;\n\n    private final String localDirectory;\n\n    void upload(String bucketName, String localName, String targetName) {\n        File f = new File(localName);\n        s3Client.putObject(bucket, remoteName, f);\n    }\n\n    String download(String bucketName, String remoteName, String localName) {\n        // Implementation omitted for brevity.\n        return downloadFileFromS3(bucketName, remoteName, localDirectory + localName);\n    }\n\n    String processFile(String localName) {\n        // Implementation omitted for brevity.\n        return compressFile(localName);\n    }\n\n    void deleteLocalFile(String fileName) {\n        File f = new File(localDirectory + fileName);\n        f.delete();\n    }\n}\n\n\n\n# Accessing Activity Info\n\nThe Activity class provides static getters to access information about the that invoked it. Note that this information is stored in a thread local variable. Therefore, calls to accessors succeed only in the thread that invoked the function.\n\npublic class FileProcessingActivitiesImpl implements FileProcessingActivities {\n\n    @Override\n    public String download(String bucketName, String remoteName, String localName) {\n        log.info("domain=" +  Activity.getDomain());\n        WorkflowExecution execution = Activity.getWorkflowExecution();\n        log.info("workflowId=" + execution.getWorkflowId());\n        log.info("runId=" + execution.getRunId());\n        ActivityTask activityTask = Activity.getTask();\n        log.info("activityId=" + activityTask.getActivityId());\n        log.info("activityTimeout=" + activityTask.getStartToCloseTimeoutSeconds());\n        return downloadFileFromS3(bucketName, remoteName, localDirectory + localName);\n    }\n    ...\n}\n\n\n\n# Asynchronous Activity Completion\n\nSometimes an lifecycle goes beyond a synchronous method invocation. For example, a request can be put in a queue and later a reply comes and is picked up by a different process. The whole request-reply interaction can be modeled as a single Cadence .\n\nTo indicate that an should not be completed upon its method return, call Activity.doNotCompleteOnReturn() from the original thread. Then later, when replies come, complete the using ActivityCompletionClient. To correlate invocation with completion, use either TaskToken or and IDs.\n\npublic class FileProcessingActivitiesImpl implements FileProcessingActivities {\n\n    public String download(String bucketName, String remoteName, String localName) {\n        byte[] taskToken = Activity.getTaskToken(); // Used to correlate reply.\n        asyncDownloadFileFromS3(taskToken, bucketName, remoteName, localDirectory + localName);\n        Activity.doNotCompleteOnReturn();\n        return "ignored"; // Return value is ignored when doNotCompleteOnReturn was called.\n    }\n    ...\n}\n\n\nWhen the download is complete, the download service potentially calls back from a different process:\n\npublic <R> void completeActivity(byte[] taskToken, R result) {\n    completionClient.complete(taskToken, result);\n}\n\npublic void failActivity(byte[] taskToken, Exception failure) {\n    completionClient.completeExceptionally(taskToken, failure);\n}\n\n\n\n# Activity Heart Beating\n\nSome are long running. To react to a crash quickly, use a heartbeat mechanism. The Activity.heartbeat function lets the Cadence service know that the is still alive. You can piggyback details on an heartbeat. If an times out, the last value of details is included in the ActivityTimeoutException delivered to a . Then the can pass the details to the next invocation. This acts as a periodic checkpoint mechanism for the progress of an .\n\npublic class FileProcessingActivitiesImpl implements FileProcessingActivities {\n\n    @Override\n    public String download(String bucketName, String remoteName, String localName) {\n        InputStream inputStream = openInputStream(file);\n        try {\n            byte[] bytes = new byte[MAX_BUFFER_SIZE];\n            while ((read = inputStream.read(bytes)) != -1) {\n                totalRead += read;\n                f.write(bytes, 0, read);\n                /*\n                 * Let the service know about the download progress.\n                 */\n                Activity.heartbeat(totalRead);\n            }\n        } finally {\n            inputStream.close();\n        }\n    }\n    ...\n}\n',normalizedContent:'# implementing activities\n\nimplementation is an implementation of an interface. a single instance of the implementation is shared across multiple simultaneous invocations. therefore, the implementation code must be thread safe.\n\nthe values passed to through invocation parameters or returned through a result value are recorded in the execution history. the entire execution history is transferred from the cadence service to when a state needs to recover. a large execution history can thus adversely impact the performance of your . therefore, be mindful of the amount of data you transfer via invocation parameters or return values. otherwise, no additional limitations exist on implementations.\n\npublic class fileprocessingactivitiesimpl implements fileprocessingactivities {\n\n    private final amazons3 s3client;\n\n    private final string localdirectory;\n\n    void upload(string bucketname, string localname, string targetname) {\n        file f = new file(localname);\n        s3client.putobject(bucket, remotename, f);\n    }\n\n    string download(string bucketname, string remotename, string localname) {\n        // implementation omitted for brevity.\n        return downloadfilefroms3(bucketname, remotename, localdirectory + localname);\n    }\n\n    string processfile(string localname) {\n        // implementation omitted for brevity.\n        return compressfile(localname);\n    }\n\n    void deletelocalfile(string filename) {\n        file f = new file(localdirectory + filename);\n        f.delete();\n    }\n}\n\n\n\n# accessing activity info\n\nthe activity class provides static getters to access information about the that invoked it. note that this information is stored in a thread local variable. therefore, calls to accessors succeed only in the thread that invoked the function.\n\npublic class fileprocessingactivitiesimpl implements fileprocessingactivities {\n\n    @override\n    public string download(string bucketname, string remotename, string localname) {\n        log.info("domain=" +  activity.getdomain());\n        workflowexecution execution = activity.getworkflowexecution();\n        log.info("workflowid=" + execution.getworkflowid());\n        log.info("runid=" + execution.getrunid());\n        activitytask activitytask = activity.gettask();\n        log.info("activityid=" + activitytask.getactivityid());\n        log.info("activitytimeout=" + activitytask.getstarttoclosetimeoutseconds());\n        return downloadfilefroms3(bucketname, remotename, localdirectory + localname);\n    }\n    ...\n}\n\n\n\n# asynchronous activity completion\n\nsometimes an lifecycle goes beyond a synchronous method invocation. for example, a request can be put in a queue and later a reply comes and is picked up by a different process. the whole request-reply interaction can be modeled as a single cadence .\n\nto indicate that an should not be completed upon its method return, call activity.donotcompleteonreturn() from the original thread. then later, when replies come, complete the using activitycompletionclient. to correlate invocation with completion, use either tasktoken or and ids.\n\npublic class fileprocessingactivitiesimpl implements fileprocessingactivities {\n\n    public string download(string bucketname, string remotename, string localname) {\n        byte[] tasktoken = activity.gettasktoken(); // used to correlate reply.\n        asyncdownloadfilefroms3(tasktoken, bucketname, remotename, localdirectory + localname);\n        activity.donotcompleteonreturn();\n        return "ignored"; // return value is ignored when donotcompleteonreturn was called.\n    }\n    ...\n}\n\n\nwhen the download is complete, the download service potentially calls back from a different process:\n\npublic <r> void completeactivity(byte[] tasktoken, r result) {\n    completionclient.complete(tasktoken, result);\n}\n\npublic void failactivity(byte[] tasktoken, exception failure) {\n    completionclient.completeexceptionally(tasktoken, failure);\n}\n\n\n\n# activity heart beating\n\nsome are long running. to react to a crash quickly, use a heartbeat mechanism. the activity.heartbeat function lets the cadence service know that the is still alive. you can piggyback details on an heartbeat. if an times out, the last value of details is included in the activitytimeoutexception delivered to a . then the can pass the details to the next invocation. this acts as a periodic checkpoint mechanism for the progress of an .\n\npublic class fileprocessingactivitiesimpl implements fileprocessingactivities {\n\n    @override\n    public string download(string bucketname, string remotename, string localname) {\n        inputstream inputstream = openinputstream(file);\n        try {\n            byte[] bytes = new byte[max_buffer_size];\n            while ((read = inputstream.read(bytes)) != -1) {\n                totalread += read;\n                f.write(bytes, 0, read);\n                /*\n                 * let the service know about the download progress.\n                 */\n                activity.heartbeat(totalread);\n            }\n        } finally {\n            inputstream.close();\n        }\n    }\n    ...\n}\n',charsets:{}},{title:"Versioning",frontmatter:{layout:"default",title:"Versioning",permalink:"/docs/java-client/versioning",readingShow:"top"},regularPath:"/docs/04-java-client/07-versioning.html",relativePath:"docs/04-java-client/07-versioning.md",key:"v-3c541bc2",path:"/docs/java-client/versioning/",codeSwitcherOptions:{},headersStr:null,content:'# Versioning\n\nAs outlined in the Workflow Implementation Constraints section, code has to be deterministic by taking the same code path when replaying history . Any code change that affects the order in which are generated breaks this assumption. The solution that allows updating code of already running is to keep both the old and new code. When replaying, use the code version that the were generated with and when executing a new code path, always take the new code.\n\nUse the Workflow.getVersion function to return a version of the code that should be executed and then use the returned value to pick a correct branch. Let\'s look at an example.\n\npublic void processFile(Arguments args) {\n    String localName = null;\n    String processedName = null;\n    try {\n        localName = activities.download(args.getSourceBucketName(), args.getSourceFilename());\n        processedName = activities.processFile(localName);\n        activities.upload(args.getTargetBucketName(), args.getTargetFilename(), processedName);\n    } finally {\n        if (localName != null) { // File was downloaded.\n            activities.deleteLocalFile(localName);\n        }\n        if (processedName != null) { // File was processed.\n            activities.deleteLocalFile(processedName);\n        }\n    }\n}\n\n\nNow we decide to calculate the processed file checksum and pass it to upload. The correct way to implement this change is:\n\npublic void processFile(Arguments args) {\n    String localName = null;\n    String processedName = null;\n    try {\n        localName = activities.download(args.getSourceBucketName(), args.getSourceFilename());\n        processedName = activities.processFile(localName);\n        int version = Workflow.getVersion("checksumAdded", Workflow.DEFAULT_VERSION, 1);\n        if (version == Workflow.DEFAULT_VERSION) {\n            activities.upload(args.getTargetBucketName(), args.getTargetFilename(), processedName);\n        } else {\n            long checksum = activities.calculateChecksum(processedName);\n            activities.uploadWithChecksum(\n                args.getTargetBucketName(), args.getTargetFilename(), processedName, checksum);\n        }\n    } finally {\n        if (localName != null) { // File was downloaded.\n            activities.deleteLocalFile(localName);\n        }\n        if (processedName != null) { // File was processed.\n            activities.deleteLocalFile(processedName);\n        }\n    }\n}\n\n\nLater, when all that use the old version are completed, the old branch can be removed.\n\npublic void processFile(Arguments args) {\n    String localName = null;\n    String processedName = null;\n    try {\n        localName = activities.download(args.getSourceBucketName(), args.getSourceFilename());\n        processedName = activities.processFile(localName);\n        // getVersion call is left here to ensure that any attempt to replay history\n        // for a different version fails. It can be removed later when there is no possibility\n        // of this happening.\n        Workflow.getVersion("checksumAdded", 1, 1);\n        long checksum = activities.calculateChecksum(processedName);\n        activities.uploadWithChecksum(\n            args.getTargetBucketName(), args.getTargetFilename(), processedName, checksum);\n    } finally {\n        if (localName != null) { // File was downloaded.\n            activities.deleteLocalFile(localName);\n        }\n        if (processedName != null) { // File was processed.\n            activities.deleteLocalFile(processedName);\n        }\n    }\n}\n\n\nThe ID that is passed to the getVersion call identifies the change. Each change is expected to have its own ID. But if a change spawns multiple places in the code and the new code should be either executed in all of them or in none of them, then they have to share the ID.',normalizedContent:'# versioning\n\nas outlined in the workflow implementation constraints section, code has to be deterministic by taking the same code path when replaying history . any code change that affects the order in which are generated breaks this assumption. the solution that allows updating code of already running is to keep both the old and new code. when replaying, use the code version that the were generated with and when executing a new code path, always take the new code.\n\nuse the workflow.getversion function to return a version of the code that should be executed and then use the returned value to pick a correct branch. let\'s look at an example.\n\npublic void processfile(arguments args) {\n    string localname = null;\n    string processedname = null;\n    try {\n        localname = activities.download(args.getsourcebucketname(), args.getsourcefilename());\n        processedname = activities.processfile(localname);\n        activities.upload(args.gettargetbucketname(), args.gettargetfilename(), processedname);\n    } finally {\n        if (localname != null) { // file was downloaded.\n            activities.deletelocalfile(localname);\n        }\n        if (processedname != null) { // file was processed.\n            activities.deletelocalfile(processedname);\n        }\n    }\n}\n\n\nnow we decide to calculate the processed file checksum and pass it to upload. the correct way to implement this change is:\n\npublic void processfile(arguments args) {\n    string localname = null;\n    string processedname = null;\n    try {\n        localname = activities.download(args.getsourcebucketname(), args.getsourcefilename());\n        processedname = activities.processfile(localname);\n        int version = workflow.getversion("checksumadded", workflow.default_version, 1);\n        if (version == workflow.default_version) {\n            activities.upload(args.gettargetbucketname(), args.gettargetfilename(), processedname);\n        } else {\n            long checksum = activities.calculatechecksum(processedname);\n            activities.uploadwithchecksum(\n                args.gettargetbucketname(), args.gettargetfilename(), processedname, checksum);\n        }\n    } finally {\n        if (localname != null) { // file was downloaded.\n            activities.deletelocalfile(localname);\n        }\n        if (processedname != null) { // file was processed.\n            activities.deletelocalfile(processedname);\n        }\n    }\n}\n\n\nlater, when all that use the old version are completed, the old branch can be removed.\n\npublic void processfile(arguments args) {\n    string localname = null;\n    string processedname = null;\n    try {\n        localname = activities.download(args.getsourcebucketname(), args.getsourcefilename());\n        processedname = activities.processfile(localname);\n        // getversion call is left here to ensure that any attempt to replay history\n        // for a different version fails. it can be removed later when there is no possibility\n        // of this happening.\n        workflow.getversion("checksumadded", 1, 1);\n        long checksum = activities.calculatechecksum(processedname);\n        activities.uploadwithchecksum(\n            args.gettargetbucketname(), args.gettargetfilename(), processedname, checksum);\n    } finally {\n        if (localname != null) { // file was downloaded.\n            activities.deletelocalfile(localname);\n        }\n        if (processedname != null) { // file was processed.\n            activities.deletelocalfile(processedname);\n        }\n    }\n}\n\n\nthe id that is passed to the getversion call identifies the change. each change is expected to have its own id. but if a change spawns multiple places in the code and the new code should be either executed in all of them or in none of them, then they have to share the id.',charsets:{}},{title:"Distributed CRON",frontmatter:{layout:"default",title:"Distributed CRON",permalink:"/docs/java-client/distributed-cron",readingShow:"top"},regularPath:"/docs/04-java-client/08-distributed-cron.html",relativePath:"docs/04-java-client/08-distributed-cron.md",key:"v-423a333c",path:"/docs/java-client/distributed-cron/",headers:[{level:2,title:"Convert an existing cron workflow",slug:"convert-an-existing-cron-workflow",normalizedTitle:"convert an existing cron workflow",charIndex:2157},{level:2,title:"Retrieve last successful result",slug:"retrieve-last-successful-result",normalizedTitle:"retrieve last successful result",charIndex:2623}],codeSwitcherOptions:{},headersStr:"Convert an existing cron workflow Retrieve last successful result",content:'# Distributed CRON\n\nIt is relatively straightforward to turn any Cadence into a Cron . All you need is to supply a cron schedule when starting the using the CronSchedule parameter of StartWorkflowOptions.\n\nYou can also start a using the Cadence with an optional cron schedule using the --cron argument.\n\nFor with CronSchedule:\n\n * CronSchedule is based on UTC time. For example cron schedule "15 8 * * *" will run daily at 8:15am UTC. Another example "*/2 * * * 5-6" will schedule a workflow every two minutes on fridays and saturdays.\n * If a failed and a RetryPolicy is supplied to the StartWorkflowOptions as well, the will retry based on the RetryPolicy. While the is retrying, the server will not schedule the next cron run.\n * Cadence server only schedules the next cron run after the current run is completed. If the next schedule is due while a is running (or retrying), then it will skip that schedule.\n * Cron will not stop until they are terminated or cancelled.\n\nCadence supports the standard cron spec:\n\n// CronSchedule - Optional cron schedule for workflow. If a cron schedule is specified, the workflow will run\n// as a cron based on the schedule. The scheduling will be based on UTC time. The schedule for the next run only happens\n// after the current run is completed/failed/timeout. If a RetryPolicy is also supplied, and the workflow failed\n// or timed out, the workflow will be retried based on the retry policy. While the workflow is retrying, it won\'t\n// schedule its next run. If the next schedule is due while the workflow is running (or retrying), then it will skip that\n// schedule. Cron workflow will not stop until it is terminated or cancelled (by returning cadence.CanceledError).\n// The cron spec is as follows:\n// ┌───────────── minute (0 - 59)\n// │ ┌───────────── hour (0 - 23)\n// │ │ ┌───────────── day of the month (1 - 31)\n// │ │ │ ┌───────────── month (1 - 12)\n// │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)\n// │ │ │ │ │\n// │ │ │ │ │\n// * * * * *\nCronSchedule string\n\n\nCadence also supports more advanced cron expressions.\n\nThe crontab guru site is useful for testing your cron expressions.\n\n\n# Convert an existing cron workflow\n\nBefore CronSchedule was available, the previous approach to implementing cron was to use a delay timer as the last step and then return ContinueAsNew. One problem with that implementation is that if the fails or times out, the cron would stop.\n\nTo convert those to make use of Cadence CronSchedule, all you need is to remove the delay timer and return without using ContinueAsNew. Then start the with the desired CronSchedule.\n\n\n# Retrieve last successful result\n\nSometimes it is useful to obtain the progress of previous successful runs. This is supported by two new APIs in the client library: HasLastCompletionResult and GetLastCompletionResult. Below is an example of how to use this in Java:\n\npublic String cronWorkflow() {\n    String lastProcessedFileName = Workflow.getLastCompletionResult(String.class);\n\n    // Process work starting from the lastProcessedFileName.\n    // Business logic implementation goes here.\n    // Updates lastProcessedFileName to the new value.\n\n    return lastProcessedFileName;\n}\n\n\nNote that this works even if one of the cron schedule runs failed. The next schedule will still get the last successful result if it ever successfully completed at least once. For example, for a daily cron , if the first day run succeeds and the second day fails, then the third day run will still get the result from first day\'s run using these APIs.',normalizedContent:'# distributed cron\n\nit is relatively straightforward to turn any cadence into a cron . all you need is to supply a cron schedule when starting the using the cronschedule parameter of startworkflowoptions.\n\nyou can also start a using the cadence with an optional cron schedule using the --cron argument.\n\nfor with cronschedule:\n\n * cronschedule is based on utc time. for example cron schedule "15 8 * * *" will run daily at 8:15am utc. another example "*/2 * * * 5-6" will schedule a workflow every two minutes on fridays and saturdays.\n * if a failed and a retrypolicy is supplied to the startworkflowoptions as well, the will retry based on the retrypolicy. while the is retrying, the server will not schedule the next cron run.\n * cadence server only schedules the next cron run after the current run is completed. if the next schedule is due while a is running (or retrying), then it will skip that schedule.\n * cron will not stop until they are terminated or cancelled.\n\ncadence supports the standard cron spec:\n\n// cronschedule - optional cron schedule for workflow. if a cron schedule is specified, the workflow will run\n// as a cron based on the schedule. the scheduling will be based on utc time. the schedule for the next run only happens\n// after the current run is completed/failed/timeout. if a retrypolicy is also supplied, and the workflow failed\n// or timed out, the workflow will be retried based on the retry policy. while the workflow is retrying, it won\'t\n// schedule its next run. if the next schedule is due while the workflow is running (or retrying), then it will skip that\n// schedule. cron workflow will not stop until it is terminated or cancelled (by returning cadence.cancelederror).\n// the cron spec is as follows:\n// ┌───────────── minute (0 - 59)\n// │ ┌───────────── hour (0 - 23)\n// │ │ ┌───────────── day of the month (1 - 31)\n// │ │ │ ┌───────────── month (1 - 12)\n// │ │ │ │ ┌───────────── day of the week (0 - 6) (sunday to saturday)\n// │ │ │ │ │\n// │ │ │ │ │\n// * * * * *\ncronschedule string\n\n\ncadence also supports more advanced cron expressions.\n\nthe crontab guru site is useful for testing your cron expressions.\n\n\n# convert an existing cron workflow\n\nbefore cronschedule was available, the previous approach to implementing cron was to use a delay timer as the last step and then return continueasnew. one problem with that implementation is that if the fails or times out, the cron would stop.\n\nto convert those to make use of cadence cronschedule, all you need is to remove the delay timer and return without using continueasnew. then start the with the desired cronschedule.\n\n\n# retrieve last successful result\n\nsometimes it is useful to obtain the progress of previous successful runs. this is supported by two new apis in the client library: haslastcompletionresult and getlastcompletionresult. below is an example of how to use this in java:\n\npublic string cronworkflow() {\n    string lastprocessedfilename = workflow.getlastcompletionresult(string.class);\n\n    // process work starting from the lastprocessedfilename.\n    // business logic implementation goes here.\n    // updates lastprocessedfilename to the new value.\n\n    return lastprocessedfilename;\n}\n\n\nnote that this works even if one of the cron schedule runs failed. the next schedule will still get the last successful result if it ever successfully completed at least once. for example, for a daily cron , if the first day run succeeds and the second day fails, then the third day run will still get the result from first day\'s run using these apis.',charsets:{}},{title:"Activity interface",frontmatter:{layout:"default",title:"Activity interface",permalink:"/docs/java-client/activity-interface",readingShow:"top"},regularPath:"/docs/04-java-client/05-activity-interface.html",relativePath:"docs/04-java-client/05-activity-interface.md",key:"v-4af1f23c",path:"/docs/java-client/activity-interface/",codeSwitcherOptions:{},headersStr:null,content:"# Activity interface\n\nAn is a manifestation of a particular in the business logic.\n\nare defined as methods of a plain Java interface. Each method defines a single type. A single can use more than one interface and call more than one method from the same interface. The only requirement is that method arguments and return values are serializable to a byte array using the provided DataConverter interface. The default implementation uses a JSON serializer, but an alternative implementation can be easily configured.\n\nFollowing is an example of an interface that defines four activities:\n\npublic interface FileProcessingActivities {\n\n    void upload(String bucketName, String localName, String targetName);\n\n    String download(String bucketName, String remoteName);\n\n    @ActivityMethod(scheduleToCloseTimeoutSeconds = 2)\n    String processFile(String localName);\n\n    void deleteLocalFile(String fileName);\n}\n\n\n\nWe recommend to use a single value type argument for methods. In this way, adding new arguments as fields to the value type is a backwards-compatible change.\n\nAn optional @ActivityMethod annotation can be used to specify options like timeouts or a . Required options that are not specified through the annotation must be specified at runtime.",normalizedContent:"# activity interface\n\nan is a manifestation of a particular in the business logic.\n\nare defined as methods of a plain java interface. each method defines a single type. a single can use more than one interface and call more than one method from the same interface. the only requirement is that method arguments and return values are serializable to a byte array using the provided dataconverter interface. the default implementation uses a json serializer, but an alternative implementation can be easily configured.\n\nfollowing is an example of an interface that defines four activities:\n\npublic interface fileprocessingactivities {\n\n    void upload(string bucketname, string localname, string targetname);\n\n    string download(string bucketname, string remotename);\n\n    @activitymethod(scheduletoclosetimeoutseconds = 2)\n    string processfile(string localname);\n\n    void deletelocalfile(string filename);\n}\n\n\n\nwe recommend to use a single value type argument for methods. in this way, adding new arguments as fields to the value type is a backwards-compatible change.\n\nan optional @activitymethod annotation can be used to specify options like timeouts or a . required options that are not specified through the annotation must be specified at runtime.",charsets:{}},{title:"Signals",frontmatter:{layout:"default",title:"Signals",permalink:"/docs/java-client/signals",readingShow:"top"},regularPath:"/docs/04-java-client/10-signals.html",relativePath:"docs/04-java-client/10-signals.md",key:"v-65cef250",path:"/docs/java-client/signals/",headers:[{level:2,title:"Implement Signal Handler in Workflow",slug:"implement-signal-handler-in-workflow",normalizedTitle:"implement signal handler in workflow",charIndex:1012},{level:2,title:"Signal From Command Line",slug:"signal-from-command-line",normalizedTitle:"signal from command line",charIndex:2494},{level:2,title:"SignalWithStart From Command Line",slug:"signalwithstart-from-command-line",normalizedTitle:"signalwithstart from command line",charIndex:6183},{level:2,title:"Signal from user/application code",slug:"signal-from-user-application-code",normalizedTitle:"signal from user/application code",charIndex:6851}],codeSwitcherOptions:{},headersStr:"Implement Signal Handler in Workflow Signal From Command Line SignalWithStart From Command Line Signal from user/application code",content:'# Signals\n\nprovide a mechanism to send data directly to a running . Previously, you had two options for passing data to the implementation:\n\n * Via start parameters\n * As return values from\n\nWith start parameters, we could only pass in values before began.\n\nReturn values from allowed us to pass information to a running , but this approach comes with its own complications. One major drawback is reliance on polling. This means that the data needs to be stored in a third-party location until it\'s ready to be picked up by the . Further, the lifecycle of this requires management, and the requires manual restart if it fails before acquiring the data.\n\n, on the other hand, provide a fully asynchronous and durable mechanism for providing data to a running . When a is received for a running , Cadence persists the and the payload in the history. The can then process the at any time afterwards without the risk of losing the information. The also has the option to stop execution by blocking on a channel.\n\n\n# Implement Signal Handler in Workflow\n\nSee the below example from sample.\n\npublic interface HelloWorld {\n    @WorkflowMethod\n    void sayHello(String name);\n\n    @SignalMethod\n    void updateGreeting(String greeting);\n}\n\npublic static class HelloWorldImpl implements HelloWorld {\n\n    private String greeting = "Hello";\n\n    @Override\n    public void sayHello(String name) {\n        int count = 0;\n        while (!"Bye".equals(greeting)) {\n            logger.info(++count + ": " + greeting + " " + name + "!");\n            String oldGreeting = greeting;\n            Workflow.await(() -> !Objects.equals(greeting, oldGreeting));\n        }\n        logger.info(++count + ": " + greeting + " " + name + "!");\n    }\n\n    @Override\n    public void updateGreeting(String greeting) {\n        this.greeting = greeting;\n    }\n}\n\n\nThe interface now has a new method annotated with @SignalMethod. It is a callback method that is invoked every time a new of "HelloWorldupdateGreeting" is delivered to a . The interface can have only one @WorkflowMethod which is a main function of the and as many methods as needed.\n\nThe updated implementation demonstrates a few important Cadence concepts. The first is that is stateful and can have fields of any complex type. Another is that the Workflow.await function that blocks until the function it receives as a parameter evaluates to true. The condition is going to be evaluated only on state changes, so it is not a busy wait in traditional sense.\n\n\n# Signal From Command Line\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflow_id "HelloSignal" --tasklist HelloWorldTaskList --workflow_type HelloWorld::sayHello --execution_timeout 3600 --input \\"World\\"\nStarted Workflow Id: HelloSignal, run Id: 6fa204cb-f478-469a-9432-78060b83b6cd\n\n\nProgram output:\n\n16:53:56.120 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 1: Hello World!\n\n\nLet\'s send a using\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "HelloSignal" --name "HelloWorld::updateGreeting" --input \\"Hi\\"\nSignal workflow succeeded.\n\n\nProgram output:\n\n16:53:56.120 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 1: Hello World!\n16:54:57.901 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 2: Hi World!\n\n\nTry sending the same with the same input again. Note that the output doesn\'t change. This happens because the await condition doesn\'t unblock when it sees the same value. But a new greeting unblocks it:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "HelloSignal" --name "HelloWorld::updateGreeting" --input \\"Welcome\\"\nSignal workflow succeeded.\n\n\nProgram output:\n\n16:53:56.120 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 1: Hello World!\n16:54:57.901 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 2: Hi World!\n16:56:24.400 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 3: Welcome World!\n\n\nNow shut down the and send the same again:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "HelloSignal" --name "HelloWorld::updateGreeting" --input \\"Welcome\\"\nSignal workflow succeeded.\n\n\nNote that sending as well as starting does not need a running. The requests are queued inside the Cadence service.\n\nNow bring the back. Note that it doesn\'t log anything besides the standard startup messages. This occurs because it ignores the queued that contains the same input as the current value of greeting. Note that the restart of the didn\'t affect the . It is still blocked on the same line of code as before the failure. This is the most important feature of Cadence. The code doesn\'t need to deal with failures at all. Its state is fully recovered to its current state that includes all the local variables and threads.\n\nLet\'s look at the line where the is blocked:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow stack --workflow_id "Hello2"\nQuery result:\n"workflow-root: (BLOCKED on await)\ncom.uber.cadence.internal.sync.SyncDecisionContext.await(SyncDecisionContext.java:546)\ncom.uber.cadence.internal.sync.WorkflowInternal.await(WorkflowInternal.java:243)\ncom.uber.cadence.workflow.Workflow.await(Workflow.java:611)\ncom.uber.cadence.samples.hello.GettingStarted$HelloWorldImpl.sayHello(GettingStarted.java:32)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)"\n\n\nYes, indeed the is blocked on await. This feature works for any open , greatly simplifying troubleshooting in production. Let\'s complete the by sending a with a "Bye" greeting:\n\n16:58:22.962 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 4: Bye World!\n\n\nNote that the value of the count variable was not lost during the restart.\n\nAlso note that while a single instance is used for this walkthrough, any real production deployment has multiple instances running. So any failure or restart does not delay any because it is just migrated to any other available .\n\n\n# SignalWithStart From Command Line\n\nYou may not know if a is running and can accept a . The signalWithStart feature allows you to send a to the current instance if one exists or to create a new run and then send the . SignalWithStartWorkflow therefore doesn\'t take a as a parameter.\n\nLearn more from the --help manual:\n\ndocker run --network=host --rm ubercadence/cli:master --do test-domain workflow signalwithstart -h\nNAME:\n   cadence workflow signalwithstart - signal the current open workflow if exists, or attempt to start a new run based on IDResuePolicy and signals it\n\nUSAGE:\n   cadence workflow signalwithstart [command options] [arguments...]\n...\n...\n...\n\n\n\n# Signal from user/application code\n\nYou may want to signal workflows without running the command line.\n\nThe WorkflowClient API allows you to send signal (or SignalWithStartWorkflow) from outside of the workflow to send a to the current .\n\nNote that when using newWorkflowStub to signal a workflow, you MUST NOT passing WorkflowOptions.\n\nThe WorkflowStub with WorkflowOptions is only for starting workflows.\n\nThe WorkflowStub without WorkflowOptions is for signal or query',normalizedContent:'# signals\n\nprovide a mechanism to send data directly to a running . previously, you had two options for passing data to the implementation:\n\n * via start parameters\n * as return values from\n\nwith start parameters, we could only pass in values before began.\n\nreturn values from allowed us to pass information to a running , but this approach comes with its own complications. one major drawback is reliance on polling. this means that the data needs to be stored in a third-party location until it\'s ready to be picked up by the . further, the lifecycle of this requires management, and the requires manual restart if it fails before acquiring the data.\n\n, on the other hand, provide a fully asynchronous and durable mechanism for providing data to a running . when a is received for a running , cadence persists the and the payload in the history. the can then process the at any time afterwards without the risk of losing the information. the also has the option to stop execution by blocking on a channel.\n\n\n# implement signal handler in workflow\n\nsee the below example from sample.\n\npublic interface helloworld {\n    @workflowmethod\n    void sayhello(string name);\n\n    @signalmethod\n    void updategreeting(string greeting);\n}\n\npublic static class helloworldimpl implements helloworld {\n\n    private string greeting = "hello";\n\n    @override\n    public void sayhello(string name) {\n        int count = 0;\n        while (!"bye".equals(greeting)) {\n            logger.info(++count + ": " + greeting + " " + name + "!");\n            string oldgreeting = greeting;\n            workflow.await(() -> !objects.equals(greeting, oldgreeting));\n        }\n        logger.info(++count + ": " + greeting + " " + name + "!");\n    }\n\n    @override\n    public void updategreeting(string greeting) {\n        this.greeting = greeting;\n    }\n}\n\n\nthe interface now has a new method annotated with @signalmethod. it is a callback method that is invoked every time a new of "helloworldupdategreeting" is delivered to a . the interface can have only one @workflowmethod which is a main function of the and as many methods as needed.\n\nthe updated implementation demonstrates a few important cadence concepts. the first is that is stateful and can have fields of any complex type. another is that the workflow.await function that blocks until the function it receives as a parameter evaluates to true. the condition is going to be evaluated only on state changes, so it is not a busy wait in traditional sense.\n\n\n# signal from command line\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflow_id "hellosignal" --tasklist helloworldtasklist --workflow_type helloworld::sayhello --execution_timeout 3600 --input \\"world\\"\nstarted workflow id: hellosignal, run id: 6fa204cb-f478-469a-9432-78060b83b6cd\n\n\nprogram output:\n\n16:53:56.120 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 1: hello world!\n\n\nlet\'s send a using\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "hellosignal" --name "helloworld::updategreeting" --input \\"hi\\"\nsignal workflow succeeded.\n\n\nprogram output:\n\n16:53:56.120 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 1: hello world!\n16:54:57.901 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 2: hi world!\n\n\ntry sending the same with the same input again. note that the output doesn\'t change. this happens because the await condition doesn\'t unblock when it sees the same value. but a new greeting unblocks it:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "hellosignal" --name "helloworld::updategreeting" --input \\"welcome\\"\nsignal workflow succeeded.\n\n\nprogram output:\n\n16:53:56.120 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 1: hello world!\n16:54:57.901 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 2: hi world!\n16:56:24.400 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 3: welcome world!\n\n\nnow shut down the and send the same again:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "hellosignal" --name "helloworld::updategreeting" --input \\"welcome\\"\nsignal workflow succeeded.\n\n\nnote that sending as well as starting does not need a running. the requests are queued inside the cadence service.\n\nnow bring the back. note that it doesn\'t log anything besides the standard startup messages. this occurs because it ignores the queued that contains the same input as the current value of greeting. note that the restart of the didn\'t affect the . it is still blocked on the same line of code as before the failure. this is the most important feature of cadence. the code doesn\'t need to deal with failures at all. its state is fully recovered to its current state that includes all the local variables and threads.\n\nlet\'s look at the line where the is blocked:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow stack --workflow_id "hello2"\nquery result:\n"workflow-root: (blocked on await)\ncom.uber.cadence.internal.sync.syncdecisioncontext.await(syncdecisioncontext.java:546)\ncom.uber.cadence.internal.sync.workflowinternal.await(workflowinternal.java:243)\ncom.uber.cadence.workflow.workflow.await(workflow.java:611)\ncom.uber.cadence.samples.hello.gettingstarted$helloworldimpl.sayhello(gettingstarted.java:32)\nsun.reflect.nativemethodaccessorimpl.invoke0(native method)\nsun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62)"\n\n\nyes, indeed the is blocked on await. this feature works for any open , greatly simplifying troubleshooting in production. let\'s complete the by sending a with a "bye" greeting:\n\n16:58:22.962 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 4: bye world!\n\n\nnote that the value of the count variable was not lost during the restart.\n\nalso note that while a single instance is used for this walkthrough, any real production deployment has multiple instances running. so any failure or restart does not delay any because it is just migrated to any other available .\n\n\n# signalwithstart from command line\n\nyou may not know if a is running and can accept a . the signalwithstart feature allows you to send a to the current instance if one exists or to create a new run and then send the . signalwithstartworkflow therefore doesn\'t take a as a parameter.\n\nlearn more from the --help manual:\n\ndocker run --network=host --rm ubercadence/cli:master --do test-domain workflow signalwithstart -h\nname:\n   cadence workflow signalwithstart - signal the current open workflow if exists, or attempt to start a new run based on idresuepolicy and signals it\n\nusage:\n   cadence workflow signalwithstart [command options] [arguments...]\n...\n...\n...\n\n\n\n# signal from user/application code\n\nyou may want to signal workflows without running the command line.\n\nthe workflowclient api allows you to send signal (or signalwithstartworkflow) from outside of the workflow to send a to the current .\n\nnote that when using newworkflowstub to signal a workflow, you must not passing workflowoptions.\n\nthe workflowstub with workflowoptions is only for starting workflows.\n\nthe workflowstub without workflowoptions is for signal or query',charsets:{}},{title:"Worker service",frontmatter:{layout:"default",title:"Worker service",permalink:"/docs/java-client/workers",readingShow:"top"},regularPath:"/docs/04-java-client/09-workers.html",relativePath:"docs/04-java-client/09-workers.md",key:"v-47638d30",path:"/docs/java-client/workers/",codeSwitcherOptions:{},headersStr:null,content:"# Worker service\n\nA or service is a service that hosts the and implementations. The polls the Cadence service for , performs those , and communicates execution results back to the Cadence service. services are developed, deployed, and operated by Cadence customers.\n\nYou can run a Cadence in a new or an existing service. Use the framework APIs to start the Cadence and link in all and implementations that you require the service to execute.\n\n  WorkerFactory factory = WorkerFactory.newInstance(workflowClient,\n          WorkerFactoryOptions.newBuilder()\n                  .setMaxWorkflowThreadCount(1000)\n                  .setStickyCacheSize(100)\n                  .setDisableStickyExecution(false)\n                  .build());\n  Worker worker = factory.newWorker(TASK_LIST,\n          WorkerOptions.newBuilder()\n                  .setMaxConcurrentActivityExecutionSize(100)\n                  .setMaxConcurrentWorkflowExecutionSize(100)\n                  .build());\n                  \n    // Workflows are stateful. So you need a type to create instances.\n    worker.registerWorkflowImplementationTypes(GreetingWorkflowImpl.class);\n    // Activities are stateless and thread safe. So a shared instance is used.\n    worker.registerActivitiesImplementations(new GreetingActivitiesImpl());\n    // Start listening to the workflow and activity task lists.\n    factory.start();\n\n\nThe code is slightly different if you are using client version prior to 3.0.0:\n\nWorker.Factory factory = new Worker.Factory(DOMAIN,\n            new Worker.FactoryOptions.Builder()\n                    .setMaxWorkflowThreadCount(1000)\n                    .setCacheMaximumSize(100)\n                    .setDisableStickyExecution(false)\n                    .build());\n    Worker worker = factory.newWorker(TASK_LIST,\n            new WorkerOptions.Builder()\n                    .setMaxConcurrentActivityExecutionSize(100)\n                    .setMaxConcurrentWorkflowExecutionSize(100)\n                    .build());\n    // Workflows are stateful. So you need a type to create instances.\n    worker.registerWorkflowImplementationTypes(GreetingWorkflowImpl.class);\n    // Activities are stateless and thread safe. So a shared instance is used.\n    worker.registerActivitiesImplementations(new GreetingActivitiesImpl());\n    // Start listening to the workflow and activity task lists.\n    factory.start();\n\n\nThe WorkerFactoryOptions includes those that need to be shared across workers on the hosts like thread pool, sticky cache.\n\nIn WorkerOptions you can customize things like pollerOptions, activities per second.",normalizedContent:"# worker service\n\na or service is a service that hosts the and implementations. the polls the cadence service for , performs those , and communicates execution results back to the cadence service. services are developed, deployed, and operated by cadence customers.\n\nyou can run a cadence in a new or an existing service. use the framework apis to start the cadence and link in all and implementations that you require the service to execute.\n\n  workerfactory factory = workerfactory.newinstance(workflowclient,\n          workerfactoryoptions.newbuilder()\n                  .setmaxworkflowthreadcount(1000)\n                  .setstickycachesize(100)\n                  .setdisablestickyexecution(false)\n                  .build());\n  worker worker = factory.newworker(task_list,\n          workeroptions.newbuilder()\n                  .setmaxconcurrentactivityexecutionsize(100)\n                  .setmaxconcurrentworkflowexecutionsize(100)\n                  .build());\n                  \n    // workflows are stateful. so you need a type to create instances.\n    worker.registerworkflowimplementationtypes(greetingworkflowimpl.class);\n    // activities are stateless and thread safe. so a shared instance is used.\n    worker.registeractivitiesimplementations(new greetingactivitiesimpl());\n    // start listening to the workflow and activity task lists.\n    factory.start();\n\n\nthe code is slightly different if you are using client version prior to 3.0.0:\n\nworker.factory factory = new worker.factory(domain,\n            new worker.factoryoptions.builder()\n                    .setmaxworkflowthreadcount(1000)\n                    .setcachemaximumsize(100)\n                    .setdisablestickyexecution(false)\n                    .build());\n    worker worker = factory.newworker(task_list,\n            new workeroptions.builder()\n                    .setmaxconcurrentactivityexecutionsize(100)\n                    .setmaxconcurrentworkflowexecutionsize(100)\n                    .build());\n    // workflows are stateful. so you need a type to create instances.\n    worker.registerworkflowimplementationtypes(greetingworkflowimpl.class);\n    // activities are stateless and thread safe. so a shared instance is used.\n    worker.registeractivitiesimplementations(new greetingactivitiesimpl());\n    // start listening to the workflow and activity task lists.\n    factory.start();\n\n\nthe workerfactoryoptions includes those that need to be shared across workers on the hosts like thread pool, sticky cache.\n\nin workeroptions you can customize things like polleroptions, activities per second.",charsets:{}},{title:"Queries",frontmatter:{layout:"default",title:"Queries",permalink:"/docs/java-client/queries",readingShow:"top"},regularPath:"/docs/04-java-client/11-queries.html",relativePath:"docs/04-java-client/11-queries.md",key:"v-47e211a0",path:"/docs/java-client/queries/",headers:[{level:2,title:"Built-in Query: Stack Trace",slug:"built-in-query-stack-trace",normalizedTitle:"built-in query: stack trace",charIndex:550},{level:2,title:"Customized Query",slug:"customized-query",normalizedTitle:"customized query",charIndex:1055},{level:2,title:"Run Query from Command Line",slug:"run-query-from-command-line",normalizedTitle:"run query from command line",charIndex:2688},{level:2,title:"Run Query from external application code",slug:"run-query-from-external-application-code",normalizedTitle:"run query from external application code",charIndex:4693},{level:2,title:"Consistent Query",slug:"consistent-query",normalizedTitle:"consistent query",charIndex:4803}],codeSwitcherOptions:{},headersStr:"Built-in Query: Stack Trace Customized Query Run Query from Command Line Run Query from external application code Consistent Query",content:'# Queries\n\nQuery is to expose this internal state to the external world Cadence provides a synchronous feature. From the implementer point of view the is exposed as a synchronous callback that is invoked by external entities. Multiple such callbacks can be provided per type exposing different information to different external systems.\n\ncallbacks must be read-only not mutating the state in any way. The other limitation is that the callback cannot contain any blocking code. Both above limitations rule out ability to invoke from the handlers.\n\n\n# Built-in Query: Stack Trace\n\nIf a has been stuck at a state for longer than an expected period of time, you might want to the current call stack. You can use the Cadence to perform this . For example:\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt __stack_trace\n\nThis command uses __stack_trace, which is a built-in type supported by the Cadence client library. You can add custom types to handle such as the current state of a , or how many the has completed.\n\n\n# Customized Query\n\nCadence provides a feature that supports synchronously returning any information from a to an external caller.\n\nInterface QueryMethod indicates that the method is a query method. Query method can be used to query a workflow state by external process at any time during its execution. This annotation applies only to workflow interface methods.\n\nSee the example code :\n\npublic interface HelloWorld {\n    @WorkflowMethod\n    void sayHello(String name);\n\n    @SignalMethod\n    void updateGreeting(String greeting);\n\n    @QueryMethod\n    int getCount();\n}\n\npublic static class HelloWorldImpl implements HelloWorld {\n\n    private String greeting = "Hello";\n    private int count = 0;\n\n    @Override\n    public void sayHello(String name) {\n        while (!"Bye".equals(greeting)) {\n            logger.info(++count + ": " + greeting + " " + name + "!");\n            String oldGreeting = greeting;\n            Workflow.await(() -> !Objects.equals(greeting, oldGreeting));\n        }\n        logger.info(++count + ": " + greeting + " " + name + "!");\n    }\n\n    @Override\n    public void updateGreeting(String greeting) {\n        this.greeting = greeting;\n    }\n\n    @Override\n    public int getCount() {\n        return count;\n    }\n}\n\n\nThe new getCount method annotated with @QueryMethod was added to the interface definition. It is allowed to have multiple methods per interface.\n\nThe main restriction on the implementation of the method is that it is not allowed to modify state in any form. It also is not allowed to block its thread in any way. It usually just returns a value derived from the fields of the object.\n\n\n# Run Query from Command Line\n\nLet\'s run the updated and send a couple to it:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflow_id "HelloQuery" --tasklist HelloWorldTaskList --workflow_type HelloWorld::sayHello --execution_timeout 3600 --input \\"World\\"\nStarted Workflow Id: HelloQuery, run Id: 1925f668-45b5-4405-8cba-74f7c68c3135\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "HelloQuery" --name "HelloWorld::updateGreeting" --input \\"Hi\\"\nSignal workflow succeeded.\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "HelloQuery" --name "HelloWorld::updateGreeting" --input \\"Welcome\\"\nSignal workflow succeeded.\n\n\nThe output:\n\n17:35:50.485 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 1: Hello World!\n17:36:10.483 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 2: Hi World!\n17:36:16.204 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 3: Welcome World!\n\n\nNow let\'s the using the\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow query --workflow_id "HelloQuery" --query_type "HelloWorld::getCount"\n:query:Query: result as JSON:\n3\n\n\nOne limitation of the is that it requires a process running because it is executing callback code. An interesting feature of the is that it works for completed as well. Let\'s complete the by sending "Bye" and it.\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "HelloQuery" --name "HelloWorld::updateGreeting" --input \\"Bye\\"\nSignal workflow succeeded.\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow query --workflow_id "HelloQuery" --query_type "HelloWorld::getCount"\n:query:Query: result as JSON:\n4\n\n\nThe method can accept parameters. This might be useful if only part of the state should be returned.\n\n\n# Run Query from external application code\n\nThe WorkflowStub without WorkflowOptions is for signal or query\n\n\n# Consistent Query\n\nhas two consistency levels, eventual and strong. Consider if you were to a and then immediately the\n\ncadence-cli --domain samples-domain workflow signal -w my_workflow_id -r my_run_id -n signal_name -if ./input.json\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state\n\nIn this example if were to change state, may or may not see that state update reflected in the result. This is what it means for to be eventually consistent.\n\nhas another consistency level called strong consistency. A strongly consistent is guaranteed to be based on state which includes all that came before the was issued. An is considered to have come before a if the call creating the external returned success before the was issued. External which are created while the is outstanding may or may not be reflected in the state the result is based on.\n\nIn order to run consistent through the do the following:\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state --qcl strong\n\nIn order to run a using application code, you need to use service client.\n\nWhen using strongly consistent you should expect higher latency than eventually consistent .',normalizedContent:'# queries\n\nquery is to expose this internal state to the external world cadence provides a synchronous feature. from the implementer point of view the is exposed as a synchronous callback that is invoked by external entities. multiple such callbacks can be provided per type exposing different information to different external systems.\n\ncallbacks must be read-only not mutating the state in any way. the other limitation is that the callback cannot contain any blocking code. both above limitations rule out ability to invoke from the handlers.\n\n\n# built-in query: stack trace\n\nif a has been stuck at a state for longer than an expected period of time, you might want to the current call stack. you can use the cadence to perform this . for example:\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt __stack_trace\n\nthis command uses __stack_trace, which is a built-in type supported by the cadence client library. you can add custom types to handle such as the current state of a , or how many the has completed.\n\n\n# customized query\n\ncadence provides a feature that supports synchronously returning any information from a to an external caller.\n\ninterface querymethod indicates that the method is a query method. query method can be used to query a workflow state by external process at any time during its execution. this annotation applies only to workflow interface methods.\n\nsee the example code :\n\npublic interface helloworld {\n    @workflowmethod\n    void sayhello(string name);\n\n    @signalmethod\n    void updategreeting(string greeting);\n\n    @querymethod\n    int getcount();\n}\n\npublic static class helloworldimpl implements helloworld {\n\n    private string greeting = "hello";\n    private int count = 0;\n\n    @override\n    public void sayhello(string name) {\n        while (!"bye".equals(greeting)) {\n            logger.info(++count + ": " + greeting + " " + name + "!");\n            string oldgreeting = greeting;\n            workflow.await(() -> !objects.equals(greeting, oldgreeting));\n        }\n        logger.info(++count + ": " + greeting + " " + name + "!");\n    }\n\n    @override\n    public void updategreeting(string greeting) {\n        this.greeting = greeting;\n    }\n\n    @override\n    public int getcount() {\n        return count;\n    }\n}\n\n\nthe new getcount method annotated with @querymethod was added to the interface definition. it is allowed to have multiple methods per interface.\n\nthe main restriction on the implementation of the method is that it is not allowed to modify state in any form. it also is not allowed to block its thread in any way. it usually just returns a value derived from the fields of the object.\n\n\n# run query from command line\n\nlet\'s run the updated and send a couple to it:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflow_id "helloquery" --tasklist helloworldtasklist --workflow_type helloworld::sayhello --execution_timeout 3600 --input \\"world\\"\nstarted workflow id: helloquery, run id: 1925f668-45b5-4405-8cba-74f7c68c3135\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "helloquery" --name "helloworld::updategreeting" --input \\"hi\\"\nsignal workflow succeeded.\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "helloquery" --name "helloworld::updategreeting" --input \\"welcome\\"\nsignal workflow succeeded.\n\n\nthe output:\n\n17:35:50.485 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 1: hello world!\n17:36:10.483 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 2: hi world!\n17:36:16.204 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 3: welcome world!\n\n\nnow let\'s the using the\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow query --workflow_id "helloquery" --query_type "helloworld::getcount"\n:query:query: result as json:\n3\n\n\none limitation of the is that it requires a process running because it is executing callback code. an interesting feature of the is that it works for completed as well. let\'s complete the by sending "bye" and it.\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "helloquery" --name "helloworld::updategreeting" --input \\"bye\\"\nsignal workflow succeeded.\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow query --workflow_id "helloquery" --query_type "helloworld::getcount"\n:query:query: result as json:\n4\n\n\nthe method can accept parameters. this might be useful if only part of the state should be returned.\n\n\n# run query from external application code\n\nthe workflowstub without workflowoptions is for signal or query\n\n\n# consistent query\n\nhas two consistency levels, eventual and strong. consider if you were to a and then immediately the\n\ncadence-cli --domain samples-domain workflow signal -w my_workflow_id -r my_run_id -n signal_name -if ./input.json\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state\n\nin this example if were to change state, may or may not see that state update reflected in the result. this is what it means for to be eventually consistent.\n\nhas another consistency level called strong consistency. a strongly consistent is guaranteed to be based on state which includes all that came before the was issued. an is considered to have come before a if the call creating the external returned success before the was issued. external which are created while the is outstanding may or may not be reflected in the state the result is based on.\n\nin order to run consistent through the do the following:\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state --qcl strong\n\nin order to run a using application code, you need to use service client.\n\nwhen using strongly consistent you should expect higher latency than eventually consistent .',charsets:{}},{title:"Retries",frontmatter:{layout:"default",title:"Retries",permalink:"/docs/java-client/retries",readingShow:"top"},regularPath:"/docs/04-java-client/12-retries.html",relativePath:"docs/04-java-client/12-retries.md",key:"v-2ef7ad44",path:"/docs/java-client/retries/",headers:[{level:2,title:"RetryOptions",slug:"retryoptions",normalizedTitle:"retryoptions",charIndex:282},{level:3,title:"InitialInterval",slug:"initialinterval",normalizedTitle:"initialinterval",charIndex:339},{level:3,title:"BackoffCoefficient",slug:"backoffcoefficient",normalizedTitle:"backoffcoefficient",charIndex:481},{level:3,title:"MaximumInterval",slug:"maximuminterval",normalizedTitle:"maximuminterval",charIndex:682},{level:3,title:"ExpirationInterval",slug:"expirationinterval",normalizedTitle:"expirationinterval",charIndex:869},{level:3,title:"MaximumAttempts",slug:"maximumattempts",normalizedTitle:"maximumattempts",charIndex:941},{level:3,title:"NonRetriableErrorReasons(via setDoNotRetry)",slug:"nonretriableerrorreasons-via-setdonotretry",normalizedTitle:"nonretriableerrorreasons(via setdonotretry)",charIndex:1466},{level:2,title:"Activity Timeout Usage",slug:"activity-timeout-usage",normalizedTitle:"activity timeout usage",charIndex:2113},{level:2,title:"Activity Timeout Internals",slug:"activity-timeout-internals",normalizedTitle:"activity timeout internals",charIndex:3466},{level:3,title:"Basics without Retry",slug:"basics-without-retry",normalizedTitle:"basics without retry",charIndex:3497},{level:3,title:"Heartbeat timeout",slug:"heartbeat-timeout",normalizedTitle:"heartbeat timeout",charIndex:2519},{level:3,title:"RetryOptions and Activity with Retry",slug:"retryoptions-and-activity-with-retry",normalizedTitle:"retryoptions and activity with retry",charIndex:6151}],codeSwitcherOptions:{},headersStr:"RetryOptions InitialInterval BackoffCoefficient MaximumInterval ExpirationInterval MaximumAttempts NonRetriableErrorReasons(via setDoNotRetry) Activity Timeout Usage Activity Timeout Internals Basics without Retry Heartbeat timeout RetryOptions and Activity with Retry",content:"# Activity and workflow retries\n\nand can fail due to various intermediate conditions. In those cases, we want to retry the failed or child or even the parent . This can be achieved by supplying an optional retry options.\n\n> Note that sometimes it's also referred as RetryPolicy\n\n\n# RetryOptions\n\nA RetryOptions includes the following.\n\n\n# InitialInterval\n\nBackoff interval for the first retry. If coefficient is 1.0 then it is used for all retries. Required, no default value.\n\n\n# BackoffCoefficient\n\nCoefficient used to calculate the next retry backoff interval. The next retry interval is previous interval multiplied by this coefficient. Must be 1 or larger. Default is 2.0.\n\n\n# MaximumInterval\n\nMaximum backoff interval between retries. Exponential backoff leads to interval increase. This value is the cap of the interval. Default is 100x of initial interval.\n\n\n# ExpirationInterval\n\nMaximum time to retry. Either ExpirationInterval or MaximumAttempts is required. When exceeded the retries stop even if maximum retries is not reached yet. First (non-retry) attempt is unaffected by this field and is guaranteed to run for the entirety of the workflow timeout duration (ExecutionStartToCloseTimeoutSeconds).\n\n\n# MaximumAttempts\n\nMaximum number of attempts. When exceeded the retries stop even if not expired yet. If not set or set to 0, it means unlimited, and relies on ExpirationInterval to stop. Either MaximumAttempts or ExpirationInterval is required.\n\n\n# NonRetriableErrorReasons(via setDoNotRetry)\n\nNon-Retriable errors. This is optional. Cadence server will stop retry if error reason matches this list. When matching an exact match is used. So adding RuntimeException.class to this list is going to include only RuntimeException itself, not all of its subclasses. The reason for such behaviour is to be able to support server side retries without knowledge of Java exception hierarchy. When considering an exception type a cause of ActivityFailureException and ChildWorkflowFailureException is looked at. Error and CancellationException are never retried and are not even passed to this filter.\n\n\n# Activity Timeout Usage\n\nIt's probably too complicated to learn how to set those timeouts by reading the above. There is an easy way to deal with it.\n\nLocalActivity without retry: Use ScheduleToClose for overall timeout\n\nRegular Activity without retry:\n\n 1. Use ScheduleToClose for overall timeout\n 2. Leave ScheduleToStart and StartToClose empty\n 3. If ScheduleToClose is too large(like 10 mins), then set Heartbeat timeout to a smaller value like 10s. Call heartbeat API inside activity regularly.\n\nLocalActivity with retry:\n\n 1. Use ScheduleToClose as timeout of each attempt.\n 2. Use retryOptions.InitialInterval, retryOptions.BackoffCoefficient, retryOptions.MaximumInterval to control backoff.\n 3. Use retryOptions.ExperiationInterval as overall timeout of all attempts.\n 4. Leave retryOptions.MaximumAttempts empty.\n\nRegular Activity with retry:\n\n 1. Use ScheduleToClose as timeout of each attempt\n 2. Leave ScheduleToStart and StartToClose empty\n 3. If ScheduleToClose is too large(like 10 mins), then set Heartbeat timeout to a smaller value like 10s. Call heartbeat API inside activity regularly.\n 4. Use retryOptions.InitialInterval, retryOptions.BackoffCoefficient, retryOptions.MaximumInterval to control backoff.\n 5. Use retryOptions.ExperiationInterval as overall timeout of all attempts.\n 6. Leave retryOptions.MaximumAttempts empty.\n\n\n# Activity Timeout Internals\n\n\n# Basics without Retry\n\nThings are easier to understand in the world without retry. Because Cadence started from it.\n\n * ScheduleToClose timeout is the overall end-to-end timeout from a workflow's perspective.\n\n * ScheduleToStart timeout is the time that activity worker needed to start an activity. Exceeding this timeout, activity will return an ScheduleToStart timeout error/exception to workflow\n\n * StartToClose timeout is the time that an activity needed to run. Exceeding this will return StartToClose to workflow.\n\n * Requirement and defaults:\n   \n   * Either ScheduleToClose is provided or both of ScheduleToStart and StartToClose are provided.\n   * If only ScheduleToClose, then ScheduleToStart and StartToClose are default to it.\n   * If only ScheduleToStart and StartToClose are provided, then ScheduleToClose = ScheduleToStart + StartToClose.\n   * All of them are capped by workflowTimeout. (e.g. if workflowTimeout is 1hour, set 2 hour for ScheduleToClose will still get 1 hour :ScheduleToClose=Min(ScheduleToClose, workflowTimeout) )\n\nSo why are they?\n\nYou may notice that ScheduleToClose is only useful when ScheduleToClose < ScheduleToStart + StartToClose. Because if ScheduleToClose >= ScheduleToStart+StartToClose the ScheduleToClose timeout is already enforced by the combination of the other two, and it become meaningless.\n\nSo the main use case of ScheduleToClose being less than the sum of two is that people want to limit the overall timeout of the activity but give more timeout for scheduleToStart or startToClose. This is extremely rare use case.\n\nAlso the main use case that people want to distinguish ScheduleToStart and StartToClose is that the workflow may need to do some special handling for ScheduleToStart timeout error. This is also very rare use case.\n\nTherefore, you can understand why in TL;DR that I recommend only using ScheduleToClose but leave the other two empty. Because only in some rare cases you may need it. If you can't think of the use case, then you do not need it.\n\nLocalActivity doesn't have ScheduleToStart/StartToClose because it's started directly inside workflow worker without server scheduling involved.\n\n\n# Heartbeat timeout\n\nHeartbeat is very important for long running activity, to prevent it from getting stuck. Not only bugs can cause activity getting stuck, regular deployment/host restart/failure could also cause it. Because without heartbeat, Cadence server couldn't know whether or not the activity is still being worked on. See more details about here https://stackoverflow.com/questions/65118584/solutions-to-stuck-timers-activities-in-cadence-swf-stepfunctions/65118585#65118585\n\n\n# RetryOptions and Activity with Retry\n\nFirst of all, here RetryOptions is for server side backoff retry -- meaning that the retry is managed automatically by Cadence without interacting with workflows. Because retry is managed by Cadence, the activity has to be specially handled in Cadence history that the started event can not written until the activity is closed. Here is some reference: https://stackoverflow.com/questions/65113363/why-an-activity-task-is-scheduled-but-not-started/65113365#65113365\n\nIn fact, workflow can do client side retry on their own. This means workflow will be managing the retry logic. You can write your own retry function, or there is some helper function in SDK, like Workflow.retry in Cadence-java-client. Client side retry will show all start events immediately, but there will be many events in the history when retrying for a single activity. It's not recommended because of performance issue.\n\nSo what do the options mean:\n\n * ExpirationInterval:\n   \n   * It replaces the ScheduleToClose timeout to become the actual overall timeout of the activity for all attempts.\n   * It's also capped to workflow timeout like other three timeout options. ScheduleToClose = Min(ScheduleToClose, workflowTimeout)\n   * The timeout of each attempt is StartToClose, but StartToClose defaults to ScheduleToClose like explanation above.\n   * ScheduleToClose will be extended to ExpirationInterval: ScheduleToClose = Max(ScheduleToClose, ExpirationInterval), and this happens before ScheduleToClose is copied to ScheduleToClose and StartToClose.\n\n * InitialInterval: the interval of first retry\n\n * BackoffCoefficient: self explained\n\n * MaximumInterval: maximum of the interval during retry\n\n * MaximumAttempts: the maximum attempts. If existing with ExpirationInterval, then retry stops when either one of them is exceeded.\n\n * Requirements and defaults:\n\n * Either MaximumAttempts or ExpirationInterval is required. ExpirationInterval is set to workflowTimeout if not provided.\n\nSince ExpirationInterval is always there, and in fact it's more useful. And I think it's quite confusing to use MaximumAttempts, so I would recommend just use ExpirationInterval. Unless you really need it.",normalizedContent:"# activity and workflow retries\n\nand can fail due to various intermediate conditions. in those cases, we want to retry the failed or child or even the parent . this can be achieved by supplying an optional retry options.\n\n> note that sometimes it's also referred as retrypolicy\n\n\n# retryoptions\n\na retryoptions includes the following.\n\n\n# initialinterval\n\nbackoff interval for the first retry. if coefficient is 1.0 then it is used for all retries. required, no default value.\n\n\n# backoffcoefficient\n\ncoefficient used to calculate the next retry backoff interval. the next retry interval is previous interval multiplied by this coefficient. must be 1 or larger. default is 2.0.\n\n\n# maximuminterval\n\nmaximum backoff interval between retries. exponential backoff leads to interval increase. this value is the cap of the interval. default is 100x of initial interval.\n\n\n# expirationinterval\n\nmaximum time to retry. either expirationinterval or maximumattempts is required. when exceeded the retries stop even if maximum retries is not reached yet. first (non-retry) attempt is unaffected by this field and is guaranteed to run for the entirety of the workflow timeout duration (executionstarttoclosetimeoutseconds).\n\n\n# maximumattempts\n\nmaximum number of attempts. when exceeded the retries stop even if not expired yet. if not set or set to 0, it means unlimited, and relies on expirationinterval to stop. either maximumattempts or expirationinterval is required.\n\n\n# nonretriableerrorreasons(via setdonotretry)\n\nnon-retriable errors. this is optional. cadence server will stop retry if error reason matches this list. when matching an exact match is used. so adding runtimeexception.class to this list is going to include only runtimeexception itself, not all of its subclasses. the reason for such behaviour is to be able to support server side retries without knowledge of java exception hierarchy. when considering an exception type a cause of activityfailureexception and childworkflowfailureexception is looked at. error and cancellationexception are never retried and are not even passed to this filter.\n\n\n# activity timeout usage\n\nit's probably too complicated to learn how to set those timeouts by reading the above. there is an easy way to deal with it.\n\nlocalactivity without retry: use scheduletoclose for overall timeout\n\nregular activity without retry:\n\n 1. use scheduletoclose for overall timeout\n 2. leave scheduletostart and starttoclose empty\n 3. if scheduletoclose is too large(like 10 mins), then set heartbeat timeout to a smaller value like 10s. call heartbeat api inside activity regularly.\n\nlocalactivity with retry:\n\n 1. use scheduletoclose as timeout of each attempt.\n 2. use retryoptions.initialinterval, retryoptions.backoffcoefficient, retryoptions.maximuminterval to control backoff.\n 3. use retryoptions.experiationinterval as overall timeout of all attempts.\n 4. leave retryoptions.maximumattempts empty.\n\nregular activity with retry:\n\n 1. use scheduletoclose as timeout of each attempt\n 2. leave scheduletostart and starttoclose empty\n 3. if scheduletoclose is too large(like 10 mins), then set heartbeat timeout to a smaller value like 10s. call heartbeat api inside activity regularly.\n 4. use retryoptions.initialinterval, retryoptions.backoffcoefficient, retryoptions.maximuminterval to control backoff.\n 5. use retryoptions.experiationinterval as overall timeout of all attempts.\n 6. leave retryoptions.maximumattempts empty.\n\n\n# activity timeout internals\n\n\n# basics without retry\n\nthings are easier to understand in the world without retry. because cadence started from it.\n\n * scheduletoclose timeout is the overall end-to-end timeout from a workflow's perspective.\n\n * scheduletostart timeout is the time that activity worker needed to start an activity. exceeding this timeout, activity will return an scheduletostart timeout error/exception to workflow\n\n * starttoclose timeout is the time that an activity needed to run. exceeding this will return starttoclose to workflow.\n\n * requirement and defaults:\n   \n   * either scheduletoclose is provided or both of scheduletostart and starttoclose are provided.\n   * if only scheduletoclose, then scheduletostart and starttoclose are default to it.\n   * if only scheduletostart and starttoclose are provided, then scheduletoclose = scheduletostart + starttoclose.\n   * all of them are capped by workflowtimeout. (e.g. if workflowtimeout is 1hour, set 2 hour for scheduletoclose will still get 1 hour :scheduletoclose=min(scheduletoclose, workflowtimeout) )\n\nso why are they?\n\nyou may notice that scheduletoclose is only useful when scheduletoclose < scheduletostart + starttoclose. because if scheduletoclose >= scheduletostart+starttoclose the scheduletoclose timeout is already enforced by the combination of the other two, and it become meaningless.\n\nso the main use case of scheduletoclose being less than the sum of two is that people want to limit the overall timeout of the activity but give more timeout for scheduletostart or starttoclose. this is extremely rare use case.\n\nalso the main use case that people want to distinguish scheduletostart and starttoclose is that the workflow may need to do some special handling for scheduletostart timeout error. this is also very rare use case.\n\ntherefore, you can understand why in tl;dr that i recommend only using scheduletoclose but leave the other two empty. because only in some rare cases you may need it. if you can't think of the use case, then you do not need it.\n\nlocalactivity doesn't have scheduletostart/starttoclose because it's started directly inside workflow worker without server scheduling involved.\n\n\n# heartbeat timeout\n\nheartbeat is very important for long running activity, to prevent it from getting stuck. not only bugs can cause activity getting stuck, regular deployment/host restart/failure could also cause it. because without heartbeat, cadence server couldn't know whether or not the activity is still being worked on. see more details about here https://stackoverflow.com/questions/65118584/solutions-to-stuck-timers-activities-in-cadence-swf-stepfunctions/65118585#65118585\n\n\n# retryoptions and activity with retry\n\nfirst of all, here retryoptions is for server side backoff retry -- meaning that the retry is managed automatically by cadence without interacting with workflows. because retry is managed by cadence, the activity has to be specially handled in cadence history that the started event can not written until the activity is closed. here is some reference: https://stackoverflow.com/questions/65113363/why-an-activity-task-is-scheduled-but-not-started/65113365#65113365\n\nin fact, workflow can do client side retry on their own. this means workflow will be managing the retry logic. you can write your own retry function, or there is some helper function in sdk, like workflow.retry in cadence-java-client. client side retry will show all start events immediately, but there will be many events in the history when retrying for a single activity. it's not recommended because of performance issue.\n\nso what do the options mean:\n\n * expirationinterval:\n   \n   * it replaces the scheduletoclose timeout to become the actual overall timeout of the activity for all attempts.\n   * it's also capped to workflow timeout like other three timeout options. scheduletoclose = min(scheduletoclose, workflowtimeout)\n   * the timeout of each attempt is starttoclose, but starttoclose defaults to scheduletoclose like explanation above.\n   * scheduletoclose will be extended to expirationinterval: scheduletoclose = max(scheduletoclose, expirationinterval), and this happens before scheduletoclose is copied to scheduletoclose and starttoclose.\n\n * initialinterval: the interval of first retry\n\n * backoffcoefficient: self explained\n\n * maximuminterval: maximum of the interval during retry\n\n * maximumattempts: the maximum attempts. if existing with expirationinterval, then retry stops when either one of them is exceeded.\n\n * requirements and defaults:\n\n * either maximumattempts or expirationinterval is required. expirationinterval is set to workflowtimeout if not provided.\n\nsince expirationinterval is always there, and in fact it's more useful. and i think it's quite confusing to use maximumattempts, so i would recommend just use expirationinterval. unless you really need it.",charsets:{}},{title:"Exception Handling",frontmatter:{layout:"default",title:"Exception Handling",permalink:"/docs/java-client/exception-handling",readingShow:"top"},regularPath:"/docs/04-java-client/14-exception-handling.html",relativePath:"docs/04-java-client/14-exception-handling.md",key:"v-d965e2bc",path:"/docs/java-client/exception-handling/",codeSwitcherOptions:{},headersStr:null,content:'# Exception Handling\n\nBy default, Exceptions thrown by an activity are received by the workflow wrapped into an com.uber.cadence.workflow.ActivityFailureException,\n\nExceptions thrown by a child workflow are received by a parent workflow wrapped into a com.uber.cadence.workflow.ChildWorkflowFailureException\n\nExceptions thrown by a workflow are received by a workflow client wrapped into com.uber.cadence.client.WorkflowFailureException.\n\nIn this example a Workflow Client executes a workflow which executes a child workflow which executes an activity which throws an IOException. The resulting exception stack trace is:\n\n com.uber.cadence.client.WorkflowFailureException: WorkflowType="GreetingWorkflow::getGreeting", WorkflowID="38b9ce7a-e370-4cd8-a9f3-35e7295f7b3d", RunID="37ceb58c-9271-4fca-b5aa-ba06c5495214\n     at com.uber.cadence.internal.dispatcher.UntypedWorkflowStubImpl.getResult(UntypedWorkflowStubImpl.java:139)\n     at com.uber.cadence.internal.dispatcher.UntypedWorkflowStubImpl.getResult(UntypedWorkflowStubImpl.java:111)\n     at com.uber.cadence.internal.dispatcher.WorkflowExternalInvocationHandler.startWorkflow(WorkflowExternalInvocationHandler.java:187)\n     at com.uber.cadence.internal.dispatcher.WorkflowExternalInvocationHandler.invoke(WorkflowExternalInvocationHandler.java:113)\n     at com.sun.proxy.$Proxy2.getGreeting(Unknown Source)\n     at com.uber.cadence.samples.hello.HelloException.main(HelloException.java:117)\n Caused by: com.uber.cadence.workflow.ChildWorkflowFailureException: WorkflowType="GreetingChild::composeGreeting", ID="37ceb58c-9271-4fca-b5aa-ba06c5495214:1", RunID="47859b47-da4c-4225-876a-462421c98c72, EventID=10\n     at java.lang.Thread.getStackTrace(Thread.java:1559)\n     at com.uber.cadence.internal.dispatcher.ChildWorkflowInvocationHandler.executeChildWorkflow(ChildWorkflowInvocationHandler.java:114)\n     at com.uber.cadence.internal.dispatcher.ChildWorkflowInvocationHandler.invoke(ChildWorkflowInvocationHandler.java:71)\n     at com.sun.proxy.$Proxy5.composeGreeting(Unknown Source:0)\n     at com.uber.cadence.samples.hello.HelloException$GreetingWorkflowImpl.getGreeting(HelloException.java:70)\n     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method:0)\n     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n     at java.lang.reflect.Method.invoke(Method.java:498)\n     at com.uber.cadence.internal.worker.POJOWorkflowImplementationFactory$POJOWorkflowImplementation.execute(POJOWorkflowImplementationFactory.java:160)\n Caused by: com.uber.cadence.workflow.ActivityFailureException: ActivityType="GreetingActivities::composeGreeting" ActivityID="1", EventID=7\n     at java.lang.Thread.getStackTrace(Thread.java:1559)\n     at com.uber.cadence.internal.dispatcher.ActivityInvocationHandler.invoke(ActivityInvocationHandler.java:75)\n     at com.sun.proxy.$Proxy6.composeGreeting(Unknown Source:0)\n     at com.uber.cadence.samples.hello.HelloException$GreetingChildImpl.composeGreeting(HelloException.java:85)\n     ... 5 more\n Caused by: java.io.IOException: Hello World!\n     at com.uber.cadence.samples.hello.HelloException$GreetingActivitiesImpl.composeGreeting(HelloException.java:93)\n     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method:0)\n     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n     at java.lang.reflect.Method.invoke(Method.java:498)\n     at com.uber.cadence.internal.worker.POJOActivityImplementationFactory$POJOActivityImplementation.execute(POJOActivityImplementationFactory.java:162)\n\n\nNote that IOException is a checked exception. The standard Java way of adding throws IOException to method signature of activity, child and workflow interfaces is not going to help. It is because at all levels it is never received directly, but in wrapped form. Propagating it without wrapping would not allow adding additional context information like activity, child workflow and parent workflow types and IDs. The Cadence library solution is to provide a special wrapper method Workflow.wrap(Exception) which wraps a checked exception in a special runtime exception. It is special because the framework strips it when chaining exceptions across logical process boundaries. In this example IOException is directly attached to ActivityFailureException besides being wrapped when rethrown.\n\npublic class HelloException {\n\n  static final String TASK_LIST = "HelloException";\n\n  public interface GreetingWorkflow {\n    @WorkflowMethod\n    String getGreeting(String name);\n  }\n\n  public interface GreetingChild {\n    @WorkflowMethod\n    String composeGreeting(String greeting, String name);\n  }\n\n  public interface GreetingActivities {\n    String composeGreeting(String greeting, String name);\n  }\n\n  /** Parent implementation that calls GreetingChild#composeGreeting.**/\n  public static class GreetingWorkflowImpl implements GreetingWorkflow {\n\n    @Override\n    public String getGreeting(String name) {\n      GreetingChild child = Workflow.newChildWorkflowStub(GreetingChild.class);\n      return child.composeGreeting("Hello", name);\n    }\n  }\n\n  /** Child workflow implementation.**/\n  public static class GreetingChildImpl implements GreetingChild {\n    private final GreetingActivities activities =\n        Workflow.newActivityStub(\n            GreetingActivities.class,\n            new ActivityOptions.Builder()\n                .setScheduleToCloseTimeout(Duration.ofSeconds(10))\n                .build());\n\n    @Override\n    public String composeGreeting(String greeting, String name) {\n      return activities.composeGreeting(greeting, name);\n    }\n  }\n\n  static class GreetingActivitiesImpl implements GreetingActivities {\n    @Override\n    public String composeGreeting(String greeting, String name) {\n      try {\n        throw new IOException(greeting + " " + name + "!");\n      } catch (IOException e) {\n        // Wrapping the exception as checked exceptions in activity and workflow interface methods\n        // are prohibited.\n        // It will be unwrapped and attached as a cause to the ActivityFailureException.\n        throw Workflow.wrap(e);\n      }\n    }\n  }\n\n  public static void main(String[] args) {\n     // Get a new client\n     // NOTE: to set a different options, you can do like this:\n     // ClientOptions.newBuilder().setRpcTimeout(5 * 1000).build();\n     WorkflowClient workflowClient =\n         WorkflowClient.newInstance(\n             new WorkflowServiceTChannel(ClientOptions.defaultInstance()),\n             WorkflowClientOptions.newBuilder().setDomain(DOMAIN).build());\n     // Get worker to poll the task list.\n     WorkerFactory factory = WorkerFactory.newInstance(workflowClient);\n     Worker worker = factory.newWorker(TASK_LIST);\n     worker.registerWorkflowImplementationTypes(GreetingWorkflowImpl.class, GreetingChildImpl.class);\n     worker.registerActivitiesImplementations(new GreetingActivitiesImpl());\n     factory.start();\n\n     WorkflowOptions workflowOptions =\n         new WorkflowOptions.Builder()\n             .setTaskList(TASK_LIST)\n             .setExecutionStartToCloseTimeout(Duration.ofSeconds(30))\n             .build();\n     GreetingWorkflow workflow =\n         workflowClient.newWorkflowStub(GreetingWorkflow.class, workflowOptions);\n     try {\n       workflow.getGreeting("World");\n       throw new IllegalStateException("unreachable");\n     } catch (WorkflowException e) {\n       Throwable cause = Throwables.getRootCause(e);\n       // prints "Hello World!"\n       System.out.println(cause.getMessage());\n       System.out.println("\\nStack Trace:\\n" + Throwables.getStackTraceAsString(e));\n     }\n     System.exit(0);\n   }\n   \n}\n\n\nThe code is slightly different if you are using client version prior to 3.0.0:\n\npublic static void main(String[] args) {\n  Worker.Factory factory = new Worker.Factory(DOMAIN);\n  Worker worker = factory.newWorker(TASK_LIST);\n  worker.registerWorkflowImplementationTypes(GreetingWorkflowImpl.class, GreetingChildImpl.class);\n  worker.registerActivitiesImplementations(new GreetingActivitiesImpl());\n  factory.start();\n\n  WorkflowClient workflowClient = WorkflowClient.newInstance(DOMAIN);\n  WorkflowOptions workflowOptions =\n      new WorkflowOptions.Builder()\n          .setTaskList(TASK_LIST)\n          .setExecutionStartToCloseTimeout(Duration.ofSeconds(30))\n          .build();\n  GreetingWorkflow workflow =\n      workflowClient.newWorkflowStub(GreetingWorkflow.class, workflowOptions);\n  try {\n    workflow.getGreeting("World");\n    throw new IllegalStateException("unreachable");\n  } catch (WorkflowException e) {\n    Throwable cause = Throwables.getRootCause(e);\n    // prints "Hello World!"\n    System.out.println(cause.getMessage());\n    System.out.println("\\nStack Trace:\\n" + Throwables.getStackTraceAsString(e));\n  }\n  System.exit(0);\n}\n',normalizedContent:'# exception handling\n\nby default, exceptions thrown by an activity are received by the workflow wrapped into an com.uber.cadence.workflow.activityfailureexception,\n\nexceptions thrown by a child workflow are received by a parent workflow wrapped into a com.uber.cadence.workflow.childworkflowfailureexception\n\nexceptions thrown by a workflow are received by a workflow client wrapped into com.uber.cadence.client.workflowfailureexception.\n\nin this example a workflow client executes a workflow which executes a child workflow which executes an activity which throws an ioexception. the resulting exception stack trace is:\n\n com.uber.cadence.client.workflowfailureexception: workflowtype="greetingworkflow::getgreeting", workflowid="38b9ce7a-e370-4cd8-a9f3-35e7295f7b3d", runid="37ceb58c-9271-4fca-b5aa-ba06c5495214\n     at com.uber.cadence.internal.dispatcher.untypedworkflowstubimpl.getresult(untypedworkflowstubimpl.java:139)\n     at com.uber.cadence.internal.dispatcher.untypedworkflowstubimpl.getresult(untypedworkflowstubimpl.java:111)\n     at com.uber.cadence.internal.dispatcher.workflowexternalinvocationhandler.startworkflow(workflowexternalinvocationhandler.java:187)\n     at com.uber.cadence.internal.dispatcher.workflowexternalinvocationhandler.invoke(workflowexternalinvocationhandler.java:113)\n     at com.sun.proxy.$proxy2.getgreeting(unknown source)\n     at com.uber.cadence.samples.hello.helloexception.main(helloexception.java:117)\n caused by: com.uber.cadence.workflow.childworkflowfailureexception: workflowtype="greetingchild::composegreeting", id="37ceb58c-9271-4fca-b5aa-ba06c5495214:1", runid="47859b47-da4c-4225-876a-462421c98c72, eventid=10\n     at java.lang.thread.getstacktrace(thread.java:1559)\n     at com.uber.cadence.internal.dispatcher.childworkflowinvocationhandler.executechildworkflow(childworkflowinvocationhandler.java:114)\n     at com.uber.cadence.internal.dispatcher.childworkflowinvocationhandler.invoke(childworkflowinvocationhandler.java:71)\n     at com.sun.proxy.$proxy5.composegreeting(unknown source:0)\n     at com.uber.cadence.samples.hello.helloexception$greetingworkflowimpl.getgreeting(helloexception.java:70)\n     at sun.reflect.nativemethodaccessorimpl.invoke0(native method:0)\n     at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62)\n     at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43)\n     at java.lang.reflect.method.invoke(method.java:498)\n     at com.uber.cadence.internal.worker.pojoworkflowimplementationfactory$pojoworkflowimplementation.execute(pojoworkflowimplementationfactory.java:160)\n caused by: com.uber.cadence.workflow.activityfailureexception: activitytype="greetingactivities::composegreeting" activityid="1", eventid=7\n     at java.lang.thread.getstacktrace(thread.java:1559)\n     at com.uber.cadence.internal.dispatcher.activityinvocationhandler.invoke(activityinvocationhandler.java:75)\n     at com.sun.proxy.$proxy6.composegreeting(unknown source:0)\n     at com.uber.cadence.samples.hello.helloexception$greetingchildimpl.composegreeting(helloexception.java:85)\n     ... 5 more\n caused by: java.io.ioexception: hello world!\n     at com.uber.cadence.samples.hello.helloexception$greetingactivitiesimpl.composegreeting(helloexception.java:93)\n     at sun.reflect.nativemethodaccessorimpl.invoke0(native method:0)\n     at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62)\n     at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43)\n     at java.lang.reflect.method.invoke(method.java:498)\n     at com.uber.cadence.internal.worker.pojoactivityimplementationfactory$pojoactivityimplementation.execute(pojoactivityimplementationfactory.java:162)\n\n\nnote that ioexception is a checked exception. the standard java way of adding throws ioexception to method signature of activity, child and workflow interfaces is not going to help. it is because at all levels it is never received directly, but in wrapped form. propagating it without wrapping would not allow adding additional context information like activity, child workflow and parent workflow types and ids. the cadence library solution is to provide a special wrapper method workflow.wrap(exception) which wraps a checked exception in a special runtime exception. it is special because the framework strips it when chaining exceptions across logical process boundaries. in this example ioexception is directly attached to activityfailureexception besides being wrapped when rethrown.\n\npublic class helloexception {\n\n  static final string task_list = "helloexception";\n\n  public interface greetingworkflow {\n    @workflowmethod\n    string getgreeting(string name);\n  }\n\n  public interface greetingchild {\n    @workflowmethod\n    string composegreeting(string greeting, string name);\n  }\n\n  public interface greetingactivities {\n    string composegreeting(string greeting, string name);\n  }\n\n  /** parent implementation that calls greetingchild#composegreeting.**/\n  public static class greetingworkflowimpl implements greetingworkflow {\n\n    @override\n    public string getgreeting(string name) {\n      greetingchild child = workflow.newchildworkflowstub(greetingchild.class);\n      return child.composegreeting("hello", name);\n    }\n  }\n\n  /** child workflow implementation.**/\n  public static class greetingchildimpl implements greetingchild {\n    private final greetingactivities activities =\n        workflow.newactivitystub(\n            greetingactivities.class,\n            new activityoptions.builder()\n                .setscheduletoclosetimeout(duration.ofseconds(10))\n                .build());\n\n    @override\n    public string composegreeting(string greeting, string name) {\n      return activities.composegreeting(greeting, name);\n    }\n  }\n\n  static class greetingactivitiesimpl implements greetingactivities {\n    @override\n    public string composegreeting(string greeting, string name) {\n      try {\n        throw new ioexception(greeting + " " + name + "!");\n      } catch (ioexception e) {\n        // wrapping the exception as checked exceptions in activity and workflow interface methods\n        // are prohibited.\n        // it will be unwrapped and attached as a cause to the activityfailureexception.\n        throw workflow.wrap(e);\n      }\n    }\n  }\n\n  public static void main(string[] args) {\n     // get a new client\n     // note: to set a different options, you can do like this:\n     // clientoptions.newbuilder().setrpctimeout(5 * 1000).build();\n     workflowclient workflowclient =\n         workflowclient.newinstance(\n             new workflowservicetchannel(clientoptions.defaultinstance()),\n             workflowclientoptions.newbuilder().setdomain(domain).build());\n     // get worker to poll the task list.\n     workerfactory factory = workerfactory.newinstance(workflowclient);\n     worker worker = factory.newworker(task_list);\n     worker.registerworkflowimplementationtypes(greetingworkflowimpl.class, greetingchildimpl.class);\n     worker.registeractivitiesimplementations(new greetingactivitiesimpl());\n     factory.start();\n\n     workflowoptions workflowoptions =\n         new workflowoptions.builder()\n             .settasklist(task_list)\n             .setexecutionstarttoclosetimeout(duration.ofseconds(30))\n             .build();\n     greetingworkflow workflow =\n         workflowclient.newworkflowstub(greetingworkflow.class, workflowoptions);\n     try {\n       workflow.getgreeting("world");\n       throw new illegalstateexception("unreachable");\n     } catch (workflowexception e) {\n       throwable cause = throwables.getrootcause(e);\n       // prints "hello world!"\n       system.out.println(cause.getmessage());\n       system.out.println("\\nstack trace:\\n" + throwables.getstacktraceasstring(e));\n     }\n     system.exit(0);\n   }\n   \n}\n\n\nthe code is slightly different if you are using client version prior to 3.0.0:\n\npublic static void main(string[] args) {\n  worker.factory factory = new worker.factory(domain);\n  worker worker = factory.newworker(task_list);\n  worker.registerworkflowimplementationtypes(greetingworkflowimpl.class, greetingchildimpl.class);\n  worker.registeractivitiesimplementations(new greetingactivitiesimpl());\n  factory.start();\n\n  workflowclient workflowclient = workflowclient.newinstance(domain);\n  workflowoptions workflowoptions =\n      new workflowoptions.builder()\n          .settasklist(task_list)\n          .setexecutionstarttoclosetimeout(duration.ofseconds(30))\n          .build();\n  greetingworkflow workflow =\n      workflowclient.newworkflowstub(greetingworkflow.class, workflowoptions);\n  try {\n    workflow.getgreeting("world");\n    throw new illegalstateexception("unreachable");\n  } catch (workflowexception e) {\n    throwable cause = throwables.getrootcause(e);\n    // prints "hello world!"\n    system.out.println(cause.getmessage());\n    system.out.println("\\nstack trace:\\n" + throwables.getstacktraceasstring(e));\n  }\n  system.exit(0);\n}\n',charsets:{}},{title:"Child workflows",frontmatter:{layout:"default",title:"Child workflows",permalink:"/docs/java-client/child-workflows",readingShow:"top"},regularPath:"/docs/04-java-client/13-child-workflows.html",relativePath:"docs/04-java-client/13-child-workflows.md",key:"v-272408a2",path:"/docs/java-client/child-workflows/",codeSwitcherOptions:{},headersStr:null,content:'# Child workflows\n\nBesides , a can also orchestrate other .\n\nworkflow.ExecuteChildWorkflow enables the scheduling of other from within a \'s implementation. The parent has the ability to monitor and impact the lifecycle of the child , similar to the way it does for an that it invoked.\n\npublic static class GreetingWorkflowImpl implements GreetingWorkflow {\n\n  @Override\n  public String getGreeting(String name) {\n    // Workflows are stateful. So a new stub must be created for each new child.\n    GreetingChild child = Workflow.newChildWorkflowStub(GreetingChild.class);\n\n    // This is a non blocking call that returns immediately.\n    // Use child.composeGreeting("Hello", name) to call synchronously.\n    Promise<String> greeting = Async.function(child::composeGreeting, "Hello", name);\n    // Do something else here.\n    return greeting.get(); // blocks waiting for the child to complete.\n  }\n\n  // This example shows how parent workflow return right after starting a child workflow,\n  // and let the child run itself.\n  private String demoAsyncChildRun(String name) {\n    GreetingChild child = Workflow.newChildWorkflowStub(GreetingChild.class);\n    // non blocking call that initiated child workflow\n    Async.function(child::composeGreeting, "Hello", name);\n    // instead of using greeting.get() to block till child complete,\n    // sometimes we just want to return parent immediately and keep child running\n    Promise<WorkflowExecution> childPromise = Workflow.getWorkflowExecution(child);\n    childPromise.get(); // block until child started,\n    // otherwise child may not start because parent complete first.\n    return "let child run, parent just return";\n  }\n}\n\n\nWorkflow.newChildWorkflowStub returns a client-side stub that implements a child interface. It takes a child type and optional child options as arguments. options may be needed to override the timeouts and if they differ from the ones defined in the @WorkflowMethod annotation or parent .\n\nThe first call to the child stub must always be to a method annotated with @WorkflowMethod. Similar to , a call can be made synchronous or asynchronous by using Async#function or Async#procedure. The synchronous call blocks until a child completes. The asynchronous call returns a Promise that can be used to wait for the completion. After an async call returns the stub, it can be used to send to the child by calling methods annotated with @SignalMethod. a child by calling methods annotated with @QueryMethod from within code is not supported. However, can be done from using the provided WorkflowClient stub.\n\nRunning two children in parallel:\n\npublic static class GreetingWorkflowImpl implements GreetingWorkflow {\n\n    @Override\n    public String getGreeting(String name) {\n\n        // Workflows are stateful, so a new stub must be created for each new child.\n        GreetingChild child1 = Workflow.newChildWorkflowStub(GreetingChild.class);\n        Promise<String> greeting1 = Async.function(child1::composeGreeting, "Hello", name);\n\n        // Both children will run concurrently.\n        GreetingChild child2 = Workflow.newChildWorkflowStub(GreetingChild.class);\n        Promise<String> greeting2 = Async.function(child2::composeGreeting, "Bye", name);\n\n        // Do something else here.\n        ...\n        return "First: " + greeting1.get() + ", second: " + greeting2.get();\n    }\n}\n\n\nTo send a to a child, call a method annotated with @SignalMethod:\n\npublic interface GreetingChild {\n    @WorkflowMethod\n    String composeGreeting(String greeting, String name);\n\n    @SignalMethod\n    void updateName(String name);\n}\n\npublic static class GreetingWorkflowImpl implements GreetingWorkflow {\n\n    @Override\n    public String getGreeting(String name) {\n        GreetingChild child = Workflow.newChildWorkflowStub(GreetingChild.class);\n        Promise<String> greeting = Async.function(child::composeGreeting, "Hello", name);\n        child.updateName("Cadence");\n        return greeting.get();\n    }\n}\n\n\nCalling methods annotated with @QueryMethod is not allowed from within code.',normalizedContent:'# child workflows\n\nbesides , a can also orchestrate other .\n\nworkflow.executechildworkflow enables the scheduling of other from within a \'s implementation. the parent has the ability to monitor and impact the lifecycle of the child , similar to the way it does for an that it invoked.\n\npublic static class greetingworkflowimpl implements greetingworkflow {\n\n  @override\n  public string getgreeting(string name) {\n    // workflows are stateful. so a new stub must be created for each new child.\n    greetingchild child = workflow.newchildworkflowstub(greetingchild.class);\n\n    // this is a non blocking call that returns immediately.\n    // use child.composegreeting("hello", name) to call synchronously.\n    promise<string> greeting = async.function(child::composegreeting, "hello", name);\n    // do something else here.\n    return greeting.get(); // blocks waiting for the child to complete.\n  }\n\n  // this example shows how parent workflow return right after starting a child workflow,\n  // and let the child run itself.\n  private string demoasyncchildrun(string name) {\n    greetingchild child = workflow.newchildworkflowstub(greetingchild.class);\n    // non blocking call that initiated child workflow\n    async.function(child::composegreeting, "hello", name);\n    // instead of using greeting.get() to block till child complete,\n    // sometimes we just want to return parent immediately and keep child running\n    promise<workflowexecution> childpromise = workflow.getworkflowexecution(child);\n    childpromise.get(); // block until child started,\n    // otherwise child may not start because parent complete first.\n    return "let child run, parent just return";\n  }\n}\n\n\nworkflow.newchildworkflowstub returns a client-side stub that implements a child interface. it takes a child type and optional child options as arguments. options may be needed to override the timeouts and if they differ from the ones defined in the @workflowmethod annotation or parent .\n\nthe first call to the child stub must always be to a method annotated with @workflowmethod. similar to , a call can be made synchronous or asynchronous by using async#function or async#procedure. the synchronous call blocks until a child completes. the asynchronous call returns a promise that can be used to wait for the completion. after an async call returns the stub, it can be used to send to the child by calling methods annotated with @signalmethod. a child by calling methods annotated with @querymethod from within code is not supported. however, can be done from using the provided workflowclient stub.\n\nrunning two children in parallel:\n\npublic static class greetingworkflowimpl implements greetingworkflow {\n\n    @override\n    public string getgreeting(string name) {\n\n        // workflows are stateful, so a new stub must be created for each new child.\n        greetingchild child1 = workflow.newchildworkflowstub(greetingchild.class);\n        promise<string> greeting1 = async.function(child1::composegreeting, "hello", name);\n\n        // both children will run concurrently.\n        greetingchild child2 = workflow.newchildworkflowstub(greetingchild.class);\n        promise<string> greeting2 = async.function(child2::composegreeting, "bye", name);\n\n        // do something else here.\n        ...\n        return "first: " + greeting1.get() + ", second: " + greeting2.get();\n    }\n}\n\n\nto send a to a child, call a method annotated with @signalmethod:\n\npublic interface greetingchild {\n    @workflowmethod\n    string composegreeting(string greeting, string name);\n\n    @signalmethod\n    void updatename(string name);\n}\n\npublic static class greetingworkflowimpl implements greetingworkflow {\n\n    @override\n    public string getgreeting(string name) {\n        greetingchild child = workflow.newchildworkflowstub(greetingchild.class);\n        promise<string> greeting = async.function(child::composegreeting, "hello", name);\n        child.updatename("cadence");\n        return greeting.get();\n    }\n}\n\n\ncalling methods annotated with @querymethod is not allowed from within code.',charsets:{}},{title:"Continue As New",frontmatter:{layout:"default",title:"Continue As New",permalink:"/docs/java-client/continue-as-new",readingShow:"top"},regularPath:"/docs/04-java-client/15-continue-as-new.html",relativePath:"docs/04-java-client/15-continue-as-new.md",key:"v-68ae0de4",path:"/docs/java-client/continue-as-new/",codeSwitcherOptions:{},headersStr:null,content:'# Continue as new\n\nthat need to rerun periodically could naively be implemented as a big for loop with a sleep where the entire logic of the is inside the body of the for loop. The problem with this approach is that the history for that will keep growing to a point where it reaches the maximum size enforced by the service.\n\nContinueAsNew is the low level construct that enables implementing such without the risk of failures down the road. The operation atomically completes the current execution and starts a new execution of the with the same . The new execution will not carry over any history from the old execution.\n\n@Override\npublic void greet(String name) {\n  activities.greet("Hello " + name + "!");\n  Workflow.continueAsNew(name);\n}\n\n',normalizedContent:'# continue as new\n\nthat need to rerun periodically could naively be implemented as a big for loop with a sleep where the entire logic of the is inside the body of the for loop. the problem with this approach is that the history for that will keep growing to a point where it reaches the maximum size enforced by the service.\n\ncontinueasnew is the low level construct that enables implementing such without the risk of failures down the road. the operation atomically completes the current execution and starts a new execution of the with the same . the new execution will not carry over any history from the old execution.\n\n@override\npublic void greet(string name) {\n  activities.greet("hello " + name + "!");\n  workflow.continueasnew(name);\n}\n\n',charsets:{}},{title:"Side Effect",frontmatter:{layout:"default",title:"Side Effect",permalink:"/docs/java-client/side-effect",readingShow:"top"},regularPath:"/docs/04-java-client/16-side-effect.html",relativePath:"docs/04-java-client/16-side-effect.md",key:"v-53d65f58",path:"/docs/java-client/side-effect/",headers:[{level:2,title:"Mutable Side Effect",slug:"mutable-side-effect",normalizedTitle:"mutable side effect",charIndex:1563}],codeSwitcherOptions:{},headersStr:"Mutable Side Effect",content:"# Side Effect\n\nSide Effect allow workflow executes the provided function once, records its result into the workflow history. The recorded result on history will be returned without executing the provided function during replay. This guarantees the deterministic requirement for workflow as the exact same result will be returned in replay. Common use case is to run some short non-deterministic code in workflow, like getting random number. The only way to fail SideEffect is to panic which causes decision task failure. The decision task after timeout is rescheduled and re-executed giving SideEffect another chance to succeed.\n\n!!Caution: do not use sideEffect function to modify any workflow state. Only use the SideEffect's return value. For example this code is BROKEN:\n\nBad example:\n\n AtomicInteger random = new AtomicInteger();\n Workflow.sideEffect(() -> {\n        random.set(random.nextInt(100));\n        return null;\n });\n // random will always be 0 in replay, thus this code is non-deterministic\n if random.get() < 50 {\n        ....\n } else {\n        ....\n }\n\n\nOn replay the provided function is not executed, the random will always be 0, and the workflow could takes a different path breaking the determinism.\n\nHere is the correct way to use sideEffect:\n\nGood example:\n\n int random = Workflow.sideEffect(Integer.class, () -> random.nextInt(100));\n if random < 50 {\n        ....\n } else {\n        ....\n }\n\n\nIf function throws any exception it is not delivered to the workflow code. It is wrapped in an Error causing failure of the current decision.\n\n\n# Mutable Side Effect\n\nMutableSideEffect is similar to sideEffect, in allowing calls of non-deterministic functions from workflow code. The difference is that every sideEffect call in non-replay mode results in a new marker event recorded into the history. However, mutableSideEffect only records a new marker if a value has changed. During the replay, mutableSideEffect will not execute the function again, but it will return the exact same value as it was returning during the non-replay run.\n\nOne good use case of mutableSideEffect is to access a dynamically changing config without breaking determinism. Even if called very frequently the config value is recorded only when it changes not causing any performance degradation due to a large history size.\n\n!!Caution: do not use mutableSideEffect function to modify any workflow sate. Only use the mutableSideEffect's return value.\n\nIf function throws any exception it is not delivered to the workflow code. It is wrapped in an Error causing failure of the current decision.",normalizedContent:"# side effect\n\nside effect allow workflow executes the provided function once, records its result into the workflow history. the recorded result on history will be returned without executing the provided function during replay. this guarantees the deterministic requirement for workflow as the exact same result will be returned in replay. common use case is to run some short non-deterministic code in workflow, like getting random number. the only way to fail sideeffect is to panic which causes decision task failure. the decision task after timeout is rescheduled and re-executed giving sideeffect another chance to succeed.\n\n!!caution: do not use sideeffect function to modify any workflow state. only use the sideeffect's return value. for example this code is broken:\n\nbad example:\n\n atomicinteger random = new atomicinteger();\n workflow.sideeffect(() -> {\n        random.set(random.nextint(100));\n        return null;\n });\n // random will always be 0 in replay, thus this code is non-deterministic\n if random.get() < 50 {\n        ....\n } else {\n        ....\n }\n\n\non replay the provided function is not executed, the random will always be 0, and the workflow could takes a different path breaking the determinism.\n\nhere is the correct way to use sideeffect:\n\ngood example:\n\n int random = workflow.sideeffect(integer.class, () -> random.nextint(100));\n if random < 50 {\n        ....\n } else {\n        ....\n }\n\n\nif function throws any exception it is not delivered to the workflow code. it is wrapped in an error causing failure of the current decision.\n\n\n# mutable side effect\n\nmutablesideeffect is similar to sideeffect, in allowing calls of non-deterministic functions from workflow code. the difference is that every sideeffect call in non-replay mode results in a new marker event recorded into the history. however, mutablesideeffect only records a new marker if a value has changed. during the replay, mutablesideeffect will not execute the function again, but it will return the exact same value as it was returning during the non-replay run.\n\none good use case of mutablesideeffect is to access a dynamically changing config without breaking determinism. even if called very frequently the config value is recorded only when it changes not causing any performance degradation due to a large history size.\n\n!!caution: do not use mutablesideeffect function to modify any workflow sate. only use the mutablesideeffect's return value.\n\nif function throws any exception it is not delivered to the workflow code. it is wrapped in an error causing failure of the current decision.",charsets:{}},{title:"Testing",frontmatter:{layout:"default",title:"Testing",permalink:"/docs/java-client/testing",readingShow:"top"},regularPath:"/docs/04-java-client/17-testing.html",relativePath:"docs/04-java-client/17-testing.md",key:"v-56629f80",path:"/docs/java-client/testing/",headers:[{level:2,title:"Workflow Test Environment",slug:"workflow-test-environment",normalizedTitle:"workflow test environment",charIndex:833}],codeSwitcherOptions:{},headersStr:"Workflow Test Environment",content:'# Activity Test Environment\n\nTestActivityEnvironment is the helper class for unit testing activity implementations. Supports calls to Activity methods from the tested activities. An example test:\n\nSee full example here.\n\n\n   public interface TestActivity {\n     String activity1(String input);\n   }\n\n   private static class ActivityImpl implements TestActivity {\n     @Override\n     public String activity1(String input) {\n       return Activity.getTask().getActivityType().getName() + "-" + input;\n     }\n   }\n\n   @Test\n   public void testSuccess() {\n     testEnvironment.registerActivitiesImplementations(new ActivityImpl());\n     TestActivity activity = testEnvironment.newActivityStub(TestActivity.class);\n     String result = activity.activity1("input1");\n     assertEquals("TestActivity::activity1-input1", result);\n   }\n\n\n\n\n# Workflow Test Environment\n\nTestWorkflowEnvironment provides workflow unit testing capabilities.\n\nTesting the workflow code is hard as it might be potentially very long running. The included in-memory implementation of the Cadence service supports an automatic time skipping. Anytime a workflow under the test as well as the unit test code are waiting on a timer (or sleep) the internal service time is automatically advanced to the nearest time that unblocks one of the waiting threads. This way a workflow that runs in production for months is unit tested in milliseconds. Here is an example of a test that executes in a few milliseconds instead of over two hours that are needed for the workflow to complete.\n\nSee full example here.\n\npublic class SignaledWorkflowImpl implements SignaledWorkflow {\n  private String signalInput;\n\n  @Override\n  public String workflow1(String input) {\n    Workflow.sleep(Duration.ofHours(1));\n    Workflow.await(() -> signalInput != null);\n    Workflow.sleep(Duration.ofHours(1));\n    return signalInput + "-" + input;\n  }\n\n  @Override\n  public void processSignal(String input) {\n    signalInput = input;\n }\n}\n\n@Test\npublic void testSignal() throws ExecutionException, InterruptedException {\n    // Get a workflow stub using the same task list the worker uses.\n    WorkflowOptions workflowOptions =\n        new WorkflowOptions.Builder()\n            .setTaskList(HelloSignal.TASK_LIST)\n            .setExecutionStartToCloseTimeout(Duration.ofDays(30))\n            .build();\n    GreetingWorkflow workflow =\n        workflowClient.newWorkflowStub(GreetingWorkflow.class, workflowOptions);\n\n    // Start workflow asynchronously to not use another thread to signal.\n    WorkflowClient.start(workflow::getGreetings);\n\n    // After start for getGreeting returns, the workflow is guaranteed to be started.\n    // So we can send a signal to it using workflow stub immediately.\n    // But just to demonstrate the unit testing of a long running workflow adding a long sleep here.\n    testEnv.sleep(Duration.ofDays(1));\n    // This workflow keeps receiving signals until exit is called\n    workflow.waitForName("World");\n    workflow.waitForName("Universe");\n    workflow.exit();\n    // Calling synchronous getGreeting after workflow has started reconnects to the existing\n    // workflow and\n    // blocks until result is available. Note that this behavior assumes that WorkflowOptions are\n    // not configured\n    // with WorkflowIdReusePolicy.AllowDuplicate. In that case the call would fail with\n    // WorkflowExecutionAlreadyStartedException.\n    List<String> greetings = workflow.getGreetings();\n    assertEquals(2, greetings.size());\n    assertEquals("Hello World!", greetings.get(0));\n    assertEquals("Hello Universe!", greetings.get(1));\n}\n',normalizedContent:'# activity test environment\n\ntestactivityenvironment is the helper class for unit testing activity implementations. supports calls to activity methods from the tested activities. an example test:\n\nsee full example here.\n\n\n   public interface testactivity {\n     string activity1(string input);\n   }\n\n   private static class activityimpl implements testactivity {\n     @override\n     public string activity1(string input) {\n       return activity.gettask().getactivitytype().getname() + "-" + input;\n     }\n   }\n\n   @test\n   public void testsuccess() {\n     testenvironment.registeractivitiesimplementations(new activityimpl());\n     testactivity activity = testenvironment.newactivitystub(testactivity.class);\n     string result = activity.activity1("input1");\n     assertequals("testactivity::activity1-input1", result);\n   }\n\n\n\n\n# workflow test environment\n\ntestworkflowenvironment provides workflow unit testing capabilities.\n\ntesting the workflow code is hard as it might be potentially very long running. the included in-memory implementation of the cadence service supports an automatic time skipping. anytime a workflow under the test as well as the unit test code are waiting on a timer (or sleep) the internal service time is automatically advanced to the nearest time that unblocks one of the waiting threads. this way a workflow that runs in production for months is unit tested in milliseconds. here is an example of a test that executes in a few milliseconds instead of over two hours that are needed for the workflow to complete.\n\nsee full example here.\n\npublic class signaledworkflowimpl implements signaledworkflow {\n  private string signalinput;\n\n  @override\n  public string workflow1(string input) {\n    workflow.sleep(duration.ofhours(1));\n    workflow.await(() -> signalinput != null);\n    workflow.sleep(duration.ofhours(1));\n    return signalinput + "-" + input;\n  }\n\n  @override\n  public void processsignal(string input) {\n    signalinput = input;\n }\n}\n\n@test\npublic void testsignal() throws executionexception, interruptedexception {\n    // get a workflow stub using the same task list the worker uses.\n    workflowoptions workflowoptions =\n        new workflowoptions.builder()\n            .settasklist(hellosignal.task_list)\n            .setexecutionstarttoclosetimeout(duration.ofdays(30))\n            .build();\n    greetingworkflow workflow =\n        workflowclient.newworkflowstub(greetingworkflow.class, workflowoptions);\n\n    // start workflow asynchronously to not use another thread to signal.\n    workflowclient.start(workflow::getgreetings);\n\n    // after start for getgreeting returns, the workflow is guaranteed to be started.\n    // so we can send a signal to it using workflow stub immediately.\n    // but just to demonstrate the unit testing of a long running workflow adding a long sleep here.\n    testenv.sleep(duration.ofdays(1));\n    // this workflow keeps receiving signals until exit is called\n    workflow.waitforname("world");\n    workflow.waitforname("universe");\n    workflow.exit();\n    // calling synchronous getgreeting after workflow has started reconnects to the existing\n    // workflow and\n    // blocks until result is available. note that this behavior assumes that workflowoptions are\n    // not configured\n    // with workflowidreusepolicy.allowduplicate. in that case the call would fail with\n    // workflowexecutionalreadystartedexception.\n    list<string> greetings = workflow.getgreetings();\n    assertequals(2, greetings.size());\n    assertequals("hello world!", greetings.get(0));\n    assertequals("hello universe!", greetings.get(1));\n}\n',charsets:{}},{title:"Creating workflows",frontmatter:{layout:"default",title:"Creating workflows",permalink:"/docs/go-client/create-workflows",readingShow:"top"},regularPath:"/docs/05-go-client/02-create-workflows.html",relativePath:"docs/05-go-client/02-create-workflows.md",key:"v-861efabc",path:"/docs/go-client/create-workflows/",headers:[{level:2,title:"Overview",slug:"overview",normalizedTitle:"overview",charIndex:968},{level:2,title:"Declaration",slug:"declaration",normalizedTitle:"declaration",charIndex:1991},{level:2,title:"Implementation",slug:"implementation",normalizedTitle:"implementation",charIndex:934},{level:3,title:"Special Cadence client library functions and types",slug:"special-cadence-client-library-functions-and-types",normalizedTitle:"special cadence client library functions and types",charIndex:4738},{level:3,title:"Failing a workflow",slug:"failing-a-workflow",normalizedTitle:"failing a workflow",charIndex:5529},{level:2,title:"Registration",slug:"registration",normalizedTitle:"registration",charIndex:5664}],codeSwitcherOptions:{},headersStr:"Overview Declaration Implementation Special Cadence client library functions and types Failing a workflow Registration",content:'# Creating workflows\n\nThe is the implementation of the coordination logic. The Cadence programming framework (aka client library) allows you to write the coordination logic as simple procedural code that uses standard Go data modeling. The client library takes care of the communication between the service and the Cadence service, and ensures state persistence between even in case of failures. Furthermore, any particular execution is not tied to a particular machine. Different steps of the coordination logic can end up executing on different instances, with the framework ensuring that the necessary state is recreated on the executing the step.\n\nHowever, in order to facilitate this operational model, both the Cadence programming framework and the managed service impose some requirements and restrictions on the implementation of the coordination logic. The details of these requirements and restrictions are described in the Implementation section below.\n\n\n# Overview\n\nThe sample code below shows a simple implementation of a that executes one . The also passes the sole parameter it receives as part of its initialization as a parameter to the .\n\npackage sample\n\nimport (\n    "time"\n\n    "go.uber.org/cadence/workflow"\n)\n\nfunc init() {\n    workflow.Register(SimpleWorkflow)\n}\n\nfunc SimpleWorkflow(ctx workflow.Context, value string) error {\n    ao := workflow.ActivityOptions{\n        TaskList:               "sampleTaskList",\n        ScheduleToCloseTimeout: time.Second * 60,\n        ScheduleToStartTimeout: time.Second * 60,\n        StartToCloseTimeout:    time.Second * 60,\n        HeartbeatTimeout:       time.Second * 10,\n        WaitForCancellation:    false,\n    }\n    ctx = workflow.WithActivityOptions(ctx, ao)\n\n    future := workflow.ExecuteActivity(ctx, SimpleActivity, value)\n    var result string\n    if err := future.Get(ctx, &result); err != nil {\n        return err\n    }\n    workflow.GetLogger(ctx).Info("Done", zap.String("result", result))\n    return nil\n}\n\n\n\n# Declaration\n\nIn the Cadence programing model, a is implemented with a function. The function declaration specifies the parameters the accepts as well as any values it might return.\n\nfunc SimpleWorkflow(ctx workflow.Context, value string) error\n\n\nLet’s deconstruct the declaration above:\n\n * The first parameter to the function is ctx workflow.Context. This is a required parameter for all functions and is used by the Cadence client library to pass execution context. Virtually all the client library functions that are callable from the functions require this ctx parameter. This context parameter is the same concept as the standard context.Context provided by Go. The only difference between workflow.Context and context.Context is that the Done() function in workflow.Context returns workflow.Channel instead the standard go chan.\n * The second parameter, string, is a custom parameter that can be used to pass data into the on start. A can have one or more such parameters. All parameters to a function must be serializable, which essentially means that params can’t be channels, functions, variadic, or unsafe pointers.\n * Since it only declares error as the return value, this means that the does not return a value. The error return value is used to indicate an error was encountered during execution and the should be terminated.\n\n\n# Implementation\n\nIn order to support the synchronous and sequential programming model for the implementation, there are certain restrictions and requirements on how the implementation must behave in order to guarantee correctness. The requirements are that:\n\n * Execution must be deterministic\n * Execution must be idempotent\n\nA straightforward way to think about these requirements is that the code is as follows:\n\n * code can only read and manipulate local state or state received as return values from Cadence client library functions.\n * code should not affect changes in external systems other than through invocation of .\n * code should interact with time only through the functions provided by the Cadence client library (i.e. workflow.Now(), workflow.Sleep()).\n * code should not create and interact with goroutines directly, it should instead use the functions provided by the Cadence client library (i.e., workflow.Go() instead of go, workflow.Channel instead of chan, workflow.Selector instead of select).\n * code should do all logging via the logger provided by the Cadence client library (i.e., workflow.GetLogger()).\n * code should not iterate over maps using range because the order of map iteration is randomized.\n\nNow that we have laid the ground rules, we can take a look at some of the special functions and types used for writing Cadence and how to implement some common patterns.\n\n\n# Special Cadence client library functions and types\n\nThe Cadence client library provides a number of functions and types as alternatives to some native Go functions and types. Usage of these replacement functions/types is necessary in order to ensure that the code execution is deterministic and repeatable within an execution context.\n\nCoroutine related constructs:\n\n * workflow.Go : This is a replacement for the the go statement.\n * workflow.Channel : This is a replacement for the native chan type. Cadence provides support for both buffered and unbuffered channels.\n * workflow.Selector : This is a replacement for the select statement.\n\nTime related functions:\n\n * workflow.Now() : This is a replacement for time.Now().\n * workflow.Sleep() : This is a replacement for time.Sleep().\n\n\n# Failing a workflow\n\nTo mark a as failed, all that needs to happen is for the function to return an error via the err return value.\n\n\n# Registration\n\nFor some client code to be able to invoke a type, the process needs to be aware of all the implementations it has access to. A is registered with the following call:\n\nworkflow.Register(SimpleWorkflow)\n\n\nThis call essentially creates an in-memory mapping inside the process between the fully qualified function name and the implementation. It is safe to call this registration method from an init() function. If the receives for a type it does not know, it will fail that . However, the failure of the will not cause the entire to fail.',normalizedContent:'# creating workflows\n\nthe is the implementation of the coordination logic. the cadence programming framework (aka client library) allows you to write the coordination logic as simple procedural code that uses standard go data modeling. the client library takes care of the communication between the service and the cadence service, and ensures state persistence between even in case of failures. furthermore, any particular execution is not tied to a particular machine. different steps of the coordination logic can end up executing on different instances, with the framework ensuring that the necessary state is recreated on the executing the step.\n\nhowever, in order to facilitate this operational model, both the cadence programming framework and the managed service impose some requirements and restrictions on the implementation of the coordination logic. the details of these requirements and restrictions are described in the implementation section below.\n\n\n# overview\n\nthe sample code below shows a simple implementation of a that executes one . the also passes the sole parameter it receives as part of its initialization as a parameter to the .\n\npackage sample\n\nimport (\n    "time"\n\n    "go.uber.org/cadence/workflow"\n)\n\nfunc init() {\n    workflow.register(simpleworkflow)\n}\n\nfunc simpleworkflow(ctx workflow.context, value string) error {\n    ao := workflow.activityoptions{\n        tasklist:               "sampletasklist",\n        scheduletoclosetimeout: time.second * 60,\n        scheduletostarttimeout: time.second * 60,\n        starttoclosetimeout:    time.second * 60,\n        heartbeattimeout:       time.second * 10,\n        waitforcancellation:    false,\n    }\n    ctx = workflow.withactivityoptions(ctx, ao)\n\n    future := workflow.executeactivity(ctx, simpleactivity, value)\n    var result string\n    if err := future.get(ctx, &result); err != nil {\n        return err\n    }\n    workflow.getlogger(ctx).info("done", zap.string("result", result))\n    return nil\n}\n\n\n\n# declaration\n\nin the cadence programing model, a is implemented with a function. the function declaration specifies the parameters the accepts as well as any values it might return.\n\nfunc simpleworkflow(ctx workflow.context, value string) error\n\n\nlet’s deconstruct the declaration above:\n\n * the first parameter to the function is ctx workflow.context. this is a required parameter for all functions and is used by the cadence client library to pass execution context. virtually all the client library functions that are callable from the functions require this ctx parameter. this context parameter is the same concept as the standard context.context provided by go. the only difference between workflow.context and context.context is that the done() function in workflow.context returns workflow.channel instead the standard go chan.\n * the second parameter, string, is a custom parameter that can be used to pass data into the on start. a can have one or more such parameters. all parameters to a function must be serializable, which essentially means that params can’t be channels, functions, variadic, or unsafe pointers.\n * since it only declares error as the return value, this means that the does not return a value. the error return value is used to indicate an error was encountered during execution and the should be terminated.\n\n\n# implementation\n\nin order to support the synchronous and sequential programming model for the implementation, there are certain restrictions and requirements on how the implementation must behave in order to guarantee correctness. the requirements are that:\n\n * execution must be deterministic\n * execution must be idempotent\n\na straightforward way to think about these requirements is that the code is as follows:\n\n * code can only read and manipulate local state or state received as return values from cadence client library functions.\n * code should not affect changes in external systems other than through invocation of .\n * code should interact with time only through the functions provided by the cadence client library (i.e. workflow.now(), workflow.sleep()).\n * code should not create and interact with goroutines directly, it should instead use the functions provided by the cadence client library (i.e., workflow.go() instead of go, workflow.channel instead of chan, workflow.selector instead of select).\n * code should do all logging via the logger provided by the cadence client library (i.e., workflow.getlogger()).\n * code should not iterate over maps using range because the order of map iteration is randomized.\n\nnow that we have laid the ground rules, we can take a look at some of the special functions and types used for writing cadence and how to implement some common patterns.\n\n\n# special cadence client library functions and types\n\nthe cadence client library provides a number of functions and types as alternatives to some native go functions and types. usage of these replacement functions/types is necessary in order to ensure that the code execution is deterministic and repeatable within an execution context.\n\ncoroutine related constructs:\n\n * workflow.go : this is a replacement for the the go statement.\n * workflow.channel : this is a replacement for the native chan type. cadence provides support for both buffered and unbuffered channels.\n * workflow.selector : this is a replacement for the select statement.\n\ntime related functions:\n\n * workflow.now() : this is a replacement for time.now().\n * workflow.sleep() : this is a replacement for time.sleep().\n\n\n# failing a workflow\n\nto mark a as failed, all that needs to happen is for the function to return an error via the err return value.\n\n\n# registration\n\nfor some client code to be able to invoke a type, the process needs to be aware of all the implementations it has access to. a is registered with the following call:\n\nworkflow.register(simpleworkflow)\n\n\nthis call essentially creates an in-memory mapping inside the process between the fully qualified function name and the implementation. it is safe to call this registration method from an init() function. if the receives for a type it does not know, it will fail that . however, the failure of the will not cause the entire to fail.',charsets:{}},{title:"Introduction",frontmatter:{layout:"default",title:"Introduction",permalink:"/docs/java-client",readingShow:"top"},regularPath:"/docs/04-java-client/",relativePath:"docs/04-java-client/index.md",key:"v-c1687e0a",path:"/docs/java-client/",codeSwitcherOptions:{},headersStr:null,content:"# Java client\n\nThe following are important links for the Cadence Java client:\n\n * GitHub project: https://github.com/uber/cadence-java-client\n * Samples: https://github.com/uber/cadence-java-samples\n * JavaDoc documentation: https://www.javadoc.io/doc/com.uber.cadence/cadence-client\n\nAdd cadence-client as a dependency to your pom.xml:\n\n<dependency>\n  <groupId>com.uber.cadence</groupId>\n  <artifactId>cadence-client</artifactId>\n  <version>LATEST.RELEASE.VERSION</version>\n</dependency>\n\n\nor to build.gradle:\n\ndependencies {\n  implementation group: 'com.uber.cadence', name: 'cadence-client', version: 'LATEST.RELEASE.VERSION'\n}\n\n\nIf you are using gradle 6.9 or older, you can use compile group\n\ndependencies {\n  compile group: 'com.uber.cadence', name: 'cadence-client', version: 'LATEST.RELEASE.VERSION'\n}\n\n\nRelease versions are available in the release page",normalizedContent:"# java client\n\nthe following are important links for the cadence java client:\n\n * github project: https://github.com/uber/cadence-java-client\n * samples: https://github.com/uber/cadence-java-samples\n * javadoc documentation: https://www.javadoc.io/doc/com.uber.cadence/cadence-client\n\nadd cadence-client as a dependency to your pom.xml:\n\n<dependency>\n  <groupid>com.uber.cadence</groupid>\n  <artifactid>cadence-client</artifactid>\n  <version>latest.release.version</version>\n</dependency>\n\n\nor to build.gradle:\n\ndependencies {\n  implementation group: 'com.uber.cadence', name: 'cadence-client', version: 'latest.release.version'\n}\n\n\nif you are using gradle 6.9 or older, you can use compile group\n\ndependencies {\n  compile group: 'com.uber.cadence', name: 'cadence-client', version: 'latest.release.version'\n}\n\n\nrelease versions are available in the release page",charsets:{}},{title:"Workflow Replay and Shadowing",frontmatter:{layout:"default",title:"Workflow Replay and Shadowing",permalink:"/docs/java-client/workflow-replay-shadowing",readingShow:"top"},regularPath:"/docs/04-java-client/18-workflow-replay-shadowing.html",relativePath:"docs/04-java-client/18-workflow-replay-shadowing.md",key:"v-7a33750a",path:"/docs/java-client/workflow-replay-shadowing/",headers:[{level:2,title:"Workflow Replayer",slug:"workflow-replayer",normalizedTitle:"workflow replayer",charIndex:469},{level:3,title:"Write a Replay Test",slug:"write-a-replay-test",normalizedTitle:"write a replay test",charIndex:824},{level:3,title:"Sample Replay Test",slug:"sample-replay-test",normalizedTitle:"sample replay test",charIndex:2164},{level:2,title:"Workflow Shadower",slug:"workflow-shadower",normalizedTitle:"workflow shadower",charIndex:491},{level:3,title:"Shadow Options",slug:"shadow-options",normalizedTitle:"shadow options",charIndex:3279},{level:3,title:"Local Shadowing Test",slug:"local-shadowing-test",normalizedTitle:"local shadowing test",charIndex:4976},{level:3,title:"Shadowing Worker",slug:"shadowing-worker",normalizedTitle:"shadowing worker",charIndex:6137}],codeSwitcherOptions:{},headersStr:"Workflow Replayer Write a Replay Test Sample Replay Test Workflow Shadower Shadow Options Local Shadowing Test Shadowing Worker",content:"# Workflow Replay and Shadowing\n\nIn the Versioning section, we mentioned that incompatible changes to workflow definition code could cause non-deterministic issues when processing workflow tasks if versioning is not done correctly. However, it may be hard for you to tell if a particular change is incompatible or not and whether versioning logic is needed. To help you identify incompatible changes and catch them before production traffic is impacted, we implemented Workflow Replayer and Workflow Shadower.\n\n\n# Workflow Replayer\n\nWorkflow Replayer is a testing component for replaying existing workflow histories against a workflow definition. The replaying logic is the same as the one used for processing workflow tasks, so if there's any incompatible changes in the workflow definition, the replay test will fail.\n\n\n# Write a Replay Test\n\n# Step 1: Prepare workflow histories\n\nReplayer can read workflow history from a local json file or fetch it directly from the Cadence server. If you would like to use the first method, you can use the following CLI command, otherwise you can skip to the next step.\n\ncadence --do <domain> workflow show --wid <workflowID> --rid <runID> --of <output file name>\n\n\nThe dumped workflow history will be stored in the file at the path you specified in json format.\n\n# Step 2: Call the replay method\n\nOnce you have the workflow history or have the connection to Cadence server for fetching history, call one of the four replay methods to start the replay test.\n\n// if workflow history has been loaded into memory\nWorkflowReplayer.replayWorkflowExecution(history, MyWorkflowImpl.class);\n\n// if workflow history is stored in a json file\nWorkflowReplayer.replayWorkflowExecutionFromResource(\"workflowHistory.json\", MyWorkflowImpl.class);\n\n// if workflow history is read from a File\nWorkflowReplayer.replayWorkflowExecution(historyFileObject, MyWorkflowImpl.class);\n\n\n# Step 3: Catch returned exception\n\nIf an exception is returned from the replay method, it means there's a incompatible change in the workflow definition and the error message will contain more information regarding where the non-deterministic error happens.\n\n\n# Sample Replay Test\n\nThis sample is also available in our samples repo at here.\n\npublic class HelloActivityReplayTest {\n  @Test\n  public void testReplay() throws Exception {\n    WorkflowReplayer.replayWorkflowExecutionFromResource(\n        \"HelloActivity.json\", HelloActivity.GreetingWorkflowImpl.class);\n  }\n}\n\n\n\n# Workflow Shadower\n\nWorkflow Replayer works well when verifying the compatibility against a small number of workflows histories. If there are lots of workflows in production that need to be verified, dumping all histories manually clearly won't work. Directly fetching histories from cadence server might be a solution, but the time to replay all workflow histories might be too long for a test.\n\nWorkflow Shadower is built on top of Workflow Replayer to address this problem. The basic idea of shadowing is: scan workflows based on the filters you defined, fetch history for each workflow in the scan result from Cadence server and run the replay test. It can be run either as a test to serve local development purpose or as a workflow in your worker to continuously replay production workflows.\n\n\n# Shadow Options\n\nComplete documentation on shadow options which includes default values, accepted values, etc. can be found here. The following sections are just a brief description of each option.\n\n# Scan Filters\n\n * WorkflowQuery: If you are familiar with our advanced visibility query syntax, you can specify a query directly. If specified, all other scan filters must be left empty.\n * WorkflowTypes: A list of workflow Type names.\n * WorkflowStatuses: A list of workflow status.\n * WorkflowStartTimeFilter: Min and max timestamp for workflow start time.\n * WorkflowSamplingRate: Sampling workflows from the scan result before executing the replay test.\n\n# Shadow Exit Condition\n\n * ExpirationInterval: Shadowing will exit when the specified interval has passed.\n * ShadowCount: Shadowing will exit after this number of workflow has been replayed. Note: replay maybe skipped due to errors like can't fetch history, history too short, etc. Skipped workflows won't be taken into account for ShadowCount.\n\n# Shadow Mode\n\n * Normal: Shadowing will complete after all workflows matches WorkflowQuery (after sampling) have been replayed or when exit condition is met.\n * Continuous: A new round of shadowing will be started after all workflows matches WorkflowQuery have been replayed. There will be a 5 min wait period between each round, and currently this wait period is not configurable. Shadowing will complete only when ExitCondition is met. ExitCondition must be specified when using this mode.\n\n# Shadow Concurrency\n\n * Concurrency: workflow replay concurrency. If not specified, it will default to 1. For local shadowing, an error will be returned if a value higher than 1 is specified.\n\n\n# Local Shadowing Test\n\nLocal shadowing test is similar to the replay test. First create a workflow shadower with optional shadow and replay options, then register the workflow that needs to be shadowed. Finally, call the Run method to start the shadowing. The method will return if shadowing has finished or any non-deterministic error is found.\n\nHere's a simple example. The example is also available here.\n\npublic void testShadowing() throws Throwable {\n  IWorkflowService service = new WorkflowServiceTChannel(ClientOptions.defaultInstance());\n\n  ShadowingOptions options = ShadowingOptions\n          .newBuilder()\n          .setDomain(DOMAIN)\n          .setShadowMode(Mode.Normal)\n          .setWorkflowTypes(Lists.newArrayList(\"GreetingWorkflow::getGreeting\"))\n          .setWorkflowStatuses(Lists.newArrayList(WorkflowStatus.OPEN, WorkflowStatus.CLOSED))\n          .setExitCondition(new ExitCondition().setExpirationIntervalInSeconds(60))\n          .build();\n  WorkflowShadower shadower = new WorkflowShadower(service, options, TASK_LIST);\n  shadower.registerWorkflowImplementationTypes(HelloActivity.GreetingWorkflowImpl.class);\n\n  shadower.run();\n}\n\n\n\n# Shadowing Worker\n\nNOTE:\n\n * All shadow workflows are running in one Cadence system domain, and right now, every user domain can only have one shadow workflow at a time.\n * The Cadence server used for scanning and getting workflow history will also be the Cadence server for running your shadow workflow. Currently, there's no way to specify different Cadence servers for hosting the shadowing workflow and scanning/fetching workflow.\n\nYour worker can also be configured to run in shadow mode to run shadow tests as a workflow. This is useful if there's a number of workflows that need to be replayed. Using a workflow can make sure the shadowing won't accidentally fail in the middle and the replay load can be distributed by deploying more shadow mode workers. It can also be incorporated into your deployment process to make sure there's no failed replay checks before deploying your change to production workers.\n\nWhen running in shadow mode, the normal decision worker will be disabled so that it won't update any production workflows. A special shadow activity worker will be started to execute activities for scanning and replaying workflows. The actual shadow workflow logic is controlled by Cadence server and your worker is only responsible for scanning and replaying workflows.\n\nReplay succeed, skipped and failed metrics will be emitted by your worker when executing the shadow workflow and you can monitor those metrics to see if there's any incompatible changes.\n\nTo enable the shadow mode, you can initialize a shadowing worker and pass in the shadowing options.\n\nTo enable the shadowing worker, here is a example. The example is also available here:\n\nWorkflowClient workflowClient =\n  WorkflowClient.newInstance(\n          new WorkflowServiceTChannel(ClientOptions.defaultInstance()),\n          WorkflowClientOptions.newBuilder().setDomain(DOMAIN).build());\n  ShadowingOptions options = ShadowingOptions\n          .newBuilder()\n          .setDomain(DOMAIN)\n          .setShadowMode(Mode.Normal)\n          .setWorkflowTypes(Lists.newArrayList(\"GreetingWorkflow::getGreeting\"))\n          .setWorkflowStatuses(Lists.newArrayList(WorkflowStatus.OPEN, WorkflowStatus.CLOSED))\n          .setExitCondition(new ExitCondition().setExpirationIntervalInSeconds(60))\n          .build();\n\n  ShadowingWorker shadowingWorker = new ShadowingWorker(\n          workflowClient,\n          \"HelloActivity\",\n          WorkerOptions.defaultInstance(),\n          options);\n  shadowingWorker.registerWorkflowImplementationTypes(HelloActivity.GreetingWorkflowImpl.class);\n\tshadowingWorker.start();\n\n\nRegistered workflows will be forwarded to the underlying WorkflowReplayer. DataConverter, WorkflowInterceptorChainFactories, ContextPropagators, and Tracer specified in the worker.Options will also be used as ReplayOptions. Since all shadow workflows are running in one system domain, to avoid conflict, the actual task list name used will be domain-tasklist.",normalizedContent:"# workflow replay and shadowing\n\nin the versioning section, we mentioned that incompatible changes to workflow definition code could cause non-deterministic issues when processing workflow tasks if versioning is not done correctly. however, it may be hard for you to tell if a particular change is incompatible or not and whether versioning logic is needed. to help you identify incompatible changes and catch them before production traffic is impacted, we implemented workflow replayer and workflow shadower.\n\n\n# workflow replayer\n\nworkflow replayer is a testing component for replaying existing workflow histories against a workflow definition. the replaying logic is the same as the one used for processing workflow tasks, so if there's any incompatible changes in the workflow definition, the replay test will fail.\n\n\n# write a replay test\n\n# step 1: prepare workflow histories\n\nreplayer can read workflow history from a local json file or fetch it directly from the cadence server. if you would like to use the first method, you can use the following cli command, otherwise you can skip to the next step.\n\ncadence --do <domain> workflow show --wid <workflowid> --rid <runid> --of <output file name>\n\n\nthe dumped workflow history will be stored in the file at the path you specified in json format.\n\n# step 2: call the replay method\n\nonce you have the workflow history or have the connection to cadence server for fetching history, call one of the four replay methods to start the replay test.\n\n// if workflow history has been loaded into memory\nworkflowreplayer.replayworkflowexecution(history, myworkflowimpl.class);\n\n// if workflow history is stored in a json file\nworkflowreplayer.replayworkflowexecutionfromresource(\"workflowhistory.json\", myworkflowimpl.class);\n\n// if workflow history is read from a file\nworkflowreplayer.replayworkflowexecution(historyfileobject, myworkflowimpl.class);\n\n\n# step 3: catch returned exception\n\nif an exception is returned from the replay method, it means there's a incompatible change in the workflow definition and the error message will contain more information regarding where the non-deterministic error happens.\n\n\n# sample replay test\n\nthis sample is also available in our samples repo at here.\n\npublic class helloactivityreplaytest {\n  @test\n  public void testreplay() throws exception {\n    workflowreplayer.replayworkflowexecutionfromresource(\n        \"helloactivity.json\", helloactivity.greetingworkflowimpl.class);\n  }\n}\n\n\n\n# workflow shadower\n\nworkflow replayer works well when verifying the compatibility against a small number of workflows histories. if there are lots of workflows in production that need to be verified, dumping all histories manually clearly won't work. directly fetching histories from cadence server might be a solution, but the time to replay all workflow histories might be too long for a test.\n\nworkflow shadower is built on top of workflow replayer to address this problem. the basic idea of shadowing is: scan workflows based on the filters you defined, fetch history for each workflow in the scan result from cadence server and run the replay test. it can be run either as a test to serve local development purpose or as a workflow in your worker to continuously replay production workflows.\n\n\n# shadow options\n\ncomplete documentation on shadow options which includes default values, accepted values, etc. can be found here. the following sections are just a brief description of each option.\n\n# scan filters\n\n * workflowquery: if you are familiar with our advanced visibility query syntax, you can specify a query directly. if specified, all other scan filters must be left empty.\n * workflowtypes: a list of workflow type names.\n * workflowstatuses: a list of workflow status.\n * workflowstarttimefilter: min and max timestamp for workflow start time.\n * workflowsamplingrate: sampling workflows from the scan result before executing the replay test.\n\n# shadow exit condition\n\n * expirationinterval: shadowing will exit when the specified interval has passed.\n * shadowcount: shadowing will exit after this number of workflow has been replayed. note: replay maybe skipped due to errors like can't fetch history, history too short, etc. skipped workflows won't be taken into account for shadowcount.\n\n# shadow mode\n\n * normal: shadowing will complete after all workflows matches workflowquery (after sampling) have been replayed or when exit condition is met.\n * continuous: a new round of shadowing will be started after all workflows matches workflowquery have been replayed. there will be a 5 min wait period between each round, and currently this wait period is not configurable. shadowing will complete only when exitcondition is met. exitcondition must be specified when using this mode.\n\n# shadow concurrency\n\n * concurrency: workflow replay concurrency. if not specified, it will default to 1. for local shadowing, an error will be returned if a value higher than 1 is specified.\n\n\n# local shadowing test\n\nlocal shadowing test is similar to the replay test. first create a workflow shadower with optional shadow and replay options, then register the workflow that needs to be shadowed. finally, call the run method to start the shadowing. the method will return if shadowing has finished or any non-deterministic error is found.\n\nhere's a simple example. the example is also available here.\n\npublic void testshadowing() throws throwable {\n  iworkflowservice service = new workflowservicetchannel(clientoptions.defaultinstance());\n\n  shadowingoptions options = shadowingoptions\n          .newbuilder()\n          .setdomain(domain)\n          .setshadowmode(mode.normal)\n          .setworkflowtypes(lists.newarraylist(\"greetingworkflow::getgreeting\"))\n          .setworkflowstatuses(lists.newarraylist(workflowstatus.open, workflowstatus.closed))\n          .setexitcondition(new exitcondition().setexpirationintervalinseconds(60))\n          .build();\n  workflowshadower shadower = new workflowshadower(service, options, task_list);\n  shadower.registerworkflowimplementationtypes(helloactivity.greetingworkflowimpl.class);\n\n  shadower.run();\n}\n\n\n\n# shadowing worker\n\nnote:\n\n * all shadow workflows are running in one cadence system domain, and right now, every user domain can only have one shadow workflow at a time.\n * the cadence server used for scanning and getting workflow history will also be the cadence server for running your shadow workflow. currently, there's no way to specify different cadence servers for hosting the shadowing workflow and scanning/fetching workflow.\n\nyour worker can also be configured to run in shadow mode to run shadow tests as a workflow. this is useful if there's a number of workflows that need to be replayed. using a workflow can make sure the shadowing won't accidentally fail in the middle and the replay load can be distributed by deploying more shadow mode workers. it can also be incorporated into your deployment process to make sure there's no failed replay checks before deploying your change to production workers.\n\nwhen running in shadow mode, the normal decision worker will be disabled so that it won't update any production workflows. a special shadow activity worker will be started to execute activities for scanning and replaying workflows. the actual shadow workflow logic is controlled by cadence server and your worker is only responsible for scanning and replaying workflows.\n\nreplay succeed, skipped and failed metrics will be emitted by your worker when executing the shadow workflow and you can monitor those metrics to see if there's any incompatible changes.\n\nto enable the shadow mode, you can initialize a shadowing worker and pass in the shadowing options.\n\nto enable the shadowing worker, here is a example. the example is also available here:\n\nworkflowclient workflowclient =\n  workflowclient.newinstance(\n          new workflowservicetchannel(clientoptions.defaultinstance()),\n          workflowclientoptions.newbuilder().setdomain(domain).build());\n  shadowingoptions options = shadowingoptions\n          .newbuilder()\n          .setdomain(domain)\n          .setshadowmode(mode.normal)\n          .setworkflowtypes(lists.newarraylist(\"greetingworkflow::getgreeting\"))\n          .setworkflowstatuses(lists.newarraylist(workflowstatus.open, workflowstatus.closed))\n          .setexitcondition(new exitcondition().setexpirationintervalinseconds(60))\n          .build();\n\n  shadowingworker shadowingworker = new shadowingworker(\n          workflowclient,\n          \"helloactivity\",\n          workeroptions.defaultinstance(),\n          options);\n  shadowingworker.registerworkflowimplementationtypes(helloactivity.greetingworkflowimpl.class);\n\tshadowingworker.start();\n\n\nregistered workflows will be forwarded to the underlying workflowreplayer. dataconverter, workflowinterceptorchainfactories, contextpropagators, and tracer specified in the worker.options will also be used as replayoptions. since all shadow workflows are running in one system domain, to avoid conflict, the actual task list name used will be domain-tasklist.",charsets:{}},{title:"Starting workflows",frontmatter:{layout:"default",title:"Starting workflows",permalink:"/docs/go-client/start-workflows",readingShow:"top"},regularPath:"/docs/05-go-client/02.5-starting-workflows.html",relativePath:"docs/05-go-client/02.5-starting-workflows.md",key:"v-76c4aa02",path:"/docs/go-client/start-workflows/",headers:[{level:2,title:"Starting a workflow",slug:"starting-a-workflow",normalizedTitle:"starting a workflow",charIndex:408},{level:2,title:"Jitter Start and Batches of Workflows",slug:"jitter-start-and-batches-of-workflows",normalizedTitle:"jitter start and batches of workflows",charIndex:1321},{level:2,title:"StartWorkflowOptions",slug:"startworkflowoptions",normalizedTitle:"startworkflowoptions",charIndex:791}],codeSwitcherOptions:{},headersStr:"Starting a workflow Jitter Start and Batches of Workflows StartWorkflowOptions",content:'# Starting workflows\n\nStarting workflows can be done from any service that can send requests to the Cadence server. There is no requirement for workflows to be started from the worker services.\n\nGenerally workflows can either be started using a direct reference to the workflow code, or by referring to the registered name of the function. In Workflow Registration we show how to register the workflows.\n\n\n# Starting a workflow\n\nAfter creating a workflow we can start it. This can be done from the cli, but typically we want to start workflow programmatically e.g. from an http handler. We can do this using the client.StartWorkflow function:\n\nimport "go.uber.org/cadence/client"\n\nvar cadenceClient client.Client \n# Initialize cadenceClient\n\ncadenceClient.StartWorkflow(\n    ctx,\n    client.StartWorkflowOptions{\n        TaskList: "workflow-task-list",\n        ExecutionStartToCloseTimeout: 10 * time.Second,\n    },\n    WorkflowFunc,\n    workflowArg1,\n    workflowArg2,\n    workflowArg3,\n    ...\n)\n\n\nThe will start the workflow defined in the function WorkflowFunc, note that for named workflows WorkflowFunc could be replaced by the name e.g. "WorkflowFuncName".\n\nworkflowArg1, workflowArg2, workflowArg3 are arguments to the workflow, as specified in WorkflowFunc, note that the arguments needs to be serializable.\n\n\n# Jitter Start and Batches of Workflows\n\nBelow we list all the startWorkflowOptions, however a particularly useful option is JitterStart.\n\nStarting many workflows at the same time will have Cadence trying to schedule all the workflows immediately. This can result in overloading Cadence and the database backing Cadence, as well as the workers processing the workflows.\n\nThis is especially bad when the workflow starts comes in batches, such as an end of month load. These sudden loads can lead to both Cadence and the workers needing to immediately scale up. Scaling up often takes some time, causing queues in Cadence, delaying the execution of all workflows, potentially causing workflows to timeout.\n\nTo solve this we can start our workflows with JitterStart. JitterStart will start the workflow at a random point between now and now + JitterStart, so if we e.g. start 1000 workflows at 12:00 AM with a JitterStart of 6 hours, the workflows will be randomly started between 12:00 AM and 6:00 PM.\n\nThis makes the sudden load of 1000 workflows much more manageable.\n\nFor many batch-like workloads a random delay is completely acceptable as the batch just needs to be processed e.g. before the end of the day.\n\nAdding a JitterStart of 6 hours in the example above is as simple as adding\n\nJitterStart: 6 * time.Hour,\n\n\nto the options like so,\n\nimport "go.uber.org/cadence/client"\n\nvar cadenceClient client.Client\n# Initialize cadenceClient\n\ncadenceClient.StartWorkflow(\n    ctx,\n    client.StartWorkflowOptions{\n        TaskList: "workflow-task-list",\n        ExecutionStartToCloseTimeout: 10 * time.Second,\n        JitterStart: 6 * time.Hour, // Added JitterStart\n    },\n    WorkflowFunc,\n    workflowArg1,\n    workflowArg2,\n    workflowArg3,\n    ...\n)\n\n\nnow the workflow will start at a random point between now and six hours from now.\n\n\n# StartWorkflowOptions\n\nThe client.StartWorkflowOptions specifies the behavior of this particular workflow. The invocation above only specifies the two mandatory options; TaskList and ExecutionStartToCloseTimeout, all the options are described in the inline documentation:\n\ntype StartWorkflowOptions struct {\n\t// ID - The business identifier of the workflow execution.\n\t// Optional: defaulted to a uuid.\n\tID string\n\n\t// TaskList - The decisions of the workflow are scheduled on this queue.\n\t// This is also the default task list on which activities are scheduled. The workflow author can choose\n\t// to override this using activity options.\n\t// Mandatory: No default.\n\tTaskList string\n\n\t// ExecutionStartToCloseTimeout - The timeout for duration of workflow execution.\n\t// The resolution is seconds.\n\t// Mandatory: No default.\n\tExecutionStartToCloseTimeout time.Duration\n\n\t// DecisionTaskStartToCloseTimeout - The timeout for processing decision task from the time the worker\n\t// pulled this task. If a decision task is lost, it is retried after this timeout.\n\t// The resolution is seconds.\n\t// Optional: defaulted to 10 secs.\n\tDecisionTaskStartToCloseTimeout time.Duration\n\n\t// WorkflowIDReusePolicy - Whether server allow reuse of workflow ID, can be useful\n\t// for dedup logic if set to WorkflowIdReusePolicyRejectDuplicate.\n\t// Optional: defaulted to WorkflowIDReusePolicyAllowDuplicateFailedOnly.\n\tWorkflowIDReusePolicy WorkflowIDReusePolicy\n\n\t// RetryPolicy - Optional retry policy for workflow. If a retry policy is specified, in case of workflow failure\n\t// server will start new workflow execution if needed based on the retry policy.\n\tRetryPolicy *RetryPolicy\n\n\t// CronSchedule - Optional cron schedule for workflow. If a cron schedule is specified, the workflow will run\n\t// as a cron based on the schedule. The scheduling will be based on UTC time. Schedule for next run only happen\n\t// after the current run is completed/failed/timeout. If a RetryPolicy is also supplied, and the workflow failed\n\t// or timeout, the workflow will be retried based on the retry policy. While the workflow is retrying, it won\'t\n\t// schedule its next run. If next schedule is due while workflow is running (or retrying), then it will skip that\n\t// schedule. Cron workflow will not stop until it is terminated or cancelled (by returning cadence.CanceledError).\n\t// The cron spec is as following:\n\t// ┌───────────── minute (0 - 59)\n\t// │ ┌───────────── hour (0 - 23)\n\t// │ │ ┌───────────── day of the month (1 - 31)\n\t// │ │ │ ┌───────────── month (1 - 12)\n\t// │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)\n\t// │ │ │ │ │\n\t// │ │ │ │ │\n\t// * * * * *\n\tCronSchedule string\n\n\t// Memo - Optional non-indexed info that will be shown in list workflow.\n\tMemo map[string]interface{}\n\n\t// SearchAttributes - Optional indexed info that can be used in query of List/Scan/Count workflow APIs (only\n\t// supported when Cadence server is using ElasticSearch). The key and value type must be registered on Cadence server side.\n\t// Use GetSearchAttributes API to get valid key and corresponding value type.\n\tSearchAttributes map[string]interface{}\n\n\t// DelayStartSeconds - Seconds to delay the workflow start\n\t// The resolution is seconds.\n\t// Optional: defaulted to 0 seconds\n\tDelayStart time.Duration\n\n\t// JitterStart - Seconds to jitter the workflow start. For example, if set to 10, the workflow will start some time between 0-10 seconds.\n\t// This works with CronSchedule and with DelayStart.\n\t// Optional: defaulted to 0 seconds\n\tJitterStart time.Duration\n}\n',normalizedContent:'# starting workflows\n\nstarting workflows can be done from any service that can send requests to the cadence server. there is no requirement for workflows to be started from the worker services.\n\ngenerally workflows can either be started using a direct reference to the workflow code, or by referring to the registered name of the function. in workflow registration we show how to register the workflows.\n\n\n# starting a workflow\n\nafter creating a workflow we can start it. this can be done from the cli, but typically we want to start workflow programmatically e.g. from an http handler. we can do this using the client.startworkflow function:\n\nimport "go.uber.org/cadence/client"\n\nvar cadenceclient client.client \n# initialize cadenceclient\n\ncadenceclient.startworkflow(\n    ctx,\n    client.startworkflowoptions{\n        tasklist: "workflow-task-list",\n        executionstarttoclosetimeout: 10 * time.second,\n    },\n    workflowfunc,\n    workflowarg1,\n    workflowarg2,\n    workflowarg3,\n    ...\n)\n\n\nthe will start the workflow defined in the function workflowfunc, note that for named workflows workflowfunc could be replaced by the name e.g. "workflowfuncname".\n\nworkflowarg1, workflowarg2, workflowarg3 are arguments to the workflow, as specified in workflowfunc, note that the arguments needs to be serializable.\n\n\n# jitter start and batches of workflows\n\nbelow we list all the startworkflowoptions, however a particularly useful option is jitterstart.\n\nstarting many workflows at the same time will have cadence trying to schedule all the workflows immediately. this can result in overloading cadence and the database backing cadence, as well as the workers processing the workflows.\n\nthis is especially bad when the workflow starts comes in batches, such as an end of month load. these sudden loads can lead to both cadence and the workers needing to immediately scale up. scaling up often takes some time, causing queues in cadence, delaying the execution of all workflows, potentially causing workflows to timeout.\n\nto solve this we can start our workflows with jitterstart. jitterstart will start the workflow at a random point between now and now + jitterstart, so if we e.g. start 1000 workflows at 12:00 am with a jitterstart of 6 hours, the workflows will be randomly started between 12:00 am and 6:00 pm.\n\nthis makes the sudden load of 1000 workflows much more manageable.\n\nfor many batch-like workloads a random delay is completely acceptable as the batch just needs to be processed e.g. before the end of the day.\n\nadding a jitterstart of 6 hours in the example above is as simple as adding\n\njitterstart: 6 * time.hour,\n\n\nto the options like so,\n\nimport "go.uber.org/cadence/client"\n\nvar cadenceclient client.client\n# initialize cadenceclient\n\ncadenceclient.startworkflow(\n    ctx,\n    client.startworkflowoptions{\n        tasklist: "workflow-task-list",\n        executionstarttoclosetimeout: 10 * time.second,\n        jitterstart: 6 * time.hour, // added jitterstart\n    },\n    workflowfunc,\n    workflowarg1,\n    workflowarg2,\n    workflowarg3,\n    ...\n)\n\n\nnow the workflow will start at a random point between now and six hours from now.\n\n\n# startworkflowoptions\n\nthe client.startworkflowoptions specifies the behavior of this particular workflow. the invocation above only specifies the two mandatory options; tasklist and executionstarttoclosetimeout, all the options are described in the inline documentation:\n\ntype startworkflowoptions struct {\n\t// id - the business identifier of the workflow execution.\n\t// optional: defaulted to a uuid.\n\tid string\n\n\t// tasklist - the decisions of the workflow are scheduled on this queue.\n\t// this is also the default task list on which activities are scheduled. the workflow author can choose\n\t// to override this using activity options.\n\t// mandatory: no default.\n\ttasklist string\n\n\t// executionstarttoclosetimeout - the timeout for duration of workflow execution.\n\t// the resolution is seconds.\n\t// mandatory: no default.\n\texecutionstarttoclosetimeout time.duration\n\n\t// decisiontaskstarttoclosetimeout - the timeout for processing decision task from the time the worker\n\t// pulled this task. if a decision task is lost, it is retried after this timeout.\n\t// the resolution is seconds.\n\t// optional: defaulted to 10 secs.\n\tdecisiontaskstarttoclosetimeout time.duration\n\n\t// workflowidreusepolicy - whether server allow reuse of workflow id, can be useful\n\t// for dedup logic if set to workflowidreusepolicyrejectduplicate.\n\t// optional: defaulted to workflowidreusepolicyallowduplicatefailedonly.\n\tworkflowidreusepolicy workflowidreusepolicy\n\n\t// retrypolicy - optional retry policy for workflow. if a retry policy is specified, in case of workflow failure\n\t// server will start new workflow execution if needed based on the retry policy.\n\tretrypolicy *retrypolicy\n\n\t// cronschedule - optional cron schedule for workflow. if a cron schedule is specified, the workflow will run\n\t// as a cron based on the schedule. the scheduling will be based on utc time. schedule for next run only happen\n\t// after the current run is completed/failed/timeout. if a retrypolicy is also supplied, and the workflow failed\n\t// or timeout, the workflow will be retried based on the retry policy. while the workflow is retrying, it won\'t\n\t// schedule its next run. if next schedule is due while workflow is running (or retrying), then it will skip that\n\t// schedule. cron workflow will not stop until it is terminated or cancelled (by returning cadence.cancelederror).\n\t// the cron spec is as following:\n\t// ┌───────────── minute (0 - 59)\n\t// │ ┌───────────── hour (0 - 23)\n\t// │ │ ┌───────────── day of the month (1 - 31)\n\t// │ │ │ ┌───────────── month (1 - 12)\n\t// │ │ │ │ ┌───────────── day of the week (0 - 6) (sunday to saturday)\n\t// │ │ │ │ │\n\t// │ │ │ │ │\n\t// * * * * *\n\tcronschedule string\n\n\t// memo - optional non-indexed info that will be shown in list workflow.\n\tmemo map[string]interface{}\n\n\t// searchattributes - optional indexed info that can be used in query of list/scan/count workflow apis (only\n\t// supported when cadence server is using elasticsearch). the key and value type must be registered on cadence server side.\n\t// use getsearchattributes api to get valid key and corresponding value type.\n\tsearchattributes map[string]interface{}\n\n\t// delaystartseconds - seconds to delay the workflow start\n\t// the resolution is seconds.\n\t// optional: defaulted to 0 seconds\n\tdelaystart time.duration\n\n\t// jitterstart - seconds to jitter the workflow start. for example, if set to 10, the workflow will start some time between 0-10 seconds.\n\t// this works with cronschedule and with delaystart.\n\t// optional: defaulted to 0 seconds\n\tjitterstart time.duration\n}\n',charsets:{}},{title:"Worker service",frontmatter:{layout:"default",title:"Worker service",permalink:"/docs/go-client/workers",readingShow:"top"},regularPath:"/docs/05-go-client/01-workers.html",relativePath:"docs/05-go-client/01-workers.md",key:"v-e5936714",path:"/docs/go-client/workers/",codeSwitcherOptions:{},headersStr:null,content:'# Worker service\n\nA or service is a service that hosts the and implementations. The polls the Cadence service for , performs those , and communicates execution results back to the Cadence service. services are developed, deployed, and operated by Cadence customers.\n\nYou can run a Cadence in a new or an existing service. Use the framework APIs to start the Cadence and link in all and implementations that you require the service to execute.\n\nThe following is an example worker service utilising tchannel, one of the two transport protocols supported by Cadence.\n\npackage main\n\nimport (\n\n    "go.uber.org/cadence/.gen/go/cadence"\n    "go.uber.org/cadence/.gen/go/cadence/workflowserviceclient"\n    "go.uber.org/cadence/worker"\n\n    "github.com/uber-go/tally"\n    "go.uber.org/zap"\n    "go.uber.org/zap/zapcore"\n    "go.uber.org/yarpc"\n    "go.uber.org/yarpc/api/transport"\n    "go.uber.org/yarpc/transport/tchannel"\n)\n\nvar HostPort = "127.0.0.1:7933"\nvar Domain = "SimpleDomain"\nvar TaskListName = "SimpleWorker"\nvar ClientName = "SimpleWorker"\nvar CadenceService = "cadence-frontend"\n\nfunc main() {\n    startWorker(buildLogger(), buildCadenceClient())\n}\n\nfunc buildLogger() *zap.Logger {\n    config := zap.NewDevelopmentConfig()\n    config.Level.SetLevel(zapcore.InfoLevel)\n\n    var err error\n    logger, err := config.Build()\n    if err != nil {\n        panic("Failed to setup logger")\n    }\n\n    return logger\n}\n\nfunc buildCadenceClient() workflowserviceclient.Interface {\n    ch, err := tchannel.NewChannelTransport(tchannel.ServiceName(ClientName))\n    if err != nil {\n        panic("Failed to setup tchannel")\n    }\n    dispatcher := yarpc.NewDispatcher(yarpc.Config{\n        Name: ClientName,\n        Outbounds: yarpc.Outbounds{\n            CadenceService: {Unary: ch.NewSingleOutbound(HostPort)},\n        },\n    })\n    if err := dispatcher.Start(); err != nil {\n        panic("Failed to start dispatcher")\n    }\n\n    return workflowserviceclient.New(dispatcher.ClientConfig(CadenceService))\n}\n\nfunc startWorker(logger *zap.Logger, service workflowserviceclient.Interface) {\n    // TaskListName identifies set of client workflows, activities, and workers.\n    // It could be your group or client or application name.\n    workerOptions := worker.Options{\n        Logger:       logger,\n        MetricsScope: tally.NewTestScope(TaskListName, map[string]string{}),\n    }\n\n    worker := worker.New(\n        service,\n        Domain,\n        TaskListName,\n        workerOptions)\n    err := worker.Start()\n    if err != nil {\n        panic("Failed to start worker")\n    }\n\n    logger.Info("Started Worker.", zap.String("worker", TaskListName))\n}\n\n\nThe other supported transport protocol is gRPC. A worker service using gRPC can be set up in similar fashion, but the buildCadenceClient function will need the following alterations, and some of the imported packages need to change.\n\n\nimport (\n\n    "go.uber.org/cadence/.gen/go/cadence"\n    "go.uber.org/cadence/.gen/go/cadence/workflowserviceclient"\n    "go.uber.org/cadence/compatibility"\n    "go.uber.org/cadence/worker"\n\n    apiv1 "github.com/uber/cadence-idl/go/proto/api/v1"\n    "github.com/uber-go/tally"\n    "go.uber.org/zap"\n    "go.uber.org/zap/zapcore"\n    "go.uber.org/yarpc"\n    "go.uber.org/yarpc/transport/grpc"\n)\n\n.\n.\n.\n\nfunc buildCadenceClient() workflowserviceclient.Interface {\n\n    dispatcher := yarpc.NewDispatcher(yarpc.Config{\n      Name: ClientName,\n      Outbounds: yarpc.Outbounds{\n        CadenceService: {Unary: grpc.NewTransport().NewSingleOutbound(HostPort)},\n      },\n    })\n    if err := dispatcher.Start(); err != nil {\n      panic("Failed to start dispatcher")\n    }\n\n    clientConfig := dispatcher.ClientConfig(CadenceService)\n\n    return compatibility.NewThrift2ProtoAdapter(\n      apiv1.NewDomainAPIYARPCClient(clientConfig),\n      apiv1.NewWorkflowAPIYARPCClient(clientConfig),\n      apiv1.NewWorkerAPIYARPCClient(clientConfig),\n      apiv1.NewVisibilityAPIYARPCClient(clientConfig),\n    )\n}\n\n\nNote also that the HostPort variable must be changed to target the gRPC listener port of the Cadence cluster (typically, 7833).\n\nFinally, gRPC can also support TLS connections between Go clients and the Cadence server. This requires the following alterations to the imported packages, and the buildCadenceClient function. Note that this also requires you replace "path/to/cert/file" in the function with a path to a valid certificate file matching the TLS configuration of the Cadence server.\n\n\nimport (\n\n    "fmt"\n\n    "go.uber.org/cadence/.gen/go/cadence"\n    "go.uber.org/cadence/.gen/go/cadence/workflowserviceclient"\n    "go.uber.org/cadence/compatibility"\n    "go.uber.org/cadence/worker"\n\n    apiv1 "github.com/uber/cadence-idl/go/proto/api/v1"\n    "github.com/uber-go/tally"\n    "go.uber.org/zap"\n    "go.uber.org/zap/zapcore"\n    "go.uber.org/yarpc"\n    "go.uber.org/yarpc/transport/grpc"\n    "go.uber.org/yarpc/peer"\n    "go.uber.org/yarpc/peer/hostport"\n\n    "crypto/tls"\n    "crypto/x509"\n    "io/ioutil"\n\n    "google.golang.org/grpc/credentials"\n)\n\n.\n.\n.\n\nfunc buildCadenceClient() workflowserviceclient.Interface {\n     grpcTransport := grpc.NewTransport()\n     var dialOptions []grpc.DialOption\n \n     caCert, err := ioutil.ReadFile("/path/to/cert/file")\n     if err != nil {\n          fmt.Printf("Failed to load server CA certificate: %v", zap.Error(err))\n     }\n \n     caCertPool := x509.NewCertPool()\n     if !caCertPool.AppendCertsFromPEM(caCert) {\n          fmt.Errorf("Failed to add server CA\'s certificate")\n     }\n \n     tlsConfig := tls.Config{\n          RootCAs: caCertPool,\n     }\n \n     creds := credentials.NewTLS(&tlsConfig)\n     dialOptions = append(dialOptions, grpc.DialerCredentials(creds))\n \n     dialer := grpcTransport.NewDialer(dialOptions...)\n     outbound := grpcTransport.NewOutbound(\n                        peer.NewSingle(hostport.PeerIdentifier(HostPort), dialer)\n                 )\n \n     dispatcher := yarpc.NewDispatcher(yarpc.Config{\n          Name: ClientName,\n          Outbounds: yarpc.Outbounds{\n               CadenceService: {Unary: outbound},\n          },\n     })\n     if err := dispatcher.Start(); err != nil {\n          panic("Failed to start dispatcher")\n     }\n \n     clientConfig := dispatcher.ClientConfig(CadenceService)\n \n     return compatibility.NewThrift2ProtoAdapter(\n          apiv1.NewDomainAPIYARPCClient(clientConfig),\n          apiv1.NewWorkflowAPIYARPCClient(clientConfig),\n          apiv1.NewWorkerAPIYARPCClient(clientConfig),\n          apiv1.NewVisibilityAPIYARPCClient(clientConfig),\n     )\n}\n',normalizedContent:'# worker service\n\na or service is a service that hosts the and implementations. the polls the cadence service for , performs those , and communicates execution results back to the cadence service. services are developed, deployed, and operated by cadence customers.\n\nyou can run a cadence in a new or an existing service. use the framework apis to start the cadence and link in all and implementations that you require the service to execute.\n\nthe following is an example worker service utilising tchannel, one of the two transport protocols supported by cadence.\n\npackage main\n\nimport (\n\n    "go.uber.org/cadence/.gen/go/cadence"\n    "go.uber.org/cadence/.gen/go/cadence/workflowserviceclient"\n    "go.uber.org/cadence/worker"\n\n    "github.com/uber-go/tally"\n    "go.uber.org/zap"\n    "go.uber.org/zap/zapcore"\n    "go.uber.org/yarpc"\n    "go.uber.org/yarpc/api/transport"\n    "go.uber.org/yarpc/transport/tchannel"\n)\n\nvar hostport = "127.0.0.1:7933"\nvar domain = "simpledomain"\nvar tasklistname = "simpleworker"\nvar clientname = "simpleworker"\nvar cadenceservice = "cadence-frontend"\n\nfunc main() {\n    startworker(buildlogger(), buildcadenceclient())\n}\n\nfunc buildlogger() *zap.logger {\n    config := zap.newdevelopmentconfig()\n    config.level.setlevel(zapcore.infolevel)\n\n    var err error\n    logger, err := config.build()\n    if err != nil {\n        panic("failed to setup logger")\n    }\n\n    return logger\n}\n\nfunc buildcadenceclient() workflowserviceclient.interface {\n    ch, err := tchannel.newchanneltransport(tchannel.servicename(clientname))\n    if err != nil {\n        panic("failed to setup tchannel")\n    }\n    dispatcher := yarpc.newdispatcher(yarpc.config{\n        name: clientname,\n        outbounds: yarpc.outbounds{\n            cadenceservice: {unary: ch.newsingleoutbound(hostport)},\n        },\n    })\n    if err := dispatcher.start(); err != nil {\n        panic("failed to start dispatcher")\n    }\n\n    return workflowserviceclient.new(dispatcher.clientconfig(cadenceservice))\n}\n\nfunc startworker(logger *zap.logger, service workflowserviceclient.interface) {\n    // tasklistname identifies set of client workflows, activities, and workers.\n    // it could be your group or client or application name.\n    workeroptions := worker.options{\n        logger:       logger,\n        metricsscope: tally.newtestscope(tasklistname, map[string]string{}),\n    }\n\n    worker := worker.new(\n        service,\n        domain,\n        tasklistname,\n        workeroptions)\n    err := worker.start()\n    if err != nil {\n        panic("failed to start worker")\n    }\n\n    logger.info("started worker.", zap.string("worker", tasklistname))\n}\n\n\nthe other supported transport protocol is grpc. a worker service using grpc can be set up in similar fashion, but the buildcadenceclient function will need the following alterations, and some of the imported packages need to change.\n\n\nimport (\n\n    "go.uber.org/cadence/.gen/go/cadence"\n    "go.uber.org/cadence/.gen/go/cadence/workflowserviceclient"\n    "go.uber.org/cadence/compatibility"\n    "go.uber.org/cadence/worker"\n\n    apiv1 "github.com/uber/cadence-idl/go/proto/api/v1"\n    "github.com/uber-go/tally"\n    "go.uber.org/zap"\n    "go.uber.org/zap/zapcore"\n    "go.uber.org/yarpc"\n    "go.uber.org/yarpc/transport/grpc"\n)\n\n.\n.\n.\n\nfunc buildcadenceclient() workflowserviceclient.interface {\n\n    dispatcher := yarpc.newdispatcher(yarpc.config{\n      name: clientname,\n      outbounds: yarpc.outbounds{\n        cadenceservice: {unary: grpc.newtransport().newsingleoutbound(hostport)},\n      },\n    })\n    if err := dispatcher.start(); err != nil {\n      panic("failed to start dispatcher")\n    }\n\n    clientconfig := dispatcher.clientconfig(cadenceservice)\n\n    return compatibility.newthrift2protoadapter(\n      apiv1.newdomainapiyarpcclient(clientconfig),\n      apiv1.newworkflowapiyarpcclient(clientconfig),\n      apiv1.newworkerapiyarpcclient(clientconfig),\n      apiv1.newvisibilityapiyarpcclient(clientconfig),\n    )\n}\n\n\nnote also that the hostport variable must be changed to target the grpc listener port of the cadence cluster (typically, 7833).\n\nfinally, grpc can also support tls connections between go clients and the cadence server. this requires the following alterations to the imported packages, and the buildcadenceclient function. note that this also requires you replace "path/to/cert/file" in the function with a path to a valid certificate file matching the tls configuration of the cadence server.\n\n\nimport (\n\n    "fmt"\n\n    "go.uber.org/cadence/.gen/go/cadence"\n    "go.uber.org/cadence/.gen/go/cadence/workflowserviceclient"\n    "go.uber.org/cadence/compatibility"\n    "go.uber.org/cadence/worker"\n\n    apiv1 "github.com/uber/cadence-idl/go/proto/api/v1"\n    "github.com/uber-go/tally"\n    "go.uber.org/zap"\n    "go.uber.org/zap/zapcore"\n    "go.uber.org/yarpc"\n    "go.uber.org/yarpc/transport/grpc"\n    "go.uber.org/yarpc/peer"\n    "go.uber.org/yarpc/peer/hostport"\n\n    "crypto/tls"\n    "crypto/x509"\n    "io/ioutil"\n\n    "google.golang.org/grpc/credentials"\n)\n\n.\n.\n.\n\nfunc buildcadenceclient() workflowserviceclient.interface {\n     grpctransport := grpc.newtransport()\n     var dialoptions []grpc.dialoption\n \n     cacert, err := ioutil.readfile("/path/to/cert/file")\n     if err != nil {\n          fmt.printf("failed to load server ca certificate: %v", zap.error(err))\n     }\n \n     cacertpool := x509.newcertpool()\n     if !cacertpool.appendcertsfrompem(cacert) {\n          fmt.errorf("failed to add server ca\'s certificate")\n     }\n \n     tlsconfig := tls.config{\n          rootcas: cacertpool,\n     }\n \n     creds := credentials.newtls(&tlsconfig)\n     dialoptions = append(dialoptions, grpc.dialercredentials(creds))\n \n     dialer := grpctransport.newdialer(dialoptions...)\n     outbound := grpctransport.newoutbound(\n                        peer.newsingle(hostport.peeridentifier(hostport), dialer)\n                 )\n \n     dispatcher := yarpc.newdispatcher(yarpc.config{\n          name: clientname,\n          outbounds: yarpc.outbounds{\n               cadenceservice: {unary: outbound},\n          },\n     })\n     if err := dispatcher.start(); err != nil {\n          panic("failed to start dispatcher")\n     }\n \n     clientconfig := dispatcher.clientconfig(cadenceservice)\n \n     return compatibility.newthrift2protoadapter(\n          apiv1.newdomainapiyarpcclient(clientconfig),\n          apiv1.newworkflowapiyarpcclient(clientconfig),\n          apiv1.newworkerapiyarpcclient(clientconfig),\n          apiv1.newvisibilityapiyarpcclient(clientconfig),\n     )\n}\n',charsets:{}},{title:"Activity overview",frontmatter:{layout:"default",title:"Activity overview",permalink:"/docs/go-client/activities",readingShow:"top"},regularPath:"/docs/05-go-client/03-activities.html",relativePath:"docs/05-go-client/03-activities.md",key:"v-43760982",path:"/docs/go-client/activities/",headers:[{level:2,title:"Overview",slug:"overview",normalizedTitle:"overview",charIndex:1160},{level:3,title:"Declaration",slug:"declaration",normalizedTitle:"declaration",charIndex:1849},{level:3,title:"Implementation",slug:"implementation",normalizedTitle:"implementation",charIndex:2975},{level:3,title:"Registration",slug:"registration",normalizedTitle:"registration",charIndex:5198},{level:2,title:"Failing an Activity",slug:"failing-an-activity",normalizedTitle:"failing an activity",charIndex:5603}],codeSwitcherOptions:{},headersStr:"Overview Declaration Implementation Registration Failing an Activity",content:'# Activity overview\n\nAn is the implementation of a particular in the business logic.\n\nare implemented as functions. Data can be passed directly to an via function parameters. The parameters can be either basic types or structs, with the only requirement being that the parameters must be serializable. Though it is not required, we recommend that the first parameter of an function is of type context.Context, in order to allow the to interact with other framework methods. The function must return an error value, and can optionally return a result value. The result value can be either a basic type or a struct with the only requirement being that it is serializable.\n\nThe values passed to through invocation parameters or returned through the result value are recorded in the execution history. The entire execution history is transferred from the Cadence service to with every that the logic needs to process. A large execution history can thus adversely impact the performance of your . Therefore, be mindful of the amount of data you transfer via invocation parameters or return values. Otherwise, no additional limitations exist on implementations.\n\n\n# Overview\n\nThe following example demonstrates a simple that accepts a string parameter, appends a word to it, and then returns a result.\n\npackage simple\n\nimport (\n    "context"\n\n    "go.uber.org/cadence/activity"\n    "go.uber.org/zap"\n)\n\nfunc init() {\n    activity.Register(SimpleActivity)\n}\n\n// SimpleActivity is a sample Cadence activity function that takes one parameter and\n// returns a string containing the parameter value.\nfunc SimpleActivity(ctx context.Context, value string) (string, error) {\n    activity.GetLogger(ctx).Info("SimpleActivity called.", zap.String("Value", value))\n    return "Processed: " + value, nil\n}\n\n\nLet\'s take a look at each component of this activity.\n\n\n# Declaration\n\nIn the Cadence programing model, an is implemented with a function. The function declaration specifies the parameters the accepts as well as any values it might return. An function can take zero or many specific parameters and can return one or two values. It must always at least return an error value. The function can accept as parameters and return as results any serializable type.\n\nfunc SimpleActivity(ctx context.Context, value string) (string, error)\n\nThe first parameter to the function is context.Context. This is an optional parameter and can be omitted. This parameter is the standard Go context. The second string parameter is a custom specific parameter that can be used to pass data into the on start. An can have one or more such parameters. All parameters to an function must be serializable, which essentially means that params can’t be channels, functions, variadic, or unsafe pointers. The declares two return values: string and error. The string return value is used to return the result of the . The error return value is used to indicate that an error was encountered during execution.\n\n\n# Implementation\n\nYou can write implementation code in the same way that you would any other Go service code. Additionally, you can use the usual loggers and metrics controllers, and the standard Go concurrency constructs.\n\n# Heart Beating\n\nFor long-running , Cadence provides an API for the code to report both liveness and progress back to the Cadence managed service.\n\nprogress := 0\nfor hasWork {\n    // Send heartbeat message to the server.\n    cadence.RecordActivityHeartbeat(ctx, progress)\n    // Do some work.\n    ...\n    progress++\n}\n\n\nWhen an times out due to a missed heartbeat, the last value of the details (progress in the above sample) is returned from the cadence.ExecuteActivity function as the details field of TimeoutError with TimeoutType_HEARTBEAT.\n\nNew auto heartbeat option in Cadence Go Client 0.17.0 release: In case you don\'t need to report progress, but still want to report liveness of your worker through heartbeating for your long running activities, there\'s a new auto-heartbeat option that you can enable when you register your activity. When this option is enabled Cadence library will do the heartbeat for you in the background.\n\n\tRegisterActivityOptions struct {\n\t\t...\n\t\t// Automatically send heartbeats for this activity at an interval that is less than the HeartbeatTimeout.\n\t\t// This option has no effect if the activity is executed with a HeartbeatTimeout of 0.\n\t\t// Default: false\n\t\tEnableAutoHeartbeat bool\n\t}\n\n\nYou can also heartbeat an from an external source:\n\n// Instantiate a Cadence service client.\ncadence.Client client = cadence.NewClient(...)\n\n// Record heartbeat.\nerr := client.RecordActivityHeartbeat(taskToken, details)\n\n\nThe parameters of the RecordActivityHeartbeat function are:\n\n * taskToken: The value of the binary TaskToken field of the ActivityInfo struct retrieved inside the .\n * details: The serializable payload containing progress information.\n\n# Cancellation\n\nWhen an is cancelled, or its has completed or failed, the context passed into its function is cancelled, which sets its channel’s closed state to Done. An can use that to perform any necessary cleanup and abort its execution. Cancellation is only delivered to that call RecordActivityHeartbeat.\n\n\n# Registration\n\nTo make the visible to the process hosting it, the must be registered via a call to activity.Register.\n\nfunc init() {\n    activity.Register(SimpleActivity)\n}\n\n\nThis call creates an in-memory mapping inside the process between the fully qualified function name and the implementation. If a receives a request to start an execution for an type it does not know, it will fail that request.\n\n\n# Failing an Activity\n\nTo mark an as failed, the function must return an error via the error return value.',normalizedContent:'# activity overview\n\nan is the implementation of a particular in the business logic.\n\nare implemented as functions. data can be passed directly to an via function parameters. the parameters can be either basic types or structs, with the only requirement being that the parameters must be serializable. though it is not required, we recommend that the first parameter of an function is of type context.context, in order to allow the to interact with other framework methods. the function must return an error value, and can optionally return a result value. the result value can be either a basic type or a struct with the only requirement being that it is serializable.\n\nthe values passed to through invocation parameters or returned through the result value are recorded in the execution history. the entire execution history is transferred from the cadence service to with every that the logic needs to process. a large execution history can thus adversely impact the performance of your . therefore, be mindful of the amount of data you transfer via invocation parameters or return values. otherwise, no additional limitations exist on implementations.\n\n\n# overview\n\nthe following example demonstrates a simple that accepts a string parameter, appends a word to it, and then returns a result.\n\npackage simple\n\nimport (\n    "context"\n\n    "go.uber.org/cadence/activity"\n    "go.uber.org/zap"\n)\n\nfunc init() {\n    activity.register(simpleactivity)\n}\n\n// simpleactivity is a sample cadence activity function that takes one parameter and\n// returns a string containing the parameter value.\nfunc simpleactivity(ctx context.context, value string) (string, error) {\n    activity.getlogger(ctx).info("simpleactivity called.", zap.string("value", value))\n    return "processed: " + value, nil\n}\n\n\nlet\'s take a look at each component of this activity.\n\n\n# declaration\n\nin the cadence programing model, an is implemented with a function. the function declaration specifies the parameters the accepts as well as any values it might return. an function can take zero or many specific parameters and can return one or two values. it must always at least return an error value. the function can accept as parameters and return as results any serializable type.\n\nfunc simpleactivity(ctx context.context, value string) (string, error)\n\nthe first parameter to the function is context.context. this is an optional parameter and can be omitted. this parameter is the standard go context. the second string parameter is a custom specific parameter that can be used to pass data into the on start. an can have one or more such parameters. all parameters to an function must be serializable, which essentially means that params can’t be channels, functions, variadic, or unsafe pointers. the declares two return values: string and error. the string return value is used to return the result of the . the error return value is used to indicate that an error was encountered during execution.\n\n\n# implementation\n\nyou can write implementation code in the same way that you would any other go service code. additionally, you can use the usual loggers and metrics controllers, and the standard go concurrency constructs.\n\n# heart beating\n\nfor long-running , cadence provides an api for the code to report both liveness and progress back to the cadence managed service.\n\nprogress := 0\nfor haswork {\n    // send heartbeat message to the server.\n    cadence.recordactivityheartbeat(ctx, progress)\n    // do some work.\n    ...\n    progress++\n}\n\n\nwhen an times out due to a missed heartbeat, the last value of the details (progress in the above sample) is returned from the cadence.executeactivity function as the details field of timeouterror with timeouttype_heartbeat.\n\nnew auto heartbeat option in cadence go client 0.17.0 release: in case you don\'t need to report progress, but still want to report liveness of your worker through heartbeating for your long running activities, there\'s a new auto-heartbeat option that you can enable when you register your activity. when this option is enabled cadence library will do the heartbeat for you in the background.\n\n\tregisteractivityoptions struct {\n\t\t...\n\t\t// automatically send heartbeats for this activity at an interval that is less than the heartbeattimeout.\n\t\t// this option has no effect if the activity is executed with a heartbeattimeout of 0.\n\t\t// default: false\n\t\tenableautoheartbeat bool\n\t}\n\n\nyou can also heartbeat an from an external source:\n\n// instantiate a cadence service client.\ncadence.client client = cadence.newclient(...)\n\n// record heartbeat.\nerr := client.recordactivityheartbeat(tasktoken, details)\n\n\nthe parameters of the recordactivityheartbeat function are:\n\n * tasktoken: the value of the binary tasktoken field of the activityinfo struct retrieved inside the .\n * details: the serializable payload containing progress information.\n\n# cancellation\n\nwhen an is cancelled, or its has completed or failed, the context passed into its function is cancelled, which sets its channel’s closed state to done. an can use that to perform any necessary cleanup and abort its execution. cancellation is only delivered to that call recordactivityheartbeat.\n\n\n# registration\n\nto make the visible to the process hosting it, the must be registered via a call to activity.register.\n\nfunc init() {\n    activity.register(simpleactivity)\n}\n\n\nthis call creates an in-memory mapping inside the process between the fully qualified function name and the implementation. if a receives a request to start an execution for an type it does not know, it will fail that request.\n\n\n# failing an activity\n\nto mark an as failed, the function must return an error via the error return value.',charsets:{}},{title:"Executing activities",frontmatter:{layout:"default",title:"Executing activities",permalink:"/docs/go-client/execute-activity",readingShow:"top"},regularPath:"/docs/05-go-client/04-execute-activity.html",relativePath:"docs/05-go-client/04-execute-activity.md",key:"v-caeda73c",path:"/docs/go-client/execute-activity/",headers:[{level:2,title:"Activity options",slug:"activity-options",normalizedTitle:"activity options",charIndex:796},{level:2,title:"Activity timeouts",slug:"activity-timeouts",normalizedTitle:"activity timeouts",charIndex:1282},{level:2,title:"ExecuteActivity call",slug:"executeactivity-call",normalizedTitle:"executeactivity call",charIndex:2346}],codeSwitcherOptions:{},headersStr:"Activity options Activity timeouts ExecuteActivity call",content:'# Executing activities\n\nThe primary responsibility of a implementation is to schedule for execution. The most straightforward way to do this is via the library method workflow.ExecuteActivity. The following sample code demonstrates making this call:\n\nao := cadence.ActivityOptions{\n    TaskList:               "sampleTaskList",\n    ScheduleToCloseTimeout: time.Second * 60,\n    ScheduleToStartTimeout: time.Second * 60,\n    StartToCloseTimeout:    time.Second * 60,\n    HeartbeatTimeout:       time.Second * 10,\n    WaitForCancellation:    false,\n}\nctx = cadence.WithActivityOptions(ctx, ao)\n\nfuture := workflow.ExecuteActivity(ctx, SimpleActivity, value)\nvar result string\nif err := future.Get(ctx, &result); err != nil {\n    return err\n}\n\n\nLet\'s take a look at each component of this call.\n\n\n# Activity options\n\nBefore calling workflow.ExecuteActivity(), you must configure ActivityOptions for the invocation. These options customize various execution timeouts, and are passed in by creating a child context from the initial context and overwriting the desired values. The child context is then passed into the workflow.ExecuteActivity() call. If multiple are sharing the same option values, then the same context instance can be used when calling workflow.ExecuteActivity().\n\n\n# Activity timeouts\n\nThere can be various kinds of timeouts associated with an . Cadence guarantees that are executed at most once, so an either succeeds or fails with one of the following timeouts:\n\nTIMEOUT                  DESCRIPTION\nStartToCloseTimeout      Maximum time that a worker can take to process a task after\n                         it has received the task.\nScheduleToStartTimeout   Time a task can wait to be picked up by an after a schedules\n                         it. If there are no workers available to process this task\n                         for the specified duration, the task will time out.\nScheduleToCloseTimeout   Time a task can take to complete after it is scheduled by a\n                         . This is usually greater than the sum of StartToClose and\n                         ScheduleToStart timeouts.\nHeartbeatTimeout         If a task doesn\'t heartbeat to the Cadence service for this\n                         duration, it will be considered to have failed. This is\n                         useful for long-running tasks.\n\n\n# ExecuteActivity call\n\nThe first parameter in the call is the required cadence.Context object. This type is a copy of context.Context with the Done() method returning cadence.Channel instead of the native Go chan.\n\nThe second parameter is the function that we registered as an function. This parameter can also be a string representing the fully qualified name of the function. The benefit of passing in the actual function object is that the framework can validate parameters.\n\nThe remaining parameters are passed to the as part of the call. In our example, we have a single parameter: value. This list of parameters must match the list of parameters declared by the function. The Cadence client library will validate this.\n\nThe method call returns immediately and returns a cadence.Future. This allows you to execute more code without having to wait for the scheduled to complete.\n\nWhen you are ready to process the results of the , call the Get() method on the future object returned. The parameters to this method are the ctx object we passed to the workflow.ExecuteActivity() call and an output parameter that will receive the output of the . The type of the output parameter must match the type of the return value declared by the function. The Get() method will block until the completes and results are available.\n\nYou can retrieve the result value returned by workflow.ExecuteActivity() from the future and use it like any normal result from a synchronous function call. The following sample code demonstrates how you can use the result if it is a string value:\n\nvar result string\nif err := future.Get(ctx1, &result); err != nil {\n    return err\n}\n\nswitch result {\ncase "apple":\n    // Do something.\ncase "banana":\n    // Do something.\ndefault:\n    return err\n}\n\n\nIn this example, we called the Get() method on the returned future immediately after workflow.ExecuteActivity(). However, this is not necessary. If you want to execute multiple in parallel, you can repeatedly call workflow.ExecuteActivity(), store the returned futures, and then wait for all to complete by calling the Get() methods of the future at a later time.\n\nTo implement more complex wait conditions on returned future objects, use the cadence.Selector class.',normalizedContent:'# executing activities\n\nthe primary responsibility of a implementation is to schedule for execution. the most straightforward way to do this is via the library method workflow.executeactivity. the following sample code demonstrates making this call:\n\nao := cadence.activityoptions{\n    tasklist:               "sampletasklist",\n    scheduletoclosetimeout: time.second * 60,\n    scheduletostarttimeout: time.second * 60,\n    starttoclosetimeout:    time.second * 60,\n    heartbeattimeout:       time.second * 10,\n    waitforcancellation:    false,\n}\nctx = cadence.withactivityoptions(ctx, ao)\n\nfuture := workflow.executeactivity(ctx, simpleactivity, value)\nvar result string\nif err := future.get(ctx, &result); err != nil {\n    return err\n}\n\n\nlet\'s take a look at each component of this call.\n\n\n# activity options\n\nbefore calling workflow.executeactivity(), you must configure activityoptions for the invocation. these options customize various execution timeouts, and are passed in by creating a child context from the initial context and overwriting the desired values. the child context is then passed into the workflow.executeactivity() call. if multiple are sharing the same option values, then the same context instance can be used when calling workflow.executeactivity().\n\n\n# activity timeouts\n\nthere can be various kinds of timeouts associated with an . cadence guarantees that are executed at most once, so an either succeeds or fails with one of the following timeouts:\n\ntimeout                  description\nstarttoclosetimeout      maximum time that a worker can take to process a task after\n                         it has received the task.\nscheduletostarttimeout   time a task can wait to be picked up by an after a schedules\n                         it. if there are no workers available to process this task\n                         for the specified duration, the task will time out.\nscheduletoclosetimeout   time a task can take to complete after it is scheduled by a\n                         . this is usually greater than the sum of starttoclose and\n                         scheduletostart timeouts.\nheartbeattimeout         if a task doesn\'t heartbeat to the cadence service for this\n                         duration, it will be considered to have failed. this is\n                         useful for long-running tasks.\n\n\n# executeactivity call\n\nthe first parameter in the call is the required cadence.context object. this type is a copy of context.context with the done() method returning cadence.channel instead of the native go chan.\n\nthe second parameter is the function that we registered as an function. this parameter can also be a string representing the fully qualified name of the function. the benefit of passing in the actual function object is that the framework can validate parameters.\n\nthe remaining parameters are passed to the as part of the call. in our example, we have a single parameter: value. this list of parameters must match the list of parameters declared by the function. the cadence client library will validate this.\n\nthe method call returns immediately and returns a cadence.future. this allows you to execute more code without having to wait for the scheduled to complete.\n\nwhen you are ready to process the results of the , call the get() method on the future object returned. the parameters to this method are the ctx object we passed to the workflow.executeactivity() call and an output parameter that will receive the output of the . the type of the output parameter must match the type of the return value declared by the function. the get() method will block until the completes and results are available.\n\nyou can retrieve the result value returned by workflow.executeactivity() from the future and use it like any normal result from a synchronous function call. the following sample code demonstrates how you can use the result if it is a string value:\n\nvar result string\nif err := future.get(ctx1, &result); err != nil {\n    return err\n}\n\nswitch result {\ncase "apple":\n    // do something.\ncase "banana":\n    // do something.\ndefault:\n    return err\n}\n\n\nin this example, we called the get() method on the returned future immediately after workflow.executeactivity(). however, this is not necessary. if you want to execute multiple in parallel, you can repeatedly call workflow.executeactivity(), store the returned futures, and then wait for all to complete by calling the get() methods of the future at a later time.\n\nto implement more complex wait conditions on returned future objects, use the cadence.selector class.',charsets:{}},{title:"Child workflows",frontmatter:{layout:"default",title:"Child workflows",permalink:"/docs/go-client/child-workflows",readingShow:"top"},regularPath:"/docs/05-go-client/05-child-workflows.html",relativePath:"docs/05-go-client/05-child-workflows.md",key:"v-0327ca12",path:"/docs/go-client/child-workflows/",codeSwitcherOptions:{},headersStr:null,content:'# Child workflows\n\nworkflow.ExecuteChildWorkflow enables the scheduling of other from within a \'s implementation. The parent has the ability to monitor and impact the lifecycle of the child , similar to the way it does for an that it invoked.\n\ncwo := workflow.ChildWorkflowOptions{\n    // Do not specify WorkflowID if you want Cadence to generate a unique ID for the child execution.\n    WorkflowID:                   "BID-SIMPLE-CHILD-WORKFLOW",\n    ExecutionStartToCloseTimeout: time.Minute * 30,\n}\nctx = workflow.WithChildWorkflowOptions(ctx, cwo)\n\nvar result string\nfuture := workflow.ExecuteChildWorkflow(ctx, SimpleChildWorkflow, value)\nif err := future.Get(ctx, &result); err != nil {\n    workflow.GetLogger(ctx).Error("SimpleChildWorkflow failed.", zap.Error(err))\n    return err\n}\n\n\nLet\'s take a look at each component of this call.\n\nBefore calling workflow.ExecuteChildworkflow(), you must configure ChildWorkflowOptions for the invocation. These options customize various execution timeouts, and are passed in by creating a child context from the initial context and overwriting the desired values. The child context is then passed into the workflow.ExecuteChildWorkflow() call. If multiple child are sharing the same option values, then the same context instance can be used when calling workflow.ExecuteChildworkflow().\n\nThe first parameter in the call is the required cadence.Context object. This type is a copy of context.Context with the Done() method returning cadence.Channel instead of the native Go chan.\n\nThe second parameter is the function that we registered as a function. This parameter can also be a string representing the fully qualified name of the function. The benefit of this is that when you pass in the actual function object, the framework can validate parameters.\n\nThe remaining parameters are passed to the as part of the call. In our example, we have a single parameter: value. This list of parameters must match the list of parameters declared by the function.\n\nThe method call returns immediately and returns a cadence.Future. This allows you to execute more code without having to wait for the scheduled to complete.\n\nWhen you are ready to process the results of the , call the Get() method on the returned future object. The parameters to this method is the ctx object we passed to the workflow.ExecuteChildWorkflow() call and an output parameter that will receive the output of the . The type of the output parameter must match the type of the return value declared by the function. The Get() method will block until the completes and results are available.\n\nThe workflow.ExecuteChildWorkflow() function is similar to workflow.ExecuteActivity(). All of the patterns described for using workflow.ExecuteActivity() apply to the workflow.ExecuteChildWorkflow() function as well.\n\nWhen a parent is cancelled by the user, the child can be cancelled or abandoned based on a configurable child policy.',normalizedContent:'# child workflows\n\nworkflow.executechildworkflow enables the scheduling of other from within a \'s implementation. the parent has the ability to monitor and impact the lifecycle of the child , similar to the way it does for an that it invoked.\n\ncwo := workflow.childworkflowoptions{\n    // do not specify workflowid if you want cadence to generate a unique id for the child execution.\n    workflowid:                   "bid-simple-child-workflow",\n    executionstarttoclosetimeout: time.minute * 30,\n}\nctx = workflow.withchildworkflowoptions(ctx, cwo)\n\nvar result string\nfuture := workflow.executechildworkflow(ctx, simplechildworkflow, value)\nif err := future.get(ctx, &result); err != nil {\n    workflow.getlogger(ctx).error("simplechildworkflow failed.", zap.error(err))\n    return err\n}\n\n\nlet\'s take a look at each component of this call.\n\nbefore calling workflow.executechildworkflow(), you must configure childworkflowoptions for the invocation. these options customize various execution timeouts, and are passed in by creating a child context from the initial context and overwriting the desired values. the child context is then passed into the workflow.executechildworkflow() call. if multiple child are sharing the same option values, then the same context instance can be used when calling workflow.executechildworkflow().\n\nthe first parameter in the call is the required cadence.context object. this type is a copy of context.context with the done() method returning cadence.channel instead of the native go chan.\n\nthe second parameter is the function that we registered as a function. this parameter can also be a string representing the fully qualified name of the function. the benefit of this is that when you pass in the actual function object, the framework can validate parameters.\n\nthe remaining parameters are passed to the as part of the call. in our example, we have a single parameter: value. this list of parameters must match the list of parameters declared by the function.\n\nthe method call returns immediately and returns a cadence.future. this allows you to execute more code without having to wait for the scheduled to complete.\n\nwhen you are ready to process the results of the , call the get() method on the returned future object. the parameters to this method is the ctx object we passed to the workflow.executechildworkflow() call and an output parameter that will receive the output of the . the type of the output parameter must match the type of the return value declared by the function. the get() method will block until the completes and results are available.\n\nthe workflow.executechildworkflow() function is similar to workflow.executeactivity(). all of the patterns described for using workflow.executeactivity() apply to the workflow.executechildworkflow() function as well.\n\nwhen a parent is cancelled by the user, the child can be cancelled or abandoned based on a configurable child policy.',charsets:{}},{title:"Activity and workflow retries",frontmatter:{layout:"default",title:"Activity and workflow retries",permalink:"/docs/go-client/retries",readingShow:"top"},regularPath:"/docs/05-go-client/06-retries.html",relativePath:"docs/05-go-client/06-retries.md",key:"v-5fac5e6c",path:"/docs/go-client/retries/",codeSwitcherOptions:{},headersStr:null,content:"# Activity and workflow retries\n\nand can fail due to various intermediate conditions. In those cases, we want to retry the failed or child or even the parent . This can be achieved by supplying an optional retry policy. A retry policy looks like the following:\n\n// RetryPolicy defines the retry policy.\nRetryPolicy struct {\n    // Backoff interval for the first retry. If coefficient is 1.0 then it is used for all retries.\n    // Required, no default value.\n    InitialInterval time.Duration\n\n    // Coefficient used to calculate the next retry backoff interval.\n    // The next retry interval is previous interval multiplied by this coefficient.\n    // Must be 1 or larger. Default is 2.0.\n    BackoffCoefficient float64\n\n    // Maximum backoff interval between retries. Exponential backoff leads to interval increase.\n    // This value is the cap of the interval. Default is 100x of initial interval.\n    MaximumInterval time.Duration\n\n    // Maximum time to retry. Either ExpirationInterval or MaximumAttempts is required.\n    // When exceeded the retries stop even if maximum retries is not reached yet.\n    // First (non-retry) attempt is unaffected by this field and is guaranteed to run \n    // for the entirety of the workflow timeout duration (ExecutionStartToCloseTimeoutSeconds).\n    ExpirationInterval time.Duration\n\n    // Maximum number of attempts. When exceeded the retries stop even if not expired yet.\n    // If not set or set to 0, it means unlimited, and relies on ExpirationInterval to stop.\n    // Either MaximumAttempts or ExpirationInterval is required.\n    MaximumAttempts int32\n\n    // Non-Retriable errors. This is optional. Cadence server will stop retry if error reason matches this list.\n    // Error reason for custom error is specified when your activity/workflow returns cadence.NewCustomError(reason).\n    // Error reason for panic error is \"cadenceInternal:Panic\".\n    // Error reason for any other error is \"cadenceInternal:Generic\".\n    // Error reason for timeouts is: \"cadenceInternal:Timeout TIMEOUT_TYPE\". TIMEOUT_TYPE could be START_TO_CLOSE or HEARTBEAT.\n    // Note that cancellation is not a failure, so it won't be retried.\n    NonRetriableErrorReasons []string\n}\n\n\nTo enable retry, supply a custom retry policy to ActivityOptions or ChildWorkflowOptions when you execute them.\n\nexpiration := time.Minute * 10\nretryPolicy := &cadence.RetryPolicy{\n    InitialInterval:    time.Second,\n    BackoffCoefficient: 2,\n    MaximumInterval:    expiration,\n    ExpirationInterval: time.Minute * 10,\n    MaximumAttempts:    5,\n}\nao := workflow.ActivityOptions{\n    ScheduleToStartTimeout: expiration,\n    StartToCloseTimeout:    expiration,\n    HeartbeatTimeout:       time.Second * 30,\n    RetryPolicy:            retryPolicy, // Enable retry.\n}\nctx = workflow.WithActivityOptions(ctx, ao)\nactivityFuture := workflow.ExecuteActivity(ctx, SampleActivity, params)\n\n\nIf heartbeat its progress before it failed, the retry attempt will contain the progress so implementation could resume from failed progress like:\n\nfunc SampleActivity(ctx context.Context, inputArg InputParams) error {\n    startIdx := inputArg.StartIndex\n    if activity.HasHeartbeatDetails(ctx) {\n        // Recover from finished progress.\n        var finishedIndex int\n        if err := activity.GetHeartbeatDetails(ctx, &finishedIndex); err == nil {\n            startIdx = finishedIndex + 1 // Start from next one.\n        }\n    }\n\n    // Normal activity logic...\n    for i:=startIdx; i<inputArg.EndIdx; i++ {\n        // Code for processing item i goes here...\n        activity.RecordHeartbeat(ctx, i) // Report progress.\n    }\n}\n\n\nLike retry for an , you need to supply a retry policy for ChildWorkflowOptions to enable retry for a child . To enable retry for a parent , supply a retry policy when you start a via StartWorkflowOptions.\n\nThere are some subtle changes to 's history when RetryPolicy is used. For an with RetryPolicy:\n\n * The ActivityTaskScheduledEvent will have extended ScheduleToStartTimeout and ScheduleToCloseTimeout. These two timeouts will be overwritten by the server to be as long as the retry policy's ExpirationInterval. If the ExpirationInterval is not specified, it will be overwritten to the 's timeout.\n * The ActivityTaskStartedEvent will not show up in history until the is completed or failed with no more retry. This is to avoid recording the ActivityTaskStarted but later it failed and retried. Using the DescribeWorkflowExecution API will return the PendingActivityInfo and it will contain attemptCount if it is retrying.\n\nFor a with RetryPolicy:\n\n * If a failed and needs to retry, the will be closed with a ContinueAsNew . The will have the ContinueAsNewInitiator set to RetryPolicy and the new RunID for the next retry attempt.\n * The new attempt will be created immediately. But the first won't be scheduled until the backoff duration which is also recorded in the new run's WorkflowExecutionStartedEventAttributes as firstDecisionTaskBackoffSeconds.",normalizedContent:"# activity and workflow retries\n\nand can fail due to various intermediate conditions. in those cases, we want to retry the failed or child or even the parent . this can be achieved by supplying an optional retry policy. a retry policy looks like the following:\n\n// retrypolicy defines the retry policy.\nretrypolicy struct {\n    // backoff interval for the first retry. if coefficient is 1.0 then it is used for all retries.\n    // required, no default value.\n    initialinterval time.duration\n\n    // coefficient used to calculate the next retry backoff interval.\n    // the next retry interval is previous interval multiplied by this coefficient.\n    // must be 1 or larger. default is 2.0.\n    backoffcoefficient float64\n\n    // maximum backoff interval between retries. exponential backoff leads to interval increase.\n    // this value is the cap of the interval. default is 100x of initial interval.\n    maximuminterval time.duration\n\n    // maximum time to retry. either expirationinterval or maximumattempts is required.\n    // when exceeded the retries stop even if maximum retries is not reached yet.\n    // first (non-retry) attempt is unaffected by this field and is guaranteed to run \n    // for the entirety of the workflow timeout duration (executionstarttoclosetimeoutseconds).\n    expirationinterval time.duration\n\n    // maximum number of attempts. when exceeded the retries stop even if not expired yet.\n    // if not set or set to 0, it means unlimited, and relies on expirationinterval to stop.\n    // either maximumattempts or expirationinterval is required.\n    maximumattempts int32\n\n    // non-retriable errors. this is optional. cadence server will stop retry if error reason matches this list.\n    // error reason for custom error is specified when your activity/workflow returns cadence.newcustomerror(reason).\n    // error reason for panic error is \"cadenceinternal:panic\".\n    // error reason for any other error is \"cadenceinternal:generic\".\n    // error reason for timeouts is: \"cadenceinternal:timeout timeout_type\". timeout_type could be start_to_close or heartbeat.\n    // note that cancellation is not a failure, so it won't be retried.\n    nonretriableerrorreasons []string\n}\n\n\nto enable retry, supply a custom retry policy to activityoptions or childworkflowoptions when you execute them.\n\nexpiration := time.minute * 10\nretrypolicy := &cadence.retrypolicy{\n    initialinterval:    time.second,\n    backoffcoefficient: 2,\n    maximuminterval:    expiration,\n    expirationinterval: time.minute * 10,\n    maximumattempts:    5,\n}\nao := workflow.activityoptions{\n    scheduletostarttimeout: expiration,\n    starttoclosetimeout:    expiration,\n    heartbeattimeout:       time.second * 30,\n    retrypolicy:            retrypolicy, // enable retry.\n}\nctx = workflow.withactivityoptions(ctx, ao)\nactivityfuture := workflow.executeactivity(ctx, sampleactivity, params)\n\n\nif heartbeat its progress before it failed, the retry attempt will contain the progress so implementation could resume from failed progress like:\n\nfunc sampleactivity(ctx context.context, inputarg inputparams) error {\n    startidx := inputarg.startindex\n    if activity.hasheartbeatdetails(ctx) {\n        // recover from finished progress.\n        var finishedindex int\n        if err := activity.getheartbeatdetails(ctx, &finishedindex); err == nil {\n            startidx = finishedindex + 1 // start from next one.\n        }\n    }\n\n    // normal activity logic...\n    for i:=startidx; i<inputarg.endidx; i++ {\n        // code for processing item i goes here...\n        activity.recordheartbeat(ctx, i) // report progress.\n    }\n}\n\n\nlike retry for an , you need to supply a retry policy for childworkflowoptions to enable retry for a child . to enable retry for a parent , supply a retry policy when you start a via startworkflowoptions.\n\nthere are some subtle changes to 's history when retrypolicy is used. for an with retrypolicy:\n\n * the activitytaskscheduledevent will have extended scheduletostarttimeout and scheduletoclosetimeout. these two timeouts will be overwritten by the server to be as long as the retry policy's expirationinterval. if the expirationinterval is not specified, it will be overwritten to the 's timeout.\n * the activitytaskstartedevent will not show up in history until the is completed or failed with no more retry. this is to avoid recording the activitytaskstarted but later it failed and retried. using the describeworkflowexecution api will return the pendingactivityinfo and it will contain attemptcount if it is retrying.\n\nfor a with retrypolicy:\n\n * if a failed and needs to retry, the will be closed with a continueasnew . the will have the continueasnewinitiator set to retrypolicy and the new runid for the next retry attempt.\n * the new attempt will be created immediately. but the first won't be scheduled until the backoff duration which is also recorded in the new run's workflowexecutionstartedeventattributes as firstdecisiontaskbackoffseconds.",charsets:{}},{title:"Error handling",frontmatter:{layout:"default",title:"Error handling",permalink:"/docs/go-client/error-handling",readingShow:"top"},regularPath:"/docs/05-go-client/07-error-handling.html",relativePath:"docs/05-go-client/07-error-handling.md",key:"v-595589a2",path:"/docs/go-client/error-handling/",codeSwitcherOptions:{},headersStr:null,content:'# Error handling\n\nAn , or child , might fail and you could handle errors differently based on different error cases. If the returns an error as errors.New() or fmt.Errorf(), those errors will be converted to workflow.GenericError. If the returns an error as cadence.NewCustomError(“err-reason”, details), that error will be converted to *cadence.CustomError. There are other types of errors such as workflow.TimeoutError, workflow.CanceledError and workflow.PanicError. Following is an example of what your error code might look like:\n\nerr := workflow.ExecuteActivity(ctx, YourActivityFunc).Get(ctx, nil)\nswitch err := err.(type) {\n    case *cadence.CustomError:\n        switch err.Reason() {\n            case "err-reason-a":\n                // Handle error-reason-a.\n                var details YourErrorDetailsType\n                err.Details(&details)\n                // Deal with details.\n            case "err-reason-b":\n                // Handle error-reason-b.\n            default:\n                // Handle all other error reasons.\n        }\n    case *workflow.GenericError:\n        switch err.Error() {\n            case "err-msg-1":\n                // Handle error with message "err-msg-1".\n            case "err-msg-2":\n                // Handle error with message "err-msg-2".\n            default:\n                // Handle all other generic errors.\n        }\n    case *workflow.TimeoutError:\n        switch err.TimeoutType() {\n            case shared.TimeoutTypeScheduleToStart:\n                // Handle ScheduleToStart timeout.\n            case shared.TimeoutTypeStartToClose:\n                // Handle StartToClose timeout.\n            case shared.TimeoutTypeHeartbeat:\n                // Handle heartbeat timeout.\n            default:\n        }\n    case *workflow.PanicError:\n        // Handle panic error.\n    case *cadence.CanceledError:\n        // Handle canceled error.\n    default:\n        // All other cases (ideally, this should not happen).\n}\n',normalizedContent:'# error handling\n\nan , or child , might fail and you could handle errors differently based on different error cases. if the returns an error as errors.new() or fmt.errorf(), those errors will be converted to workflow.genericerror. if the returns an error as cadence.newcustomerror(“err-reason”, details), that error will be converted to *cadence.customerror. there are other types of errors such as workflow.timeouterror, workflow.cancelederror and workflow.panicerror. following is an example of what your error code might look like:\n\nerr := workflow.executeactivity(ctx, youractivityfunc).get(ctx, nil)\nswitch err := err.(type) {\n    case *cadence.customerror:\n        switch err.reason() {\n            case "err-reason-a":\n                // handle error-reason-a.\n                var details yourerrordetailstype\n                err.details(&details)\n                // deal with details.\n            case "err-reason-b":\n                // handle error-reason-b.\n            default:\n                // handle all other error reasons.\n        }\n    case *workflow.genericerror:\n        switch err.error() {\n            case "err-msg-1":\n                // handle error with message "err-msg-1".\n            case "err-msg-2":\n                // handle error with message "err-msg-2".\n            default:\n                // handle all other generic errors.\n        }\n    case *workflow.timeouterror:\n        switch err.timeouttype() {\n            case shared.timeouttypescheduletostart:\n                // handle scheduletostart timeout.\n            case shared.timeouttypestarttoclose:\n                // handle starttoclose timeout.\n            case shared.timeouttypeheartbeat:\n                // handle heartbeat timeout.\n            default:\n        }\n    case *workflow.panicerror:\n        // handle panic error.\n    case *cadence.cancelederror:\n        // handle canceled error.\n    default:\n        // all other cases (ideally, this should not happen).\n}\n',charsets:{}},{title:"Continue as new",frontmatter:{layout:"default",title:"Continue as new",permalink:"/docs/go-client/continue-as-new",readingShow:"top"},regularPath:"/docs/05-go-client/09-continue-as-new.html",relativePath:"docs/05-go-client/09-continue-as-new.md",key:"v-7732347a",path:"/docs/go-client/continue-as-new/",codeSwitcherOptions:{},headersStr:null,content:"# Continue as new\n\nthat need to rerun periodically could naively be implemented as a big for loop with a sleep where the entire logic of the is inside the body of the for loop. The problem with this approach is that the history for that will keep growing to a point where it reaches the maximum size enforced by the service.\n\nContinueAsNew is the low level construct that enables implementing such without the risk of failures down the road. The operation atomically completes the current execution and starts a new execution of the with the same . The new execution will not carry over any history from the old execution. To trigger this behavior, the function should terminate by returning the special ContinueAsNewError error:\n\nfunc SimpleWorkflow(workflow.Context ctx, value string) error {\n    ...\n    return workflow.NewContinueAsNewError(ctx, SimpleWorkflow, value)\n}\n",normalizedContent:"# continue as new\n\nthat need to rerun periodically could naively be implemented as a big for loop with a sleep where the entire logic of the is inside the body of the for loop. the problem with this approach is that the history for that will keep growing to a point where it reaches the maximum size enforced by the service.\n\ncontinueasnew is the low level construct that enables implementing such without the risk of failures down the road. the operation atomically completes the current execution and starts a new execution of the with the same . the new execution will not carry over any history from the old execution. to trigger this behavior, the function should terminate by returning the special continueasnewerror error:\n\nfunc simpleworkflow(workflow.context ctx, value string) error {\n    ...\n    return workflow.newcontinueasnewerror(ctx, simpleworkflow, value)\n}\n",charsets:{}},{title:"Signals",frontmatter:{layout:"default",title:"Signals",permalink:"/docs/go-client/signals",readingShow:"top"},regularPath:"/docs/05-go-client/08-signals.html",relativePath:"docs/05-go-client/08-signals.md",key:"v-67f3ae7c",path:"/docs/go-client/signals/",headers:[{level:2,title:"SignalWithStart",slug:"signalwithstart",normalizedTitle:"signalwithstart",charIndex:1651}],codeSwitcherOptions:{},headersStr:"SignalWithStart",content:'# Signals\n\nprovide a mechanism to send data directly to a running . Previously, you had two options for passing data to the implementation:\n\n * Via start parameters\n * As return values from\n\nWith start parameters, we could only pass in values before began.\n\nReturn values from allowed us to pass information to a running , but this approach comes with its own complications. One major drawback is reliance on polling. This means that the data needs to be stored in a third-party location until it\'s ready to be picked up by the . Further, the lifecycle of this requires management, and the requires manual restart if it fails before acquiring the data.\n\n, on the other hand, provide a fully asynchronous and durable mechanism for providing data to a running . When a is received for a running , Cadence persists the and the payload in the history. The can then process the at any time afterwards without the risk of losing the information. The also has the option to stop execution by blocking on a channel.\n\nvar signalVal string\nsignalChan := workflow.GetSignalChannel(ctx, signalName)\n\ns := workflow.NewSelector(ctx)\ns.AddReceive(signalChan, func(c workflow.Channel, more bool) {\n    c.Receive(ctx, &signalVal)\n    workflow.GetLogger(ctx).Info("Received signal!", zap.String("signal", signalName), zap.String("value", signalVal))\n})\ns.Select(ctx)\n\nif len(signalVal) > 0 && signalVal != "SOME_VALUE" {\n    return errors.New("signalVal")\n}\n\n\nIn the example above, the code uses workflow.GetSignalChannel to open a workflow.Channel for the named . We then use a workflow.Selector to wait on this channel and process the payload received with the .\n\n\n# SignalWithStart\n\nYou may not know if a is running and can accept a . The client.SignalWithStartWorkflow API allows you to send a to the current instance if one exists or to create a new run and then send the . SignalWithStartWorkflow therefore doesn\'t take a as a parameter.',normalizedContent:'# signals\n\nprovide a mechanism to send data directly to a running . previously, you had two options for passing data to the implementation:\n\n * via start parameters\n * as return values from\n\nwith start parameters, we could only pass in values before began.\n\nreturn values from allowed us to pass information to a running , but this approach comes with its own complications. one major drawback is reliance on polling. this means that the data needs to be stored in a third-party location until it\'s ready to be picked up by the . further, the lifecycle of this requires management, and the requires manual restart if it fails before acquiring the data.\n\n, on the other hand, provide a fully asynchronous and durable mechanism for providing data to a running . when a is received for a running , cadence persists the and the payload in the history. the can then process the at any time afterwards without the risk of losing the information. the also has the option to stop execution by blocking on a channel.\n\nvar signalval string\nsignalchan := workflow.getsignalchannel(ctx, signalname)\n\ns := workflow.newselector(ctx)\ns.addreceive(signalchan, func(c workflow.channel, more bool) {\n    c.receive(ctx, &signalval)\n    workflow.getlogger(ctx).info("received signal!", zap.string("signal", signalname), zap.string("value", signalval))\n})\ns.select(ctx)\n\nif len(signalval) > 0 && signalval != "some_value" {\n    return errors.new("signalval")\n}\n\n\nin the example above, the code uses workflow.getsignalchannel to open a workflow.channel for the named . we then use a workflow.selector to wait on this channel and process the payload received with the .\n\n\n# signalwithstart\n\nyou may not know if a is running and can accept a . the client.signalwithstartworkflow api allows you to send a to the current instance if one exists or to create a new run and then send the . signalwithstartworkflow therefore doesn\'t take a as a parameter.',charsets:{}},{title:"Queries",frontmatter:{layout:"default",title:"Queries",permalink:"/docs/go-client/queries",readingShow:"top"},regularPath:"/docs/05-go-client/11-queries.html",relativePath:"docs/05-go-client/11-queries.md",key:"v-a1460e54",path:"/docs/go-client/queries/",headers:[{level:2,title:"Consistent Query",slug:"consistent-query",normalizedTitle:"consistent query",charIndex:2009}],codeSwitcherOptions:{},headersStr:"Consistent Query",content:'# Queries\n\nIf a has been stuck at a state for longer than an expected period of time, you might want to the current call stack. You can use the Cadence to perform this . For example:\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt __stack_trace\n\nThis command uses __stack_trace, which is a built-in type supported by the Cadence client library. You can add custom types to handle such as the current state of a , or how many the has completed. To do this, you need to set up a handler using workflow.SetQueryHandler.\n\nThe handler must be a function that returns two values:\n\n 1. A serializable result\n 2. An error\n\nThe handler function can receive any number of input parameters, but all input parameters must be serializable. The following sample code sets up a handler that handles the type of current_state:\n\nfunc MyWorkflow(ctx workflow.Context, input string) error {\n    currentState := "started" // This could be any serializable struct.\n    err := workflow.SetQueryHandler(ctx, "current_state", func() (string, error) {\n        return currentState, nil\n    })\n    if err != nil {\n        currentState = "failed to register query handler"\n        return err\n    }\n    // Your normal workflow code begins here, and you update the currentState as the code makes progress.\n    currentState = "waiting timer"\n    err = NewTimer(ctx, time.Hour).Get(ctx, nil)\n    if err != nil {\n        currentState = "timer failed"\n        return err\n    }\n\n    currentState = "waiting activity"\n    ctx = WithActivityOptions(ctx, myActivityOptions)\n    err = ExecuteActivity(ctx, MyActivity, "my_input").Get(ctx, nil)\n    if err != nil {\n        currentState = "activity failed"\n        return err\n    }\n    currentState = "done"\n    return nil\n}\n\n\nYou can now current_state by using the\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state\n\nYou can also issue a from code using the QueryWorkflow() API on a Cadence client object.\n\n\n# Consistent Query\n\nhas two consistency levels, eventual and strong. Consider if you were to a and then immediately the\n\ncadence-cli --domain samples-domain workflow signal -w my_workflow_id -r my_run_id -n signal_name -if ./input.json\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state\n\nIn this example if were to change state, may or may not see that state update reflected in the result. This is what it means for to be eventually consistent.\n\nhas another consistency level called strong consistency. A strongly consistent is guaranteed to be based on state which includes all that came before the was issued. An is considered to have come before a if the call creating the external returned success before the was issued. External which are created while the is outstanding may or may not be reflected in the state the result is based on.\n\nIn order to run consistent through the do the following:\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state --qcl strong\n\nIn order to run a using the go client do the following:\n\nresp, err := cadenceClient.QueryWorkflowWithOptions(ctx, &client.QueryWorkflowWithOptionsRequest{\n    WorkflowID:            workflowID,\n    RunID:                 runID,\n    QueryType:             queryType,\n    QueryConsistencyLevel: shared.QueryConsistencyLevelStrong.Ptr(),\n})\n\n\nWhen using strongly consistent you should expect higher latency than eventually consistent .',normalizedContent:'# queries\n\nif a has been stuck at a state for longer than an expected period of time, you might want to the current call stack. you can use the cadence to perform this . for example:\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt __stack_trace\n\nthis command uses __stack_trace, which is a built-in type supported by the cadence client library. you can add custom types to handle such as the current state of a , or how many the has completed. to do this, you need to set up a handler using workflow.setqueryhandler.\n\nthe handler must be a function that returns two values:\n\n 1. a serializable result\n 2. an error\n\nthe handler function can receive any number of input parameters, but all input parameters must be serializable. the following sample code sets up a handler that handles the type of current_state:\n\nfunc myworkflow(ctx workflow.context, input string) error {\n    currentstate := "started" // this could be any serializable struct.\n    err := workflow.setqueryhandler(ctx, "current_state", func() (string, error) {\n        return currentstate, nil\n    })\n    if err != nil {\n        currentstate = "failed to register query handler"\n        return err\n    }\n    // your normal workflow code begins here, and you update the currentstate as the code makes progress.\n    currentstate = "waiting timer"\n    err = newtimer(ctx, time.hour).get(ctx, nil)\n    if err != nil {\n        currentstate = "timer failed"\n        return err\n    }\n\n    currentstate = "waiting activity"\n    ctx = withactivityoptions(ctx, myactivityoptions)\n    err = executeactivity(ctx, myactivity, "my_input").get(ctx, nil)\n    if err != nil {\n        currentstate = "activity failed"\n        return err\n    }\n    currentstate = "done"\n    return nil\n}\n\n\nyou can now current_state by using the\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state\n\nyou can also issue a from code using the queryworkflow() api on a cadence client object.\n\n\n# consistent query\n\nhas two consistency levels, eventual and strong. consider if you were to a and then immediately the\n\ncadence-cli --domain samples-domain workflow signal -w my_workflow_id -r my_run_id -n signal_name -if ./input.json\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state\n\nin this example if were to change state, may or may not see that state update reflected in the result. this is what it means for to be eventually consistent.\n\nhas another consistency level called strong consistency. a strongly consistent is guaranteed to be based on state which includes all that came before the was issued. an is considered to have come before a if the call creating the external returned success before the was issued. external which are created while the is outstanding may or may not be reflected in the state the result is based on.\n\nin order to run consistent through the do the following:\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state --qcl strong\n\nin order to run a using the go client do the following:\n\nresp, err := cadenceclient.queryworkflowwithoptions(ctx, &client.queryworkflowwithoptionsrequest{\n    workflowid:            workflowid,\n    runid:                 runid,\n    querytype:             querytype,\n    queryconsistencylevel: shared.queryconsistencylevelstrong.ptr(),\n})\n\n\nwhen using strongly consistent you should expect higher latency than eventually consistent .',charsets:{}},{title:"Side effect",frontmatter:{layout:"default",title:"Side effect",permalink:"/docs/go-client/side-effect",readingShow:"top"},regularPath:"/docs/05-go-client/10-side-effect.html",relativePath:"docs/05-go-client/10-side-effect.md",key:"v-d0383dd4",path:"/docs/go-client/side-effect/",codeSwitcherOptions:{},headersStr:null,content:'# Side effect\n\nworkflow.SideEffect is useful for short, nondeterministic code snippets, such as getting a random value or generating a UUID. It executes the provided function once and records its result into the history. workflow.SideEffect does not re-execute upon replay, but instead returns the recorded result. It can be seen as an "inline" . Something to note about workflow.SideEffect is that, unlike the Cadence guarantee of at-most-once execution for , there is no such guarantee with workflow.SideEffect. Under certain failure conditions, workflow.SideEffect can end up executing a function more than once.\n\nThe only way to fail SideEffect is to panic, which causes a failure. After the timeout, Cadence reschedules and then re-executes the , giving SideEffect another chance to succeed. Do not return any data from SideEffect other than through its recorded return value.\n\nThe following sample demonstrates how to use SideEffect:\n\nencodedRandom := SideEffect(func(ctx cadence.Context) interface{} {\n    return rand.Intn(100)\n})\n\nvar random int\nencodedRandom.Get(&random)\nif random < 50 {\n    ...\n} else {\n    ...\n}\n',normalizedContent:'# side effect\n\nworkflow.sideeffect is useful for short, nondeterministic code snippets, such as getting a random value or generating a uuid. it executes the provided function once and records its result into the history. workflow.sideeffect does not re-execute upon replay, but instead returns the recorded result. it can be seen as an "inline" . something to note about workflow.sideeffect is that, unlike the cadence guarantee of at-most-once execution for , there is no such guarantee with workflow.sideeffect. under certain failure conditions, workflow.sideeffect can end up executing a function more than once.\n\nthe only way to fail sideeffect is to panic, which causes a failure. after the timeout, cadence reschedules and then re-executes the , giving sideeffect another chance to succeed. do not return any data from sideeffect other than through its recorded return value.\n\nthe following sample demonstrates how to use sideeffect:\n\nencodedrandom := sideeffect(func(ctx cadence.context) interface{} {\n    return rand.intn(100)\n})\n\nvar random int\nencodedrandom.get(&random)\nif random < 50 {\n    ...\n} else {\n    ...\n}\n',charsets:{}},{title:"Async activity completion",frontmatter:{layout:"default",title:"Async activity completion",permalink:"/docs/go-client/activity-async-completion",readingShow:"top"},regularPath:"/docs/05-go-client/12-activity-async-completion.html",relativePath:"docs/05-go-client/12-activity-async-completion.md",key:"v-0a1dd2ec",path:"/docs/go-client/activity-async-completion/",codeSwitcherOptions:{},headersStr:null,content:'# Asynchronous activity completion\n\nThere are certain scenarios when completing an upon completion of its function is not possible or desirable. For example, you might have an application that requires user input in order to complete the . You could implement the with a polling mechanism, but a simpler and less resource-intensive implementation is to asynchronously complete a Cadence .\n\nThere two parts to implementing an asynchronously completed activity:\n\n 1. The provides the information necessary for completion from an external system and notifies the Cadence service that it is waiting for that outside callback.\n 2. The external service calls the Cadence service to complete the .\n\nThe following example demonstrates the first part:\n\n// Retrieve the activity information needed to asynchronously complete the activity.\nactivityInfo := cadence.GetActivityInfo(ctx)\ntaskToken := activityInfo.TaskToken\n\n// Send the taskToken to the external service that will complete the activity.\n...\n\n// Return from the activity a function indicating that Cadence should wait for an async completion\n// message.\nreturn "", activity.ErrResultPending\n\n\nThe following code demonstrates how to complete the successfully:\n\n// Instantiate a Cadence service client.\n// The same client can be used to complete or fail any number of activities.\ncadence.Client client = cadence.NewClient(...)\n\n// Complete the activity.\nclient.CompleteActivity(taskToken, result, nil)\n\n\nTo fail the , you would do the following:\n\n// Fail the activity.\nclient.CompleteActivity(taskToken, nil, err)\n\n\nFollowing are the parameters of the CompleteActivity function:\n\n * taskToken: The value of the binary TaskToken field of the ActivityInfo struct retrieved inside the .\n * result: The return value to record for the . The type of this value must match the type of the return value declared by the function.\n * err: The error code to return if the terminates with an error.\n\nIf error is not null, the value of the result field is ignored.',normalizedContent:'# asynchronous activity completion\n\nthere are certain scenarios when completing an upon completion of its function is not possible or desirable. for example, you might have an application that requires user input in order to complete the . you could implement the with a polling mechanism, but a simpler and less resource-intensive implementation is to asynchronously complete a cadence .\n\nthere two parts to implementing an asynchronously completed activity:\n\n 1. the provides the information necessary for completion from an external system and notifies the cadence service that it is waiting for that outside callback.\n 2. the external service calls the cadence service to complete the .\n\nthe following example demonstrates the first part:\n\n// retrieve the activity information needed to asynchronously complete the activity.\nactivityinfo := cadence.getactivityinfo(ctx)\ntasktoken := activityinfo.tasktoken\n\n// send the tasktoken to the external service that will complete the activity.\n...\n\n// return from the activity a function indicating that cadence should wait for an async completion\n// message.\nreturn "", activity.errresultpending\n\n\nthe following code demonstrates how to complete the successfully:\n\n// instantiate a cadence service client.\n// the same client can be used to complete or fail any number of activities.\ncadence.client client = cadence.newclient(...)\n\n// complete the activity.\nclient.completeactivity(tasktoken, result, nil)\n\n\nto fail the , you would do the following:\n\n// fail the activity.\nclient.completeactivity(tasktoken, nil, err)\n\n\nfollowing are the parameters of the completeactivity function:\n\n * tasktoken: the value of the binary tasktoken field of the activityinfo struct retrieved inside the .\n * result: the return value to record for the . the type of this value must match the type of the return value declared by the function.\n * err: the error code to return if the terminates with an error.\n\nif error is not null, the value of the result field is ignored.',charsets:{}},{title:"Testing",frontmatter:{layout:"default",title:"Testing",permalink:"/docs/go-client/workflow-testing",readingShow:"top"},regularPath:"/docs/05-go-client/13-workflow-testing.html",relativePath:"docs/05-go-client/13-workflow-testing.md",key:"v-c8a8f07c",path:"/docs/go-client/workflow-testing/",headers:[{level:2,title:"Setup",slug:"setup",normalizedTitle:"setup",charIndex:619},{level:2,title:"A Simple Test",slug:"a-simple-test",normalizedTitle:"a simple test",charIndex:2858},{level:2,title:"Activity mocking and overriding",slug:"activity-mocking-and-overriding",normalizedTitle:"activity mocking and overriding",charIndex:3534},{level:2,title:"Testing signals",slug:"testing-signals",normalizedTitle:"testing signals",charIndex:6905}],codeSwitcherOptions:{},headersStr:"Setup A Simple Test Activity mocking and overriding Testing signals",content:'# Testing\n\nThe Cadence Go client library provides a test framework to facilitate testing implementations. The framework is suited for implementing unit tests as well as functional tests of the logic.\n\nThe following code implements unit tests for the SimpleWorkflow sample:\n\npackage sample\n\nimport (\n    "errors"\n    "testing"\n\n    "github.com/stretchr/testify/mock"\n    "github.com/stretchr/testify/suite"\n\n    "go.uber.org/cadence"\n    "go.uber.org/cadence/testsuite"\n)\n\ntype UnitTestSuite struct {\n    suite.Suite\n    testsuite.WorkflowTestSuite\n\n    env *testsuite.TestWorkflowEnvironment\n}\n\nfunc (s *UnitTestSuite) SetupTest() {\n    s.env = s.NewTestWorkflowEnvironment()\n}\n\nfunc (s *UnitTestSuite) AfterTest(suiteName, testName string) {\n    s.env.AssertExpectations(s.T())\n}\n\nfunc (s *UnitTestSuite) Test_SimpleWorkflow_Success() {\n    s.env.ExecuteWorkflow(SimpleWorkflow, "test_success")\n\n    s.True(s.env.IsWorkflowCompleted())\n    s.NoError(s.env.GetWorkflowError())\n}\n\nfunc (s *UnitTestSuite) Test_SimpleWorkflow_ActivityParamCorrect() {\n    s.env.OnActivity(SimpleActivity, mock.Anything, mock.Anything).Return(\n        func(ctx context.Context, value string) (string, error) {\n            s.Equal("test_success", value)\n            return value, nil\n        }\n    )\n    s.env.ExecuteWorkflow(SimpleWorkflow, "test_success")\n\n    s.True(s.env.IsWorkflowCompleted())\n    s.NoError(s.env.GetWorkflowError())\n}\n\nfunc (s *UnitTestSuite) Test_SimpleWorkflow_ActivityFails() {\n    s.env.OnActivity(SimpleActivity, mock.Anything, mock.Anything).Return(\n        "", errors.New("SimpleActivityFailure"))\n    s.env.ExecuteWorkflow(SimpleWorkflow, "test_failure")\n\n    s.True(s.env.IsWorkflowCompleted())\n\n    s.NotNil(s.env.GetWorkflowError())\n    s.True(cadence.IsGenericError(s.env.GetWorkflowError()))\n    s.Equal("SimpleActivityFailure", s.env.GetWorkflowError().Error())\n}\n\nfunc TestUnitTestSuite(t *testing.T) {\n    suite.Run(t, new(UnitTestSuite))\n}\n\n\n\n# Setup\n\nTo run unit tests, we first define a "test suite" struct that absorbs both the basic suite functionality from testify via suite.Suite and the suite functionality from the Cadence test framework via cadence.WorkflowTestSuite. Because every test in this test suite will test our , we add a property to our struct to hold an instance of the test environment. This allows us to initialize the test environment in a setup method. For testing , we use a cadence.TestWorkflowEnvironment.\n\nNext, we implement a SetupTest method to setup a new test environment before each test. Doing so ensures that each test runs in its own isolated sandbox. We also implement an AfterTest function where we assert that all mocks we set up were indeed called by invoking s.env.AssertExpectations(s.T()).\n\nFinally, we create a regular test function recognized by "go test" and pass the struct to suite.Run.\n\n\n# A Simple Test\n\nThe most simple test case we can write is to have the test environment execute the and then evaluate the results.\n\nfunc (s *UnitTestSuite) Test_SimpleWorkflow_Success() {\n    s.env.ExecuteWorkflow(SimpleWorkflow, "test_success")\n\n    s.True(s.env.IsWorkflowCompleted())\n    s.NoError(s.env.GetWorkflowError())\n}\n\n\nCalling s.env.ExecuteWorkflow(...) executes the logic and any invoked inside the test process. The first parameter of s.env.ExecuteWorkflow(...) contains the functions, and any subsequent parameters contain values for custom input parameters declared by the function.\n\n> Note that unless the invocations are mocked or implementation replaced (see Activity mocking and overriding), the test environment will execute the actual code including any calls to outside services.\n\nAfter executing the in the above example, we assert that the ran through completion via the call to s.env.IsWorkflowComplete(). We also assert that no errors were returned by asserting on the return value of s.env.GetWorkflowError(). If our returned a value, we could have retrieved that value via a call to s.env.GetWorkflowResult(&value) and had additional asserts on that value.\n\n\n# Activity mocking and overriding\n\nWhen running unit tests on , we want to test the logic in isolation. Additionally, we want to inject errors during our test runs. The test framework provides two mechanisms that support these scenarios: mocking and overriding. Both of these mechanisms allow you to change the behavior of invoked by your without the need to modify the actual code.\n\nLet\'s take a look at a test that simulates a test that fails via the "activity mocking" mechanism.\n\nfunc (s *UnitTestSuite) Test_SimpleWorkflow_ActivityFails() {\n    s.env.OnActivity(SimpleActivity, mock.Anything, mock.Anything).Return(\n        "", errors.New("SimpleActivityFailure"))\n    s.env.ExecuteWorkflow(SimpleWorkflow, "test_failure")\n\n    s.True(s.env.IsWorkflowCompleted())\n\n    s.NotNil(s.env.GetWorkflowError())\n    _, ok := s.env.GetWorkflowError().(*cadence.GenericError)\n    s.True(ok)\n    s.Equal("SimpleActivityFailure", s.env.GetWorkflowError().Error())\n}\n\n\nThis test simulates the execution of the SimpleActivity that is invoked by our SimpleWorkflow returning an error. We accomplish this by setting up a mock on the test environment for the SimpleActivity that returns an error.\n\ns.env.OnActivity(SimpleActivity, mock.Anything, mock.Anything).Return(\n    "", errors.New("SimpleActivityFailure"))\n\n\nWith the mock set up we can now execute the via the s.env.ExecuteWorkflow(...) method and assert that the completed successfully and returned the expected error.\n\nSimply mocking the execution to return a desired value or error is a pretty powerful mechanism to isolate logic. However, sometimes we want to replace the with an alternate implementation to support a more complex test scenario. Let\'s assume we want to validate that the gets called with the correct parameters.\n\nfunc (s *UnitTestSuite) Test_SimpleWorkflow_ActivityParamCorrect() {\n    s.env.OnActivity(SimpleActivity, mock.Anything, mock.Anything).Return(\n        func(ctx context.Context, value string) (string, error) {\n            s.Equal("test_success", value)\n            return value, nil\n        }\n    )\n    s.env.ExecuteWorkflow(SimpleWorkflow, "test_success")\n\n    s.True(s.env.IsWorkflowCompleted())\n    s.NoError(s.env.GetWorkflowError())\n}\n\n\nIn this example, we provide a function implementation as the parameter to Return. This allows us to provide an alternate implementation for the SimpleActivity. The framework will execute this function whenever the is invoked and pass on the return value from the function as the result of the invocation. Additionally, the framework will validate that the signature of the “mock” function matches the signature of the original function.\n\nSince this can be an entire function, there is no limitation as to what we can do here. In this example, we assert that the “value” param has the same content as the value param we passed to the .\n\n\n# Testing signals\n\nTo test signals we can use the functions s.env.SignalWorkflow, and s.env.SignalWorkflowByID. These functions needs to be called inside s.env.RegisterDelayedCallback, as the signal should be send while the is running. It is important to register the signal before calling s.env.ExecuteWorkflow, otherwise the signal will not be send.\n\nIf our is waiting for a signal with name signalName we can register to send this signal before the workflow is executed like this:\n\nfunc (s *UnitTestSuite) Test_SimpleWorkflow_Signal() {\n    // Send the signal\n\ts.env.RegisterDelayedCallback(func() {\n\t\ts.env.SignalWorkflow(signalName, signalData)\n\t}, time.Minute*10)\n\n    // Execute the workflow\n    s.env.ExecuteWorkflow(SimpleWorkflow, "test_success")\n\n    s.True(s.env.IsWorkflowCompleted())\n    s.NoError(s.env.GetWorkflowError())\n}\n\n\nNote that the s.env.RegisterDelayedCallback function does not actually wait 10 minutes in the unit test instead the cadence test framework uses an internal clock which knows which event is the next, and executes it immediately.',normalizedContent:'# testing\n\nthe cadence go client library provides a test framework to facilitate testing implementations. the framework is suited for implementing unit tests as well as functional tests of the logic.\n\nthe following code implements unit tests for the simpleworkflow sample:\n\npackage sample\n\nimport (\n    "errors"\n    "testing"\n\n    "github.com/stretchr/testify/mock"\n    "github.com/stretchr/testify/suite"\n\n    "go.uber.org/cadence"\n    "go.uber.org/cadence/testsuite"\n)\n\ntype unittestsuite struct {\n    suite.suite\n    testsuite.workflowtestsuite\n\n    env *testsuite.testworkflowenvironment\n}\n\nfunc (s *unittestsuite) setuptest() {\n    s.env = s.newtestworkflowenvironment()\n}\n\nfunc (s *unittestsuite) aftertest(suitename, testname string) {\n    s.env.assertexpectations(s.t())\n}\n\nfunc (s *unittestsuite) test_simpleworkflow_success() {\n    s.env.executeworkflow(simpleworkflow, "test_success")\n\n    s.true(s.env.isworkflowcompleted())\n    s.noerror(s.env.getworkflowerror())\n}\n\nfunc (s *unittestsuite) test_simpleworkflow_activityparamcorrect() {\n    s.env.onactivity(simpleactivity, mock.anything, mock.anything).return(\n        func(ctx context.context, value string) (string, error) {\n            s.equal("test_success", value)\n            return value, nil\n        }\n    )\n    s.env.executeworkflow(simpleworkflow, "test_success")\n\n    s.true(s.env.isworkflowcompleted())\n    s.noerror(s.env.getworkflowerror())\n}\n\nfunc (s *unittestsuite) test_simpleworkflow_activityfails() {\n    s.env.onactivity(simpleactivity, mock.anything, mock.anything).return(\n        "", errors.new("simpleactivityfailure"))\n    s.env.executeworkflow(simpleworkflow, "test_failure")\n\n    s.true(s.env.isworkflowcompleted())\n\n    s.notnil(s.env.getworkflowerror())\n    s.true(cadence.isgenericerror(s.env.getworkflowerror()))\n    s.equal("simpleactivityfailure", s.env.getworkflowerror().error())\n}\n\nfunc testunittestsuite(t *testing.t) {\n    suite.run(t, new(unittestsuite))\n}\n\n\n\n# setup\n\nto run unit tests, we first define a "test suite" struct that absorbs both the basic suite functionality from testify via suite.suite and the suite functionality from the cadence test framework via cadence.workflowtestsuite. because every test in this test suite will test our , we add a property to our struct to hold an instance of the test environment. this allows us to initialize the test environment in a setup method. for testing , we use a cadence.testworkflowenvironment.\n\nnext, we implement a setuptest method to setup a new test environment before each test. doing so ensures that each test runs in its own isolated sandbox. we also implement an aftertest function where we assert that all mocks we set up were indeed called by invoking s.env.assertexpectations(s.t()).\n\nfinally, we create a regular test function recognized by "go test" and pass the struct to suite.run.\n\n\n# a simple test\n\nthe most simple test case we can write is to have the test environment execute the and then evaluate the results.\n\nfunc (s *unittestsuite) test_simpleworkflow_success() {\n    s.env.executeworkflow(simpleworkflow, "test_success")\n\n    s.true(s.env.isworkflowcompleted())\n    s.noerror(s.env.getworkflowerror())\n}\n\n\ncalling s.env.executeworkflow(...) executes the logic and any invoked inside the test process. the first parameter of s.env.executeworkflow(...) contains the functions, and any subsequent parameters contain values for custom input parameters declared by the function.\n\n> note that unless the invocations are mocked or implementation replaced (see activity mocking and overriding), the test environment will execute the actual code including any calls to outside services.\n\nafter executing the in the above example, we assert that the ran through completion via the call to s.env.isworkflowcomplete(). we also assert that no errors were returned by asserting on the return value of s.env.getworkflowerror(). if our returned a value, we could have retrieved that value via a call to s.env.getworkflowresult(&value) and had additional asserts on that value.\n\n\n# activity mocking and overriding\n\nwhen running unit tests on , we want to test the logic in isolation. additionally, we want to inject errors during our test runs. the test framework provides two mechanisms that support these scenarios: mocking and overriding. both of these mechanisms allow you to change the behavior of invoked by your without the need to modify the actual code.\n\nlet\'s take a look at a test that simulates a test that fails via the "activity mocking" mechanism.\n\nfunc (s *unittestsuite) test_simpleworkflow_activityfails() {\n    s.env.onactivity(simpleactivity, mock.anything, mock.anything).return(\n        "", errors.new("simpleactivityfailure"))\n    s.env.executeworkflow(simpleworkflow, "test_failure")\n\n    s.true(s.env.isworkflowcompleted())\n\n    s.notnil(s.env.getworkflowerror())\n    _, ok := s.env.getworkflowerror().(*cadence.genericerror)\n    s.true(ok)\n    s.equal("simpleactivityfailure", s.env.getworkflowerror().error())\n}\n\n\nthis test simulates the execution of the simpleactivity that is invoked by our simpleworkflow returning an error. we accomplish this by setting up a mock on the test environment for the simpleactivity that returns an error.\n\ns.env.onactivity(simpleactivity, mock.anything, mock.anything).return(\n    "", errors.new("simpleactivityfailure"))\n\n\nwith the mock set up we can now execute the via the s.env.executeworkflow(...) method and assert that the completed successfully and returned the expected error.\n\nsimply mocking the execution to return a desired value or error is a pretty powerful mechanism to isolate logic. however, sometimes we want to replace the with an alternate implementation to support a more complex test scenario. let\'s assume we want to validate that the gets called with the correct parameters.\n\nfunc (s *unittestsuite) test_simpleworkflow_activityparamcorrect() {\n    s.env.onactivity(simpleactivity, mock.anything, mock.anything).return(\n        func(ctx context.context, value string) (string, error) {\n            s.equal("test_success", value)\n            return value, nil\n        }\n    )\n    s.env.executeworkflow(simpleworkflow, "test_success")\n\n    s.true(s.env.isworkflowcompleted())\n    s.noerror(s.env.getworkflowerror())\n}\n\n\nin this example, we provide a function implementation as the parameter to return. this allows us to provide an alternate implementation for the simpleactivity. the framework will execute this function whenever the is invoked and pass on the return value from the function as the result of the invocation. additionally, the framework will validate that the signature of the “mock” function matches the signature of the original function.\n\nsince this can be an entire function, there is no limitation as to what we can do here. in this example, we assert that the “value” param has the same content as the value param we passed to the .\n\n\n# testing signals\n\nto test signals we can use the functions s.env.signalworkflow, and s.env.signalworkflowbyid. these functions needs to be called inside s.env.registerdelayedcallback, as the signal should be send while the is running. it is important to register the signal before calling s.env.executeworkflow, otherwise the signal will not be send.\n\nif our is waiting for a signal with name signalname we can register to send this signal before the workflow is executed like this:\n\nfunc (s *unittestsuite) test_simpleworkflow_signal() {\n    // send the signal\n\ts.env.registerdelayedcallback(func() {\n\t\ts.env.signalworkflow(signalname, signaldata)\n\t}, time.minute*10)\n\n    // execute the workflow\n    s.env.executeworkflow(simpleworkflow, "test_success")\n\n    s.true(s.env.isworkflowcompleted())\n    s.noerror(s.env.getworkflowerror())\n}\n\n\nnote that the s.env.registerdelayedcallback function does not actually wait 10 minutes in the unit test instead the cadence test framework uses an internal clock which knows which event is the next, and executes it immediately.',charsets:{}},{title:"Versioning",frontmatter:{layout:"default",title:"Versioning",permalink:"/docs/go-client/workflow-versioning",readingShow:"top"},regularPath:"/docs/05-go-client/14-workflow-versioning.html",relativePath:"docs/05-go-client/14-workflow-versioning.md",key:"v-0b9844ac",path:"/docs/go-client/workflow-versioning/",headers:[{level:2,title:"workflow.GetVersion()",slug:"workflow-getversion",normalizedTitle:"workflow.getversion()",charIndex:315},{level:2,title:"Sanity checking",slug:"sanity-checking",normalizedTitle:"sanity checking",charIndex:5619}],codeSwitcherOptions:{},headersStr:"workflow.GetVersion() Sanity checking",content:'# Versioning\n\nThe definition code of a Cadence must be deterministic because Cadence uses sourcing to reconstruct the state by replaying the saved history data on the definition code. This means that any incompatible update to the definition code could cause a non-deterministic issue if not handled correctly.\n\n\n# workflow.GetVersion()\n\nConsider the following definition:\n\nfunc MyWorkflow(ctx workflow.Context, data string) (string, error) {\n    ao := workflow.ActivityOptions{\n        ScheduleToStartTimeout: time.Minute,\n        StartToCloseTimeout:    time.Minute,\n    }\n    ctx = workflow.WithActivityOptions(ctx, ao)\n    var result1 string\n    err := workflow.ExecuteActivity(ctx, ActivityA, data).Get(ctx, &result1)\n    if err != nil {\n        return "", err\n    }\n    var result2 string\n    err = workflow.ExecuteActivity(ctx, ActivityB, result1).Get(ctx, &result2)\n    return result2, err\n}\n\n\nNow let\'s say we have replaced ActivityA with ActivityC, and deployed the updated code. If there is an existing that was started by the original version of the code, where ActivityA had already completed and the result was recorded to history, the new version of the code will pick up that and try to resume from there. However, the will fail because the new code expects a result for ActivityC from the history data, but instead it gets the result for ActivityA. This causes the to fail on the non-deterministic error.\n\nThus we use workflow.GetVersion().\n\nvar err error\nv := workflow.GetVersion(ctx, "Step1", workflow.DefaultVersion, 1)\nif v == workflow.DefaultVersion {\n    err = workflow.ExecuteActivity(ctx, ActivityA, data).Get(ctx, &result1)\n} else {\n    err = workflow.ExecuteActivity(ctx, ActivityC, data).Get(ctx, &result1)\n}\nif err != nil {\n    return "", err\n}\n\nvar result2 string\nerr = workflow.ExecuteActivity(ctx, ActivityB, result1).Get(ctx, &result2)\nreturn result2, err\n\n\nWhen workflow.GetVersion() is run for the new , it records a marker in the history so that all future calls to GetVersion for this change ID--Step 1 in the example--on this will always return the given version number, which is 1 in the example.\n\nIf you make an additional change, such as replacing ActivityC with ActivityD, you need to add some additional code:\n\nv := workflow.GetVersion(ctx, "Step1", workflow.DefaultVersion, 2)\nif v == workflow.DefaultVersion {\n    err = workflow.ExecuteActivity(ctx, ActivityA, data).Get(ctx, &result1)\n} else if v == 1 {\n    err = workflow.ExecuteActivity(ctx, ActivityC, data).Get(ctx, &result1)\n} else {\n    err = workflow.ExecuteActivity(ctx, ActivityD, data).Get(ctx, &result1)\n}\n\n\nNote that we have changed maxSupported from 1 to 2. A that had already passed this GetVersion() call before it was introduced will return DefaultVersion. A that was run with maxSupported set to 1, will return 1. New will return 2.\n\nAfter you are sure that all of the prior to version 1 have completed, you can remove the code for that version. It should now look like the following:\n\nv := workflow.GetVersion(ctx, "Step1", 1, 2)\nif v == 1 {\n    err = workflow.ExecuteActivity(ctx, ActivityC, data).Get(ctx, &result1)\n} else {\n    err = workflow.ExecuteActivity(ctx, ActivityD, data).Get(ctx, &result1)\n}\n\n\nYou\'ll note that minSupported has changed from DefaultVersion to 1. If an older version of the history is replayed on this code, it will fail because the minimum expected version is 1. After you are sure that all of the for version 1 have completed, then you can remove 1 so that your code would look like the following:\n\n_ := workflow.GetVersion(ctx, "Step1", 2, 2)\nerr = workflow.ExecuteActivity(ctx, ActivityD, data).Get(ctx, &result1)\n\n\nNote that we have preserved the call to GetVersion(). There are two reasons to preserve this call:\n\n 1. This ensures that if there is a still running for an older version, it will fail here and not proceed.\n 2. If you need to make additional changes for Step1, such as changing ActivityD to ActivityE, you only need to update maxVersion from 2 to 3 and branch from there.\n\nYou only need to preserve the first call to GetVersion() for each changeID. All subsequent calls to GetVersion() with the same change ID are safe to remove. If necessary, you can remove the first GetVersion() call, but you need to ensure the following:\n\n * All executions with an older version are completed.\n * You can no longer use Step1 for the changeID. If you need to make changes to that same part in the future, such as change from ActivityD to ActivityE, you would need to use a different changeID like Step1-fix2, and start minVersion from DefaultVersion again. The code would look like the following:\n\nv := workflow.GetVersion(ctx, "Step1-fix2", workflow.DefaultVersion, 1)\nif v == workflow.DefaultVersion {\n    err = workflow.ExecuteActivity(ctx, ActivityD, data).Get(ctx, &result1)\n} else {\n    err = workflow.ExecuteActivity(ctx, ActivityE, data).Get(ctx, &result1)\n}\n\n\nUpgrading a is straightforward if you don\'t need to preserve your currently running . You can simply terminate all of the currently running and suspend new ones from being created while you deploy the new version of your code, which does not use GetVersion(), and then resume creation. However, that is often not the case, and you need to take care of the currently running , so using GetVersion() to update your code is the method to use.\n\nHowever, if you want your currently running to proceed based on the current logic, but you want to ensure new are running on new logic, you can define your as a new WorkflowType, and change your start path (calls to StartWorkflow()) to start the new type.\n\n\n# Sanity checking\n\nThe Cadence client SDK performs a sanity check to help prevent obvious incompatible changes. The sanity check verifies whether a made in replay matches the recorded in history, in the same order. The is generated by calling any of the following methods:\n\n * workflow.ExecuteActivity()\n * workflow.ExecuteChildWorkflow()\n * workflow.NewTimer()\n * workflow.Sleep()\n * workflow.SideEffect()\n * workflow.RequestCancelWorkflow()\n * workflow.SignalExternalWorkflow()\n * workflow.UpsertSearchAttributes()\n\nAdding, removing, or reordering any of the above methods triggers the sanity check and results in a non-deterministic error.\n\nThe sanity check does not perform a thorough check. For example, it does not check on the \'s input arguments or the timer duration. If the check is enforced on every property, then it becomes too restricted and harder to maintain the code. For example, if you move your code from one package to another package, that changes the ActivityType, which technically becomes a different . But, we don\'t want to fail on that change, so we only check the function name part of the ActivityType.',normalizedContent:'# versioning\n\nthe definition code of a cadence must be deterministic because cadence uses sourcing to reconstruct the state by replaying the saved history data on the definition code. this means that any incompatible update to the definition code could cause a non-deterministic issue if not handled correctly.\n\n\n# workflow.getversion()\n\nconsider the following definition:\n\nfunc myworkflow(ctx workflow.context, data string) (string, error) {\n    ao := workflow.activityoptions{\n        scheduletostarttimeout: time.minute,\n        starttoclosetimeout:    time.minute,\n    }\n    ctx = workflow.withactivityoptions(ctx, ao)\n    var result1 string\n    err := workflow.executeactivity(ctx, activitya, data).get(ctx, &result1)\n    if err != nil {\n        return "", err\n    }\n    var result2 string\n    err = workflow.executeactivity(ctx, activityb, result1).get(ctx, &result2)\n    return result2, err\n}\n\n\nnow let\'s say we have replaced activitya with activityc, and deployed the updated code. if there is an existing that was started by the original version of the code, where activitya had already completed and the result was recorded to history, the new version of the code will pick up that and try to resume from there. however, the will fail because the new code expects a result for activityc from the history data, but instead it gets the result for activitya. this causes the to fail on the non-deterministic error.\n\nthus we use workflow.getversion().\n\nvar err error\nv := workflow.getversion(ctx, "step1", workflow.defaultversion, 1)\nif v == workflow.defaultversion {\n    err = workflow.executeactivity(ctx, activitya, data).get(ctx, &result1)\n} else {\n    err = workflow.executeactivity(ctx, activityc, data).get(ctx, &result1)\n}\nif err != nil {\n    return "", err\n}\n\nvar result2 string\nerr = workflow.executeactivity(ctx, activityb, result1).get(ctx, &result2)\nreturn result2, err\n\n\nwhen workflow.getversion() is run for the new , it records a marker in the history so that all future calls to getversion for this change id--step 1 in the example--on this will always return the given version number, which is 1 in the example.\n\nif you make an additional change, such as replacing activityc with activityd, you need to add some additional code:\n\nv := workflow.getversion(ctx, "step1", workflow.defaultversion, 2)\nif v == workflow.defaultversion {\n    err = workflow.executeactivity(ctx, activitya, data).get(ctx, &result1)\n} else if v == 1 {\n    err = workflow.executeactivity(ctx, activityc, data).get(ctx, &result1)\n} else {\n    err = workflow.executeactivity(ctx, activityd, data).get(ctx, &result1)\n}\n\n\nnote that we have changed maxsupported from 1 to 2. a that had already passed this getversion() call before it was introduced will return defaultversion. a that was run with maxsupported set to 1, will return 1. new will return 2.\n\nafter you are sure that all of the prior to version 1 have completed, you can remove the code for that version. it should now look like the following:\n\nv := workflow.getversion(ctx, "step1", 1, 2)\nif v == 1 {\n    err = workflow.executeactivity(ctx, activityc, data).get(ctx, &result1)\n} else {\n    err = workflow.executeactivity(ctx, activityd, data).get(ctx, &result1)\n}\n\n\nyou\'ll note that minsupported has changed from defaultversion to 1. if an older version of the history is replayed on this code, it will fail because the minimum expected version is 1. after you are sure that all of the for version 1 have completed, then you can remove 1 so that your code would look like the following:\n\n_ := workflow.getversion(ctx, "step1", 2, 2)\nerr = workflow.executeactivity(ctx, activityd, data).get(ctx, &result1)\n\n\nnote that we have preserved the call to getversion(). there are two reasons to preserve this call:\n\n 1. this ensures that if there is a still running for an older version, it will fail here and not proceed.\n 2. if you need to make additional changes for step1, such as changing activityd to activitye, you only need to update maxversion from 2 to 3 and branch from there.\n\nyou only need to preserve the first call to getversion() for each changeid. all subsequent calls to getversion() with the same change id are safe to remove. if necessary, you can remove the first getversion() call, but you need to ensure the following:\n\n * all executions with an older version are completed.\n * you can no longer use step1 for the changeid. if you need to make changes to that same part in the future, such as change from activityd to activitye, you would need to use a different changeid like step1-fix2, and start minversion from defaultversion again. the code would look like the following:\n\nv := workflow.getversion(ctx, "step1-fix2", workflow.defaultversion, 1)\nif v == workflow.defaultversion {\n    err = workflow.executeactivity(ctx, activityd, data).get(ctx, &result1)\n} else {\n    err = workflow.executeactivity(ctx, activitye, data).get(ctx, &result1)\n}\n\n\nupgrading a is straightforward if you don\'t need to preserve your currently running . you can simply terminate all of the currently running and suspend new ones from being created while you deploy the new version of your code, which does not use getversion(), and then resume creation. however, that is often not the case, and you need to take care of the currently running , so using getversion() to update your code is the method to use.\n\nhowever, if you want your currently running to proceed based on the current logic, but you want to ensure new are running on new logic, you can define your as a new workflowtype, and change your start path (calls to startworkflow()) to start the new type.\n\n\n# sanity checking\n\nthe cadence client sdk performs a sanity check to help prevent obvious incompatible changes. the sanity check verifies whether a made in replay matches the recorded in history, in the same order. the is generated by calling any of the following methods:\n\n * workflow.executeactivity()\n * workflow.executechildworkflow()\n * workflow.newtimer()\n * workflow.sleep()\n * workflow.sideeffect()\n * workflow.requestcancelworkflow()\n * workflow.signalexternalworkflow()\n * workflow.upsertsearchattributes()\n\nadding, removing, or reordering any of the above methods triggers the sanity check and results in a non-deterministic error.\n\nthe sanity check does not perform a thorough check. for example, it does not check on the \'s input arguments or the timer duration. if the check is enforced on every property, then it becomes too restricted and harder to maintain the code. for example, if you move your code from one package to another package, that changes the activitytype, which technically becomes a different . but, we don\'t want to fail on that change, so we only check the function name part of the activitytype.',charsets:{}},{title:"Sessions",frontmatter:{layout:"default",title:"Sessions",permalink:"/docs/go-client/sessions",readingShow:"top"},regularPath:"/docs/05-go-client/15-sessions.html",relativePath:"docs/05-go-client/15-sessions.md",key:"v-edf882bc",path:"/docs/go-client/sessions/",headers:[{level:2,title:"Use Cases",slug:"use-cases",normalizedTitle:"use cases",charIndex:254},{level:2,title:"Basic Usage",slug:"basic-usage",normalizedTitle:"basic usage",charIndex:822},{level:3,title:"Sample Code",slug:"sample-code",normalizedTitle:"sample code",charIndex:3519},{level:2,title:"Session Metadata",slug:"session-metadata",normalizedTitle:"session metadata",charIndex:4548},{level:2,title:"Concurrent Session Limitation",slug:"concurrent-session-limitation",normalizedTitle:"concurrent session limitation",charIndex:3044},{level:2,title:"Recreate Session",slug:"recreate-session",normalizedTitle:"recreate session",charIndex:5565},{level:2,title:"Q & A",slug:"q-a",normalizedTitle:"q &amp; a",charIndex:null},{level:3,title:"Is there a complete example?",slug:"is-there-a-complete-example",normalizedTitle:"is there a complete example?",charIndex:6228},{level:3,title:"What happens to my activity if the worker dies?",slug:"what-happens-to-my-activity-if-the-worker-dies",normalizedTitle:"what happens to my activity if the worker dies?",charIndex:6369},{level:3,title:"Is the concurrent session limitation per process or per host?",slug:"is-the-concurrent-session-limitation-per-process-or-per-host",normalizedTitle:"is the concurrent session limitation per process or per host?",charIndex:6577},{level:2,title:"Future Work",slug:"future-work",normalizedTitle:"future work",charIndex:6753}],codeSwitcherOptions:{},headersStr:"Use Cases Basic Usage Sample Code Session Metadata Concurrent Session Limitation Recreate Session Q & A Is there a complete example? What happens to my activity if the worker dies? Is the concurrent session limitation per process or per host? Future Work",content:"# Sessions\n\nThe session framework provides a straightforward interface for scheduling multiple on a single without requiring you to manually specify the name. It also includes features like concurrent session limitation and worker failure detection.\n\n\n# Use Cases\n\n * File Processing: You may want to implement a that can download a file, process it, and then upload the modified version. If these three steps are implemented as three different , all of them should be executed by the same .\n\n * Machine Learning Model Training: Training a machine learning model typically involves three stages: download the data set, optimize the model, and upload the trained parameter. Since the models may consume a large amount of resources (GPU memory for example), the number of models processed on a host needs to be limited.\n\n\n# Basic Usage\n\nBefore using the session framework to write your code, you need to configure your to process sessions. To do that, set the EnableSessionWorker field of worker.Options to true when starting your .\n\nThe most important APIs provided by the session framework are workflow.CreateSession() and workflow.CompleteSession(). The basic idea is that all the executed within a session will be processed by the same and these two APIs allow you to create new sessions and close them after all finish executing.\n\nHere's a more detailed description of these two APIs:\n\ntype SessionOptions struct {\n    // ExecutionTimeout: required, no default.\n    //     Specifies the maximum amount of time the session can run.\n    ExecutionTimeout time.Duration\n\n    // CreationTimeout: required, no default.\n    //     Specifies how long session creation can take before returning an error.\n    CreationTimeout  time.Duration\n}\n\nfunc CreateSession(ctx Context, sessionOptions *SessionOptions) (Context, error)\n\n\nCreateSession() takes in workflow.Context, sessionOptions and returns a new context which contains metadata information of the created session (referred to as the session context below). When it's called, it will check the name specified in the ActivityOptions (or in the StartWorkflowOptions if the name is not specified in ActivityOptions), and create the session on one of the which is polling that .\n\nThe returned session context should be used to execute all belonging to the session. The context will be cancelled if the executing this session dies or CompleteSession() is called. When using the returned session context to execute , a workflow.ErrSessionFailed error may be returned if the session framework detects that the executing this session has died. The failure of your won't affect the state of the session, so you still need to handle the errors returned from your and call CompleteSession() if necessary.\n\nCreateSession() will return an error if the context passed in already contains an open session. If all the are currently busy and unable to handle new sessions, the framework will keep retrying until the CreationTimeout you specified in SessionOptions has passed before returning an error (check the Concurrent Session Limitation section for more details).\n\nfunc CompleteSession(ctx Context)\n\n\nCompleteSession() releases the resources reserved on the , so it's important to call it as soon as you no longer need the session. It will cancel the session context and therefore all the using that session context. Note that it's safe to call CompleteSession() on a failed session, meaning that you can call it from a defer function after the session is successfully created.\n\n\n# Sample Code\n\nfunc FileProcessingWorkflow(ctx workflow.Context, fileID string) (err error) {\n    ao := workflow.ActivityOptions{\n        ScheduleToStartTimeout: time.Second * 5,\n        StartToCloseTimeout:    time.Minute,\n    }\n    ctx = workflow.WithActivityOptions(ctx, ao)\n\n    so := &workflow.SessionOptions{\n        CreationTimeout:  time.Minute,\n        ExecutionTimeout: time.Minute,\n    }\n    sessionCtx, err := workflow.CreateSession(ctx, so)\n    if err != nil {\n        return err\n    }\n    defer workflow.CompleteSession(sessionCtx)\n\n    var fInfo *fileInfo\n    err = workflow.ExecuteActivity(sessionCtx, downloadFileActivityName, fileID).Get(sessionCtx, &fInfo)\n    if err != nil {\n        return err\n    }\n\n    var fInfoProcessed *fileInfo\n    err = workflow.ExecuteActivity(sessionCtx, processFileActivityName, *fInfo).Get(sessionCtx, &fInfoProcessed)\n    if err != nil {\n        return err\n    }\n\n    return workflow.ExecuteActivity(sessionCtx, uploadFileActivityName, *fInfoProcessed).Get(sessionCtx, nil)\n}\n\n\n\n# Session Metadata\n\ntype SessionInfo struct {\n    // A unique ID for the session\n    SessionID         string\n\n    // The hostname of the worker that is executing the session\n    HostName          string\n\n    // ... other unexported fields\n}\n\nfunc GetSessionInfo(ctx Context) *SessionInfo\n\n\nThe session context also stores some session metadata, which can be retrieved by the GetSessionInfo() API. If the context passed in doesn't contain any session metadata, this API will return a nil pointer.\n\n\n# Concurrent Session Limitation\n\nTo limit the number of concurrent sessions running on a , set the MaxConcurrentSessionExecutionSize field of worker.Options to the desired value. By default this field is set to a very large value, so there's no need to manually set it if no limitation is needed.\n\nIf a hits this limitation, it won't accept any new CreateSession() requests until one of the existing sessions is completed. CreateSession() will return an error if the session can't be created within CreationTimeout.\n\n\n# Recreate Session\n\nFor long-running sessions, you may want to use the ContinueAsNew feature to split the into multiple runs when all need to be executed by the same . The RecreateSession() API is designed for such a use case.\n\nfunc RecreateSession(ctx Context, recreateToken []byte, sessionOptions *SessionOptions) (Context, error)\n\n\nIts usage is the same as CreateSession() except that it also takes in a recreateToken, which is needed to create a new session on the same as the previous one. You can get the token by calling the GetRecreateToken() method of the SessionInfo object.\n\ntoken := workflow.GetSessionInfo(sessionCtx).GetRecreateToken()\n\n\n\n# Q & A\n\n\n# Is there a complete example?\n\nYes, the file processing example in the cadence-sample repo has been updated to use the session framework.\n\n\n# What happens to my activity if the worker dies?\n\nIf your has already been scheduled, it will be cancelled. If not, you will get a workflow.ErrSessionFailed error when you call workflow.ExecuteActivity().\n\n\n# Is the concurrent session limitation per process or per host?\n\nIt's per process, so make sure there's only one process running on the host if you plan to use that feature.\n\n\n# Future Work\n\n * Support automatic session re-establishing Right now a session is considered failed if the process dies. However, for some use cases, you may only care whether host is alive or not. For these uses cases, the session should be automatically re-established if the process is restarted.\n\n * Support fine-grained concurrent session limitation The current implementation assumes that all sessions are consuming the same type of resource and there's only one global limitation. Our plan is to allow you to specify what type of resource your session will consume and enforce different limitations on different types of resources.",normalizedContent:"# sessions\n\nthe session framework provides a straightforward interface for scheduling multiple on a single without requiring you to manually specify the name. it also includes features like concurrent session limitation and worker failure detection.\n\n\n# use cases\n\n * file processing: you may want to implement a that can download a file, process it, and then upload the modified version. if these three steps are implemented as three different , all of them should be executed by the same .\n\n * machine learning model training: training a machine learning model typically involves three stages: download the data set, optimize the model, and upload the trained parameter. since the models may consume a large amount of resources (gpu memory for example), the number of models processed on a host needs to be limited.\n\n\n# basic usage\n\nbefore using the session framework to write your code, you need to configure your to process sessions. to do that, set the enablesessionworker field of worker.options to true when starting your .\n\nthe most important apis provided by the session framework are workflow.createsession() and workflow.completesession(). the basic idea is that all the executed within a session will be processed by the same and these two apis allow you to create new sessions and close them after all finish executing.\n\nhere's a more detailed description of these two apis:\n\ntype sessionoptions struct {\n    // executiontimeout: required, no default.\n    //     specifies the maximum amount of time the session can run.\n    executiontimeout time.duration\n\n    // creationtimeout: required, no default.\n    //     specifies how long session creation can take before returning an error.\n    creationtimeout  time.duration\n}\n\nfunc createsession(ctx context, sessionoptions *sessionoptions) (context, error)\n\n\ncreatesession() takes in workflow.context, sessionoptions and returns a new context which contains metadata information of the created session (referred to as the session context below). when it's called, it will check the name specified in the activityoptions (or in the startworkflowoptions if the name is not specified in activityoptions), and create the session on one of the which is polling that .\n\nthe returned session context should be used to execute all belonging to the session. the context will be cancelled if the executing this session dies or completesession() is called. when using the returned session context to execute , a workflow.errsessionfailed error may be returned if the session framework detects that the executing this session has died. the failure of your won't affect the state of the session, so you still need to handle the errors returned from your and call completesession() if necessary.\n\ncreatesession() will return an error if the context passed in already contains an open session. if all the are currently busy and unable to handle new sessions, the framework will keep retrying until the creationtimeout you specified in sessionoptions has passed before returning an error (check the concurrent session limitation section for more details).\n\nfunc completesession(ctx context)\n\n\ncompletesession() releases the resources reserved on the , so it's important to call it as soon as you no longer need the session. it will cancel the session context and therefore all the using that session context. note that it's safe to call completesession() on a failed session, meaning that you can call it from a defer function after the session is successfully created.\n\n\n# sample code\n\nfunc fileprocessingworkflow(ctx workflow.context, fileid string) (err error) {\n    ao := workflow.activityoptions{\n        scheduletostarttimeout: time.second * 5,\n        starttoclosetimeout:    time.minute,\n    }\n    ctx = workflow.withactivityoptions(ctx, ao)\n\n    so := &workflow.sessionoptions{\n        creationtimeout:  time.minute,\n        executiontimeout: time.minute,\n    }\n    sessionctx, err := workflow.createsession(ctx, so)\n    if err != nil {\n        return err\n    }\n    defer workflow.completesession(sessionctx)\n\n    var finfo *fileinfo\n    err = workflow.executeactivity(sessionctx, downloadfileactivityname, fileid).get(sessionctx, &finfo)\n    if err != nil {\n        return err\n    }\n\n    var finfoprocessed *fileinfo\n    err = workflow.executeactivity(sessionctx, processfileactivityname, *finfo).get(sessionctx, &finfoprocessed)\n    if err != nil {\n        return err\n    }\n\n    return workflow.executeactivity(sessionctx, uploadfileactivityname, *finfoprocessed).get(sessionctx, nil)\n}\n\n\n\n# session metadata\n\ntype sessioninfo struct {\n    // a unique id for the session\n    sessionid         string\n\n    // the hostname of the worker that is executing the session\n    hostname          string\n\n    // ... other unexported fields\n}\n\nfunc getsessioninfo(ctx context) *sessioninfo\n\n\nthe session context also stores some session metadata, which can be retrieved by the getsessioninfo() api. if the context passed in doesn't contain any session metadata, this api will return a nil pointer.\n\n\n# concurrent session limitation\n\nto limit the number of concurrent sessions running on a , set the maxconcurrentsessionexecutionsize field of worker.options to the desired value. by default this field is set to a very large value, so there's no need to manually set it if no limitation is needed.\n\nif a hits this limitation, it won't accept any new createsession() requests until one of the existing sessions is completed. createsession() will return an error if the session can't be created within creationtimeout.\n\n\n# recreate session\n\nfor long-running sessions, you may want to use the continueasnew feature to split the into multiple runs when all need to be executed by the same . the recreatesession() api is designed for such a use case.\n\nfunc recreatesession(ctx context, recreatetoken []byte, sessionoptions *sessionoptions) (context, error)\n\n\nits usage is the same as createsession() except that it also takes in a recreatetoken, which is needed to create a new session on the same as the previous one. you can get the token by calling the getrecreatetoken() method of the sessioninfo object.\n\ntoken := workflow.getsessioninfo(sessionctx).getrecreatetoken()\n\n\n\n# q & a\n\n\n# is there a complete example?\n\nyes, the file processing example in the cadence-sample repo has been updated to use the session framework.\n\n\n# what happens to my activity if the worker dies?\n\nif your has already been scheduled, it will be cancelled. if not, you will get a workflow.errsessionfailed error when you call workflow.executeactivity().\n\n\n# is the concurrent session limitation per process or per host?\n\nit's per process, so make sure there's only one process running on the host if you plan to use that feature.\n\n\n# future work\n\n * support automatic session re-establishing right now a session is considered failed if the process dies. however, for some use cases, you may only care whether host is alive or not. for these uses cases, the session should be automatically re-established if the process is restarted.\n\n * support fine-grained concurrent session limitation the current implementation assumes that all sessions are consuming the same type of resource and there's only one global limitation. our plan is to allow you to specify what type of resource your session will consume and enforce different limitations on different types of resources.",charsets:{}},{title:"Distributed CRON",frontmatter:{layout:"default",title:"Distributed CRON",permalink:"/docs/go-client/distributed-cron",readingShow:"top"},regularPath:"/docs/05-go-client/16-distributed-cron.html",relativePath:"docs/05-go-client/16-distributed-cron.md",key:"v-35913a62",path:"/docs/go-client/distributed-cron/",headers:[{level:2,title:"Convert existing cron workflow",slug:"convert-existing-cron-workflow",normalizedTitle:"convert existing cron workflow",charIndex:2151},{level:2,title:"Retrieve last successful result",slug:"retrieve-last-successful-result",normalizedTitle:"retrieve last successful result",charIndex:2614}],codeSwitcherOptions:{},headersStr:"Convert existing cron workflow Retrieve last successful result",content:'# Distributed CRON\n\nIt is relatively straightforward to turn any Cadence into a Cron . All you need is to supply a cron schedule when starting the using the CronSchedule parameter of StartWorkflowOptions.\n\nYou can also start a using the Cadence with an optional cron schedule using the --cron argument.\n\nFor with CronSchedule:\n\n * Cron schedule is based on UTC time. For example cron schedule "15 8 * * *" will run daily at 8:15am UTC. Another example "*/2 * * * 5-6" will schedule a workflow every two minutes on fridays and saturdays.\n * If a failed and a RetryPolicy is supplied to the StartWorkflowOptions as well, the will retry based on the RetryPolicy. While the is retrying, the server will not schedule the next cron run.\n * Cadence server only schedules the next cron run after the current run is completed. If the next schedule is due while a is running (or retrying), then it will skip that schedule.\n * Cron will not stop until they are terminated or cancelled.\n\nCadence supports the standard cron spec:\n\n// CronSchedule - Optional cron schedule for workflow. If a cron schedule is specified, the workflow will run\n// as a cron based on the schedule. The scheduling will be based on UTC time. The schedule for next run only happen\n// after the current run is completed/failed/timeout. If a RetryPolicy is also supplied, and the workflow failed\n// or timed out, the workflow will be retried based on the retry policy. While the workflow is retrying, it won\'t\n// schedule its next run. If next schedule is due while the workflow is running (or retrying), then it will skip that\n// schedule. Cron workflow will not stop until it is terminated or cancelled (by returning cadence.CanceledError).\n// The cron spec is as following:\n// ┌───────────── minute (0 - 59)\n// │ ┌───────────── hour (0 - 23)\n// │ │ ┌───────────── day of the month (1 - 31)\n// │ │ │ ┌───────────── month (1 - 12)\n// │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)\n// │ │ │ │ │\n// │ │ │ │ │\n// * * * * *\nCronSchedule string\n\n\nCadence also supports more advanced cron expressions.\n\nThe crontab guru site is useful for testing your cron expressions.\n\n\n# Convert existing cron workflow\n\nBefore CronSchedule was available, the previous approach to implementing cron was to use a delay timer as the last step and then return ContinueAsNew. One problem with that implementation is that if the fails or times out, the cron would stop.\n\nTo convert those to make use of Cadence CronSchedule, all you need is to remove the delay timer and return without using ContinueAsNew. Then start the with the desired CronSchedule.\n\n\n# Retrieve last successful result\n\nSometimes it is useful to obtain the progress of previous successful runs. This is supported by two new APIs in the client library: HasLastCompletionResult and GetLastCompletionResult. Below is an example of how to use this in Go:\n\nfunc CronWorkflow(ctx workflow.Context) (CronResult, error) {\n    startTimestamp := time.Time{} // By default start from 0 time.\n    if workflow.HasLastCompletionResult(ctx) {\n        var progress CronResult\n        if err := workflow.GetLastCompletionResult(ctx, &progress); err == nil {\n            startTimestamp = progress.LastSyncTimestamp\n        }\n    }\n    endTimestamp := workflow.Now(ctx)\n\n    // Process work between startTimestamp (exclusive), endTimestamp (inclusive).\n    // Business logic implementation goes here.\n\n    result := CronResult{LastSyncTimestamp: endTimestamp}\n    return result, nil\n}\n\n\nNote that this works even if one of the cron schedule runs failed. The next schedule will still get the last successful result if it ever successfully completed at least once. For example, for a daily cron , if the first day run succeeds and the second day fails, then the third day run will still get the result from first day\'s run using these APIs.',normalizedContent:'# distributed cron\n\nit is relatively straightforward to turn any cadence into a cron . all you need is to supply a cron schedule when starting the using the cronschedule parameter of startworkflowoptions.\n\nyou can also start a using the cadence with an optional cron schedule using the --cron argument.\n\nfor with cronschedule:\n\n * cron schedule is based on utc time. for example cron schedule "15 8 * * *" will run daily at 8:15am utc. another example "*/2 * * * 5-6" will schedule a workflow every two minutes on fridays and saturdays.\n * if a failed and a retrypolicy is supplied to the startworkflowoptions as well, the will retry based on the retrypolicy. while the is retrying, the server will not schedule the next cron run.\n * cadence server only schedules the next cron run after the current run is completed. if the next schedule is due while a is running (or retrying), then it will skip that schedule.\n * cron will not stop until they are terminated or cancelled.\n\ncadence supports the standard cron spec:\n\n// cronschedule - optional cron schedule for workflow. if a cron schedule is specified, the workflow will run\n// as a cron based on the schedule. the scheduling will be based on utc time. the schedule for next run only happen\n// after the current run is completed/failed/timeout. if a retrypolicy is also supplied, and the workflow failed\n// or timed out, the workflow will be retried based on the retry policy. while the workflow is retrying, it won\'t\n// schedule its next run. if next schedule is due while the workflow is running (or retrying), then it will skip that\n// schedule. cron workflow will not stop until it is terminated or cancelled (by returning cadence.cancelederror).\n// the cron spec is as following:\n// ┌───────────── minute (0 - 59)\n// │ ┌───────────── hour (0 - 23)\n// │ │ ┌───────────── day of the month (1 - 31)\n// │ │ │ ┌───────────── month (1 - 12)\n// │ │ │ │ ┌───────────── day of the week (0 - 6) (sunday to saturday)\n// │ │ │ │ │\n// │ │ │ │ │\n// * * * * *\ncronschedule string\n\n\ncadence also supports more advanced cron expressions.\n\nthe crontab guru site is useful for testing your cron expressions.\n\n\n# convert existing cron workflow\n\nbefore cronschedule was available, the previous approach to implementing cron was to use a delay timer as the last step and then return continueasnew. one problem with that implementation is that if the fails or times out, the cron would stop.\n\nto convert those to make use of cadence cronschedule, all you need is to remove the delay timer and return without using continueasnew. then start the with the desired cronschedule.\n\n\n# retrieve last successful result\n\nsometimes it is useful to obtain the progress of previous successful runs. this is supported by two new apis in the client library: haslastcompletionresult and getlastcompletionresult. below is an example of how to use this in go:\n\nfunc cronworkflow(ctx workflow.context) (cronresult, error) {\n    starttimestamp := time.time{} // by default start from 0 time.\n    if workflow.haslastcompletionresult(ctx) {\n        var progress cronresult\n        if err := workflow.getlastcompletionresult(ctx, &progress); err == nil {\n            starttimestamp = progress.lastsynctimestamp\n        }\n    }\n    endtimestamp := workflow.now(ctx)\n\n    // process work between starttimestamp (exclusive), endtimestamp (inclusive).\n    // business logic implementation goes here.\n\n    result := cronresult{lastsynctimestamp: endtimestamp}\n    return result, nil\n}\n\n\nnote that this works even if one of the cron schedule runs failed. the next schedule will still get the last successful result if it ever successfully completed at least once. for example, for a daily cron , if the first day run succeeds and the second day fails, then the third day run will still get the result from first day\'s run using these apis.',charsets:{}},{title:"Tracing and context propagation",frontmatter:{layout:"default",title:"Tracing and context propagation",permalink:"/docs/go-client/tracing",readingShow:"top"},regularPath:"/docs/05-go-client/17-tracing.html",relativePath:"docs/05-go-client/17-tracing.md",key:"v-9d2716dc",path:"/docs/go-client/tracing/",headers:[{level:2,title:"Tracing",slug:"tracing",normalizedTitle:"tracing",charIndex:2},{level:2,title:"Context Propagation",slug:"context-propagation",normalizedTitle:"context propagation",charIndex:651},{level:3,title:"Server-Side Headers Support",slug:"server-side-headers-support",normalizedTitle:"server-side headers support",charIndex:1158},{level:3,title:"Context Propagators",slug:"context-propagators",normalizedTitle:"context propagators",charIndex:2070},{level:2,title:"Q & A",slug:"q-a",normalizedTitle:"q &amp; a",charIndex:null},{level:3,title:"Is there a complete example?",slug:"is-there-a-complete-example",normalizedTitle:"is there a complete example?",charIndex:3015},{level:3,title:"Can I configure multiple context propagators?",slug:"can-i-configure-multiple-context-propagators",normalizedTitle:"can i configure multiple context propagators?",charIndex:3182}],codeSwitcherOptions:{},headersStr:"Tracing Context Propagation Server-Side Headers Support Context Propagators Q & A Is there a complete example? Can I configure multiple context propagators?",content:"# Tracing and context propagation\n\n\n# Tracing\n\nThe Go client provides distributed tracing support through OpenTracing. Tracing can be configured by providing an opentracing.Tracer implementation in ClientOptions and WorkerOptions during client and instantiation, respectively. Tracing allows you to view the call graph of a along with its , child etc. For more details on how to configure and leverage tracing, see the OpenTracing documentation. The OpenTracing support has been validated using Jaeger, but other implementations mentioned here should also work. Tracing support utilizes generic context propagation support provided by the client.\n\n\n# Context Propagation\n\nWe provide a standard way to propagate custom context across a . ClientOptions and WorkerOptions allow configuring a context propagator. The context propagator extracts and passes on information present in the context.Context and workflow.Context objects across the . Once a context propagator is configured, you should be able to access the required values in the context objects as you would normally do in Go. For a sample, the Go client implements a tracing context propagator.\n\n\n# Server-Side Headers Support\n\nOn the server side, Cadence provides a mechanism to propagate what it calls headers across different transitions.\n\nstruct Header {\n    10: optional map<string, binary> fields\n}\n\n\nThe client leverages this to pass around selected context information. HeaderReader and HeaderWriter are interfaces that allow reading and writing to the Cadence server headers. The client already provides implementations for these. HeaderWriter sets a field in the header. Headers is a map, so setting a value for the the same key multiple times will overwrite the previous values. HeaderReader iterates through the headers map and runs the provided handler function on each key/value pair, allowing you to deal with the fields you are interested in.\n\ntype HeaderWriter interface {\n    Set(string, []byte)\n}\n\ntype HeaderReader interface {\n    ForEachKey(handler func(string, []byte) error) error\n}\n\n\n\n# Context Propagators\n\nContext propagators require implementing the following four methods to propagate selected context across a workflow:\n\n * Inject is meant to pick out the context keys of interest from a Go context.Context object and write that into the headers using the HeaderWriter interface\n * InjectFromWorkflow is the same as above, but operates on a workflow.Context object\n * Extract reads the headers and places the information of interest back into the context.Context object\n * ExtractToWorkflow is the same as above, but operates on a workflow.Context object\n\nThe tracing context propagator shows a sample implementation of context propagation.\n\ntype ContextPropagator interface {\n    Inject(context.Context, HeaderWriter) error\n\n    Extract(context.Context, HeaderReader) (context.Context, error)\n\n    InjectFromWorkflow(Context, HeaderWriter) error\n\n    ExtractToWorkflow(Context, HeaderReader) (Context, error)\n}\n\n\n\n# Q & A\n\n\n# Is there a complete example?\n\nThe context propagation sample configures a custom context propagator and shows context propagation of custom keys across a and an .\n\n\n# Can I configure multiple context propagators?\n\nYes, we recommended that you configure multiple context propagators with each propagator meant to propagate a particular type of context.",normalizedContent:"# tracing and context propagation\n\n\n# tracing\n\nthe go client provides distributed tracing support through opentracing. tracing can be configured by providing an opentracing.tracer implementation in clientoptions and workeroptions during client and instantiation, respectively. tracing allows you to view the call graph of a along with its , child etc. for more details on how to configure and leverage tracing, see the opentracing documentation. the opentracing support has been validated using jaeger, but other implementations mentioned here should also work. tracing support utilizes generic context propagation support provided by the client.\n\n\n# context propagation\n\nwe provide a standard way to propagate custom context across a . clientoptions and workeroptions allow configuring a context propagator. the context propagator extracts and passes on information present in the context.context and workflow.context objects across the . once a context propagator is configured, you should be able to access the required values in the context objects as you would normally do in go. for a sample, the go client implements a tracing context propagator.\n\n\n# server-side headers support\n\non the server side, cadence provides a mechanism to propagate what it calls headers across different transitions.\n\nstruct header {\n    10: optional map<string, binary> fields\n}\n\n\nthe client leverages this to pass around selected context information. headerreader and headerwriter are interfaces that allow reading and writing to the cadence server headers. the client already provides implementations for these. headerwriter sets a field in the header. headers is a map, so setting a value for the the same key multiple times will overwrite the previous values. headerreader iterates through the headers map and runs the provided handler function on each key/value pair, allowing you to deal with the fields you are interested in.\n\ntype headerwriter interface {\n    set(string, []byte)\n}\n\ntype headerreader interface {\n    foreachkey(handler func(string, []byte) error) error\n}\n\n\n\n# context propagators\n\ncontext propagators require implementing the following four methods to propagate selected context across a workflow:\n\n * inject is meant to pick out the context keys of interest from a go context.context object and write that into the headers using the headerwriter interface\n * injectfromworkflow is the same as above, but operates on a workflow.context object\n * extract reads the headers and places the information of interest back into the context.context object\n * extracttoworkflow is the same as above, but operates on a workflow.context object\n\nthe tracing context propagator shows a sample implementation of context propagation.\n\ntype contextpropagator interface {\n    inject(context.context, headerwriter) error\n\n    extract(context.context, headerreader) (context.context, error)\n\n    injectfromworkflow(context, headerwriter) error\n\n    extracttoworkflow(context, headerreader) (context, error)\n}\n\n\n\n# q & a\n\n\n# is there a complete example?\n\nthe context propagation sample configures a custom context propagator and shows context propagation of custom keys across a and an .\n\n\n# can i configure multiple context propagators?\n\nyes, we recommended that you configure multiple context propagators with each propagator meant to propagate a particular type of context.",charsets:{}},{title:"Workflow Replay and Shadowing",frontmatter:{layout:"default",title:"Workflow Replay and Shadowing",permalink:"/docs/go-client/workflow-replay-shadowing",readingShow:"top"},regularPath:"/docs/05-go-client/18-workflow-replay-shadowing.html",relativePath:"docs/05-go-client/18-workflow-replay-shadowing.md",key:"v-d043b980",path:"/docs/go-client/workflow-replay-shadowing/",headers:[{level:2,title:"Workflow Replayer",slug:"workflow-replayer",normalizedTitle:"workflow replayer",charIndex:469},{level:3,title:"Write a Replay Test",slug:"write-a-replay-test",normalizedTitle:"write a replay test",charIndex:824},{level:3,title:"Sample Replay Test",slug:"sample-replay-test",normalizedTitle:"sample replay test",charIndex:3778},{level:2,title:"Workflow Shadower",slug:"workflow-shadower",normalizedTitle:"workflow shadower",charIndex:491},{level:3,title:"Shadow Options",slug:"shadow-options",normalizedTitle:"shadow options",charIndex:4923},{level:3,title:"Local Shadowing Test",slug:"local-shadowing-test",normalizedTitle:"local shadowing test",charIndex:6606},{level:3,title:"Shadowing Worker",slug:"shadowing-worker",normalizedTitle:"shadowing worker",charIndex:7673}],codeSwitcherOptions:{},headersStr:"Workflow Replayer Write a Replay Test Sample Replay Test Workflow Shadower Shadow Options Local Shadowing Test Shadowing Worker",content:"# Workflow Replay and Shadowing\n\nIn the Versioning section, we mentioned that incompatible changes to workflow definition code could cause non-deterministic issues when processing workflow tasks if versioning is not done correctly. However, it may be hard for you to tell if a particular change is incompatible or not and whether versioning logic is needed. To help you identify incompatible changes and catch them before production traffic is impacted, we implemented Workflow Replayer and Workflow Shadower.\n\n\n# Workflow Replayer\n\nWorkflow Replayer is a testing component for replaying existing workflow histories against a workflow definition. The replaying logic is the same as the one used for processing workflow tasks, so if there's any incompatible changes in the workflow definition, the replay test will fail.\n\n\n# Write a Replay Test\n\n# Step 1: Create workflow replayer\n\nCreate a workflow Replayer by:\n\nreplayer := worker.NewWorkflowReplayer()\n\n\nor if custom data converter, context propagator, interceptor, etc. is used in your workflow:\n\noptions := worker.ReplayOptions{\n  DataConverter: myDataConverter,\n  ContextPropagators: []workflow.ContextPropagator{\n    myContextPropagator,\n  },\n  WorkflowInterceptorChainFactories: []interceptors.WorkflowInterceptorFactory{\n    myInterceptorFactory,\n  },\n  Tracer: myTracer,\n}\nreplayer := worker.NewWorkflowReplayWithOptions(options)\n\n\n# Step 2: Register workflow definition\n\nNext, register your workflow definitions as you normally do. Make sure workflows are registered the same way as they were when running and generating histories; otherwise the replay will not be able to find the corresponding definition.\n\nreplayer.RegisterWorkflow(myWorkflowFunc1)\nreplayer.RegisterWorkflow(myWorkflowFunc2, workflow.RegisterOptions{\n\tName: workflowName,\n})\n\n\n# Step 3: Prepare workflow histories\n\nReplayer can read workflow history from a local json file or fetch it directly from the Cadence server. If you would like to use the first method, you can use the following CLI command, otherwise you can skip to the next step.\n\ncadence --do <domain> workflow show --wid <workflowID> --rid <runID> --of <output file name>\n\n\nThe dumped workflow history will be stored in the file at the path you specified in json format.\n\n# Step 4: Call the replay method\n\nOnce you have the workflow history or have the connection to Cadence server for fetching history, call one of the four replay methods to start the replay test.\n\n// if workflow history has been loaded into memory\nerr := replayer.ReplayWorkflowHistory(logger, history)\n\n// if workflow history is stored in a json file\nerr = replayer.ReplayWorkflowHistoryFromJSONFile(logger, jsonFileName)\n\n// if workflow history is stored in a json file and you only want to replay part of it\n// NOTE: lastEventID can't be set arbitrarily. It must be the end of of a history events batch\n// when in doubt, set to the eventID of decisionTaskStarted events.\nerr = replayer.ReplayPartialWorkflowHistoryFromJSONFile(logger, jsonFileName, lastEventID)\n\n// if you want to fetch workflow history directly from cadence server\n// please check the Worker Service page for how to create a cadence service client\nerr = replayer.ReplayWorkflowExecution(ctx, cadenceServiceClient, logger, domain, execution)\n\n\n# Step 5: Check returned error\n\nIf an error is returned from the replay method, it means there's a incompatible change in the workflow definition and the error message will contain more information regarding where the non-deterministic error happens.\n\nNote: currently an error will be returned if there are less than 3 events in the history. It is because the first 3 events in the history has nothing to do with the workflow code, so Replayer can't tell if there's a incompatible change or not.\n\n\n# Sample Replay Test\n\nThis sample is also available in our samples repo at here.\n\nfunc TestReplayWorkflowHistoryFromFile(t *testing.T) {\n\treplayer := worker.NewWorkflowReplayer()\n\treplayer.RegisterWorkflow(helloWorldWorkflow)\n\terr := replayer.ReplayWorkflowHistoryFromJSONFile(zaptest.NewLogger(t), \"helloworld.json\")\n\trequire.NoError(t, err)\n}\n\n\n\n# Workflow Shadower\n\nWorkflow Replayer works well when verifying the compatibility against a small number of workflow histories. If there are lots of workflows in production need to be verified, dumping all histories manually clearly won't work. Directly fetching histories from cadence server might be a solution, but the time to replay all workflow histories might be too long for a test.\n\nWorkflow Shadower is built on top of Workflow Replayer to address this problem. The basic idea of shadowing is: scan workflows based on the filters you defined, fetch history for each of workflow in the scan result from Cadence server and run the replay test. It can be run either as a test to serve local development purpose or as a workflow in your worker to continuously replay production workflows.\n\n\n# Shadow Options\n\nComplete documentation on shadow options which includes default values, accepted values, etc. can be found here. The following sections are just a brief description of each option.\n\n# Scan Filters\n\n * WorkflowQuery: If you are familiar with our advanced visibility query syntax, you can specify a query directly. If specified, all other scan filters must be left empty.\n * WorkflowTypes: A list of workflow Type names.\n * WorkflowStatus: A list of workflow status.\n * WorkflowStartTimeFilter: Min and max timestamp for workflow start time.\n * SamplingRate: Sampling workflows from the scan result before executing the replay test.\n\n# Shadow Exit Condition\n\n * ExpirationInterval: Shadowing will exit when the specified interval has passed.\n * ShadowCount: Shadowing will exit after this number of workflow has been replayed. Note: replay maybe skipped due to errors like can't fetch history, history too short, etc. Skipped workflows won't be taken account into ShadowCount.\n\n# Shadow Mode\n\n * Normal: Shadowing will complete after all workflows matches WorkflowQuery (after sampling) have been replayed or when exit condition is met.\n * Continuous: A new round of shadowing will be started after all workflows matches WorkflowQuery have been replayed. There will be a 5 min wait period between each round, and currently this wait period is not configurable. Shadowing will complete only when ExitCondition is met. ExitCondition must be specified when using this mode.\n\n# Shadow Concurrency\n\n * Concurrency: workflow replay concurrency. If not specified, will be default to 1. For local shadowing, an error will be returned if a value higher than 1 is specified.\n\n\n# Local Shadowing Test\n\nLocal shadowing test is similar to the replay test. First create a workflow shadower with optional shadow and replay options, then register the workflow that need to be shadowed. Finally, call the Run method to start the shadowing. The method will return if shadowing has finished or any non-deterministic error is found.\n\nHere's a simple example. The example is also available here.\n\nfunc TestShadowWorkflow(t *testing.T) {\n\toptions := worker.ShadowOptions{\n\t\tWorkflowStartTimeFilter: worker.TimeFilter{\n\t\t\tMinTimestamp: time.Now().Add(-time.Hour),\n\t\t},\n\t\tExitCondition: worker.ShadowExitCondition{\n\t\t\tShadowCount: 10,\n\t\t},\n\t}\n\n  // please check the Worker Service page for how to create a cadence service client\n\tservice := buildCadenceClient()\n\tshadower, err := worker.NewWorkflowShadower(service, \"samples-domain\", options, worker.ReplayOptions{}, zaptest.NewLogger(t))\n\tassert.NoError(t, err)\n\n\tshadower.RegisterWorkflowWithOptions(helloWorldWorkflow, workflow.RegisterOptions{Name: \"helloWorld\"})\n\tassert.NoError(t, shadower.Run())\n}\n\n\n\n# Shadowing Worker\n\nNOTE:\n\n * All shadow workflows are running in one Cadence system domain, and right now, every user domain can only have one shadow workflow at a time.\n * The Cadence server used for scanning and getting workflow history will also be the Cadence server for running your shadow workflow. Currently, there's no way to specify different Cadence servers for hosting the shadowing workflow and scanning/fetching workflow.\n\nYour worker can also be configured to run in shadow mode to run shadow tests as a workflow. This is useful if there's a number of workflows need to be replayed. Using a workflow can make sure the shadowing won't accidentally fail in the middle and the replay load can be distributed by deploying more shadow mode workers. It can also be incorporated into your deployment process to make sure there's no failed replay checks before deploying your change to production workers.\n\nWhen running in shadow mode, the normal decision, activity and session worker will be disabled so that it won't update any production workflows. A special shadow activity worker will be started to execute activities for scanning and replaying workflows. The actual shadow workflow logic is controlled by Cadence server and your worker is only responsible for scanning and replaying workflows.\n\nReplay succeed, skipped and failed metrics will be emitted by your worker when executing the shadow workflow and you can monitor those metrics to see if there's any incompatible changes.\n\nTo enable the shadow mode, the only change needed is setting the EnableShadowWorker field in worker.Options to true, and then specify the ShadowOptions.\n\nRegistered workflows will be forwarded to the underlying WorkflowReplayer. DataConverter, WorkflowInterceptorChainFactories, ContextPropagators, and Tracer specified in the worker.Options will also be used as ReplayOptions. Since all shadow workflows are running in one system domain, to avoid conflict, the actual task list name used will be domain-tasklist.\n\nA sample setup can be found here.",normalizedContent:"# workflow replay and shadowing\n\nin the versioning section, we mentioned that incompatible changes to workflow definition code could cause non-deterministic issues when processing workflow tasks if versioning is not done correctly. however, it may be hard for you to tell if a particular change is incompatible or not and whether versioning logic is needed. to help you identify incompatible changes and catch them before production traffic is impacted, we implemented workflow replayer and workflow shadower.\n\n\n# workflow replayer\n\nworkflow replayer is a testing component for replaying existing workflow histories against a workflow definition. the replaying logic is the same as the one used for processing workflow tasks, so if there's any incompatible changes in the workflow definition, the replay test will fail.\n\n\n# write a replay test\n\n# step 1: create workflow replayer\n\ncreate a workflow replayer by:\n\nreplayer := worker.newworkflowreplayer()\n\n\nor if custom data converter, context propagator, interceptor, etc. is used in your workflow:\n\noptions := worker.replayoptions{\n  dataconverter: mydataconverter,\n  contextpropagators: []workflow.contextpropagator{\n    mycontextpropagator,\n  },\n  workflowinterceptorchainfactories: []interceptors.workflowinterceptorfactory{\n    myinterceptorfactory,\n  },\n  tracer: mytracer,\n}\nreplayer := worker.newworkflowreplaywithoptions(options)\n\n\n# step 2: register workflow definition\n\nnext, register your workflow definitions as you normally do. make sure workflows are registered the same way as they were when running and generating histories; otherwise the replay will not be able to find the corresponding definition.\n\nreplayer.registerworkflow(myworkflowfunc1)\nreplayer.registerworkflow(myworkflowfunc2, workflow.registeroptions{\n\tname: workflowname,\n})\n\n\n# step 3: prepare workflow histories\n\nreplayer can read workflow history from a local json file or fetch it directly from the cadence server. if you would like to use the first method, you can use the following cli command, otherwise you can skip to the next step.\n\ncadence --do <domain> workflow show --wid <workflowid> --rid <runid> --of <output file name>\n\n\nthe dumped workflow history will be stored in the file at the path you specified in json format.\n\n# step 4: call the replay method\n\nonce you have the workflow history or have the connection to cadence server for fetching history, call one of the four replay methods to start the replay test.\n\n// if workflow history has been loaded into memory\nerr := replayer.replayworkflowhistory(logger, history)\n\n// if workflow history is stored in a json file\nerr = replayer.replayworkflowhistoryfromjsonfile(logger, jsonfilename)\n\n// if workflow history is stored in a json file and you only want to replay part of it\n// note: lasteventid can't be set arbitrarily. it must be the end of of a history events batch\n// when in doubt, set to the eventid of decisiontaskstarted events.\nerr = replayer.replaypartialworkflowhistoryfromjsonfile(logger, jsonfilename, lasteventid)\n\n// if you want to fetch workflow history directly from cadence server\n// please check the worker service page for how to create a cadence service client\nerr = replayer.replayworkflowexecution(ctx, cadenceserviceclient, logger, domain, execution)\n\n\n# step 5: check returned error\n\nif an error is returned from the replay method, it means there's a incompatible change in the workflow definition and the error message will contain more information regarding where the non-deterministic error happens.\n\nnote: currently an error will be returned if there are less than 3 events in the history. it is because the first 3 events in the history has nothing to do with the workflow code, so replayer can't tell if there's a incompatible change or not.\n\n\n# sample replay test\n\nthis sample is also available in our samples repo at here.\n\nfunc testreplayworkflowhistoryfromfile(t *testing.t) {\n\treplayer := worker.newworkflowreplayer()\n\treplayer.registerworkflow(helloworldworkflow)\n\terr := replayer.replayworkflowhistoryfromjsonfile(zaptest.newlogger(t), \"helloworld.json\")\n\trequire.noerror(t, err)\n}\n\n\n\n# workflow shadower\n\nworkflow replayer works well when verifying the compatibility against a small number of workflow histories. if there are lots of workflows in production need to be verified, dumping all histories manually clearly won't work. directly fetching histories from cadence server might be a solution, but the time to replay all workflow histories might be too long for a test.\n\nworkflow shadower is built on top of workflow replayer to address this problem. the basic idea of shadowing is: scan workflows based on the filters you defined, fetch history for each of workflow in the scan result from cadence server and run the replay test. it can be run either as a test to serve local development purpose or as a workflow in your worker to continuously replay production workflows.\n\n\n# shadow options\n\ncomplete documentation on shadow options which includes default values, accepted values, etc. can be found here. the following sections are just a brief description of each option.\n\n# scan filters\n\n * workflowquery: if you are familiar with our advanced visibility query syntax, you can specify a query directly. if specified, all other scan filters must be left empty.\n * workflowtypes: a list of workflow type names.\n * workflowstatus: a list of workflow status.\n * workflowstarttimefilter: min and max timestamp for workflow start time.\n * samplingrate: sampling workflows from the scan result before executing the replay test.\n\n# shadow exit condition\n\n * expirationinterval: shadowing will exit when the specified interval has passed.\n * shadowcount: shadowing will exit after this number of workflow has been replayed. note: replay maybe skipped due to errors like can't fetch history, history too short, etc. skipped workflows won't be taken account into shadowcount.\n\n# shadow mode\n\n * normal: shadowing will complete after all workflows matches workflowquery (after sampling) have been replayed or when exit condition is met.\n * continuous: a new round of shadowing will be started after all workflows matches workflowquery have been replayed. there will be a 5 min wait period between each round, and currently this wait period is not configurable. shadowing will complete only when exitcondition is met. exitcondition must be specified when using this mode.\n\n# shadow concurrency\n\n * concurrency: workflow replay concurrency. if not specified, will be default to 1. for local shadowing, an error will be returned if a value higher than 1 is specified.\n\n\n# local shadowing test\n\nlocal shadowing test is similar to the replay test. first create a workflow shadower with optional shadow and replay options, then register the workflow that need to be shadowed. finally, call the run method to start the shadowing. the method will return if shadowing has finished or any non-deterministic error is found.\n\nhere's a simple example. the example is also available here.\n\nfunc testshadowworkflow(t *testing.t) {\n\toptions := worker.shadowoptions{\n\t\tworkflowstarttimefilter: worker.timefilter{\n\t\t\tmintimestamp: time.now().add(-time.hour),\n\t\t},\n\t\texitcondition: worker.shadowexitcondition{\n\t\t\tshadowcount: 10,\n\t\t},\n\t}\n\n  // please check the worker service page for how to create a cadence service client\n\tservice := buildcadenceclient()\n\tshadower, err := worker.newworkflowshadower(service, \"samples-domain\", options, worker.replayoptions{}, zaptest.newlogger(t))\n\tassert.noerror(t, err)\n\n\tshadower.registerworkflowwithoptions(helloworldworkflow, workflow.registeroptions{name: \"helloworld\"})\n\tassert.noerror(t, shadower.run())\n}\n\n\n\n# shadowing worker\n\nnote:\n\n * all shadow workflows are running in one cadence system domain, and right now, every user domain can only have one shadow workflow at a time.\n * the cadence server used for scanning and getting workflow history will also be the cadence server for running your shadow workflow. currently, there's no way to specify different cadence servers for hosting the shadowing workflow and scanning/fetching workflow.\n\nyour worker can also be configured to run in shadow mode to run shadow tests as a workflow. this is useful if there's a number of workflows need to be replayed. using a workflow can make sure the shadowing won't accidentally fail in the middle and the replay load can be distributed by deploying more shadow mode workers. it can also be incorporated into your deployment process to make sure there's no failed replay checks before deploying your change to production workers.\n\nwhen running in shadow mode, the normal decision, activity and session worker will be disabled so that it won't update any production workflows. a special shadow activity worker will be started to execute activities for scanning and replaying workflows. the actual shadow workflow logic is controlled by cadence server and your worker is only responsible for scanning and replaying workflows.\n\nreplay succeed, skipped and failed metrics will be emitted by your worker when executing the shadow workflow and you can monitor those metrics to see if there's any incompatible changes.\n\nto enable the shadow mode, the only change needed is setting the enableshadowworker field in worker.options to true, and then specify the shadowoptions.\n\nregistered workflows will be forwarded to the underlying workflowreplayer. dataconverter, workflowinterceptorchainfactories, contextpropagators, and tracer specified in the worker.options will also be used as replayoptions. since all shadow workflows are running in one system domain, to avoid conflict, the actual task list name used will be domain-tasklist.\n\na sample setup can be found here.",charsets:{}},{title:"Introduction",frontmatter:{layout:"default",title:"Introduction",permalink:"/docs/cli",readingShow:"top"},regularPath:"/docs/06-cli/",relativePath:"docs/06-cli/index.md",key:"v-6fa6d57b",path:"/docs/cli/",headers:[{level:2,title:"Using the CLI",slug:"using-the-cli",normalizedTitle:"using the cli",charIndex:237},{level:3,title:"Homebrew",slug:"homebrew",normalizedTitle:"homebrew",charIndex:255},{level:3,title:"Docker",slug:"docker",normalizedTitle:"docker",charIndex:492},{level:3,title:"Build it yourself",slug:"build-it-yourself",normalizedTitle:"build it yourself",charIndex:2034},{level:2,title:"Documentation",slug:"documentation",normalizedTitle:"documentation",charIndex:2418},{level:2,title:"Environment variables",slug:"environment-variables",normalizedTitle:"environment variables",charIndex:6296},{level:2,title:"Quick Start",slug:"quick-start",normalizedTitle:"quick start",charIndex:6577},{level:3,title:"Domain operation examples",slug:"domain-operation-examples",normalizedTitle:"domain operation examples",charIndex:6936},{level:3,title:"Workflow operation examples",slug:"workflow-operation-examples",normalizedTitle:"workflow operation examples",charIndex:7463}],codeSwitcherOptions:{},headersStr:"Using the CLI Homebrew Docker Build it yourself Documentation Environment variables Quick Start Domain operation examples Workflow operation examples",content:'# Command Line Interface\n\nThe Cadence is a command-line tool you can use to perform various on a Cadence server. It can perform operations such as register, update, and describe as well as operations like start , show history, and .\n\n\n# Using the CLI\n\n\n# Homebrew\n\nbrew install cadence-workflow\n\n\nAfter the installation is done, you can use CLI:\n\ncadence --help\n\n\nThis will always install the latest version. Follow this instructions if you need to install older versions of Cadence CLI.\n\n\n# Docker\n\nThe Cadence can be used directly from the Docker Hub image ubercadence/cli or by building the tool locally.\n\nExample of using the docker image to describe a\n\ndocker run -it --rm ubercadence/cli:master --address <frontendAddress> --domain samples-domain domain describe\n\n\nmaster will be the latest CLI binary from the project. But you can specify a version to best match your server version:\n\ndocker run -it --rm ubercadence/cli:<version> --address <frontendAddress> --domain samples-domain domain describe\n\n\nFor example docker run --rm ubercadence/cli:0.21.3 --domain samples-domain domain describe will be the CLI that is released as part of the v0.21.3 release. See docker hub page for all the CLI image tags. Note that CLI versions of 0.20.0 works for all server versions of 0.12 to 0.19 as well. That\'s because the CLI version doesn\'t change in those versions.\n\nNOTE: On Docker versions 18.03 and later, you may get a "connection refused" error when connecting to local server. You can work around this by setting the host to "host.docker.internal" (see here for more info).\n\ndocker run -it --rm ubercadence/cli:master --address host.docker.internal:7933 --domain samples-domain domain describe\n\n\nNOTE: Be sure to update your image when you want to try new features: docker pull ubercadence/cli:master\n\nNOTE: If you are running docker-compose Cadence server, you can also logon to the container to execute CLI:\n\ndocker exec -it docker_cadence_1 /bin/bash\n\n# cadence --address $(hostname -i):7933 --do samples domain register\n\n\n\n# Build it yourself\n\nTo build the tool locally, clone the Cadence server repo, check out the version tag (e.g. git checkout v0.21.3) and run make tools. This produces an executable called cadence. With a local build, the same command to describe a would look like this:\n\ncadence --domain samples-domain domain describe\n\n\nAlternatively, you can build the CLI image, see instructions\n\n\n# Documentation\n\nCLI are documented by --help or -h in ANY tab of all levels:\n\n$cadence --help\nNAME:\n   cadence - A command-line tool for cadence users\n\nUSAGE:\n   cadence [global options] command [command options] [arguments...]\n\nVERSION:\n   0.18.4\n\nCOMMANDS:\n   domain, d     Operate cadence domain\n   workflow, wf  Operate cadence workflow\n   tasklist, tl  Operate cadence tasklist\n   admin, adm    Run admin operation\n   cluster, cl   Operate cadence cluster\n   help, h       Shows a list of commands or help for one command\n\nGLOBAL OPTIONS:\n   --address value, --ad value          host:port for cadence frontend service [$CADENCE_CLI_ADDRESS]\n   --domain value, --do value           cadence workflow domain [$CADENCE_CLI_DOMAIN]\n   --context_timeout value, --ct value  optional timeout for context of RPC call in seconds (default: 5) [$CADENCE_CONTEXT_TIMEOUT]\n   --help, -h                           show help\n   --version, -v                        print the version\n\n\nAnd\n\n$cadence workflow -h\nNAME:\n   cadence workflow - Operate cadence workflow\n\nUSAGE:\n   cadence workflow command [command options] [arguments...]\n\nCOMMANDS:\n   activity, act       operate activities of workflow\n   show                show workflow history\n   showid              show workflow history with given workflow_id and run_id (a shortcut of `show -w <wid> -r <rid>`). run_id is only required for archived history\n   start               start a new workflow execution\n   run                 start a new workflow execution and get workflow progress\n   cancel, c           cancel a workflow execution\n   signal, s           signal a workflow execution\n   signalwithstart     signal the current open workflow if exists, or attempt to start a new run based on IDResuePolicy and signals it\n   terminate, term     terminate a new workflow execution\n   list, l             list open or closed workflow executions\n   listall, la         list all open or closed workflow executions\n   listarchived        list archived workflow executions\n   scan, sc, scanall   scan workflow executions (need to enable Cadence server on ElasticSearch). It will be faster than listall, but result are not sorted.\n   count, cnt          count number of workflow executions (need to enable Cadence server on ElasticSearch)\n   query               query workflow execution\n   stack               query workflow execution with __stack_trace as query type\n   describe, desc      show information of workflow execution\n   describeid, descid  show information of workflow execution with given workflow_id and optional run_id (a shortcut of `describe -w <wid> -r <rid>`)\n   observe, ob         show the progress of workflow history\n   observeid, obid     show the progress of workflow history with given workflow_id and optional run_id (a shortcut of `observe -w <wid> -r <rid>`)\n   reset, rs           reset the workflow, by either eventID or resetType.\n   reset-batch         reset workflow in batch by resetType: LastDecisionCompleted,LastContinuedAsNew,BadBinary,DecisionCompletedTime,FirstDecisionScheduled,LastDecisionScheduled,FirstDecisionCompletedTo get base workflowIDs/runIDs to reset, source is from input file or visibility query.\n   batch               batch operation on a list of workflows from query.\n\nOPTIONS:\n   --help, -h  show help\n\n\n$cadence wf signal -h\nNAME:\n   cadence workflow signal - signal a workflow execution\n\nUSAGE:\n   cadence workflow signal [command options] [arguments...]\n\nOPTIONS:\n   --workflow_id value, --wid value, -w value  WorkflowID\n   --run_id value, --rid value, -r value       RunID\n   --name value, -n value                      SignalName\n   --input value, -i value                     Input for the signal, in JSON format.\n   --input_file value, --if value              Input for the signal from JSON file.\n\n\n\nAnd etc.\n\nThe example commands below will use cadence for brevity.\n\n\n# Environment variables\n\nSetting environment variables for repeated parameters can shorten the commands.\n\n * CADENCE_CLI_ADDRESS - host:port for Cadence frontend service, the default is for the local server\n * CADENCE_CLI_DOMAIN - default , so you don\'t need to specify --domain\n\n\n# Quick Start\n\nRun cadence for help on top level commands and global options Run cadence domain for help on operations Run cadence workflow for help on operations Run cadence tasklist for help on tasklist operations (cadence help, cadence help [domain|workflow] will also print help messages)\n\nNote: make sure you have a Cadence server running before using\n\n\n# Domain operation examples\n\n * Register a new named "samples-domain":\n\ncadence --domain samples-domain domain register\n# OR using short alias\ncadence --do samples-domain d re \n\n\nIf your Cadence cluster has enable global domain(XDC replication), then you have to specify the replicaiton settings when registering a domain:\n\ncadence --domains amples-domain domain register --active_cluster clusterNameA --clusters clusterNameA clusterNameB\n\n\n * View "samples-domain" details:\n\ncadence --domain samples-domain domain describe\n\n\n\n# Workflow operation examples\n\nThe following examples assume the CADENCE_CLI_DOMAIN environment variable is set.\n\n# Run workflow\n\nStart a and see its progress. This command doesn\'t finish until completes.\n\ncadence workflow run --tl helloWorldGroup --wt main.Workflow --et 60 -i \'"cadence"\'\n\n# view help messages for workflow run\ncadence workflow run -h\n\n\nBrief explanation: To run a , the user must specify the following:\n\n 1. Tasklist name (--tl)\n 2. Workflow type (--wt)\n 3. Execution start to close timeout in seconds (--et)\n 4. Input in JSON format (--i) (optional)\n\ns example uses this cadence-samples workflow and takes a string as input with the -i \'"cadence"\' parameter. Single quotes (\'\') are used to wrap input as JSON.\n\nNote: You need to start the so that the can make progress. (Run make && ./bin/helloworld -m worker in cadence-samples to start the )\n\n# Show running workers of a tasklist\n\ncadence tasklist desc --tl helloWorldGroup\n\n\n# Start workflow\n\ncadence workflow start --tl helloWorldGroup --wt main.Workflow --et 60 -i \'"cadence"\'\n\n# view help messages for workflow start\ncadence workflow start -h\n\n# for a workflow with multiple inputs, separate each json with space/newline like\ncadence workflow start --tl helloWorldGroup --wt main.WorkflowWith3Args --et 60 -i \'"your_input_string" 123 {"Name":"my-string", "Age":12345}\'\n\n\nThe start command is similar to the run command, but immediately returns the workflow_id and run_id after starting the . Use the show command to view the \'s history/progress.\n\n# Reuse the same workflow id when starting/running a workflow\n\nUse option --workflowidreusepolicy or --wrp to configure the reuse policy. Option 0 AllowDuplicateFailedOnly: Allow starting a using the same when a with the same is not already running and the last execution close state is one of [terminated, cancelled, timedout, failed]. Option 1 AllowDuplicate: Allow starting a using the same when a with the same is not already running. Option 2 RejectDuplicate: Do not allow starting a using the same as a previous .\n\n# use AllowDuplicateFailedOnly option to start a workflow\ncadence workflow start --tl helloWorldGroup --wt main.Workflow --et 60 -i \'"cadence"\' --wid "<duplicated workflow id>" --wrp 0\n\n# use AllowDuplicate option to run a workflow\ncadence workflow run --tl helloWorldGroup --wt main.Workflow --et 60 -i \'"cadence"\' --wid "<duplicated workflow id>" --wrp 1\n\n\n# Start a workflow with a memo\n\nMemos are immutable key/value pairs that can be attached to a run when starting the . These are visible when listing . More information on memos can be found here.\n\ncadence wf start -tl helloWorldGroup -wt main.Workflow -et 60 -i \'"cadence"\' -memo_key ‘“Service” “Env” “Instance”’ -memo ‘“serverName1” “test” 5’\n\n\n# Show workflow history\n\ncadence workflow show -w 3ea6b242-b23c-4279-bb13-f215661b4717 -r 866ae14c-88cf-4f1e-980f-571e031d71b0\n# a shortcut of this is (without -w -r flag)\ncadence workflow showid 3ea6b242-b23c-4279-bb13-f215661b4717 866ae14c-88cf-4f1e-980f-571e031d71b0\n\n# if run_id is not provided, it will show the latest run history of that workflow_id\ncadence workflow show -w 3ea6b242-b23c-4279-bb13-f215661b4717\n# a shortcut of this is\ncadence workflow showid 3ea6b242-b23c-4279-bb13-f215661b4717\n\n\n# Show workflow execution information\n\ncadence workflow describe -w 3ea6b242-b23c-4279-bb13-f215661b4717 -r 866ae14c-88cf-4f1e-980f-571e031d71b0\n# a shortcut of this is (without -w -r flag)\ncadence workflow describeid 3ea6b242-b23c-4279-bb13-f215661b4717 866ae14c-88cf-4f1e-980f-571e031d71b0\n\n# if run_id is not provided, it will show the latest workflow execution of that workflow_id\ncadence workflow describe -w 3ea6b242-b23c-4279-bb13-f215661b4717\n# a shortcut of this is\ncadence workflow describeid 3ea6b242-b23c-4279-bb13-f215661b4717\n\n\n# List closed or open workflow executions\n\ncadence workflow list\n\n# default will only show one page, to view more items, use --more flag\ncadence workflow list -m\n\n\nUse --query to list with SQL like\n\ncadence workflow list --query "WorkflowType=\'main.SampleParentWorkflow\' AND CloseTime = missing "\n\n\nThis will return all open with workflowType as "main.SampleParentWorkflow".\n\n# Query workflow execution\n\n# use custom query type\ncadence workflow query -w <wid> -r <rid> --qt <query-type>\n\n# use build-in query type "__stack_trace" which is supported by Cadence client library\ncadence workflow query -w <wid> -r <rid> --qt __stack_trace\n# a shortcut to query using __stack_trace is (without --qt flag)\ncadence workflow stack -w <wid> -r <rid>\n\n\n# Signal, cancel, terminate workflow\n\n# signal\ncadence workflow signal -w <wid> -r <rid> -n <signal-name> -i \'"signal-value"\'\n\n# cancel\ncadence workflow cancel -w <wid> -r <rid>\n\n# terminate\ncadence workflow terminate -w <wid> -r <rid> --reason\n\n\nTerminating a running will record a WorkflowExecutionTerminated as the closing in the history. No more will be scheduled for a terminated . Canceling a running will record a WorkflowExecutionCancelRequested in the history, and a new will be scheduled. The has a chance to do some clean up work after cancellation.\n\n# Signal, cancel, terminate workflows as a batch job\n\nBatch job is based on List Workflow Query(--query). It supports , cancel and terminate as batch job type. For terminating as batch job, it will terminte the children recursively.\n\nStart a batch job(using as batch type):\n\ncadence --do samples-domain wf batch start --query "WorkflowType=\'main.SampleParentWorkflow\' AND CloseTime=missing" --reason "test" --bt signal --sig testname\nThis batch job will be operating on 5 workflows.\nPlease confirm[Yes/No]:yes\n{\n    "jobID": "<batch-job-id>",\n    "msg": "batch job is started"\n}\n\n\n\nYou need to remember the JobID or use List command to get all your batch jobs:\n\ncadence --do samples-domain wf batch list\n\n\nDescribe the progress of a batch job:\n\ncadence --do samples-domain wf batch desc -jid <batch-job-id>\n\n\nTerminate a batch job:\n\ncadence --do samples-domain wf batch terminate -jid <batch-job-id>\n\n\nNote that the operation performed by a batch will not be rolled back by terminating the batch. However, you can use reset to rollback your .\n\n# Restart, reset workflow\n\nThe Reset command allows resetting a to a particular point and continue running from there. There are a lot of use cases:\n\n * Rerun a failed from the beginning with the same start parameters.\n * Rerun a failed from the failing point without losing the achieved progress(history).\n * After deploying new code, reset an open to let the run to different flows.\n\nYou can reset to some predefined types:\n\ncadence workflow reset -w <wid> -r <rid> --reset_type <reset_type> --reason "some_reason"\n\n\n * FirstDecisionCompleted: reset to the beginning of the history.\n * LastDecisionCompleted: reset to the end of the history.\n * LastContinuedAsNew: reset to the end of the history for the previous run.\n\nIf you are familiar with the Cadence history , You can also reset to any finish by using:\n\ncadence workflow reset -w <wid> -r <rid> --event_id <decision_finish_event_id> --reason "some_reason"\n\n\nSome things to note:\n\n * When reset, a new run will be kicked off with the same workflowID. But if there is a running execution for the workflow(workflowID), the current run will be terminated.\n * decision_finish_event_id is the ID of of the type: DecisionTaskComplete/DecisionTaskFailed/DecisionTaskTimeout.\n * To restart a from the beginning, reset to the first finish .\n\nTo reset multiple , you can use batch reset command:\n\ncadence workflow reset-batch --input_file <file_of_workflows_to_reset> --reset_type <reset_type> --reason "some_reason"\n\n\n# Recovery from bad deployment -- auto-reset workflow\n\nIf a bad deployment lets a run into a wrong state, you might want to reset the to the point that the bad deployment started to run. But usually it is not easy to find out all the impacted, and every reset point for each . In this case, auto-reset will automatically reset all the given a bad deployment identifier.\n\nLet\'s get familiar with some concepts. Each deployment will have an identifier, we call it "Binary Checksum" as it is usually generated by the md5sum of a binary file. For a , each binary checksum will be associated with an auto-reset point, which contains a runID, an eventID, and the created_time that binary/deployment made the first for the .\n\nTo find out which binary checksum of the bad deployment to reset, you should be aware of at least one running into a bad state. Use the describe command with --reset_points_only option to show all the reset points:\n\ncadence wf desc -w <WorkflowID>  --reset_points_only\n+----------------------------------+--------------------------------+--------------------------------------+---------+\n|         BINARY CHECKSUM          |          CREATE TIME           |                RUNID                 | EVENTID |\n+----------------------------------+--------------------------------+--------------------------------------+---------+\n| c84c5afa552613a83294793f4e664a7f | 2019-05-24 10:01:00.398455019  | 2dd29ab7-2dd8-4668-83e0-89cae261cfb1 |       4 |\n| aae748fdc557a3f873adbe1dd066713f | 2019-05-24 11:01:00.067691445  | d42d21b8-2adb-4313-b069-3837d44d6ce6 |       4 |\n...\n...\n\n\nThen use this command to tell Cadence to auto-reset all impacted by the bad deployment. The command will store the bad binary checksum into info and trigger a process to reset all your .\n\ncadence --do <YourDomainName> domain update --add_bad_binary aae748fdc557a3f873adbe1dd066713f  --reason "rollback bad deployment"\n\n\nAs you add the bad binary checksum to your , Cadence will not dispatch any to the bad binary. So make sure that you have rolled back to a good deployment(or roll out new bits with bug fixes). Otherwise your can\'t make any progress after auto-reset.',normalizedContent:'# command line interface\n\nthe cadence is a command-line tool you can use to perform various on a cadence server. it can perform operations such as register, update, and describe as well as operations like start , show history, and .\n\n\n# using the cli\n\n\n# homebrew\n\nbrew install cadence-workflow\n\n\nafter the installation is done, you can use cli:\n\ncadence --help\n\n\nthis will always install the latest version. follow this instructions if you need to install older versions of cadence cli.\n\n\n# docker\n\nthe cadence can be used directly from the docker hub image ubercadence/cli or by building the tool locally.\n\nexample of using the docker image to describe a\n\ndocker run -it --rm ubercadence/cli:master --address <frontendaddress> --domain samples-domain domain describe\n\n\nmaster will be the latest cli binary from the project. but you can specify a version to best match your server version:\n\ndocker run -it --rm ubercadence/cli:<version> --address <frontendaddress> --domain samples-domain domain describe\n\n\nfor example docker run --rm ubercadence/cli:0.21.3 --domain samples-domain domain describe will be the cli that is released as part of the v0.21.3 release. see docker hub page for all the cli image tags. note that cli versions of 0.20.0 works for all server versions of 0.12 to 0.19 as well. that\'s because the cli version doesn\'t change in those versions.\n\nnote: on docker versions 18.03 and later, you may get a "connection refused" error when connecting to local server. you can work around this by setting the host to "host.docker.internal" (see here for more info).\n\ndocker run -it --rm ubercadence/cli:master --address host.docker.internal:7933 --domain samples-domain domain describe\n\n\nnote: be sure to update your image when you want to try new features: docker pull ubercadence/cli:master\n\nnote: if you are running docker-compose cadence server, you can also logon to the container to execute cli:\n\ndocker exec -it docker_cadence_1 /bin/bash\n\n# cadence --address $(hostname -i):7933 --do samples domain register\n\n\n\n# build it yourself\n\nto build the tool locally, clone the cadence server repo, check out the version tag (e.g. git checkout v0.21.3) and run make tools. this produces an executable called cadence. with a local build, the same command to describe a would look like this:\n\ncadence --domain samples-domain domain describe\n\n\nalternatively, you can build the cli image, see instructions\n\n\n# documentation\n\ncli are documented by --help or -h in any tab of all levels:\n\n$cadence --help\nname:\n   cadence - a command-line tool for cadence users\n\nusage:\n   cadence [global options] command [command options] [arguments...]\n\nversion:\n   0.18.4\n\ncommands:\n   domain, d     operate cadence domain\n   workflow, wf  operate cadence workflow\n   tasklist, tl  operate cadence tasklist\n   admin, adm    run admin operation\n   cluster, cl   operate cadence cluster\n   help, h       shows a list of commands or help for one command\n\nglobal options:\n   --address value, --ad value          host:port for cadence frontend service [$cadence_cli_address]\n   --domain value, --do value           cadence workflow domain [$cadence_cli_domain]\n   --context_timeout value, --ct value  optional timeout for context of rpc call in seconds (default: 5) [$cadence_context_timeout]\n   --help, -h                           show help\n   --version, -v                        print the version\n\n\nand\n\n$cadence workflow -h\nname:\n   cadence workflow - operate cadence workflow\n\nusage:\n   cadence workflow command [command options] [arguments...]\n\ncommands:\n   activity, act       operate activities of workflow\n   show                show workflow history\n   showid              show workflow history with given workflow_id and run_id (a shortcut of `show -w <wid> -r <rid>`). run_id is only required for archived history\n   start               start a new workflow execution\n   run                 start a new workflow execution and get workflow progress\n   cancel, c           cancel a workflow execution\n   signal, s           signal a workflow execution\n   signalwithstart     signal the current open workflow if exists, or attempt to start a new run based on idresuepolicy and signals it\n   terminate, term     terminate a new workflow execution\n   list, l             list open or closed workflow executions\n   listall, la         list all open or closed workflow executions\n   listarchived        list archived workflow executions\n   scan, sc, scanall   scan workflow executions (need to enable cadence server on elasticsearch). it will be faster than listall, but result are not sorted.\n   count, cnt          count number of workflow executions (need to enable cadence server on elasticsearch)\n   query               query workflow execution\n   stack               query workflow execution with __stack_trace as query type\n   describe, desc      show information of workflow execution\n   describeid, descid  show information of workflow execution with given workflow_id and optional run_id (a shortcut of `describe -w <wid> -r <rid>`)\n   observe, ob         show the progress of workflow history\n   observeid, obid     show the progress of workflow history with given workflow_id and optional run_id (a shortcut of `observe -w <wid> -r <rid>`)\n   reset, rs           reset the workflow, by either eventid or resettype.\n   reset-batch         reset workflow in batch by resettype: lastdecisioncompleted,lastcontinuedasnew,badbinary,decisioncompletedtime,firstdecisionscheduled,lastdecisionscheduled,firstdecisioncompletedto get base workflowids/runids to reset, source is from input file or visibility query.\n   batch               batch operation on a list of workflows from query.\n\noptions:\n   --help, -h  show help\n\n\n$cadence wf signal -h\nname:\n   cadence workflow signal - signal a workflow execution\n\nusage:\n   cadence workflow signal [command options] [arguments...]\n\noptions:\n   --workflow_id value, --wid value, -w value  workflowid\n   --run_id value, --rid value, -r value       runid\n   --name value, -n value                      signalname\n   --input value, -i value                     input for the signal, in json format.\n   --input_file value, --if value              input for the signal from json file.\n\n\n\nand etc.\n\nthe example commands below will use cadence for brevity.\n\n\n# environment variables\n\nsetting environment variables for repeated parameters can shorten the commands.\n\n * cadence_cli_address - host:port for cadence frontend service, the default is for the local server\n * cadence_cli_domain - default , so you don\'t need to specify --domain\n\n\n# quick start\n\nrun cadence for help on top level commands and global options run cadence domain for help on operations run cadence workflow for help on operations run cadence tasklist for help on tasklist operations (cadence help, cadence help [domain|workflow] will also print help messages)\n\nnote: make sure you have a cadence server running before using\n\n\n# domain operation examples\n\n * register a new named "samples-domain":\n\ncadence --domain samples-domain domain register\n# or using short alias\ncadence --do samples-domain d re \n\n\nif your cadence cluster has enable global domain(xdc replication), then you have to specify the replicaiton settings when registering a domain:\n\ncadence --domains amples-domain domain register --active_cluster clusternamea --clusters clusternamea clusternameb\n\n\n * view "samples-domain" details:\n\ncadence --domain samples-domain domain describe\n\n\n\n# workflow operation examples\n\nthe following examples assume the cadence_cli_domain environment variable is set.\n\n# run workflow\n\nstart a and see its progress. this command doesn\'t finish until completes.\n\ncadence workflow run --tl helloworldgroup --wt main.workflow --et 60 -i \'"cadence"\'\n\n# view help messages for workflow run\ncadence workflow run -h\n\n\nbrief explanation: to run a , the user must specify the following:\n\n 1. tasklist name (--tl)\n 2. workflow type (--wt)\n 3. execution start to close timeout in seconds (--et)\n 4. input in json format (--i) (optional)\n\ns example uses this cadence-samples workflow and takes a string as input with the -i \'"cadence"\' parameter. single quotes (\'\') are used to wrap input as json.\n\nnote: you need to start the so that the can make progress. (run make && ./bin/helloworld -m worker in cadence-samples to start the )\n\n# show running workers of a tasklist\n\ncadence tasklist desc --tl helloworldgroup\n\n\n# start workflow\n\ncadence workflow start --tl helloworldgroup --wt main.workflow --et 60 -i \'"cadence"\'\n\n# view help messages for workflow start\ncadence workflow start -h\n\n# for a workflow with multiple inputs, separate each json with space/newline like\ncadence workflow start --tl helloworldgroup --wt main.workflowwith3args --et 60 -i \'"your_input_string" 123 {"name":"my-string", "age":12345}\'\n\n\nthe start command is similar to the run command, but immediately returns the workflow_id and run_id after starting the . use the show command to view the \'s history/progress.\n\n# reuse the same workflow id when starting/running a workflow\n\nuse option --workflowidreusepolicy or --wrp to configure the reuse policy. option 0 allowduplicatefailedonly: allow starting a using the same when a with the same is not already running and the last execution close state is one of [terminated, cancelled, timedout, failed]. option 1 allowduplicate: allow starting a using the same when a with the same is not already running. option 2 rejectduplicate: do not allow starting a using the same as a previous .\n\n# use allowduplicatefailedonly option to start a workflow\ncadence workflow start --tl helloworldgroup --wt main.workflow --et 60 -i \'"cadence"\' --wid "<duplicated workflow id>" --wrp 0\n\n# use allowduplicate option to run a workflow\ncadence workflow run --tl helloworldgroup --wt main.workflow --et 60 -i \'"cadence"\' --wid "<duplicated workflow id>" --wrp 1\n\n\n# start a workflow with a memo\n\nmemos are immutable key/value pairs that can be attached to a run when starting the . these are visible when listing . more information on memos can be found here.\n\ncadence wf start -tl helloworldgroup -wt main.workflow -et 60 -i \'"cadence"\' -memo_key ‘“service” “env” “instance”’ -memo ‘“servername1” “test” 5’\n\n\n# show workflow history\n\ncadence workflow show -w 3ea6b242-b23c-4279-bb13-f215661b4717 -r 866ae14c-88cf-4f1e-980f-571e031d71b0\n# a shortcut of this is (without -w -r flag)\ncadence workflow showid 3ea6b242-b23c-4279-bb13-f215661b4717 866ae14c-88cf-4f1e-980f-571e031d71b0\n\n# if run_id is not provided, it will show the latest run history of that workflow_id\ncadence workflow show -w 3ea6b242-b23c-4279-bb13-f215661b4717\n# a shortcut of this is\ncadence workflow showid 3ea6b242-b23c-4279-bb13-f215661b4717\n\n\n# show workflow execution information\n\ncadence workflow describe -w 3ea6b242-b23c-4279-bb13-f215661b4717 -r 866ae14c-88cf-4f1e-980f-571e031d71b0\n# a shortcut of this is (without -w -r flag)\ncadence workflow describeid 3ea6b242-b23c-4279-bb13-f215661b4717 866ae14c-88cf-4f1e-980f-571e031d71b0\n\n# if run_id is not provided, it will show the latest workflow execution of that workflow_id\ncadence workflow describe -w 3ea6b242-b23c-4279-bb13-f215661b4717\n# a shortcut of this is\ncadence workflow describeid 3ea6b242-b23c-4279-bb13-f215661b4717\n\n\n# list closed or open workflow executions\n\ncadence workflow list\n\n# default will only show one page, to view more items, use --more flag\ncadence workflow list -m\n\n\nuse --query to list with sql like\n\ncadence workflow list --query "workflowtype=\'main.sampleparentworkflow\' and closetime = missing "\n\n\nthis will return all open with workflowtype as "main.sampleparentworkflow".\n\n# query workflow execution\n\n# use custom query type\ncadence workflow query -w <wid> -r <rid> --qt <query-type>\n\n# use build-in query type "__stack_trace" which is supported by cadence client library\ncadence workflow query -w <wid> -r <rid> --qt __stack_trace\n# a shortcut to query using __stack_trace is (without --qt flag)\ncadence workflow stack -w <wid> -r <rid>\n\n\n# signal, cancel, terminate workflow\n\n# signal\ncadence workflow signal -w <wid> -r <rid> -n <signal-name> -i \'"signal-value"\'\n\n# cancel\ncadence workflow cancel -w <wid> -r <rid>\n\n# terminate\ncadence workflow terminate -w <wid> -r <rid> --reason\n\n\nterminating a running will record a workflowexecutionterminated as the closing in the history. no more will be scheduled for a terminated . canceling a running will record a workflowexecutioncancelrequested in the history, and a new will be scheduled. the has a chance to do some clean up work after cancellation.\n\n# signal, cancel, terminate workflows as a batch job\n\nbatch job is based on list workflow query(--query). it supports , cancel and terminate as batch job type. for terminating as batch job, it will terminte the children recursively.\n\nstart a batch job(using as batch type):\n\ncadence --do samples-domain wf batch start --query "workflowtype=\'main.sampleparentworkflow\' and closetime=missing" --reason "test" --bt signal --sig testname\nthis batch job will be operating on 5 workflows.\nplease confirm[yes/no]:yes\n{\n    "jobid": "<batch-job-id>",\n    "msg": "batch job is started"\n}\n\n\n\nyou need to remember the jobid or use list command to get all your batch jobs:\n\ncadence --do samples-domain wf batch list\n\n\ndescribe the progress of a batch job:\n\ncadence --do samples-domain wf batch desc -jid <batch-job-id>\n\n\nterminate a batch job:\n\ncadence --do samples-domain wf batch terminate -jid <batch-job-id>\n\n\nnote that the operation performed by a batch will not be rolled back by terminating the batch. however, you can use reset to rollback your .\n\n# restart, reset workflow\n\nthe reset command allows resetting a to a particular point and continue running from there. there are a lot of use cases:\n\n * rerun a failed from the beginning with the same start parameters.\n * rerun a failed from the failing point without losing the achieved progress(history).\n * after deploying new code, reset an open to let the run to different flows.\n\nyou can reset to some predefined types:\n\ncadence workflow reset -w <wid> -r <rid> --reset_type <reset_type> --reason "some_reason"\n\n\n * firstdecisioncompleted: reset to the beginning of the history.\n * lastdecisioncompleted: reset to the end of the history.\n * lastcontinuedasnew: reset to the end of the history for the previous run.\n\nif you are familiar with the cadence history , you can also reset to any finish by using:\n\ncadence workflow reset -w <wid> -r <rid> --event_id <decision_finish_event_id> --reason "some_reason"\n\n\nsome things to note:\n\n * when reset, a new run will be kicked off with the same workflowid. but if there is a running execution for the workflow(workflowid), the current run will be terminated.\n * decision_finish_event_id is the id of of the type: decisiontaskcomplete/decisiontaskfailed/decisiontasktimeout.\n * to restart a from the beginning, reset to the first finish .\n\nto reset multiple , you can use batch reset command:\n\ncadence workflow reset-batch --input_file <file_of_workflows_to_reset> --reset_type <reset_type> --reason "some_reason"\n\n\n# recovery from bad deployment -- auto-reset workflow\n\nif a bad deployment lets a run into a wrong state, you might want to reset the to the point that the bad deployment started to run. but usually it is not easy to find out all the impacted, and every reset point for each . in this case, auto-reset will automatically reset all the given a bad deployment identifier.\n\nlet\'s get familiar with some concepts. each deployment will have an identifier, we call it "binary checksum" as it is usually generated by the md5sum of a binary file. for a , each binary checksum will be associated with an auto-reset point, which contains a runid, an eventid, and the created_time that binary/deployment made the first for the .\n\nto find out which binary checksum of the bad deployment to reset, you should be aware of at least one running into a bad state. use the describe command with --reset_points_only option to show all the reset points:\n\ncadence wf desc -w <workflowid>  --reset_points_only\n+----------------------------------+--------------------------------+--------------------------------------+---------+\n|         binary checksum          |          create time           |                runid                 | eventid |\n+----------------------------------+--------------------------------+--------------------------------------+---------+\n| c84c5afa552613a83294793f4e664a7f | 2019-05-24 10:01:00.398455019  | 2dd29ab7-2dd8-4668-83e0-89cae261cfb1 |       4 |\n| aae748fdc557a3f873adbe1dd066713f | 2019-05-24 11:01:00.067691445  | d42d21b8-2adb-4313-b069-3837d44d6ce6 |       4 |\n...\n...\n\n\nthen use this command to tell cadence to auto-reset all impacted by the bad deployment. the command will store the bad binary checksum into info and trigger a process to reset all your .\n\ncadence --do <yourdomainname> domain update --add_bad_binary aae748fdc557a3f873adbe1dd066713f  --reason "rollback bad deployment"\n\n\nas you add the bad binary checksum to your , cadence will not dispatch any to the bad binary. so make sure that you have rolled back to a good deployment(or roll out new bits with bug fixes). otherwise your can\'t make any progress after auto-reset.',charsets:{cjk:!0}},{title:"Introduction",frontmatter:{layout:"default",title:"Introduction",permalink:"/docs/go-client",readingShow:"top"},regularPath:"/docs/05-go-client/",relativePath:"docs/05-go-client/index.md",key:"v-740be4db",path:"/docs/go-client/",headers:[{level:2,title:"Overview",slug:"overview",normalizedTitle:"overview",charIndex:16},{level:2,title:"Links",slug:"links",normalizedTitle:"links",charIndex:712}],codeSwitcherOptions:{},headersStr:"Overview Links",content:"# Go client\n\n\n# Overview\n\nGo client attempts to follow Go language conventions. The conversion of a Go program to the fault-oblivious function is expected to be pretty mechanical.\n\nCadence requires determinism of the code. It supports deterministic execution of the multithreaded code and constructs like select that are non-deterministic by Go design. The Cadence solution is to provide corresponding constructs in the form of interfaces that have similar capability but support deterministic execution.\n\nFor example, instead of native Go channels, code must use the workflow.Channel interface. Instead of select, the workflow.Selector interface must be used.\n\nFor more information, see Creating Workflows.\n\n\n# Links\n\n * GitHub project: https://github.com/uber-go/cadence-client\n * Samples: https://github.com/uber-common/cadence-samples\n * GoDoc documentation: https://godoc.org/go.uber.org/cadence",normalizedContent:"# go client\n\n\n# overview\n\ngo client attempts to follow go language conventions. the conversion of a go program to the fault-oblivious function is expected to be pretty mechanical.\n\ncadence requires determinism of the code. it supports deterministic execution of the multithreaded code and constructs like select that are non-deterministic by go design. the cadence solution is to provide corresponding constructs in the form of interfaces that have similar capability but support deterministic execution.\n\nfor example, instead of native go channels, code must use the workflow.channel interface. instead of select, the workflow.selector interface must be used.\n\nfor more information, see creating workflows.\n\n\n# links\n\n * github project: https://github.com/uber-go/cadence-client\n * samples: https://github.com/uber-common/cadence-samples\n * godoc documentation: https://godoc.org/go.uber.org/cadence",charsets:{}},{title:"Workflow Non-deterministic errors",frontmatter:{layout:"default",title:"Workflow Non-deterministic errors",permalink:"/docs/go-client/workflow-non-deterministic-errors",readingShow:"top"},regularPath:"/docs/05-go-client/19-workflow-non-deterministic-error.html",relativePath:"docs/05-go-client/19-workflow-non-deterministic-error.md",key:"v-5df8103c",path:"/docs/go-client/workflow-non-deterministic-errors/",headers:[{level:2,title:"Root cause of non-deterministic errors",slug:"root-cause-of-non-deterministic-errors",normalizedTitle:"root cause of non-deterministic errors",charIndex:40},{level:2,title:"Decision tasks of workflow",slug:"decision-tasks-of-workflow",normalizedTitle:"decision tasks of workflow",charIndex:1533},{level:2,title:"Categories of non-deterministic errors",slug:"categories-of-non-deterministic-errors",normalizedTitle:"categories of non-deterministic errors",charIndex:5698},{level:3,title:"1. Missing decisions",slug:"_1-missing-decisions",normalizedTitle:"1. missing decisions",charIndex:6002},{level:3,title:"2. Extra decisions",slug:"_2-extra-decisions",normalizedTitle:"2. extra decisions",charIndex:6618},{level:3,title:"3. Mismatched decisions",slug:"_3-mismatched-decisions",normalizedTitle:"3. mismatched decisions",charIndex:7562},{level:3,title:"4. Decision state machine panic",slug:"_4-decision-state-machine-panic",normalizedTitle:"4. decision state machine panic",charIndex:8294},{level:2,title:"Common Q&A",slug:"common-q-a",normalizedTitle:"common q&amp;a",charIndex:null},{level:3,title:"I want to change my workflow implementation. What code changes may produce non-deterministic errors?",slug:"i-want-to-change-my-workflow-implementation-what-code-changes-may-produce-non-deterministic-errors",normalizedTitle:"i want to change my workflow implementation. what code changes may produce non-deterministic errors?",charIndex:8843},{level:3,title:"What are some changes that will NOT trigger non-deterministic errors?",slug:"what-are-some-changes-that-will-not-trigger-non-deterministic-errors",normalizedTitle:"what are some changes that will not trigger non-deterministic errors?",charIndex:9548},{level:3,title:"I want to check if my code change will produce non-deterministic errors, how can I debug?",slug:"i-want-to-check-if-my-code-change-will-produce-non-deterministic-errors-how-can-i-debug",normalizedTitle:"i want to check if my code change will produce non-deterministic errors, how can i debug?",charIndex:10476}],codeSwitcherOptions:{},headersStr:"Root cause of non-deterministic errors Decision tasks of workflow Categories of non-deterministic errors 1. Missing decisions 2. Extra decisions 3. Mismatched decisions 4. Decision state machine panic Common Q&A I want to change my workflow implementation. What code changes may produce non-deterministic errors? What are some changes that will NOT trigger non-deterministic errors? I want to check if my code change will produce non-deterministic errors, how can I debug?",content:'# Workflow Non-deterministic errors\n\n\n# Root cause of non-deterministic errors\n\nCadence workflows are designed as long-running operations, and therefore the workflow code you write must be deterministic so that no matter how many time it is executed it always produce the same results.\n\nIn production environment, your workflow code will run on a distributed system orchestrated by clusters of machines. However, machine failures are inevitable and can happen anytime to your workflow host. If you have a workflow running for long period of time, maybe months even years, and it fails due to loss of a host, it will be resumed on another machine and continue the rest of its execution.\n\nConsider the following diagram where Workflow A is running on Host A but suddenly it crashes.\n\n\n\nWorkflow A then will be picked up by Host B and continues its execution. This process is called change of workflow ownership. However, after Host B gains ownership of the Workflow A, it does not have any information about its historical executions. For example, Workflow A may have executed many activities and it fails. Host B needs to redo all its history until the moment of failure. The process of reconstructing history of a workflow is called history replay.\n\nIn general, any errors occurs during the replay process are called non-deterministic errors. We will explore different types of non-deterministic errors in sections below but first let\'s try to understand how Cadence is able to perform the replay of workflow in case of failure.\n\n\n# Decision tasks of workflow\n\nIn the previous section, we learned that Cadence is able to replay workflow histories in case of failure. We will learn exactly how Cadence keeps track of histories and how they get replayed when necessary.\n\nWorkflow histories are built based on event-sourcing, and each history event are persisted in Cadence storage. In Cadence, we call these history events decision tasks, the foundation of history replay. Most decision tasks have three status - Scheduled, Started, Completed and we will go over decision tasks produced by each Cadence operation in section below.\n\nWhen changing a workflow ownership of host and replaying a workflow, the decision tasks are downloaded from database and persisted in memory. Then during the workflow replaying process, if Cadence finds a decision task already exists for a particular step, it will immediately return the value of a decision task instead of rerunning the whole workflow logic. Let\'s take a look at the following simple workflow implementation and explicitly list all decision tasks produced by this workflow.\n\nfunc SimpleWorkflow(ctx workflow.Context) error {\n\tao := workflow.ActivityOptions{\n\t\t...\n\t}\n\tctx = workflow.WithActivityOptions(ctx, ao)\n\n\tvar a int\n\terr := workflow.ExecuteActivity(ctx, ActivityA).Get(ctx, &a)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tworkflow.Sleep(time.Minute)\n\n\terr = workflow.ExecuteActivity(ctx, ActivityB, a).Get(ctx, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tworkflow.Sleep(time.Hour)\n\treturn nil\n}\n\n\nIn this workflow, when it starts, it first execute ActivityA and then assign the result to an integer. It sleeps for one minute and then use the integer as an input argument to execute ActivityB. Finally it sleeps for one hour and completes.\n\nThe following table lists the decision tasks stack produced by this workflow. It may look overwhelming first but if you associate each decision task with its corresponding Cadence operation, it becomes self-explanatory.\n\nID   DECISION TASK TYPE      EXPLANATION\n1    WorkflowStarted         the recorded StartWorkflow call\'s data, which usually\n                             schedules a new decision task immediately\n2    DecisionTaskScheduled   workflow worker polling for work\n3    DecisionTaskStarted     worker gets the type SimpleWorkflow, lookup registred funcs,\n                             deserialize input, call it\n4    DecisionTaskCompleted   worker finishes\n5    ActivityTaskScheduled   activity available for a worker\n6    ActivityTaskStarted     activity worker polls and gets type ActivityA and do the job\n7    ActivityTaskCompleted   activity work completed with result of var a\n8    DecisionTaskScheduled   triggered by ActivityCompleted. server schedule next task\n9    DecisionTaskStarted     \n10   DecisionTaskCompleted   \n11   TimerStarted            decision scheduled a timer for 1 minute\n12   TimerFired              fired after 1 minute\n13   DecisionTaskScheduled   triggered by TimerFired\n14   DecisionTaskStarted     \n15   DecisionTaskCompleted   \n16   ActivityTaskScheduled   ActivityB scheduled by decision with param a\n17   ActivityTaskStarted     started by worker\n18   ActivityTaskCompleted   completed with nil\n19   DecisionTaskScheduled   triggered by ActivityCompleted\n20   DecisionTaskStarted     \n21   DecisionTaskCompleted   \n22   TimerStarted            decision scheduled a timer for 1 hour\n23   TimerFired              fired after 1 hour\n24   DecisionTaskScheduled   triggered by TimerFired\n25   DecisionTaskStarted     \n26   DecisionTaskCompleted   \n27   WorkflowCompleted       completed by decision (the function call returned)\n\nAs you may observe that this stack has strict orders. The whole point of the table above is that if the code you write involves some orchestration by Cadence, either your worker or Cadence server, they produce decision tasks. When your workflow gets replayed, it will strive to reconstruct this stack. Therefore, code changes to your workflow needs to make sure that they do not mess up with these decision tasks, which trigger non-deterministic errors. Then let\'s explore different types of non-deterministic errors and their root causes.\n\n\n# Categories of non-deterministic errors\n\nProgrammatically, Cadence surfaces 4 categories of non-deterministic errors. With understanding of decision tasks in the previous section and combining the error messages, you should be able to pinpoint what code changes may yield to non-deterministic errors.\n\n\n# 1. Missing decisions\n\nfmt.Errorf("nondeterministic workflow: missing replay decision for %s", util.HistoryEventToString(e))\n\n\nFor source code click here\n\nThis means after replay code, the decision is scheduled less than history events. Using the previous history as an example, when the workflow is waiting at the one hour timer(event ID 22), if we delete the line of :\n\nworkflow.Sleep(time.Hour)\n\n\nand restart worker, then it will run into this error. Because in the history, the workflow has a timer event that is supposed to fire in one hour. However, during replay, there is no logic to schedule that timer.\n\n\n# 2. Extra decisions\n\nfmt.Errorf("nondeterministic workflow: extra replay decision for %s", util.DecisionToString(d))\n\n\nFor source code click here\n\nThis is basically the opposite of the previous case, which means that during replay, Cadence generates more decisions than those in history events. Using the previous history as an example, when the workflow is waiting at the one hour timer(event ID 22), if we change the line of:\n\nerr = workflow.ExecuteActivity(ctx, activityB, a).Get(ctx, nil)\n\n\nto\n\nfb := workflow.ExecuteActivity(ctx, activityB, a)\nfc := workflow.ExecuteActivity(ctx, activityC, a)\nerr = fb.Get(ctx,nil)\nif err != nil {\n\treturn err\n}\nerr = fc.Get(ctx,nil)\nif err != nil {\n\treturn err\n}\n\n\nAnd restart worker, then it will run into this error. Because in the history, the workflow has scheduled only activityB after the one minute timer, however, during replay, there are two activities scheduled in a decision (in parallel).\n\n\n# 3. Mismatched decisions\n\nfmt.Errorf("nondeterministic workflow: history event is %s, replay decision is %s",util.HistoryEventToString(e), util.DecisionToString(d))\n\n\nFor source code click here\n\nThis means after replay code, the decision scheduled is different than the one in history. Using the previous history as an example, when the workflow is waiting at the one hour timer(event ID 22), if we change the line of :\n\nerr = workflow.ExecuteActivity(ctx, ActivityB, a).Get(ctx, nil)\n\n\nto\n\nerr = workflow.ExecuteActivity(ctx, ActivityC, a).Get(ctx, nil)\n\n\nAnd restart worker, then it will run into this error. Because in the history, the workflow has scheduled ActivityB with input a, but during replay, it schedules ActivityC.\n\n\n# 4. Decision state machine panic\n\nfmt.Sprintf("unknown decision %v, possible causes are nondeterministic workflow definition code"+" or incompatible change in the workflow definition", id)\n\n\nFor source code click here\n\nThis usually means workflow history is corrupted due to some bug. For example, the same activity can be scheduled and differentiated by activityID. So ActivityIDs for different activities are supposed to be unique in workflow history. If however we have an ActivityID collision, replay will run into this error.\n\n\n# Common Q&A\n\n\n# I want to change my workflow implementation. What code changes may produce non-deterministic errors?\n\nAs we discussed in previous sections, if your changes change decision tasks, then they will probably lead to non-deterministic errors. These are some common changes that can be categorized by these previous 4 types mentioned above.\n\n 1. Changing the order of executing Cadence defined operations, such as activities, timer, child workflows, signals, cancelRequest.\n 2. Change the duration of a timer\n 3. Use build-in goroutine of golang instead of using workflow.Go\n 4. Use build-in channel of golang instead of using workflow.Channel\n 5. Use build-in sleep function instead of using workflow.Sleep\n\n\n# What are some changes that will NOT trigger non-deterministic errors?\n\nCode changes that are free of non-deterministic erorrs normally do not involve decision tasks in Cadence.\n\n 1. Activity input and output changes do not directly cause non-deterministic errors because the contents are not checked. However, changes may produce serialization errors based on your data converter implementation (type or number-of-arg changes are particularly prone to problems, so we recommend you always use a single struct). Cadence uses json.Marshal and json.Unmarshal (with Decoder.UseNumber()) by default.\n 2. Code changes that does not modify history events are safe to be checked in. For example, logging or metrics implementations.\n 3. Change of retry policies, as these are not compared. Adding or removing retry policies is also safe. Changes will only take effect on new calls however, not ones that have already been scheduled.\n\n\n# I want to check if my code change will produce non-deterministic errors, how can I debug?\n\nCadence provides replayer test, which functions as an unit test on your local machine to replay your workflow history comparing to your potential code change. If you introduce a non-deterministic change and your history triggers it, the test should fail. Check out this page for more details.',normalizedContent:'# workflow non-deterministic errors\n\n\n# root cause of non-deterministic errors\n\ncadence workflows are designed as long-running operations, and therefore the workflow code you write must be deterministic so that no matter how many time it is executed it always produce the same results.\n\nin production environment, your workflow code will run on a distributed system orchestrated by clusters of machines. however, machine failures are inevitable and can happen anytime to your workflow host. if you have a workflow running for long period of time, maybe months even years, and it fails due to loss of a host, it will be resumed on another machine and continue the rest of its execution.\n\nconsider the following diagram where workflow a is running on host a but suddenly it crashes.\n\n\n\nworkflow a then will be picked up by host b and continues its execution. this process is called change of workflow ownership. however, after host b gains ownership of the workflow a, it does not have any information about its historical executions. for example, workflow a may have executed many activities and it fails. host b needs to redo all its history until the moment of failure. the process of reconstructing history of a workflow is called history replay.\n\nin general, any errors occurs during the replay process are called non-deterministic errors. we will explore different types of non-deterministic errors in sections below but first let\'s try to understand how cadence is able to perform the replay of workflow in case of failure.\n\n\n# decision tasks of workflow\n\nin the previous section, we learned that cadence is able to replay workflow histories in case of failure. we will learn exactly how cadence keeps track of histories and how they get replayed when necessary.\n\nworkflow histories are built based on event-sourcing, and each history event are persisted in cadence storage. in cadence, we call these history events decision tasks, the foundation of history replay. most decision tasks have three status - scheduled, started, completed and we will go over decision tasks produced by each cadence operation in section below.\n\nwhen changing a workflow ownership of host and replaying a workflow, the decision tasks are downloaded from database and persisted in memory. then during the workflow replaying process, if cadence finds a decision task already exists for a particular step, it will immediately return the value of a decision task instead of rerunning the whole workflow logic. let\'s take a look at the following simple workflow implementation and explicitly list all decision tasks produced by this workflow.\n\nfunc simpleworkflow(ctx workflow.context) error {\n\tao := workflow.activityoptions{\n\t\t...\n\t}\n\tctx = workflow.withactivityoptions(ctx, ao)\n\n\tvar a int\n\terr := workflow.executeactivity(ctx, activitya).get(ctx, &a)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tworkflow.sleep(time.minute)\n\n\terr = workflow.executeactivity(ctx, activityb, a).get(ctx, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tworkflow.sleep(time.hour)\n\treturn nil\n}\n\n\nin this workflow, when it starts, it first execute activitya and then assign the result to an integer. it sleeps for one minute and then use the integer as an input argument to execute activityb. finally it sleeps for one hour and completes.\n\nthe following table lists the decision tasks stack produced by this workflow. it may look overwhelming first but if you associate each decision task with its corresponding cadence operation, it becomes self-explanatory.\n\nid   decision task type      explanation\n1    workflowstarted         the recorded startworkflow call\'s data, which usually\n                             schedules a new decision task immediately\n2    decisiontaskscheduled   workflow worker polling for work\n3    decisiontaskstarted     worker gets the type simpleworkflow, lookup registred funcs,\n                             deserialize input, call it\n4    decisiontaskcompleted   worker finishes\n5    activitytaskscheduled   activity available for a worker\n6    activitytaskstarted     activity worker polls and gets type activitya and do the job\n7    activitytaskcompleted   activity work completed with result of var a\n8    decisiontaskscheduled   triggered by activitycompleted. server schedule next task\n9    decisiontaskstarted     \n10   decisiontaskcompleted   \n11   timerstarted            decision scheduled a timer for 1 minute\n12   timerfired              fired after 1 minute\n13   decisiontaskscheduled   triggered by timerfired\n14   decisiontaskstarted     \n15   decisiontaskcompleted   \n16   activitytaskscheduled   activityb scheduled by decision with param a\n17   activitytaskstarted     started by worker\n18   activitytaskcompleted   completed with nil\n19   decisiontaskscheduled   triggered by activitycompleted\n20   decisiontaskstarted     \n21   decisiontaskcompleted   \n22   timerstarted            decision scheduled a timer for 1 hour\n23   timerfired              fired after 1 hour\n24   decisiontaskscheduled   triggered by timerfired\n25   decisiontaskstarted     \n26   decisiontaskcompleted   \n27   workflowcompleted       completed by decision (the function call returned)\n\nas you may observe that this stack has strict orders. the whole point of the table above is that if the code you write involves some orchestration by cadence, either your worker or cadence server, they produce decision tasks. when your workflow gets replayed, it will strive to reconstruct this stack. therefore, code changes to your workflow needs to make sure that they do not mess up with these decision tasks, which trigger non-deterministic errors. then let\'s explore different types of non-deterministic errors and their root causes.\n\n\n# categories of non-deterministic errors\n\nprogrammatically, cadence surfaces 4 categories of non-deterministic errors. with understanding of decision tasks in the previous section and combining the error messages, you should be able to pinpoint what code changes may yield to non-deterministic errors.\n\n\n# 1. missing decisions\n\nfmt.errorf("nondeterministic workflow: missing replay decision for %s", util.historyeventtostring(e))\n\n\nfor source code click here\n\nthis means after replay code, the decision is scheduled less than history events. using the previous history as an example, when the workflow is waiting at the one hour timer(event id 22), if we delete the line of :\n\nworkflow.sleep(time.hour)\n\n\nand restart worker, then it will run into this error. because in the history, the workflow has a timer event that is supposed to fire in one hour. however, during replay, there is no logic to schedule that timer.\n\n\n# 2. extra decisions\n\nfmt.errorf("nondeterministic workflow: extra replay decision for %s", util.decisiontostring(d))\n\n\nfor source code click here\n\nthis is basically the opposite of the previous case, which means that during replay, cadence generates more decisions than those in history events. using the previous history as an example, when the workflow is waiting at the one hour timer(event id 22), if we change the line of:\n\nerr = workflow.executeactivity(ctx, activityb, a).get(ctx, nil)\n\n\nto\n\nfb := workflow.executeactivity(ctx, activityb, a)\nfc := workflow.executeactivity(ctx, activityc, a)\nerr = fb.get(ctx,nil)\nif err != nil {\n\treturn err\n}\nerr = fc.get(ctx,nil)\nif err != nil {\n\treturn err\n}\n\n\nand restart worker, then it will run into this error. because in the history, the workflow has scheduled only activityb after the one minute timer, however, during replay, there are two activities scheduled in a decision (in parallel).\n\n\n# 3. mismatched decisions\n\nfmt.errorf("nondeterministic workflow: history event is %s, replay decision is %s",util.historyeventtostring(e), util.decisiontostring(d))\n\n\nfor source code click here\n\nthis means after replay code, the decision scheduled is different than the one in history. using the previous history as an example, when the workflow is waiting at the one hour timer(event id 22), if we change the line of :\n\nerr = workflow.executeactivity(ctx, activityb, a).get(ctx, nil)\n\n\nto\n\nerr = workflow.executeactivity(ctx, activityc, a).get(ctx, nil)\n\n\nand restart worker, then it will run into this error. because in the history, the workflow has scheduled activityb with input a, but during replay, it schedules activityc.\n\n\n# 4. decision state machine panic\n\nfmt.sprintf("unknown decision %v, possible causes are nondeterministic workflow definition code"+" or incompatible change in the workflow definition", id)\n\n\nfor source code click here\n\nthis usually means workflow history is corrupted due to some bug. for example, the same activity can be scheduled and differentiated by activityid. so activityids for different activities are supposed to be unique in workflow history. if however we have an activityid collision, replay will run into this error.\n\n\n# common q&a\n\n\n# i want to change my workflow implementation. what code changes may produce non-deterministic errors?\n\nas we discussed in previous sections, if your changes change decision tasks, then they will probably lead to non-deterministic errors. these are some common changes that can be categorized by these previous 4 types mentioned above.\n\n 1. changing the order of executing cadence defined operations, such as activities, timer, child workflows, signals, cancelrequest.\n 2. change the duration of a timer\n 3. use build-in goroutine of golang instead of using workflow.go\n 4. use build-in channel of golang instead of using workflow.channel\n 5. use build-in sleep function instead of using workflow.sleep\n\n\n# what are some changes that will not trigger non-deterministic errors?\n\ncode changes that are free of non-deterministic erorrs normally do not involve decision tasks in cadence.\n\n 1. activity input and output changes do not directly cause non-deterministic errors because the contents are not checked. however, changes may produce serialization errors based on your data converter implementation (type or number-of-arg changes are particularly prone to problems, so we recommend you always use a single struct). cadence uses json.marshal and json.unmarshal (with decoder.usenumber()) by default.\n 2. code changes that does not modify history events are safe to be checked in. for example, logging or metrics implementations.\n 3. change of retry policies, as these are not compared. adding or removing retry policies is also safe. changes will only take effect on new calls however, not ones that have already been scheduled.\n\n\n# i want to check if my code change will produce non-deterministic errors, how can i debug?\n\ncadence provides replayer test, which functions as an unit test on your local machine to replay your workflow history comparing to your potential code change. if you introduce a non-deterministic change and your history triggers it, the test should fail. check out this page for more details.',charsets:{}},{title:"Cluster Configuration",frontmatter:{layout:"default",title:"Cluster Configuration",permalink:"/docs/operation-guide/setup",readingShow:"top"},regularPath:"/docs/07-operation-guide/01-setup.html",relativePath:"docs/07-operation-guide/01-setup.md",key:"v-6be5daf6",path:"/docs/operation-guide/setup/",headers:[{level:2,title:"Static configuration",slug:"static-configuration",normalizedTitle:"static configuration",charIndex:818},{level:3,title:"Configuration Directory and Files",slug:"configuration-directory-and-files",normalizedTitle:"configuration directory and files",charIndex:843},{level:3,title:"Understand the basic static configuration",slug:"understand-the-basic-static-configuration",normalizedTitle:"understand the basic static configuration",charIndex:2745},{level:3,title:"The full list of static configuration",slug:"the-full-list-of-static-configuration",normalizedTitle:"the full list of static configuration",charIndex:17568},{level:2,title:"Dynamic Configuration",slug:"dynamic-configuration",normalizedTitle:"dynamic configuration",charIndex:234},{level:3,title:"How to update Dynamic Configuration",slug:"how-to-update-dynamic-configuration",normalizedTitle:"how to update dynamic configuration",charIndex:21945},{level:2,title:"Other Advanced Features",slug:"other-advanced-features",normalizedTitle:"other advanced features",charIndex:25391},{level:2,title:"Deployment & Release",slug:"deployment-release",normalizedTitle:"deployment &amp; release",charIndex:null},{level:2,title:"Stress/Bench Test a cluster",slug:"stress-bench-test-a-cluster",normalizedTitle:"stress/bench test a cluster",charIndex:26347}],codeSwitcherOptions:{},headersStr:"Static configuration Configuration Directory and Files Understand the basic static configuration The full list of static configuration Dynamic Configuration How to update Dynamic Configuration Other Advanced Features Deployment & Release Stress/Bench Test a cluster",content:'# Cluster Configuration\n\nThis section will help to understand what you need for setting up a Cadence cluster.\n\nYou should understand some basic static configuration of Cadence cluster.\n\nThere are also many other configuration called "Dynamic Configuration" for fine tuning the cluster. The default values are good to go for small clusters.\n\nCadence’s minimum dependency is a database(Cassandra or SQL based like MySQL/Postgres). Cadence uses it for persistence. All instances of Cadence clusters are stateless.\n\nFor production you also need a metric server(Prometheus/Statsd/M3/etc).\n\nFor advanced features Cadence depends on others like Elastisearch/OpenSearch+Kafka if you need Advanced visibility feature to search workflows. Cadence will depends on a blob store like S3 if you need to enable archival feature.\n\n\n# Static configuration\n\n\n# Configuration Directory and Files\n\nThe default directory for configuration files is named config/. This directory contains various configuration files, but not all files will necessarily be used in every scenario.\n\n# Combining Configuration Files\n\n * Base Configuration: The base.yaml file is always loaded first, providing a common configuration that applies to all environments.\n * Runtime Environment File: The second file to be loaded is specific to the runtime environment. The environment name can be specified through the $CADENCE_ENVIRONMENT environment variable or passed as a command-line argument. If neither option is specified, development.yaml is used by default.\n * Availability Zone File: If an availability zone is specified (either through the $CADENCE_AVAILABILITY_ZONE environment variable or as a command-line argument), a file named after the zone will be merged. For example, if you specify "az1" as the zone, production_az1.yaml will be used as well.\n\nTo merge base.yaml, production.yaml, and production_az1.yaml files, you need to specify "production" as the runtime environment and "az1" as the zone.\n\n// base.yaml -> production.yaml -> production_az1.yaml = final configuration\n\n\n# Using Environment Variables\n\nConfiguration values can be provided using environment variables with a specific syntax. $VAR: This notation will be replaced with the value of the specified environment variable. If the environment variable is not set, the value will be left blank. You can declare a default value using the syntax {$VAR:default}. This means that if the environment variable VAR is not set, the default value will be used instead.\n\nNote: If you want to include the $ symbol literally in your configuration file (without interpreting it as an environment variable substitution), escape it by using $$. This will prevent it from being replaced by an environment variable value.\n\n\n# Understand the basic static configuration\n\nThere are quite many configs in Cadence. Here are the most basic configuration that you should understand.\n\nCONFIG NAME                                               EXPLANATION                                                    RECOMMENDED VALUE\nnumHistoryShards                                          This is the most important one in Cadence config.It will be    1K~16K depending on the size ranges of the cluster you\n                                                          a fixed number in the cluster forever. The only way to         expect to run, and the instance size. Typically 2K for SQL\n                                                          change it is to migrate to another cluster. Refer to Migrate   based persistence, and 8K for Cassandra based.\n                                                          cluster section.\n                                                          \n                                                          Some facts about it:\n                                                          1. Each workflow will be mapped to a single shard. Within a\n                                                          shard, all the workflow creation/updates are serialized.\n                                                          2. Each shard will be assigned to only one History node to\n                                                          own the shard, using a Consistent Hashing Ring. Each shard\n                                                          will consume a small amount of memory/CPU to do background\n                                                          processing. Therefore, a single History node cannot own too\n                                                          many shards. You may need to figure out a good number range\n                                                          based on your instance size(memory/CPU).\n                                                          3. Also, you can’t add an infinite number of nodes to a\n                                                          cluster because this config is fixed. When the number of\n                                                          History nodes is closed or equal to numHistoryShards, there\n                                                          will be some History nodes that have no shards assigned to\n                                                          it. This will be wasting resources.\n                                                          \n                                                          Based on above, you don’t want to have a small number of\n                                                          shards which will limit the maximum size of your cluster.\n                                                          You also don’t want to have a too big number, which will\n                                                          require you to have a quite big initial size of the cluster.\n                                                          Also, typically a production cluster will start with a\n                                                          smaller number and then we add more nodes/hosts to it. But\n                                                          to keep high availability, it’s recommended to use at least\n                                                          4 nodes for each service(Frontend/History/Matching) at the\n                                                          beginning.\nringpop                                                   This is the config to let all nodes of all services            For dns mode: Recommended to put the DNS of Frontend service\n                                                          connected to each other. ALL the bootstrap nodes MUST be       \n                                                          reachable by ringpop when a service is starting up, within a   For hosts or hostfile mode: A list of Frontend service node\n                                                          MaxJoinDuration. defaultMaxJoinDuration is 2 minutes.          addresses if using hosts mode. Make sure all the bootstrap\n                                                                                                                         nodes are reachable at startup.\n                                                          It’s not required that bootstrap nodes need to be\n                                                          Frontend/History or Matching. In fact, it can be running\n                                                          none of them as long as it runs Ringpop protocol.\npublicClient                                              The Cadence Frontend service addresses that internal Cadence   Recommended be DNS of Frontend service, so that requests\n                                                          system(like system workflows) need to talk to.                 will be distributed to all Frontend nodes.\n                                                                                                                         \n                                                          After connected, all nodes in Ringpop will form a ring with    Using localhost+Port or local container IP address+Port will\n                                                          identifiers of what service they serve. Ideally Cadence        not work if the IP/container is not running frontend\n                                                          should be able to get Frontend address from there. But\n                                                          Ringpop doesn’t expose this API yet.\nservices.NAME.rpc                                         Configuration of how to listen to network ports and serve      Name: Use as recommended in development.yaml. bindOnIP : an\n                                                          traffic.                                                       IP address that the container will serve the traffic with\n                                                          \n                                                          bindOnLocalHost:true will bind on 127.0.0.1. It’s mostly for\n                                                          local development. In production usually you have to specify\n                                                          the IP that containers will use by using bindOnIP\n                                                          \n                                                          NAME is the matter for the “--services” option in the server\n                                                          startup command.\nservices.NAME.pprof                                       Golang profiling service , will bind on the same IP as RPC     a port that you want to serve pprof request\nservices.Name.metrics                                     See Metrics&Logging section                                    cc\nclusterMetadata                                           Cadence cluster configuration.                                 As explanation.\n                                                          \n                                                          enableGlobalDomain：true will enable Cadence Cross datacenter\n                                                          replication(aka XDC) feature.\n                                                          \n                                                          failoverVersionIncrement: This decides the maximum clusters\n                                                          that you will have replicated to each other at the same\n                                                          time. For example 10 is sufficient for most cases.\n                                                          \n                                                          masterClusterName: a master cluster must be one of the\n                                                          enabled clusters, usually the very first cluster to start.\n                                                          It is only meaningful for internal purposes.\n                                                          \n                                                          currentClusterName: current cluster name using this config\n                                                          file.\n                                                          \n                                                          clusterInformation is a map from clusterName to the cluster\n                                                          configure\n                                                          \n                                                          initialFailoverVersion: each cluster must use a different\n                                                          value from 0 to failoverVersionIncrement-1.\n                                                          \n                                                          rpcName: must be “cadence-frontend”. Can be improved in this\n                                                          issue.\n                                                          \n                                                          rpcAddress: the address to talk to the Frontend of the\n                                                          cluster for inter-cluster replication.\n                                                          \n                                                          Note that even if you don’t need XDC replication right now,\n                                                          if you want to migrate data stores in the future, you should\n                                                          enable xdc from every beginning. You just need to use the\n                                                          same name of cluster for both masterClusterName and\n                                                          currentClusterName.\n                                                          \n                                                          Go to cross dc replication for how to configure replication\n                                                          in production\ndcRedirectionPolicy                                       For allowing forwarding frontend requests from passive         “selected-apis-forwarding”\n                                                          cluster to active clusters.\narchival                                                  This is for archival history feature, skip if you don’t need   N/A\n                                                          it. Go to workflow archival for how to configure archival in\n                                                          production\nblobstore                                                 This is also for archival history feature Default cadence      N/A\n                                                          server is using file based blob store implementation.\ndomainDefaults                                            default config for each domain. Right now only being used      N/A\n                                                          for Archival feature.\ndynamicconfig (previously known as dynamicConfigClient)   Dynamic config is a config manager that enables you to         Same as the sample development config\n                                                          change configs without restarting servers. It’s a good way\n                                                          for Cadence to keep high availability and make things easy\n                                                          to configure.\n                                                          \n                                                          By default Cadence server uses filebased client which allows\n                                                          you to override default configs using a YAML file. However,\n                                                          this approach can be cumbersome in production environment\n                                                          because it\'s the operator\'s responsibility to sync the YAML\n                                                          files across Cadence nodes.\n                                                          \n                                                          Therefore, we provide another option, configstore client,\n                                                          that stores config changes in the persistent data store for\n                                                          Cadence (e.g., Cassandra database) rather than the YAML\n                                                          file. This approach shifts the responsibility of syncing\n                                                          config changes from the operator to Cadence service. You can\n                                                          use Cadence CLI commands to list/get/update/restore config\n                                                          changes.\n                                                          \n                                                          You can also implement the dynamic config interface if you\n                                                          have a better way to manage configs.\npersistence                                               Configuration for data store / persistence layer.              As explanation\n                                                          \n                                                          Values of DefaultStore VisibilityStore\n                                                          AdvancedVisibilityStore should be keys of map DataStores.\n                                                          \n                                                          DefaultStore is for core Cadence functionality.\n                                                          \n                                                          VisibilityStore is for basic visibility feature\n                                                          \n                                                          AdvancedVisibilityStore is for advanced visibility\n                                                          \n                                                          Go to advanced visibility for detailed configuration of\n                                                          advanced visibility. See persistence documentation about\n                                                          using different database for Cadence\n\n\n# The full list of static configuration\n\nStarting from v0.21.0, all the static configuration are defined by GoDocs in details.\n\nVERSION                    GODOCS LINK                                    GITHUB LINK\nv0.21.0                    Configuration Docs                             Configuration\n...other higher versions   ...Replace the version in the URL of v0.21.0   ...Replace the version in the URL of v0.21.0\n\nFor earlier versions, you can find all the configurations similarly:\n\nVERSION                   GODOCS LINK                                    GITHUB LINK\nv0.20.0                   Configuration Docs                             Configuration\nv0.19.2                   Configuration Docs                             Configuration\nv0.18.2                   Configuration Docs                             Configuration\nv0.17.0                   Configuration Docs                             Configuration\n...other lower versions   ...Replace the version in the URL of v0.20.0   ...Replace the version in the URL of v0.20.0\n\n\n# Dynamic Configuration\n\nDynamic configuration is for fine tuning a Cadence cluster.\n\nThere are a lot more dynamic configurations than static configurations. Most of the default values are good for small clusters. As a cluster is scaled up, you may look for tuning it for the optimal performance.\n\nStarting from v0.21.0 with this change, all the dynamic configuration are well defined by GoDocs.\n\nVERSION                    GODOCS LINK                                    GITHUB LINK\nv0.21.0                    Dynamic Configuration Docs                     Dynamic Configuration\n...other higher versions   ...Replace the version in the URL of v0.21.0   ...Replace the version in the URL of v0.21.0\n\nFor earlier versions, you can find all the configurations similarly:\n\nVERSION                   GODOCS LINK                                    GITHUB LINK\nv0.20.0                   Dynamic Configuration Docs                     Dynamic Configuration\nv0.19.2                   Dynamic Configuration Docs                     Dynamic Configuration\nv0.18.2                   Dynamic Configuration Docs                     Dynamic Configuration\nv0.17.0                   Dynamic Configuration Docs                     Dynamic Configuration\n...other lower versions   ...Replace the version in the URL of v0.20.0   ...Replace the version in the URL of v0.20.0\n\nHowever, the GoDocs in earlier versions don\'t contain detailed information. You need to look it up the newer version of GoDocs.\nFor example, search for "EnableGlobalDomain" in Dynamic Configuration Comments in v0.21.0 or Docs of v0.21.0, as the usage of DynamicConfiguration never changes.\n\n * KeyName is the key that you will use in the dynamicconfig yaml content\n * Default value is the default value\n * Value type indicates the type that you should change the yaml value of:\n   * Int should be integer like 123\n   * Float should be number like 123.4\n   * Duration should be Golang duration like: 10s, 2m, 5h for 10 seconds, 2 minutes and 5 hours.\n   * Bool should be true or false\n   * Map should be map of yaml\n * Allowed filters indicates what kinds of filters you can set as constraints with the dynamic configuration.\n   * DomainName can be used with domainName\n   * N/A means no filters can be set. The config will be global.\n\nFor example, if you want to change the ratelimiting for List API, below is the config:\n\n// FrontendVisibilityListMaxQPS is max qps frontend can list open/close workflows\n// KeyName: frontend.visibilityListMaxQPS\n// Value type: Int\n// Default value: 10\n// Allowed filters: DomainName\nFrontendVisibilityListMaxQPS\n\n\nThen you can add the config like:\n\nfrontend.visibilityListMaxQPS:\n  - value: 1000\n  constraints:\n    domainName: "domainA"\n  - value: 2000\n  constraints:\n    domainName: "domainB"      \n\n\nYou will expect to see domainA will be able to perform 1K List operation per second, while domainB can perform 2K per second.\n\nNOTE 1: the size related configuration numbers are based on byte.\n\nNOTE 2: for <frontend,history,matching>.persistenceMaxQPS versus <frontend,history,matching>.persistenceGlobalMaxQPS --- persistenceMaxQPS is local for single node while persistenceGlobalMaxQPS is global for all node. persistenceGlobalMaxQPS is preferred if set as greater than zero. But by default it is zero so persistenceMaxQPS is being used.\n\n\n# How to update Dynamic Configuration\n\n# File-based client\n\nBy default, Cadence uses file-based client to manage dynamic configurations. Following are the approaches to changing dynamic configs using a yaml file.\n\n * Local docker-compose by mounting volume: 1. Change the dynamic configs in cadence/config/dynamicconfig/development.yaml. 2. Update the cadence section in the docker compose file and mount dynamicconfig folder to host machine like the following:\n\ncadence:\n  image: ubercadence/server:master-auto-setup\n  ports:\n    ...(don\'t change anything here)\n  environment:\n    ...(don\'t change anything here)\n    - "DYNAMIC_CONFIG_FILE_PATH=/etc/custom-dynamicconfig/development.yaml"\n  volumes:\n    - "/Users/<?>/cadence/config/dynamicconfig:/etc/custom-dynamicconfig"\n\n\n * Local docker-compose by logging into the container: run docker exec -it docker_cadence_1 /bin/bash to login your container. Then vi config/dynamicconfig/development.yaml to make any change. After you changed the config, use docker restart docker_cadence_1 to restart the cadence instance. Note that you can also use this approach to change static config, but it must be changed through config/config_template.yaml instead of config/docker.yaml because config/docker.yaml is generated on startup.\n\n * In production cluster: Follow this example of Helm Chart to deploy Cadence, update dynamic config here and restart the cluster.\n\n * DEBUG: How to make sure your updates on dynamicconfig is loaded? for example, if you added the following to development.yaml\n\nfrontend.visibilityListMaxQPS:\n  - value: 10000\n\n\nAfter restarting Cadence instances, execute a command like this to let Cadence load the config(it\'s lazy loading when using it). cadence --domain <> workflow list\n\nThen you should see the logs like below\n\ncadence_1        | {"level":"info","ts":"2021-05-07T18:43:07.869Z","msg":"First loading dynamic config","service":"cadence-frontend","key":"frontend.visibilityListMaxQPS,domainName:sample,clusterName:primary","value":"10000","default-value":"10","logging-call-at":"config.go:93"}\n\n\n# Config store client\n\nYou can set the dynamicconfig client in the static configuration to configstore in order to store config changes in a database, as shown below.\n\ndynamicconfig:\n  client: configstore\n  configstore:\n    pollInterval: "10s"\n    updateRetryAttempts: 2\n    FetchTimeout: "2s"\n    UpdateTimeout: "2s"\n\n\nIf you are still using the deprecated config dynamicConfigClient like below, you need to replace it with the new dynamicconfig as shown above to use configstore client.\n\ndynamicConfigClient:\n  filepath: "/etc/cadence/config/dynamicconfig/config.yaml"\n  pollInterval: "10s"\n\n\nAfter changing the client to configstore and restarting Cadence, you can manage dynamic configs using cadence admin config CLI commands. You may need to set your custom dynamic configs again as the previous configs are not automatically migrated from the YAML file to the database.\n\n * cadence admin config listdc lists all dynamic config overrides\n * cadence admin config getdc --dynamic_config_name <dynamic config keyname> gets the value of a specific dynamic config\n * cadence admin config updc --dynamic_config_name <dynamic config keyname> --dynamic_config_value \'{"Value": <new value>}\' updates the value of a specific dynamic config\n * cadence admin config resdc --dynamic_config_name <dynamic config keyname> restores a specific dynamic config to its default value\n\n\n# Other Advanced Features\n\n * Go to advanced visibility for how to configure advanced visibility in production.\n\n * Go to workflow archival for how to configure archival in production.\n\n * Go to cross dc replication for how to configure replication in production.\n\n\n# Deployment & Release\n\nKubernetes is the most popular way to deploy Cadence cluster. And easiest way is to use Cadence Helm Charts that maintained by a community project.\n\nIf you are looking for deploying Cadence using other technologies, then it\'s reccomended to use Cadence docker images. You can use offical ones, or you may customize it based on what you need. See Cadence docker package for how to run the images.\n\nIt\'s always recommended to use the latest release. See Cadence release pages.\n\nPlease subscribe the release of project by :\n\nGo to https://github.com/uber/cadence -> Click the right top "Watch" button -> Custom -> "Release".\n\nAnd see how to upgrade a Cadence cluster\n\n\n# Stress/Bench Test a cluster\n\nIt\'s recommended to run bench test on your cluster following this package to see the maximum throughput that it can take, whenever you change some setup.',normalizedContent:'# cluster configuration\n\nthis section will help to understand what you need for setting up a cadence cluster.\n\nyou should understand some basic static configuration of cadence cluster.\n\nthere are also many other configuration called "dynamic configuration" for fine tuning the cluster. the default values are good to go for small clusters.\n\ncadence’s minimum dependency is a database(cassandra or sql based like mysql/postgres). cadence uses it for persistence. all instances of cadence clusters are stateless.\n\nfor production you also need a metric server(prometheus/statsd/m3/etc).\n\nfor advanced features cadence depends on others like elastisearch/opensearch+kafka if you need advanced visibility feature to search workflows. cadence will depends on a blob store like s3 if you need to enable archival feature.\n\n\n# static configuration\n\n\n# configuration directory and files\n\nthe default directory for configuration files is named config/. this directory contains various configuration files, but not all files will necessarily be used in every scenario.\n\n# combining configuration files\n\n * base configuration: the base.yaml file is always loaded first, providing a common configuration that applies to all environments.\n * runtime environment file: the second file to be loaded is specific to the runtime environment. the environment name can be specified through the $cadence_environment environment variable or passed as a command-line argument. if neither option is specified, development.yaml is used by default.\n * availability zone file: if an availability zone is specified (either through the $cadence_availability_zone environment variable or as a command-line argument), a file named after the zone will be merged. for example, if you specify "az1" as the zone, production_az1.yaml will be used as well.\n\nto merge base.yaml, production.yaml, and production_az1.yaml files, you need to specify "production" as the runtime environment and "az1" as the zone.\n\n// base.yaml -> production.yaml -> production_az1.yaml = final configuration\n\n\n# using environment variables\n\nconfiguration values can be provided using environment variables with a specific syntax. $var: this notation will be replaced with the value of the specified environment variable. if the environment variable is not set, the value will be left blank. you can declare a default value using the syntax {$var:default}. this means that if the environment variable var is not set, the default value will be used instead.\n\nnote: if you want to include the $ symbol literally in your configuration file (without interpreting it as an environment variable substitution), escape it by using $$. this will prevent it from being replaced by an environment variable value.\n\n\n# understand the basic static configuration\n\nthere are quite many configs in cadence. here are the most basic configuration that you should understand.\n\nconfig name                                               explanation                                                    recommended value\nnumhistoryshards                                          this is the most important one in cadence config.it will be    1k~16k depending on the size ranges of the cluster you\n                                                          a fixed number in the cluster forever. the only way to         expect to run, and the instance size. typically 2k for sql\n                                                          change it is to migrate to another cluster. refer to migrate   based persistence, and 8k for cassandra based.\n                                                          cluster section.\n                                                          \n                                                          some facts about it:\n                                                          1. each workflow will be mapped to a single shard. within a\n                                                          shard, all the workflow creation/updates are serialized.\n                                                          2. each shard will be assigned to only one history node to\n                                                          own the shard, using a consistent hashing ring. each shard\n                                                          will consume a small amount of memory/cpu to do background\n                                                          processing. therefore, a single history node cannot own too\n                                                          many shards. you may need to figure out a good number range\n                                                          based on your instance size(memory/cpu).\n                                                          3. also, you can’t add an infinite number of nodes to a\n                                                          cluster because this config is fixed. when the number of\n                                                          history nodes is closed or equal to numhistoryshards, there\n                                                          will be some history nodes that have no shards assigned to\n                                                          it. this will be wasting resources.\n                                                          \n                                                          based on above, you don’t want to have a small number of\n                                                          shards which will limit the maximum size of your cluster.\n                                                          you also don’t want to have a too big number, which will\n                                                          require you to have a quite big initial size of the cluster.\n                                                          also, typically a production cluster will start with a\n                                                          smaller number and then we add more nodes/hosts to it. but\n                                                          to keep high availability, it’s recommended to use at least\n                                                          4 nodes for each service(frontend/history/matching) at the\n                                                          beginning.\nringpop                                                   this is the config to let all nodes of all services            for dns mode: recommended to put the dns of frontend service\n                                                          connected to each other. all the bootstrap nodes must be       \n                                                          reachable by ringpop when a service is starting up, within a   for hosts or hostfile mode: a list of frontend service node\n                                                          maxjoinduration. defaultmaxjoinduration is 2 minutes.          addresses if using hosts mode. make sure all the bootstrap\n                                                                                                                         nodes are reachable at startup.\n                                                          it’s not required that bootstrap nodes need to be\n                                                          frontend/history or matching. in fact, it can be running\n                                                          none of them as long as it runs ringpop protocol.\npublicclient                                              the cadence frontend service addresses that internal cadence   recommended be dns of frontend service, so that requests\n                                                          system(like system workflows) need to talk to.                 will be distributed to all frontend nodes.\n                                                                                                                         \n                                                          after connected, all nodes in ringpop will form a ring with    using localhost+port or local container ip address+port will\n                                                          identifiers of what service they serve. ideally cadence        not work if the ip/container is not running frontend\n                                                          should be able to get frontend address from there. but\n                                                          ringpop doesn’t expose this api yet.\nservices.name.rpc                                         configuration of how to listen to network ports and serve      name: use as recommended in development.yaml. bindonip : an\n                                                          traffic.                                                       ip address that the container will serve the traffic with\n                                                          \n                                                          bindonlocalhost:true will bind on 127.0.0.1. it’s mostly for\n                                                          local development. in production usually you have to specify\n                                                          the ip that containers will use by using bindonip\n                                                          \n                                                          name is the matter for the “--services” option in the server\n                                                          startup command.\nservices.name.pprof                                       golang profiling service , will bind on the same ip as rpc     a port that you want to serve pprof request\nservices.name.metrics                                     see metrics&logging section                                    cc\nclustermetadata                                           cadence cluster configuration.                                 as explanation.\n                                                          \n                                                          enableglobaldomain：true will enable cadence cross datacenter\n                                                          replication(aka xdc) feature.\n                                                          \n                                                          failoverversionincrement: this decides the maximum clusters\n                                                          that you will have replicated to each other at the same\n                                                          time. for example 10 is sufficient for most cases.\n                                                          \n                                                          masterclustername: a master cluster must be one of the\n                                                          enabled clusters, usually the very first cluster to start.\n                                                          it is only meaningful for internal purposes.\n                                                          \n                                                          currentclustername: current cluster name using this config\n                                                          file.\n                                                          \n                                                          clusterinformation is a map from clustername to the cluster\n                                                          configure\n                                                          \n                                                          initialfailoverversion: each cluster must use a different\n                                                          value from 0 to failoverversionincrement-1.\n                                                          \n                                                          rpcname: must be “cadence-frontend”. can be improved in this\n                                                          issue.\n                                                          \n                                                          rpcaddress: the address to talk to the frontend of the\n                                                          cluster for inter-cluster replication.\n                                                          \n                                                          note that even if you don’t need xdc replication right now,\n                                                          if you want to migrate data stores in the future, you should\n                                                          enable xdc from every beginning. you just need to use the\n                                                          same name of cluster for both masterclustername and\n                                                          currentclustername.\n                                                          \n                                                          go to cross dc replication for how to configure replication\n                                                          in production\ndcredirectionpolicy                                       for allowing forwarding frontend requests from passive         “selected-apis-forwarding”\n                                                          cluster to active clusters.\narchival                                                  this is for archival history feature, skip if you don’t need   n/a\n                                                          it. go to workflow archival for how to configure archival in\n                                                          production\nblobstore                                                 this is also for archival history feature default cadence      n/a\n                                                          server is using file based blob store implementation.\ndomaindefaults                                            default config for each domain. right now only being used      n/a\n                                                          for archival feature.\ndynamicconfig (previously known as dynamicconfigclient)   dynamic config is a config manager that enables you to         same as the sample development config\n                                                          change configs without restarting servers. it’s a good way\n                                                          for cadence to keep high availability and make things easy\n                                                          to configure.\n                                                          \n                                                          by default cadence server uses filebased client which allows\n                                                          you to override default configs using a yaml file. however,\n                                                          this approach can be cumbersome in production environment\n                                                          because it\'s the operator\'s responsibility to sync the yaml\n                                                          files across cadence nodes.\n                                                          \n                                                          therefore, we provide another option, configstore client,\n                                                          that stores config changes in the persistent data store for\n                                                          cadence (e.g., cassandra database) rather than the yaml\n                                                          file. this approach shifts the responsibility of syncing\n                                                          config changes from the operator to cadence service. you can\n                                                          use cadence cli commands to list/get/update/restore config\n                                                          changes.\n                                                          \n                                                          you can also implement the dynamic config interface if you\n                                                          have a better way to manage configs.\npersistence                                               configuration for data store / persistence layer.              as explanation\n                                                          \n                                                          values of defaultstore visibilitystore\n                                                          advancedvisibilitystore should be keys of map datastores.\n                                                          \n                                                          defaultstore is for core cadence functionality.\n                                                          \n                                                          visibilitystore is for basic visibility feature\n                                                          \n                                                          advancedvisibilitystore is for advanced visibility\n                                                          \n                                                          go to advanced visibility for detailed configuration of\n                                                          advanced visibility. see persistence documentation about\n                                                          using different database for cadence\n\n\n# the full list of static configuration\n\nstarting from v0.21.0, all the static configuration are defined by godocs in details.\n\nversion                    godocs link                                    github link\nv0.21.0                    configuration docs                             configuration\n...other higher versions   ...replace the version in the url of v0.21.0   ...replace the version in the url of v0.21.0\n\nfor earlier versions, you can find all the configurations similarly:\n\nversion                   godocs link                                    github link\nv0.20.0                   configuration docs                             configuration\nv0.19.2                   configuration docs                             configuration\nv0.18.2                   configuration docs                             configuration\nv0.17.0                   configuration docs                             configuration\n...other lower versions   ...replace the version in the url of v0.20.0   ...replace the version in the url of v0.20.0\n\n\n# dynamic configuration\n\ndynamic configuration is for fine tuning a cadence cluster.\n\nthere are a lot more dynamic configurations than static configurations. most of the default values are good for small clusters. as a cluster is scaled up, you may look for tuning it for the optimal performance.\n\nstarting from v0.21.0 with this change, all the dynamic configuration are well defined by godocs.\n\nversion                    godocs link                                    github link\nv0.21.0                    dynamic configuration docs                     dynamic configuration\n...other higher versions   ...replace the version in the url of v0.21.0   ...replace the version in the url of v0.21.0\n\nfor earlier versions, you can find all the configurations similarly:\n\nversion                   godocs link                                    github link\nv0.20.0                   dynamic configuration docs                     dynamic configuration\nv0.19.2                   dynamic configuration docs                     dynamic configuration\nv0.18.2                   dynamic configuration docs                     dynamic configuration\nv0.17.0                   dynamic configuration docs                     dynamic configuration\n...other lower versions   ...replace the version in the url of v0.20.0   ...replace the version in the url of v0.20.0\n\nhowever, the godocs in earlier versions don\'t contain detailed information. you need to look it up the newer version of godocs.\nfor example, search for "enableglobaldomain" in dynamic configuration comments in v0.21.0 or docs of v0.21.0, as the usage of dynamicconfiguration never changes.\n\n * keyname is the key that you will use in the dynamicconfig yaml content\n * default value is the default value\n * value type indicates the type that you should change the yaml value of:\n   * int should be integer like 123\n   * float should be number like 123.4\n   * duration should be golang duration like: 10s, 2m, 5h for 10 seconds, 2 minutes and 5 hours.\n   * bool should be true or false\n   * map should be map of yaml\n * allowed filters indicates what kinds of filters you can set as constraints with the dynamic configuration.\n   * domainname can be used with domainname\n   * n/a means no filters can be set. the config will be global.\n\nfor example, if you want to change the ratelimiting for list api, below is the config:\n\n// frontendvisibilitylistmaxqps is max qps frontend can list open/close workflows\n// keyname: frontend.visibilitylistmaxqps\n// value type: int\n// default value: 10\n// allowed filters: domainname\nfrontendvisibilitylistmaxqps\n\n\nthen you can add the config like:\n\nfrontend.visibilitylistmaxqps:\n  - value: 1000\n  constraints:\n    domainname: "domaina"\n  - value: 2000\n  constraints:\n    domainname: "domainb"      \n\n\nyou will expect to see domaina will be able to perform 1k list operation per second, while domainb can perform 2k per second.\n\nnote 1: the size related configuration numbers are based on byte.\n\nnote 2: for <frontend,history,matching>.persistencemaxqps versus <frontend,history,matching>.persistenceglobalmaxqps --- persistencemaxqps is local for single node while persistenceglobalmaxqps is global for all node. persistenceglobalmaxqps is preferred if set as greater than zero. but by default it is zero so persistencemaxqps is being used.\n\n\n# how to update dynamic configuration\n\n# file-based client\n\nby default, cadence uses file-based client to manage dynamic configurations. following are the approaches to changing dynamic configs using a yaml file.\n\n * local docker-compose by mounting volume: 1. change the dynamic configs in cadence/config/dynamicconfig/development.yaml. 2. update the cadence section in the docker compose file and mount dynamicconfig folder to host machine like the following:\n\ncadence:\n  image: ubercadence/server:master-auto-setup\n  ports:\n    ...(don\'t change anything here)\n  environment:\n    ...(don\'t change anything here)\n    - "dynamic_config_file_path=/etc/custom-dynamicconfig/development.yaml"\n  volumes:\n    - "/users/<?>/cadence/config/dynamicconfig:/etc/custom-dynamicconfig"\n\n\n * local docker-compose by logging into the container: run docker exec -it docker_cadence_1 /bin/bash to login your container. then vi config/dynamicconfig/development.yaml to make any change. after you changed the config, use docker restart docker_cadence_1 to restart the cadence instance. note that you can also use this approach to change static config, but it must be changed through config/config_template.yaml instead of config/docker.yaml because config/docker.yaml is generated on startup.\n\n * in production cluster: follow this example of helm chart to deploy cadence, update dynamic config here and restart the cluster.\n\n * debug: how to make sure your updates on dynamicconfig is loaded? for example, if you added the following to development.yaml\n\nfrontend.visibilitylistmaxqps:\n  - value: 10000\n\n\nafter restarting cadence instances, execute a command like this to let cadence load the config(it\'s lazy loading when using it). cadence --domain <> workflow list\n\nthen you should see the logs like below\n\ncadence_1        | {"level":"info","ts":"2021-05-07t18:43:07.869z","msg":"first loading dynamic config","service":"cadence-frontend","key":"frontend.visibilitylistmaxqps,domainname:sample,clustername:primary","value":"10000","default-value":"10","logging-call-at":"config.go:93"}\n\n\n# config store client\n\nyou can set the dynamicconfig client in the static configuration to configstore in order to store config changes in a database, as shown below.\n\ndynamicconfig:\n  client: configstore\n  configstore:\n    pollinterval: "10s"\n    updateretryattempts: 2\n    fetchtimeout: "2s"\n    updatetimeout: "2s"\n\n\nif you are still using the deprecated config dynamicconfigclient like below, you need to replace it with the new dynamicconfig as shown above to use configstore client.\n\ndynamicconfigclient:\n  filepath: "/etc/cadence/config/dynamicconfig/config.yaml"\n  pollinterval: "10s"\n\n\nafter changing the client to configstore and restarting cadence, you can manage dynamic configs using cadence admin config cli commands. you may need to set your custom dynamic configs again as the previous configs are not automatically migrated from the yaml file to the database.\n\n * cadence admin config listdc lists all dynamic config overrides\n * cadence admin config getdc --dynamic_config_name <dynamic config keyname> gets the value of a specific dynamic config\n * cadence admin config updc --dynamic_config_name <dynamic config keyname> --dynamic_config_value \'{"value": <new value>}\' updates the value of a specific dynamic config\n * cadence admin config resdc --dynamic_config_name <dynamic config keyname> restores a specific dynamic config to its default value\n\n\n# other advanced features\n\n * go to advanced visibility for how to configure advanced visibility in production.\n\n * go to workflow archival for how to configure archival in production.\n\n * go to cross dc replication for how to configure replication in production.\n\n\n# deployment & release\n\nkubernetes is the most popular way to deploy cadence cluster. and easiest way is to use cadence helm charts that maintained by a community project.\n\nif you are looking for deploying cadence using other technologies, then it\'s reccomended to use cadence docker images. you can use offical ones, or you may customize it based on what you need. see cadence docker package for how to run the images.\n\nit\'s always recommended to use the latest release. see cadence release pages.\n\nplease subscribe the release of project by :\n\ngo to https://github.com/uber/cadence -> click the right top "watch" button -> custom -> "release".\n\nand see how to upgrade a cadence cluster\n\n\n# stress/bench test a cluster\n\nit\'s recommended to run bench test on your cluster following this package to see the maximum throughput that it can take, whenever you change some setup.',charsets:{cjk:!0}},{title:"Cluster Maintenance",frontmatter:{layout:"default",title:"Cluster Maintenance",permalink:"/docs/operation-guide/maintain",readingShow:"top"},regularPath:"/docs/07-operation-guide/02-maintain.html",relativePath:"docs/07-operation-guide/02-maintain.md",key:"v-c3677d3c",path:"/docs/operation-guide/maintain/",headers:[{level:2,title:"Scale up & down Cluster",slug:"scale-up-down-cluster",normalizedTitle:"scale up &amp; down cluster",charIndex:null},{level:2,title:"Scale up a tasklist using Scalable tasklist feature",slug:"scale-up-a-tasklist-using-scalable-tasklist-feature",normalizedTitle:"scale up a tasklist using scalable tasklist feature",charIndex:674},{level:2,title:"Restarting Cluster",slug:"restarting-cluster",normalizedTitle:"restarting cluster",charIndex:2978},{level:2,title:"Optimize SQL Persistence",slug:"optimize-sql-persistence",normalizedTitle:"optimize sql persistence",charIndex:3055},{level:2,title:"Upgrading Server",slug:"upgrading-server",normalizedTitle:"upgrading server",charIndex:4289},{level:3,title:"How to upgrade:",slug:"how-to-upgrade",normalizedTitle:"how to upgrade:",charIndex:5029},{level:3,title:"How to apply DB schema changes",slug:"how-to-apply-db-schema-changes",normalizedTitle:"how to apply db schema changes",charIndex:6295}],codeSwitcherOptions:{},headersStr:"Scale up & down Cluster Scale up a tasklist using Scalable tasklist feature Restarting Cluster Optimize SQL Persistence Upgrading Server How to upgrade: How to apply DB schema changes",content:'# Cluster Maintenance\n\nThis includes how to use and maintain a Cadence cluster for both clients and server clusters.\n\n\n# Scale up & down Cluster\n\n * When CPU/Memory is getting bottleneck on Cadence instances, you may scale up or add more instances.\n * Watch Cadence metrics\n   * See if the external traffic to frontend is normal\n   * If the slowness is due to too many tasks on a tasklist, you may need to scale up the tasklist\n   * If persistence latency is getting too high, try scale up your DB instance\n * Never change the numOfShards of a cluster. If you need that because the current one is too small, follow the instructions to migrate your cluster to a new one.\n\n\n# Scale up a tasklist using Scalable tasklist feature\n\nBy default a tasklist is not scalable enough to support hundreds of tasks per second. That’s mainly because each tasklist is assigned to a Matching service node, and dispatching tasks in a tasklist is in sequence.\n\nIn the past, Cadence recommended using multiple tasklists to start workflow/activity. You need to make a list of tasklists and randomly pick one when starting workflows. And then when starting workers, let them listen to all the tasklists.\n\nNowadays, Cadence has a feature called “Scalable tasklist”. It will divide a tasklist into multiple logical partitions, which can distribute tasks to multiple Matching service nodes. By default this feature is not enabled because there is some performance penalty on the server side, plus it’s not common that a tasklist needs to support more than hundreds tasks per second.\n\nYou must make a dynamic configuration change in Cadence server to use this feature:\n\nmatching.numTasklistWritePartitions\n\nand\n\nmatching.numTasklistReadPartitions\n\nmatching.numTasklistWritePartitions is the number of partitions when a Cadence server sends a task to the tasklist. matching.numTasklistReadPartitions is the number of partitions when your worker accepts a task from the tasklist.\n\nThere are a few things to know when using this feature:\n\n * Always make sure matching.numTasklistWritePartitions <= matching.numTasklistReadPartitions . Otherwise there may be some tasks that are sent to a tasklist partition but no poller(worker) will be able to pick up.\n * Because of above, when scaling down the number of partitions, you must decrease the WritePartitions first, to wait for a certain time to ensure that tasks are drained, and then decrease ReadPartitions.\n * Both domain names and taskListName should be specified in the dynamic config. An example of using this feature. See more details about dynamic config format using file based dynamic config.\n\nmatching.numTasklistWritePartitions:\n  - value: 10\n    constraints:\n      domainName: "samples-domain"\n      taskListName: "aScalableTasklistName"\nmatching.numTasklistReadPartitions:\n  - value: 10\n    constraints:\n      domainName: "samples-domain"\n      taskListName: "aScalableTasklistName"\n\n\nNOTE: the value must be integer without double quotes.\n\n\n# Restarting Cluster\n\nMake sure rolling restart to keep high availability.\n\n\n# Optimize SQL Persistence\n\n * Connection is shared within a Cadence server host\n * For each host, The max number of connections it will consume is maxConn of defaultStore + maxConn of visibilityStore.\n * The total max number of connections your Cadence cluster will consume is the summary from all hosts(from Frontend/Matching/History/SysWorker services)\n * Frontend and history nodes need both default and visibility Stores, but matching and sys workers only need default Stores, they don\'t need to talk to visibility DBs.\n * For default Stores, history service will take the most connection, then Frontend/Matching. SysWorker will use much less than others\n * Default Stores is for Cadence’ core data model, which requires strong consistency. So it cannot use replicas. VisibilityStore is not for core data models. It’s recommended to use a separate DB for visibility store if using DB based visibility.\n * Visibility Stores usually take much less connection as the workload is much lightweight(less QPS and no explicit transactions).\n * Visibility Stores require eventual consistency for read. So it can use replicas.\n * MaxIdelConns should be less than MaxConns, so that the connections can be distributed better across hosts.\n\n\n# Upgrading Server\n\nTo get notified about release, please subscribe the release of project by : Go to https://github.com/uber/cadence -> Click the right top "Watch" button -> Custom -> "Release".\n\nIt\'s recommended to upgrade one minor version at a time. E.g, if you are at 0.10, you should upgrade to 0.11, stabilize it with running some normal workload to make sure that the upgraded server is happy with the schema changes. After ~1 hour, then upgrade to 0.12. then 0.13. etc.\n\nThe reason is that for each minor upgrade, you should be able to follow the release notes about what you should do for upgrading. The release notes may require you to run some commands. This will also help to narrow down the cause when something goes wrong.\n\n\n# How to upgrade:\n\nThings that you may need to do for upgrading a minor version(patch version upgrades should not need it):\n\n * Schema(DB/ElasticSearch) changes\n * Configuration format/layout changes\n * Data migration -- this is very rare. For example, upgrading from 0.15.x to 0.16.0 requires a data migration.\n\nYou should read through the release instruction for each minor release to understand what needs to be done.\n\n * Schema changes need to be applied before upgrading server\n   * Upgrade MySQL/Postgres schema if applicable\n   * Upgrade Cassandra schema if applicable\n   * Upgrade ElasticSearch schema if applicable\n * Usually schema change is backward compatible. So rolling back usually is not a problem. It also means that Cadence allows running a mixed version of schema, as long as they are all greater than or equal to the required version of the server. Other requirements for upgrading should be found in the release notes. It may contain information about config changes, or special rollback instructions if normal rollback may cause problems.\n * Similarly, data migration should be done before upgrading the server binary.\n\nNOTE: Do not use “auto-setup” images to upgrade your schema. It\'s mainly for development. At most for initial setup only.\n\n\n# How to apply DB schema changes\n\nFor how to apply database schema, refer to this doc: SQL tool README Cassandra tool README\n\nThe tool makes use of a table called “schema_versions” to keep track of upgrading History. But there is no transaction guarantee for cross table operations. So in case of some error, you may need to fix or apply schema change manually. Also, the schema tool by default will upgrade schema to the latest, so no manual is required. ( you can also specify to let it upgrade to any place, like 0.14).\n\nDatabase schema changes are versioned in the folders: Versioned Schema Changes for Default Store and Versioned Schema Changes for Visibility Store if you use database for basic visibility instead of ElasticSearch.\n\nIf you use homebrew, the schema files are located at /usr/local/etc/cadence/schema/.\n\nAlternatively, you can checkout the repo and the release tag. E.g. git checkout v0.21.0 and then the schema files is at ./schema/',normalizedContent:'# cluster maintenance\n\nthis includes how to use and maintain a cadence cluster for both clients and server clusters.\n\n\n# scale up & down cluster\n\n * when cpu/memory is getting bottleneck on cadence instances, you may scale up or add more instances.\n * watch cadence metrics\n   * see if the external traffic to frontend is normal\n   * if the slowness is due to too many tasks on a tasklist, you may need to scale up the tasklist\n   * if persistence latency is getting too high, try scale up your db instance\n * never change the numofshards of a cluster. if you need that because the current one is too small, follow the instructions to migrate your cluster to a new one.\n\n\n# scale up a tasklist using scalable tasklist feature\n\nby default a tasklist is not scalable enough to support hundreds of tasks per second. that’s mainly because each tasklist is assigned to a matching service node, and dispatching tasks in a tasklist is in sequence.\n\nin the past, cadence recommended using multiple tasklists to start workflow/activity. you need to make a list of tasklists and randomly pick one when starting workflows. and then when starting workers, let them listen to all the tasklists.\n\nnowadays, cadence has a feature called “scalable tasklist”. it will divide a tasklist into multiple logical partitions, which can distribute tasks to multiple matching service nodes. by default this feature is not enabled because there is some performance penalty on the server side, plus it’s not common that a tasklist needs to support more than hundreds tasks per second.\n\nyou must make a dynamic configuration change in cadence server to use this feature:\n\nmatching.numtasklistwritepartitions\n\nand\n\nmatching.numtasklistreadpartitions\n\nmatching.numtasklistwritepartitions is the number of partitions when a cadence server sends a task to the tasklist. matching.numtasklistreadpartitions is the number of partitions when your worker accepts a task from the tasklist.\n\nthere are a few things to know when using this feature:\n\n * always make sure matching.numtasklistwritepartitions <= matching.numtasklistreadpartitions . otherwise there may be some tasks that are sent to a tasklist partition but no poller(worker) will be able to pick up.\n * because of above, when scaling down the number of partitions, you must decrease the writepartitions first, to wait for a certain time to ensure that tasks are drained, and then decrease readpartitions.\n * both domain names and tasklistname should be specified in the dynamic config. an example of using this feature. see more details about dynamic config format using file based dynamic config.\n\nmatching.numtasklistwritepartitions:\n  - value: 10\n    constraints:\n      domainname: "samples-domain"\n      tasklistname: "ascalabletasklistname"\nmatching.numtasklistreadpartitions:\n  - value: 10\n    constraints:\n      domainname: "samples-domain"\n      tasklistname: "ascalabletasklistname"\n\n\nnote: the value must be integer without double quotes.\n\n\n# restarting cluster\n\nmake sure rolling restart to keep high availability.\n\n\n# optimize sql persistence\n\n * connection is shared within a cadence server host\n * for each host, the max number of connections it will consume is maxconn of defaultstore + maxconn of visibilitystore.\n * the total max number of connections your cadence cluster will consume is the summary from all hosts(from frontend/matching/history/sysworker services)\n * frontend and history nodes need both default and visibility stores, but matching and sys workers only need default stores, they don\'t need to talk to visibility dbs.\n * for default stores, history service will take the most connection, then frontend/matching. sysworker will use much less than others\n * default stores is for cadence’ core data model, which requires strong consistency. so it cannot use replicas. visibilitystore is not for core data models. it’s recommended to use a separate db for visibility store if using db based visibility.\n * visibility stores usually take much less connection as the workload is much lightweight(less qps and no explicit transactions).\n * visibility stores require eventual consistency for read. so it can use replicas.\n * maxidelconns should be less than maxconns, so that the connections can be distributed better across hosts.\n\n\n# upgrading server\n\nto get notified about release, please subscribe the release of project by : go to https://github.com/uber/cadence -> click the right top "watch" button -> custom -> "release".\n\nit\'s recommended to upgrade one minor version at a time. e.g, if you are at 0.10, you should upgrade to 0.11, stabilize it with running some normal workload to make sure that the upgraded server is happy with the schema changes. after ~1 hour, then upgrade to 0.12. then 0.13. etc.\n\nthe reason is that for each minor upgrade, you should be able to follow the release notes about what you should do for upgrading. the release notes may require you to run some commands. this will also help to narrow down the cause when something goes wrong.\n\n\n# how to upgrade:\n\nthings that you may need to do for upgrading a minor version(patch version upgrades should not need it):\n\n * schema(db/elasticsearch) changes\n * configuration format/layout changes\n * data migration -- this is very rare. for example, upgrading from 0.15.x to 0.16.0 requires a data migration.\n\nyou should read through the release instruction for each minor release to understand what needs to be done.\n\n * schema changes need to be applied before upgrading server\n   * upgrade mysql/postgres schema if applicable\n   * upgrade cassandra schema if applicable\n   * upgrade elasticsearch schema if applicable\n * usually schema change is backward compatible. so rolling back usually is not a problem. it also means that cadence allows running a mixed version of schema, as long as they are all greater than or equal to the required version of the server. other requirements for upgrading should be found in the release notes. it may contain information about config changes, or special rollback instructions if normal rollback may cause problems.\n * similarly, data migration should be done before upgrading the server binary.\n\nnote: do not use “auto-setup” images to upgrade your schema. it\'s mainly for development. at most for initial setup only.\n\n\n# how to apply db schema changes\n\nfor how to apply database schema, refer to this doc: sql tool readme cassandra tool readme\n\nthe tool makes use of a table called “schema_versions” to keep track of upgrading history. but there is no transaction guarantee for cross table operations. so in case of some error, you may need to fix or apply schema change manually. also, the schema tool by default will upgrade schema to the latest, so no manual is required. ( you can also specify to let it upgrade to any place, like 0.14).\n\ndatabase schema changes are versioned in the folders: versioned schema changes for default store and versioned schema changes for visibility store if you use database for basic visibility instead of elasticsearch.\n\nif you use homebrew, the schema files are located at /usr/local/etc/cadence/schema/.\n\nalternatively, you can checkout the repo and the release tag. e.g. git checkout v0.21.0 and then the schema files is at ./schema/',charsets:{}},{title:"Cluster Monitoring",frontmatter:{layout:"default",title:"Cluster Monitoring",permalink:"/docs/operation-guide/monitor",readingShow:"top"},regularPath:"/docs/07-operation-guide/03-monitoring.html",relativePath:"docs/07-operation-guide/03-monitoring.md",key:"v-1a836dbc",path:"/docs/operation-guide/monitor/",headers:[{level:2,title:"Instructions",slug:"instructions",normalizedTitle:"instructions",charIndex:25},{level:2,title:"DataDog dashboard templates",slug:"datadog-dashboard-templates",normalizedTitle:"datadog dashboard templates",charIndex:2407},{level:2,title:"Grafana+Prometheus dashboard templates",slug:"grafana-prometheus-dashboard-templates",normalizedTitle:"grafana+prometheus dashboard templates",charIndex:3295},{level:2,title:"Periodic tests(Canary) for health check",slug:"periodic-tests-canary-for-health-check",normalizedTitle:"periodic tests(canary) for health check",charIndex:3981},{level:2,title:"Cadence Frontend Monitoring",slug:"cadence-frontend-monitoring",normalizedTitle:"cadence frontend monitoring",charIndex:4197},{level:3,title:"Service Availability(server metrics)",slug:"service-availability-server-metrics",normalizedTitle:"service availability(server metrics)",charIndex:4399},{level:3,title:"StartWorkflow Per Second",slug:"startworkflow-per-second",normalizedTitle:"startworkflow per second",charIndex:4917},{level:3,title:"Activities Started Per Second",slug:"activities-started-per-second",normalizedTitle:"activities started per second",charIndex:5291},{level:3,title:"Decisions Started Per Second",slug:"decisions-started-per-second",normalizedTitle:"decisions started per second",charIndex:5622},{level:3,title:"Periodical Test Suite Success(aka Canary)",slug:"periodical-test-suite-success-aka-canary",normalizedTitle:"periodical test suite success(aka canary)",charIndex:5960},{level:3,title:"Frontend all API per second",slug:"frontend-all-api-per-second",normalizedTitle:"frontend all api per second",charIndex:6306},{level:3,title:"Frontend API per second (breakdown per operation)",slug:"frontend-api-per-second-breakdown-per-operation",normalizedTitle:"frontend api per second (breakdown per operation)",charIndex:6553},{level:3,title:"Frontend API errors per second(breakdown per operation)",slug:"frontend-api-errors-per-second-breakdown-per-operation",normalizedTitle:"frontend api errors per second(breakdown per operation)",charIndex:6833},{level:3,title:"Frontend Regular API Latency",slug:"frontend-regular-api-latency",normalizedTitle:"frontend regular api latency",charIndex:9890},{level:3,title:"Frontend ListWorkflow API Latency",slug:"frontend-listworkflow-api-latency",normalizedTitle:"frontend listworkflow api latency",charIndex:10636},{level:3,title:"Frontend Long Poll API Latency",slug:"frontend-long-poll-api-latency",normalizedTitle:"frontend long poll api latency",charIndex:11243},{level:3,title:"Frontend Get History/Query Workflow API Latency",slug:"frontend-get-history-query-workflow-api-latency",normalizedTitle:"frontend get history/query workflow api latency",charIndex:11923},{level:3,title:"Frontend WorkflowClient API per seconds by domain",slug:"frontend-workflowclient-api-per-seconds-by-domain",normalizedTitle:"frontend workflowclient api per seconds by domain",charIndex:12700},{level:2,title:"Cadence Application Monitoring",slug:"cadence-application-monitoring",normalizedTitle:"cadence application monitoring",charIndex:13351},{level:3,title:"Workflow Start and Successful completion",slug:"workflow-start-and-successful-completion",normalizedTitle:"workflow start and successful completion",charIndex:13560},{level:3,title:"Workflow Failure",slug:"workflow-failure",normalizedTitle:"workflow failure",charIndex:14392},{level:3,title:"Decision Poll Counters",slug:"decision-poll-counters",normalizedTitle:"decision poll counters",charIndex:15449},{level:3,title:"DecisionTasks Scheduled per second",slug:"decisiontasks-scheduled-per-second",normalizedTitle:"decisiontasks scheduled per second",charIndex:16462},{level:3,title:"Decision Scheduled To Start Latency",slug:"decision-scheduled-to-start-latency",normalizedTitle:"decision scheduled to start latency",charIndex:16798},{level:3,title:"Decision Execution Failure",slug:"decision-execution-failure",normalizedTitle:"decision execution failure",charIndex:17930},{level:3,title:"Decision Execution Timeout",slug:"decision-execution-timeout",normalizedTitle:"decision execution timeout",charIndex:18452},{level:3,title:"Workflow End to End Latency",slug:"workflow-end-to-end-latency",normalizedTitle:"workflow end to end latency",charIndex:18962},{level:3,title:"Workflow Panic and NonDeterministicError",slug:"workflow-panic-and-nondeterministicerror",normalizedTitle:"workflow panic and nondeterministicerror",charIndex:19678},{level:3,title:"Workflow Sticky Cache Hit Rate and Miss Count",slug:"workflow-sticky-cache-hit-rate-and-miss-count",normalizedTitle:"workflow sticky cache hit rate and miss count",charIndex:20254},{level:3,title:"Activity Task Operations",slug:"activity-task-operations",normalizedTitle:"activity task operations",charIndex:21458},{level:3,title:"Local Activity Task Operations",slug:"local-activity-task-operations",normalizedTitle:"local activity task operations",charIndex:21873},{level:3,title:"Activity Execution Latency",slug:"activity-execution-latency",normalizedTitle:"activity execution latency",charIndex:22097},{level:3,title:"Activity Poll Counters",slug:"activity-poll-counters",normalizedTitle:"activity poll counters",charIndex:22715},{level:3,title:"ActivityTasks Scheduled per second",slug:"activitytasks-scheduled-per-second",normalizedTitle:"activitytasks scheduled per second",charIndex:23808},{level:3,title:"Activity Scheduled To Start Latency",slug:"activity-scheduled-to-start-latency",normalizedTitle:"activity scheduled to start latency",charIndex:24146},{level:3,title:"Activity Failure",slug:"activity-failure",normalizedTitle:"activity failure",charIndex:25061},{level:3,title:"Service API success rate",slug:"service-api-success-rate",normalizedTitle:"service api success rate",charIndex:26435},{level:3,title:"Service API Latency",slug:"service-api-latency",normalizedTitle:"service api latency",charIndex:27418},{level:3,title:"Service API Breakdown",slug:"service-api-breakdown",normalizedTitle:"service api breakdown",charIndex:27768},{level:3,title:"Service API Error Breakdown",slug:"service-api-error-breakdown",normalizedTitle:"service api error breakdown",charIndex:28087},{level:3,title:"Max Event Blob size",slug:"max-event-blob-size",normalizedTitle:"max event blob size",charIndex:28316},{level:3,title:"Max History Size",slug:"max-history-size",normalizedTitle:"max history size",charIndex:28917},{level:3,title:"Max History Length",slug:"max-history-length",normalizedTitle:"max history length",charIndex:29680},{level:2,title:"Cadence History Service Monitoring",slug:"cadence-history-service-monitoring",normalizedTitle:"cadence history service monitoring",charIndex:30220},{level:3,title:"History shard movements",slug:"history-shard-movements",normalizedTitle:"history shard movements",charIndex:30351},{level:3,title:"Transfer Tasks Per Second",slug:"transfer-tasks-per-second",normalizedTitle:"transfer tasks per second",charIndex:31134},{level:3,title:"Timer Tasks Per Second",slug:"timer-tasks-per-second",normalizedTitle:"timer tasks per second",charIndex:31491},{level:3,title:"Transfer Tasks Per Domain",slug:"transfer-tasks-per-domain",normalizedTitle:"transfer tasks per domain",charIndex:31844},{level:3,title:"Timer Tasks Per Domain",slug:"timer-tasks-per-domain",normalizedTitle:"timer tasks per domain",charIndex:32026},{level:3,title:"Transfer Latency by Type",slug:"transfer-latency-by-type",normalizedTitle:"transfer latency by type",charIndex:32202},{level:3,title:"Timer Task Latency by type",slug:"timer-task-latency-by-type",normalizedTitle:"timer task latency by type",charIndex:33084},{level:3,title:"NOTE: Task Queue Latency vs Executing Latency vs Processing Latency In Transfer & Timer Task Latency Metrics",slug:"note-task-queue-latency-vs-executing-latency-vs-processing-latency-in-transfer-timer-task-latency-metrics",normalizedTitle:"note: task queue latency vs executing latency vs processing latency in transfer &amp; timer task latency metrics",charIndex:null},{level:3,title:"Transfer Task Latency Per Domain",slug:"transfer-task-latency-per-domain",normalizedTitle:"transfer task latency per domain",charIndex:34475},{level:3,title:"Timer Task Latency Per Domain",slug:"timer-task-latency-per-domain",normalizedTitle:"timer task latency per domain",charIndex:34632},{level:3,title:"History API per Second",slug:"history-api-per-second",normalizedTitle:"history api per second",charIndex:34786},{level:3,title:"History API Errors per Second",slug:"history-api-errors-per-second",normalizedTitle:"history api errors per second",charIndex:34933},{level:3,title:"Max History Size",slug:"max-history-size-2",normalizedTitle:"max history size",charIndex:28917},{level:3,title:"Max History Length",slug:"max-history-length-2",normalizedTitle:"max history length",charIndex:29680},{level:3,title:"Max Event Blob Size",slug:"max-event-blob-size-2",normalizedTitle:"max event blob size",charIndex:38417},{level:2,title:"Cadence Matching Service Monitoring",slug:"cadence-matching-service-monitoring",normalizedTitle:"cadence matching service monitoring",charIndex:38816},{level:3,title:"Matching APIs per Second",slug:"matching-apis-per-second",normalizedTitle:"matching apis per second",charIndex:39200},{level:3,title:"Matching API Errors per Second",slug:"matching-api-errors-per-second",normalizedTitle:"matching api errors per second",charIndex:39392},{level:3,title:"Matching Regular API Latency",slug:"matching-regular-api-latency",normalizedTitle:"matching regular api latency",charIndex:43179},{level:3,title:"Sync Match Latency:",slug:"sync-match-latency",normalizedTitle:"sync match latency:",charIndex:43446},{level:3,title:"Async match Latency",slug:"async-match-latency",normalizedTitle:"async match latency",charIndex:43936},{level:2,title:"Cadence Default Persistence Monitoring",slug:"cadence-default-persistence-monitoring",normalizedTitle:"cadence default persistence monitoring",charIndex:44299},{level:3,title:"Persistence Availability",slug:"persistence-availability",normalizedTitle:"persistence availability",charIndex:44408},{level:3,title:"Persistence By Service TPS",slug:"persistence-by-service-tps",normalizedTitle:"persistence by service tps",charIndex:45440},{level:3,title:"Persistence By Operation TPS",slug:"persistence-by-operation-tps",normalizedTitle:"persistence by operation tps",charIndex:45738},{level:3,title:"Persistence By Operation Latency",slug:"persistence-by-operation-latency",normalizedTitle:"persistence by operation latency",charIndex:46098},{level:3,title:"Persistence Error By Operation Count",slug:"persistence-error-by-operation-count",normalizedTitle:"persistence error by operation count",charIndex:46759},{level:2,title:"Cadence Advanced Visibility Persistence Monitoring(if applicable)",slug:"cadence-advanced-visibility-persistence-monitoring-if-applicable",normalizedTitle:"cadence advanced visibility persistence monitoring(if applicable)",charIndex:50700},{level:3,title:"Persistence Availability",slug:"persistence-availability-2",normalizedTitle:"persistence availability",charIndex:44408},{level:3,title:"Persistence By Service TPS",slug:"persistence-by-service-tps-2",normalizedTitle:"persistence by service tps",charIndex:45440},{level:3,title:"Persistence By Operation TPS(read: ES, write: Kafka)",slug:"persistence-by-operation-tps-read-es-write-kafka",normalizedTitle:"persistence by operation tps(read: es, write: kafka)",charIndex:51861},{level:3,title:"Persistence By Operation Latency(in seconds) (read: ES, write: Kafka)",slug:"persistence-by-operation-latency-in-seconds-read-es-write-kafka",normalizedTitle:"persistence by operation latency(in seconds) (read: es, write: kafka)",charIndex:52153},{level:3,title:"Persistence Error By Operation Count (read: ES, write: Kafka)",slug:"persistence-error-by-operation-count-read-es-write-kafka",normalizedTitle:"persistence error by operation count (read: es, write: kafka)",charIndex:52474},{level:3,title:"Kafka->ES processor counter",slug:"kafka-es-processor-counter",normalizedTitle:"kafka-&gt;es processor counter",charIndex:null},{level:3,title:"Kafka->ES processor error",slug:"kafka-es-processor-error",normalizedTitle:"kafka-&gt;es processor error",charIndex:null},{level:3,title:"Kafka->ES processor latency",slug:"kafka-es-processor-latency",normalizedTitle:"kafka-&gt;es processor latency",charIndex:null},{level:2,title:"Cadence Dependency Metrics Monitor suggestion",slug:"cadence-dependency-metrics-monitor-suggestion",normalizedTitle:"cadence dependency metrics monitor suggestion",charIndex:54250},{level:3,title:"Computing platform metrics for Cadence deployment",slug:"computing-platform-metrics-for-cadence-deployment",normalizedTitle:"computing platform metrics for cadence deployment",charIndex:54300},{level:3,title:"Database",slug:"database",normalizedTitle:"database",charIndex:54488},{level:3,title:"Kafka (if applicable)",slug:"kafka-if-applicable",normalizedTitle:"kafka (if applicable)",charIndex:54651},{level:3,title:"ElasticSearch (if applicable)",slug:"elasticsearch-if-applicable",normalizedTitle:"elasticsearch (if applicable)",charIndex:54709},{level:2,title:"Cadence Service SLO Recommendation",slug:"cadence-service-slo-recommendation",normalizedTitle:"cadence service slo recommendation",charIndex:54775}],codeSwitcherOptions:{},headersStr:"Instructions DataDog dashboard templates Grafana+Prometheus dashboard templates Periodic tests(Canary) for health check Cadence Frontend Monitoring Service Availability(server metrics) StartWorkflow Per Second Activities Started Per Second Decisions Started Per Second Periodical Test Suite Success(aka Canary) Frontend all API per second Frontend API per second (breakdown per operation) Frontend API errors per second(breakdown per operation) Frontend Regular API Latency Frontend ListWorkflow API Latency Frontend Long Poll API Latency Frontend Get History/Query Workflow API Latency Frontend WorkflowClient API per seconds by domain Cadence Application Monitoring Workflow Start and Successful completion Workflow Failure Decision Poll Counters DecisionTasks Scheduled per second Decision Scheduled To Start Latency Decision Execution Failure Decision Execution Timeout Workflow End to End Latency Workflow Panic and NonDeterministicError Workflow Sticky Cache Hit Rate and Miss Count Activity Task Operations Local Activity Task Operations Activity Execution Latency Activity Poll Counters ActivityTasks Scheduled per second Activity Scheduled To Start Latency Activity Failure Service API success rate Service API Latency Service API Breakdown Service API Error Breakdown Max Event Blob size Max History Size Max History Length Cadence History Service Monitoring History shard movements Transfer Tasks Per Second Timer Tasks Per Second Transfer Tasks Per Domain Timer Tasks Per Domain Transfer Latency by Type Timer Task Latency by type NOTE: Task Queue Latency vs Executing Latency vs Processing Latency In Transfer & Timer Task Latency Metrics Transfer Task Latency Per Domain Timer Task Latency Per Domain History API per Second History API Errors per Second Max History Size Max History Length Max Event Blob Size Cadence Matching Service Monitoring Matching APIs per Second Matching API Errors per Second Matching Regular API Latency Sync Match Latency: Async match Latency Cadence Default Persistence Monitoring Persistence Availability Persistence By Service TPS Persistence By Operation TPS Persistence By Operation Latency Persistence Error By Operation Count Cadence Advanced Visibility Persistence Monitoring(if applicable) Persistence Availability Persistence By Service TPS Persistence By Operation TPS(read: ES, write: Kafka) Persistence By Operation Latency(in seconds) (read: ES, write: Kafka) Persistence Error By Operation Count (read: ES, write: Kafka) Kafka->ES processor counter Kafka->ES processor error Kafka->ES processor latency Cadence Dependency Metrics Monitor suggestion Computing platform metrics for Cadence deployment Database Kafka (if applicable) ElasticSearch (if applicable) Cadence Service SLO Recommendation",content:"# Cluster Monitoring\n\n\n# Instructions\n\nCadence emits metrics for both Server and client libraries:\n\n * Follow this example to emit client side metrics for Golang client\n   \n   * You can use other metrics emitter like M3\n   * Alternatively, you can implement the tally Reporter interface\n\n * Follow this example to emit client side metrics for Java client if using 3.x client, or this example if using 2.x client.\n   \n   * You can use other metrics emitter like M3\n   * Alternatively, you can implement the tally Reporter interface\n\n * For running Cadence services in production, please follow this example of hemlchart to emit server side metrics. Or you can follow the example of local environment to Prometheus. All services need to expose a HTTP port to provide metircs like below\n\nmetrics:\n  prometheus:\n    timerType: \"histogram\"\n    listenAddress: \"0.0.0.0:8001\"\n\n\nThe rest of the instruction uses local environment as an example.\n\nFor testing local server emitting metrics to Promethues, the easiest way is to use docker-compose to start a local Cadence instance.\n\nMake sure to update the prometheus_config.yml to add \"host.docker.internal:9098\" to the scrape list before starting the docker-compose:\n\nglobal:\n  scrape_interval: 5s\n  external_labels:\n    monitor: 'cadence-monitor'\nscrape_configs:\n  - job_name: 'prometheus'\n    static_configs:\n      - targets: # addresses to scrape\n          - 'cadence:9090'\n          - 'cadence:8000'\n          - 'cadence:8001'\n          - 'cadence:8002'\n          - 'cadence:8003'\n          - 'host.docker.internal:9098'\n\n\nNote: host.docker.internal may not work for some docker versions\n\n * After updating the prometheus_config.yaml as above, run docker-compose up to start the local Cadence instance\n\n * Go the the sample repo, build the helloworld sample make helloworld and run the worker ./bin/helloworld -m worker, and then in another Shell start a workflow ./bin/helloworld\n\n * Go to your local Prometheus dashboard, you should be able to check the metrics emitted by handler from client/frontend/matching/history/sysWorker and confirm your services are healthy through targets\n\n * Go to local Grafana , login as admin/admin.\n\n * Configure Prometheus as datasource: use http://host.docker.internal:9090 as URL of prometheus.\n\n * Import the Grafana dashboard tempalte as JSON files.\n\nClient side dashboard looks like this:\n\nAnd server basic dashboard:\n\n\n# DataDog dashboard templates\n\nThis package contains examples of Cadence dashboards with DataDog.\n\n * Cadence-Client is the dashboard that includes all the metrics to help you understand Cadence client behavior. Most of these metrics are emitted by the client SDKs, with a few exceptions from server side (for example, workflow timeout).\n\n * Cadence-Server is the the server dashboard that you can use to monitor and undertand the health and status of your Cadence cluster.\n\nTo use DataDog with Cadence, follow this instruction to collect Prometheus metrics using DataDog agent.\n\nNOTE1: don't forget to adjust max_returned_metrics to a higher number(e.g. 100000). Otherwise DataDog agent won't be able to collect all metrics(default is 2000).\n\nNOTE2: the template contains templating variables $App and $Availability_Zone. Feel free to remove them if you don't have them in your setup.\n\n\n# Grafana+Prometheus dashboard templates\n\nThis package contains examples of Cadence dashboards with Prometheus.\n\n * Cadence-Client is the dashboard of client metrics, and a few server side metrics that belong to client side but have to be emitted by server(for example, workflow timeout).\n\n * Cadence-Server-Basic is the the basic server dashboard to monitor/navigate the health/status of a Cadence cluster.\n\n * Apart from the basic server dashboard, it's recommended to set up dashboards on different components for Cadence server: Frontend, History, Matching, Worker, Persistence, Archival, etc. Any contribution is always welcome to enrich the existing templates or new templates!\n\n\n# Periodic tests(Canary) for health check\n\nIt's recommended that you run periodical test to get signals on the healthness of your cluster. Please following instructions in our canary package to set these tests up.\n\n\n# Cadence Frontend Monitoring\n\nThis section describes recommended dashboards for monitoring Cadence services in your cluster. The structure mostly follows the DataDog dashboard template listed above.\n\n\n# Service Availability(server metrics)\n\n * Meaning: the availability of Cadence server using server metrics.\n * Suggested monitor: below 95% > 5 min then alert, below 99% for > 5 min triggers a warning\n * Monitor action: When fired, check if there is any persistence errors. If so then check the healthness of the database(may need to restart or scale up). If not then check the error logs.\n * Datadog query example\n\nsum:cadence_frontend.cadence_errors{*}\nsum:cadence_frontend.cadence_requests{*}\n(1 - a / b) * 100\n\n\n\n# StartWorkflow Per Second\n\n * Meaning: how many workflows are started per second. This helps determine if your server is overloaded.\n * Suggested monitor: This is a business metrics. No monitoring required.\n * Datadog query example\n\nsum:cadence_frontend.cadence_requests{(operation IN (startworkflowexecution,signalwithstartworkflowexecution))} by {operation}.as_rate()\n\n\n\n# Activities Started Per Second\n\n * Meaning: How many activities are started per second. Helps determine if the server is overloaded.\n * Suggested monitor: This is a business metrics. No monitoring required.\n * Datadog query example\n\nsum:cadence_frontend.cadence_requests{operation:pollforactivitytask} by {operation}.as_rate()\n\n\n\n# Decisions Started Per Second\n\n * Meaning: How many workflow decisions are started per second. Helps determine if the server is overloaded.\n * Suggested monitor: This is a business metrics. No monitoring required.\n * Datadog query example\n\nsum:cadence_frontend.cadence_requests{operation:pollfordecisiontask} by {operation}.as_rate()\n\n\n\n# Periodical Test Suite Success(aka Canary)\n\n * Meaning: The success counter of canary test suite\n * Suggested monitor: Monitor needed. If fired, look at the failed canary test case and investigate the reason of failure.\n * Datadog query example\n\nsum:cadence_history.workflow_success{workflowtype:workflow_sanity} by {workflowtype}.as_count()\n\n\n\n# Frontend all API per second\n\n * Meaning: all API on frontend per second. Information only.\n * Suggested monitor: This is a business metrics. No monitoring required.\n * Datadog query example\n\nsum:cadence_frontend.cadence_requests{*}.as_rate()\n\n\n\n# Frontend API per second (breakdown per operation)\n\n * Meaning: API on frontend per second. Information only.\n * Suggested monitor: This is a business metrics. No monitoring required.\n * Datadog query example\n\nsum:cadence_frontend.cadence_requests{*} by {operation}.as_rate()\n\n\n\n# Frontend API errors per second(breakdown per operation)\n\n * Meaning: API error on frontend per second. Information only.\n * Suggested monitor: This is to facilitate investigation. No monitoring required.\n * Datadog query example\n\nsum:cadence_frontend.cadence_errors{*} by {operation}.as_rate()  \nsum:cadence_frontend.cadence_errors_bad_request{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_domain_not_active{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_service_busy{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_entity_not_exists{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_workflow_execution_already_completed{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_execution_already_started{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_domain_already_exists{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_cancellation_already_requested{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_query_failed{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_limit_exceeded{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_context_timeout{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_retry_task{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_bad_binary{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_client_version_not_supported{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_incomplete_history{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_nondeterministic{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_unauthorized{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_authorize_failed{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_remote_syncmatch_failed{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_domain_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_identity_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_workflow_id_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_signal_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_workflow_type_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_request_id_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_task_list_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_activity_id_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_activity_type_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_marker_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_timer_id_exceeded_warn_limit{*} by {operation}.as_rate() \n\n\n * cadence_errors is internal service errors.\n * any cadence_errors_* is client side error\n\n\n# Frontend Regular API Latency\n\n * Meaning: The latency of regular core API -- excluding long-poll/queryWorkflow/getHistory/ListWorkflow/CountWorkflow API.\n * Suggested monitor: 95% of all apis and of all operations that take over 1.5 seconds triggers a warning, over 2 seconds triggers an alert\n * Monitor action: If fired, investigate the database read/write latency. May need to throttle some spiky traffic from certain domains, or scale up the database\n * Datadog query example\n\navg:cadence_frontend.cadence_latency.quantile{(operation NOT IN (pollfordecisiontask,pollforactivitytask,getworkflowexecutionhistory,queryworkflow,listworkflowexecutions,listclosedworkflowexecutions,listopenworkflowexecutions)) AND $pXXLatency} by {operation}\n\n\n\n# Frontend ListWorkflow API Latency\n\n * Meaning: The latency of ListWorkflow API.\n * Monitor: 95% of all apis and of all operations that take over 2 seconds triggers a warning, over 3 seconds triggers an alert\n * Monitor action: If fired, investigate the ElasticSearch read latency. May need to throttle some spiky traffic from certain domains, or scale up ElasticSearch cluster.\n * Datadog query example\n\navg:cadence_frontend.cadence_latency.quantile{(operation IN (listclosedworkflowexecutions,listopenworkflowexecutions,listworkflowexecutions,countworkflowexecutions)) AND $pXXLatency} by {operation}\n\n\n\n# Frontend Long Poll API Latency\n\n * Meaning: Long poll means that the worker is waiting for a task. The latency is an Indicator for how busy the worker is. Poll for activity task and poll for decision task are the types of long poll requests.The api call times out at 50 seconds if no task can be picked up.A very low latency could mean that more workers need to be added.\n * Suggested monitor: No monitor needed as long latency is expected.\n * Datadog query example\n\navg:cadence_frontend.cadence_latency.quantile{$pXXLatency,operation:pollforactivitytask} by {operation}\navg:cadence_frontend.cadence_latency.quantile{$pXXLatency,operation:pollfordecisiontask} by {operation}\n\n\n\n# Frontend Get History/Query Workflow API Latency\n\n * Meaning: GetHistory API acts like a long poll api, but there’s no explicit timeout. Long-poll of GetHistory is being used when WorkflowClient is waiting for the result of the workflow(essentially, WorkflowExecutionCompletedEvent). This latency depends on the time it takes for the workflow to complete. QueryWorkflow API latency is also unpredictable as it depends on the availability and performance of workflow workers, which are owned by the application and workflow implementation(may require replaying history).\n * Suggested monitor: No monitor needed\n * Datadog query example\n\navg:cadence_frontend.cadence_latency.quantile{(operation IN (getworkflowexecutionhistory,queryworkflow)) AND $pXXLatency} by {operation}\n\n\n\n# Frontend WorkflowClient API per seconds by domain\n\n * Meaning: Shows which domains are making the most requests using WorkflowClient(excluding worker API like PollForDecisionTask and RespondDecisionTaskCompleted). Used for troubleshooting. In the future it can be used to set some rate limiting per domain.\n * Suggested monitor: No monitor needed.\n * Datadog query example\n\nsum:cadence_frontend.cadence_requests{(operation IN (signalwithstartworkflowexecution,signalworkflowexecution,startworkflowexecution,terminateworkflowexecution,resetworkflowexecution,requestcancelworkflowexecution,listworkflowexecutions))} by {domain,operation}.as_rate()\n\n\n\n# Cadence Application Monitoring\n\nThis section describes the recommended dashboards for monitoring Cadence application using metrics emitted by SDK. See the setup section about how to collect those metrics.\n\n\n# Workflow Start and Successful completion\n\n * Workflow successfully started/signalWithStart and completed/canceled/continuedAsNew\n * Monitor: not recommended\n * Datadog query example\n\nsum:cadence_client.cadence_workflow_start{$Domain,$Tasklist,$WorkflowType} by {workflowtype,env,domain,tasklist}.as_rate()\nsum:cadence_client.cadence_workflow_completed{$Domain,$Tasklist,$WorkflowType} by {workflowtype,env,domain,tasklist}.as_rate()\nsum:cadence_client.cadence_workflow_canceled{$Domain,$Tasklist,$WorkflowType} by {workflowtype,domain,env,tasklist}.as_rate()\nsum:cadence_client.cadence_workflow_continue_as_new{$Domain,$Tasklist,$WorkflowType} by {workflowtype,domain,env,tasklist}.as_rate()\nsum:cadence_client.cadence_workflow_signal_with_start{$Domain,$Tasklist,$WorkflowType} by {workflowtype,domain,env,tasklist}.as_rate()\n\n\n\n# Workflow Failure\n\n * Metrics for all types of failures, including workflow failures(throw uncaught exceptions), workflow timeout and termination.\n * For timeout and termination, workflow worker doesn’t have a chance to emit metrics when it’s terminate, so the metric comes from the history service\n * Monitor: application should set monitor on timeout and failure to make sure workflow are not failing. Cancel/terminate are usually triggered by human intentionally.\n * When the metrics fire, go to Cadence UI to find the failed workflows and investigate the workflow history to understand the type of failure\n * Datadog query example\n\nsum:cadence_client.cadence_workflow_failed{$Domain,$Tasklist,$WorkflowType} by {workflowtype,domain,env}.as_count()\nsum:cadence_history.workflow_failed{$Domain,$WorkflowType} by {domain,env,workflowtype}.as_count()\nsum:cadence_history.workflow_terminate{$Domain,$WorkflowType} by {domain,env,workflowtype}.as_count()\nsum:cadence_history.workflow_timeout{$Domain,$WorkflowType} by {domain,env,workflowtype}.as_count()\n\n\n\n# Decision Poll Counters\n\n * Indicates if the workflow worker is available and is polling tasks. If the worker is not available no counters will show. Can also check if the worker is using the right task list. “No task” poll type means that the worker exists and is idle. The timeout for this long poll api is 50 seconds. If no task is received within 50 seconds, then an empty response will be returned and another long poll request will be sent.\n * Monitor: application can should monitor on it to make sure workers are available\n * When fires, investigate the worker deployment to see why they are not available, also check if they are using the right domain/tasklist\n * Datadog query example\n\nsum:cadence_client.cadence_decision_poll_total{$Domain,$Tasklist}.as_count()\nsum:cadence_client.cadence_decision_poll_failed{$Domain,$Tasklist}.as_count()\nsum:cadence_client.cadence_decision_poll_no_task{$Domain,$Tasklist}.as_count()\nsum:cadence_client.cadence_decision_poll_succeed{$Domain,$Tasklist}.as_count()\n\n\n\n# DecisionTasks Scheduled per second\n\n * Indicate how many decision tasks are scheduled\n * Monitor: not recommended -- Information only to know whether or not a tasklist is overloaded\n * Datadog query example\n\nsum:cadence_matching.cadence_requests_per_tl{*,operation:adddecisiontask,$Tasklist,$Domain} by {tasklist,domain}.as_rate()\n\n\n\n# Decision Scheduled To Start Latency\n\n * If this latency is too high then either: The worker is not available or too busy after the task has been scheduled. The task list is overloaded(confirmed by DecisionTaskScheduled per second widget). By default a task list only has one partition and a partition can only be owned by one host and so the throughput of a task list is limited. More task lists can be added to scale or a scalable task list can be used to add more partitions.\n * Monitor: application can set monitor on it to make sure latency is tolerable\n * When fired, check if worker capacity is enough, then check if tasklist is overloaded. If needed, contact the Cadence cluster Admin to enable scalable tasklist to add more partitions to the tasklist\n * Datadog query example\n\navg:cadence_client.cadence_decision_scheduled_to_start_latency.avg{$Domain,$Tasklist} by {env,domain,tasklist}\nmax:cadence_client.cadence_decision_scheduled_to_start_latency.max{$Domain,$Tasklist} by {env,domain,tasklist}\nmax:cadence_client.cadence_decision_scheduled_to_start_latency.95percentile{$Domain,$Tasklist} by {env,domain,tasklist}\n\n\n\n# Decision Execution Failure\n\n * This means some critical bugs in workflow code causing decision task execution failure\n * Monitor: application should set monitor on it to make sure no consistent failure\n * When fired, you may need to terminate the problematic workflows to mitigate the issue. After you identify the bugs, you can fix the code and then reset the workflow to recover\n * Datadog query example\n\nsum:cadence_client.cadence_decision_execution_failed{$Domain,$Tasklist} by {tasklist,workflowtype}.as_count()\n\n\n\n# Decision Execution Timeout\n\n * This means some critical bugs in workflow code causing decision task execution timeout\n * Monitor: application should set monitor on it to make sure no consistent timeout\n * When fired, you may need to terminate the problematic workflows to mitigate the issue. After you identify the bugs, you can fix the code and then reset the workflow to recover\n * Datadog query example\n\nsum:cadence_history.start_to_close_timeout{operation:timeractivetaskdecision*,$Domain}.as_count()\n\n\n\n# Workflow End to End Latency\n\n * This is for the client application to track their SLOs For example, if you expect a workflow to take duration d to complete, you can use this latency to set a monitor.\n * Monitor: application can monitor this metrics if expecting workflow to complete within a certain duration.\n * When fired, investigate the workflow history to see the workflow takes longer than expected to complete\n * Datadog query example\n\navg:cadence_client.cadence_workflow_endtoend_latency.median{$Domain,$Tasklist,$WorkflowType} by {env,domain,tasklist,workflowtype}\navg:cadence_client.cadence_workflow_endtoend_latency.95percentile{$Domain,$Tasklist,$WorkflowType} by {env,domain,tasklist,workflowtype}\n\n\n\n# Workflow Panic and NonDeterministicError\n\n * These errors mean that there is a bug in the code and the deploy should be rolled back.\n * A monitor should be set on this metric\n * When fired, you may rollback the deployment to mitigate your issue. Usually this caused by bad (non-backward compatible) code change. After rollback, look at your worker error logs to see where the bug is.\n * Datadog query example\n\nsum:cadence_client.cadence_worker_panic{$Domain} by {env,domain}.as_rate()\nsum:cadence_client.cadence_non_deterministic_error{$Domain} by {env,domain}.as_rate()\n\n\n\n# Workflow Sticky Cache Hit Rate and Miss Count\n\n * This metric can be used for performance optimization. This can be improved by adding more worker instances, or adjust the workerOption(GoSDK) or WorkferFactoryOption(Java SDK). CacheHitRate too low means workers will have to replay history to rebuild the workflow stack when executing a decision task. Depending on the the history size\n   * If less than 1MB, then it’s okay to be lower than 50%\n   * If greater than 1MB, then it’s okay to be greater than 50%\n   * If greater than 5MB, , then it’s okay to be greater than 60%\n   * If greater than 10MB , then it’s okay to be greater than 70%\n   * If greater than 20MB , then it’s okay to be greater than 80%\n   * If greater than 30MB , then it’s okay to be greater than 90%\n   * Workflow history size should never be greater than 50MB.\n * A monitor can be set on this metric, if performance is important.\n * When fired, adjust the stickyCacheSize in the WorkerFactoryOption, or add more workers\n * Datadog query example\n\nsum:cadence_client.cadence_sticky_cache_miss{$Domain} by {env,domain}.as_count()\nsum:cadence_client.cadence_sticky_cache_hit{$Domain} by {env,domain}.as_count()\n(b / (a+b)) * 100\n\n\n\n# Activity Task Operations\n\n * Activity started/completed counters\n * Monitor: not recommended\n * Datadog query example\n\nsum:cadence_client.cadence_activity_task_failed{$Domain,$Tasklist} by {activitytype}.as_rate()\nsum:cadence_client.cadence_activity_task_completed{$Domain,$Tasklist} by {activitytype}.as_rate()\nsum:cadence_client.cadence_activity_task_timeouted{$Domain,$Tasklist} by {activitytype}.as_rate()\n\n\n\n# Local Activity Task Operations\n\n * Local Activity execution counters\n * Monitor: not recommended\n * Datadog query example\n\nsum:cadence_client.cadence_local_activity_total{$Domain,$Tasklist} by {activitytype}.as_count()\n\n\n\n# Activity Execution Latency\n\n * If it’s expected that an activity will take x amount of time to complete, a monitor on this metric could be helpful to enforce that expectation.\n * Monitor: application can set monitor on it if expecting workflow start/complete activities with certain latency\n * When fired, investigate the activity code and its dependencies\n * Datadog query example\n\navg:cadence_client.cadence_activity_execution_latency.avg{$Domain,$Tasklist} by {env,domain,tasklist,activitytype}\nmax:cadence_client.cadence_activity_execution_latency.max{$Domain,$Tasklist} by {env,domain,tasklist,activitytype}\n\n\n\n# Activity Poll Counters\n\n * Indicates the activity worker is available and is polling tasks. If the worker is not available no counters will show. Can also check if the worker is using the right task list. “No task” poll type means that the worker exists and is idle. The timeout for this long poll api is 50 seconds. If within that 50 seconds, no task is received then an empty response will be returned and another long poll request will be sent.\n * Monitor: application can set monitor on it to make sure activity workers are available\n * When fires, investigate the worker deployment to see why they are not available, also check if they are using the right domain/tasklist\n * Datadog query example\n\nsum:cadence_client.cadence_activity_poll_total{$Domain,$Tasklist} by {activitytype}.as_count()\nsum:cadence_client.cadence_activity_poll_failed{$Domain,$Tasklist} by {activitytype}.as_count()\nsum:cadence_client.cadence_activity_poll_succeed{$Domain,$Tasklist} by {activitytype}.as_count()\nsum:cadence_client.cadence_activity_poll_no_task{$Domain,$Tasklist} by {activitytype}.as_count()\n\n\n\n# ActivityTasks Scheduled per second\n\n * Indicate how many activities tasks are scheduled\n * Monitor: not recommended -- Information only to know whether or not a tasklist is overloaded\n * Datadog query example\n\nsum:cadence_matching.cadence_requests_per_tl{*,operation:addactivitytask,$Tasklist,$Domain} by {tasklist,domain}.as_rate()\n\n\n\n# Activity Scheduled To Start Latency\n\n * If the latency is too high either: The worker is not available or too busy There are too many activities scheduled into the same tasklist and the tasklist is not scalable. Same as Decision Scheduled To Start Latency\n * Monitor: application Should set monitor on it\n * When fired, check if workers are enough, then check if the tasklist is overloaded. If needed, contact the Cadence cluster Admin to enable scalable tasklist to add more partitions to the tasklist\n * Datadog query example\n\navg:cadence_client.cadence_activity_scheduled_to_start_latency.avg{$Domain,$Tasklist} by {env,domain,tasklist,activitytype}\nmax:cadence_client.cadence_activity_scheduled_to_start_latency.max{$Domain,$Tasklist} by {env,domain,tasklist,activitytype}\nmax:cadence_client.cadence_activity_scheduled_to_start_latency.95percentile{$Domain,$Tasklist} by {env,domain,tasklist,activitytype}\n\n\n\n# Activity Failure\n\n * A monitor on this metric will alert the team that activities are failing The activity timeout metrics are emitted by the history service, because a timeout causes a hard stop and the client doesn’t have time to emit metrics.\n * Monitor: application can set monitor on it\n * When fired, investigate the activity code and its dependencies\n * cadence_activity_execution_failed vs cadence_activity_task_failed: Only have different when using RetryPolicy cadence_activity_task_failed counter increase per activity attempt cadence_activity_execution_failed counter increase when activity fails after all attempts\n * should only monitor on cadence_activity_execution_failed\n * Datadog query example\n\nsum:cadence_client.cadence_activity_execution_failed{$Domain} by {domain,env}.as_rate()\nsum:cadence_client.cadence_activity_task_panic{$Domain} by {domain,env}.as_count()\nsum:cadence_client.cadence_activity_task_failed{$Domain} by {domain,env}.as_rate()\nsum:cadence_client.cadence_activity_task_canceled{$Domain} by {domain,env}.as_count()\nsum:cadence_history.heartbeat_timeout{$Domain} by {domain,env}.as_count()\nsum:cadence_history.schedule_to_start_timeout{$Domain} by {domain,env}.as_rate()\nsum:cadence_history.start_to_close_timeout{$Domain} by {domain,env}.as_rate()\nsum:cadence_history.schedule_to_close_timeout{$Domain} by {domain,env}.as_count()\n\n\n\n# Service API success rate\n\n * The client’s experience of the service availability. It encompasses many apis. Things that could affect the service’s API success rate are:\n   * Service availability\n   * The network could have issues.\n   * A required api is not available.\n   * Client side errors like EntityNotExists, WorkflowAlreadyStarted etc. This means that application code has potential bugs of calling Cadence service.\n * Monitor: application can set monitor on it\n * When fired, check application logs to see if the error is Cadence server error or client side error. Error like EntityNotExists/ExecutionAlreadyStarted/QueryWorkflowFailed/etc are client side error, meaning that the application is misusing the APIs. If most errors are server side errors(internalServiceError), you can contact Cadence admin.\n * Datadog query example\n\nsum:cadence_client.cadence_error{*} by {domain}.as_count()\nsum:cadence_client.cadence_request{*} by {domain}.as_count()\n(1 - a / b) * 100\n\n\n\n# Service API Latency\n\n * The latency of the API, excluding long poll APIs.\n * Application can set monitor on certain APIs, if necessary.\n * Datadog query example\n\navg:cadence_client.cadence_latency.95percentile{$Domain,!cadence_metric_scope:cadence-pollforactivitytask,!cadence_metric_scope:cadence-pollfordecisiontask} by {cadence_metric_scope}\n\n\n\n# Service API Breakdown\n\n * A counter breakdown by API to help investigate availability\n * No monitor needed\n * Datadog query example\n\nsum:cadence_client.cadence_request{$Domain,!cadence_metric_scope:cadence-pollforactivitytask,!cadence_metric_scope:cadence-pollfordecisiontask} by {cadence_metric_scope}.as_count()\n\n\n\n# Service API Error Breakdown\n\n * A counter breakdown by API error to help investigate availability\n * No monitor needed\n * Datadog query example\n\nsum:cadence_client.cadence_error{$Domain} by {cadence_metric_scope}.as_count()\n\n\n\n# Max Event Blob size\n\n * By default the max size is 2 MB. If the input is greater than the max size the server will reject the request. The size of a single history event. This applies to any event input, like start workflow event, start activity event, or signal event. It should never be greater than 2MB.\n * A monitor should be set on this metric.\n * When fired, please review the design/code ASAP to reduce the blob size. Reducing the input/output of workflow/activity/signal will help.\n * Datadog query example\n\n​​max:cadence_history.event_blob_size.quantile{!domain:all,$Domain} by {domain}\n\n\n\n# Max History Size\n\n * Workflow history cannot grow indefinitely. It will cause replay issues. If the workflow exceeds the history’s max size the workflow will be terminate automatically. The max size by default is 200 megabytes. As a suggestion for workflow design, workflow history should never grow greater than 50MB. Use continueAsNew to break long workflows into multiple runs.\n * A monitor should be set on this metric.\n * When fired, please review the design/code ASAP to reduce the history size. Reducing the input/output of workflow/activity/signal will help. Also you may need to use ContinueAsNew to break a single execution into smaller pieces.\n * Datadog query example\n\n​​max:cadence_history.history_size.quantile{!domain:all,$Domain} by {domain}\n\n\n\n# Max History Length\n\n * The number of events of workflow history. It should never be greater than 50K(workflow exceeding 200K events will be terminated by server). Use continueAsNew to break long workflows into multiple runs.\n * A monitor should be set on this metric.\n * When fired, please review the design/code ASAP to reduce the history length. You may need to use ContinueAsNew to break a single execution into smaller pieces.\n * Datadog query example\n\n​​max:cadence_history.history_count.quantile{!domain:all,$Domain} by {domain}\n\n\n\n# Cadence History Service Monitoring\n\nHistory is the most critical/core service for cadence which implements the workflow logic.\n\n\n# History shard movements\n\n * Should only happen during deployment or when the node restarts. If there’s shard movement without deployments then that’s unexpected and there’s probably a performance issue. The shard ownership is assigned by a particular history host, so if the shard is moving it’ll be hard for the frontend service to route a request to a particular history shard and to find it.\n * A monitor can be set to be alerted on shard movements without deployment.\n * Datadog query example\n\nsum:cadence_history.membership_changed_count{operation:shardcontroller}\nsum:cadence_history.shard_closed_count{operation:shardcontroller}\nsum:cadence_history.sharditem_created_count{operation:shardcontroller}\nsum:cadence_history.sharditem_removed_count{operation:shardcontroller}\n\n\n\n# Transfer Tasks Per Second\n\n * TransferTask is an internal background task that moves workflow state and transfers an action task from the history engine to another service(e.g. Matching service, ElasticSearch, etc)\n * No monitor needed\n * Datadog query example\n\nsum:cadence_history.task_requests{operation:transferactivetask*} by {operation}.as_rate()\n\n\n\n# Timer Tasks Per Second\n\n * Timer tasks are tasks that are scheduled to be triggered at a given time in future. For example, workflow.sleep() will wait an x amount of time then the task will be pushed somewhere for a worker to pick up.\n * Datadog query example\n\nsum:cadence_history.task_requests{operation:timeractivetask*} by {operation}.as_rate()\n\n\n\n# Transfer Tasks Per Domain\n\n * Count breakdown by domain\n * Datadog query example\n\nsum:cadence_history.task_requests_per_domain{operation:transferactive*} by {domain}.as_count()\n\n\n\n# Timer Tasks Per Domain\n\n * Count breakdown by domain\n * Datadog query example\n\nsum:cadence_history.task_requests_per_domain{operation:timeractive*} by {domain}.as_count()\n\n\n\n# Transfer Latency by Type\n\n * If latency is too high then it’s an issue for a workflow. For example, if transfer task latency is 5 second, then it takes 5 second for activity/decision to actual receive the task.\n * Monitor should be set on diffeernt types of latency. Note that queue_latency can go very high during deployment and it's expected. See below NOTE for explanation.\n * When fired, check if it’s due to some persistence issue. If so then investigate the database(may need to scale up) If not then see if need to scale up Cadence deployment(K8s instance)\n * Datadog query example\n\navg:cadence_history.task_latency.quantile{$pXXLatency,operation:transfer*} by {operation}\navg:cadence_history.task_latency_processing.quantile{$pXXLatency,operation:transfer*} by {operation}\navg:cadence_history.task_latency_queue.quantile{$pXXLatency,operation:transfer*} by {operation}\n\n\n\n# Timer Task Latency by type\n\n * If latency is too high then it’s an issue for a workflow. For example, if you set the workflow.sleep() for 10 seconds and the timer latency is 5 secs then the workflow will sleep for 15 seconds.\n * Monitor should be set on diffeernt types of latency.\n * When fired, check if it’s due to some persistence issue. If so then investigate the database(may need to scale up) [Mostly] If not then see if need to scale up Cadence deployment(K8s instance)\n * Datadog query example\n\navg:cadence_history.task_latency.quantile{$pXXLatency,operation:timer*} by {operation}\navg:cadence_history.task_latency_processing.quantile{$pXXLatency,operation:timer*} by {operation}\navg:cadence_history.task_latency_queue.quantile{$pXXLatency,operation:timer*} by {operation}\n\n\n\n# NOTE: Task Queue Latency vs Executing Latency vs Processing Latency In Transfer & Timer Task Latency Metrics\n\n * task_latency_queue: “Queue Latency” is “end to end” latency for users. The latency could go to several minutes during deployment because of metrics being re-emitted (but the actual latency is not that high)\n * task_latency: “Executing latency” is the time from submission to executing pool to completion. It includes scheduling, retry and processing time of the task.\n * task_latency_processing: “Processing latency” is the processing time of the task of a single attempt(without retry)\n\n\n# Transfer Task Latency Per Domain\n\n * Latency breakdown by domain\n * No monitor needed.\n * Datadog query example: modify above queries to use domain tag.\n\n\n# Timer Task Latency Per Domain\n\n * Latency breakdown by domain\n * No monitor needed.\n * Datadog query example: modify above queries to use domain tag.\n\n\n# History API per Second\n\nInformation about history API Datadog query example\n\nsum:cadence_history.cadence_requests{*} by {operation}.as_rate()\n\n\n\n# History API Errors per Second\n\n * Information about history API\n * No monitor needed\n * Datadog query example\n\nsum:cadence_history.cadence_errors{*} by {operation}.as_rate()\nsum:cadence_history.cadence_errors_bad_request{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_domain_not_active{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_service_busy{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_entity_not_exists{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_workflow_execution_already_completed{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_execution_already_started{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_domain_already_exists{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_cancellation_already_requested{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_query_failed{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_limit_exceeded{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_context_timeout{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_retry_task{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_bad_binary{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_client_version_not_supported{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_incomplete_history{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_nondeterministic{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_unauthorized{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_authorize_failed{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_remote_syncmatch_failed{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_domain_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_identity_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_workflow_id_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_signal_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_workflow_type_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_request_id_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_task_list_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_activity_id_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_activity_type_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_marker_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_timer_id_exceeded_warn_limit{*} by {operation}.as_rate() \n\n\n * cadence_errors is internal service errors.\n * any cadence_errors_* is client side error\n\n\n# Max History Size\n\nThe history size of the workflow cannot be too large otherwise it will cause performance issue during replay. The soft limit is 200MB. If exceeding workflow will be terminated by server.\n\n * No monitor needed\n * Datadog query is same as the client section\n\n\n# Max History Length\n\nSimilarly, the history length of the workflow cannot be too large otherwise it will cause performance issues during replay. The soft limit is 200K events. If exceeding, workflow will be terminated by server.\n\n * No monitor needed\n * Datadog query is same as the client section\n\n\n# Max Event Blob Size\n\n * The size of each event(e.g. Decided by input/output of workflow/activity/signal/chidlWorkflow/etc) cannot be too large otherwise it will also cause performance issue. The soft limit is 2MB. If exceeding, the requests will be rejected by server, meaning that workflow won’t be able to make any progress.\n * No monitor needed\n * Datadog query is same as the client section\n\n\n# Cadence Matching Service Monitoring\n\nMatching service is to match/assign tasks from cadence service to workers. Matching got the tasks from history service. If workers are active the task will be matched immediately , It’s called “sync match”. If workers are not available, matching will persist into database and then reload the tasks when workers are back(called “async match”)\n\n\n# Matching APIs per Second\n\n * API processed by matching service per second\n * No monitor needed\n * Datadog query example\n\nsum:cadence_matching.cadence_requests{*} by {operation}.as_rate()\n\n\n\n# Matching API Errors per Second\n\n * API errors by matching service per second\n * No monitor needed\n * Datadog query example\n\nsum:cadence_matching.cadence_errors_per_tl{*} by {operation,domain,tasklist}.as_rate()\nsum:cadence_matching.cadence_errors_bad_request_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_bad_request{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_domain_not_active_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_domain_not_active{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_service_busy_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_service_busy{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_entity_not_exists_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_entity_not_exists{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_execution_already_started_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_execution_already_started{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_domain_already_exists_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_domain_already_exists{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_cancellation_already_requested_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_cancellation_already_requested{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_query_failed_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_query_failed{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_limit_exceeded_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_limit_exceeded{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_context_timeout_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_context_timeout{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_retry_task_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_retry_task{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_bad_binary_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_bad_binary{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_client_version_not_supported_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_client_version_not_supported{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_incomplete_history_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_incomplete_history{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_nondeterministic_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_nondeterministic{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_unauthorized_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_unauthorized{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_authorize_failed_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_authorize_failed{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_remote_syncmatch_failed_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_remote_syncmatch_failed{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_shard_ownership_lost{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_event_already_started{*} by {operation,domain,tasklist}\n\n\n * cadence_errors is internal service errors.\n * any cadence_errors_* is client side error\n\n\n# Matching Regular API Latency\n\n * Regular APIs are the APIs excluding long polls\n * No monitor needed\n * Datadog query example\n\navg:cadence_matching.cadence_latency_per_tl.quantile{$pXXLatency,!operation:pollfor*,!operation:queryworkflow} by {operation,tasklist}\n\n\n\n# Sync Match Latency:\n\n * If the latency is too high, probably the tasklist is overloaded. Consider using multiple tasklist, or enable scalable tasklist feature by adding more partition to the tasklist(default is one) To confirm if there are too many tasks being added to the tasklist, use “AddTasks per second - domain, tasklist breakdown”\n * No monitor needed\n * Datadog query example\n\nsum:cadence_matching.syncmatch_latency_per_tl.quantile{$pXXLatency} by {operation,tasklist,domain}\n\n\n\n# Async match Latency\n\n * If a match is done asynchronously it writes a match to the db to use later. Measures the time when the worker is not actively looking for tasks. If this is high, more workers are needed.\n * No monitor needed\n * Datadog query example\n\nsum:cadence_matching.asyncmatch_latency_per_tl.quantile{$pXXLatency} by {operation,tasklist,domain}\n\n\n\n# Cadence Default Persistence Monitoring\n\nThe following monotors should be set up for Cadence persistence.\n\n\n# Persistence Availability\n\n * The availability of the primary database for your Cadence server\n * Monitor required: Below 95% > 5min then alert, below 99% triggers a slack warning\n * When fired, check if it’s due to some persistence issue. If so then investigate the database(may need to scale up) [Mostly] If not then see if need to scale up Cadence deployment(K8s instance)\n * Datadog query example\n\nsum:cadence_frontend.persistence_errors{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_requests{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors{*} by {operation}.as_count()\nsum:cadence_matching.persistence_requests{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors{*} by {operation}.as_count()\nsum:cadence_history.persistence_requests{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors{*} by {operation}.as_count()\nsum:cadence_worker.persistence_requests{*} by {operation}.as_count()\n(1 - a / b) * 100\n(1 - c / d) * 100\n(1 - e / f) * 100\n(1 - g / h) * 100\n\n\n\n# Persistence By Service TPS\n\n * No monitor needed\n * Datadog query example\n\nsum:cadence_frontend.persistence_requests{*}.as_rate()\nsum:cadence_history.persistence_requests{*}.as_rate()\nsum:cadence_worker.persistence_requests{*}.as_rate()\nsum:cadence_matching.persistence_requests{*}.as_rate()\n\n\n\n\n# Persistence By Operation TPS\n\n * No monitor needed\n * Datadog query example\n\nsum:cadence_frontend.persistence_requests{*} by {operation}.as_rate()\nsum:cadence_history.persistence_requests{*} by {operation}.as_rate()\nsum:cadence_worker.persistence_requests{*} by {operation}.as_rate()\nsum:cadence_matching.persistence_requests{*} by {operation}.as_rate()\n\n\n\n\n# Persistence By Operation Latency\n\n * Monitor required, alert if 95% of all operation latency is greater than 1 second for 5mins, warning if greater than 0.5 seconds\n * When fired, investigate the database(may need to scale up) [Mostly] If there’s a high latency, then there could be errors or something wrong with the db\n * Datadog query example\n\navg:cadence_matching.persistence_latency.quantile{$pXXLatency} by {operation}\navg:cadence_worker.persistence_latency.quantile{$pXXLatency} by {operation}\navg:cadence_frontend.persistence_latency.quantile{$pXXLatency} by {operation}\navg:cadence_history.persistence_latency.quantile{$pXXLatency} by {operation}\n\n\n\n# Persistence Error By Operation Count\n\n * It's to help investigate availability issue\n * No monitor needed\n * Datadog query example\n\nsum:cadence_frontend.persistence_errors{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors{*} by {operation}.as_count()\n\nsum:cadence_frontend.persistence_errors_shard_exists{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_shard_ownership_lost{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_condition_failed{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_current_workflow_condition_failed{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_timeout{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_busy{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_entity_not_exists{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_execution_already_started{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_domain_already_exists{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_bad_request{*} by {operation}.as_count()\n\nsum:cadence_history.persistence_errors_shard_exists{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_shard_ownership_lost{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_condition_failed{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_current_workflow_condition_failed{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_timeout{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_busy{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_entity_not_exists{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_execution_already_started{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_domain_already_exists{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_bad_request{*} by {operation}.as_count()\n\nsum:cadence_matching.persistence_errors_shard_exists{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_shard_ownership_lost{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_condition_failed{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_current_workflow_condition_failed{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_timeout{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_busy{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_entity_not_exists{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_execution_already_started{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_domain_already_exists{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_bad_request{*} by {operation}.as_count()\n\nsum:cadence_worker.persistence_errors_shard_exists{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_shard_ownership_lost{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_condition_failed{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_current_workflow_condition_failed{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_timeout{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_busy{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_entity_not_exists{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_execution_already_started{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_domain_already_exists{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_bad_request{*} by {operation}.as_count()\n\n\n\n * cadence_errors is internal service errors.\n * any cadence_errors_* is client side error\n\n\n# Cadence Advanced Visibility Persistence Monitoring(if applicable)\n\nKafka & ElasticSearch are only for visibility. Only applicable if using advanced visibility. For writing visibility records, Cadence history service will write down the records into Kafka, and then Cadence worker service will read from Kafka and write into ElasticSearch(in batch, for performance optimization) For reading visibility records, Frontend service will query ElasticSearch directly.\n\n\n# Persistence Availability\n\n * The availability of Cadence server using database\n * Monitor can be set\n * Datadog query example\n\nsum:cadence_frontend.elasticsearch_errors{*} by {operation}.as_count()\nsum:cadence_frontend.elasticsearch_requests{*} by {operation}.as_count()\nsum:cadence_history.elasticsearch_errors{*} by {operation}.as_count()\nsum:cadence_history.elasticsearch_requests{*} by {operation}.as_count()\n(1 - a / b) * 100\n(1 - c / d) * 100\n\n\n\n# Persistence By Service TPS\n\n * The error of persistence API call by service\n * No monitor needed\n * Datadog query example\n\nsum:cadence_frontend.elasticsearch_requests{*}.as_rate()\nsum:cadence_history.elasticsearch_requests{*}.as_rate()\n\n\n\n# Persistence By Operation TPS(read: ES, write: Kafka)\n\n * The rate of persistence API call by API\n * No monitor needed\n * Datadog query example\n\nsum:cadence_frontend.elasticsearch_requests{*} by {operation}.as_rate()\nsum:cadence_history.elasticsearch_requests{*} by {operation}.as_rate()\n\n\n\n# Persistence By Operation Latency(in seconds) (read: ES, write: Kafka)\n\n * The latency of persistence API call\n * No monitor needed\n * Datadog query example\n\navg:cadence_frontend.elasticsearch_latency.quantile{$pXXLatency} by {operation}\navg:cadence_history.elasticsearch_latency.quantile{$pXXLatency} by {operation}\n\n\n\n# Persistence Error By Operation Count (read: ES, write: Kafka)\n\n * The error of persistence API call\n * No monitor needed\n * Datadog query example\n\nsum:cadence_frontend.elasticsearch_errors{*} by {operation}.as_count()\nsum:cadence_history.elasticsearch_errors{*} by {operation}.as_count()\n\n\n\n# Kafka->ES processor counter\n\n * This is the metrics of a background processing: consuming Kafka messages and then populate to ElasticSearch in batch\n * Monitor on the running of the background processing(counter metrics is > 0)\n * When fired, restart Cadence service first to mitigate. Then look at logs to see why the process is stopped(process panic/error/etc). May consider add more pods (replicaCount) to sys-worker service for higher availability\n * Datadog query example\n\nsum:cadence_worker.es_processor_requests{*} by {operation}.as_count()\nsum:cadence_worker.es_processor_retries{*} by {operation}.as_count()\n\n\n\n# Kafka->ES processor error\n\n * This is the error metrics of the above processing logic Almost all errors are retryable errors so it’s not a problem.\n * Need to monitor error\n * When fired, Go to Kibana to find logs about the error details. The most common error is missing the ElasticSearch index field -- an index field is added in dynamicconfig but not in ElasticSearch, or vice versa . If so, follow the runbook to add the field to ElasticSearch or dynamic config.\n * Datadog query example\n\nsum:cadence_worker.es_processor_error{*} by {operation}.as_count()\nsum:cadence_worker.es_processor_corrupted_data{*} by {operation}.as_count()\n\n\n\n# Kafka->ES processor latency\n\n * The latency of the processing logic\n * No monitor needed\n * Datadog query example\n\nsum:cadence_worker.es_processor_process_msg_latency.quantile{$pXXLatency} by {operation}.as_count()\n\n\n\n# Cadence Dependency Metrics Monitor suggestion\n\n\n# Computing platform metrics for Cadence deployment\n\nCadence server being deployed on any computing platform(e.g. Kubernetese) should be monitored on the blow metrics:\n\n * CPU\n * Memory\n\n\n# Database\n\nDepends on which database, you should at least monitor on the below metrics\n\n * Disk Usage\n * CPU\n * Memory\n * Read API latency\n * Write API Latency\n\n\n# Kafka (if applicable)\n\n * Disk Usage\n * CPU\n * Memory\n\n\n# ElasticSearch (if applicable)\n\n * Disk Usage\n * CPU\n * Memory\n\n\n# Cadence Service SLO Recommendation\n\n * Core API availability: 99.9%\n * Core API latency: <1s\n * Overall task dispatch latency: <2s (queue_latency for transfer task and timer task)",normalizedContent:"# cluster monitoring\n\n\n# instructions\n\ncadence emits metrics for both server and client libraries:\n\n * follow this example to emit client side metrics for golang client\n   \n   * you can use other metrics emitter like m3\n   * alternatively, you can implement the tally reporter interface\n\n * follow this example to emit client side metrics for java client if using 3.x client, or this example if using 2.x client.\n   \n   * you can use other metrics emitter like m3\n   * alternatively, you can implement the tally reporter interface\n\n * for running cadence services in production, please follow this example of hemlchart to emit server side metrics. or you can follow the example of local environment to prometheus. all services need to expose a http port to provide metircs like below\n\nmetrics:\n  prometheus:\n    timertype: \"histogram\"\n    listenaddress: \"0.0.0.0:8001\"\n\n\nthe rest of the instruction uses local environment as an example.\n\nfor testing local server emitting metrics to promethues, the easiest way is to use docker-compose to start a local cadence instance.\n\nmake sure to update the prometheus_config.yml to add \"host.docker.internal:9098\" to the scrape list before starting the docker-compose:\n\nglobal:\n  scrape_interval: 5s\n  external_labels:\n    monitor: 'cadence-monitor'\nscrape_configs:\n  - job_name: 'prometheus'\n    static_configs:\n      - targets: # addresses to scrape\n          - 'cadence:9090'\n          - 'cadence:8000'\n          - 'cadence:8001'\n          - 'cadence:8002'\n          - 'cadence:8003'\n          - 'host.docker.internal:9098'\n\n\nnote: host.docker.internal may not work for some docker versions\n\n * after updating the prometheus_config.yaml as above, run docker-compose up to start the local cadence instance\n\n * go the the sample repo, build the helloworld sample make helloworld and run the worker ./bin/helloworld -m worker, and then in another shell start a workflow ./bin/helloworld\n\n * go to your local prometheus dashboard, you should be able to check the metrics emitted by handler from client/frontend/matching/history/sysworker and confirm your services are healthy through targets\n\n * go to local grafana , login as admin/admin.\n\n * configure prometheus as datasource: use http://host.docker.internal:9090 as url of prometheus.\n\n * import the grafana dashboard tempalte as json files.\n\nclient side dashboard looks like this:\n\nand server basic dashboard:\n\n\n# datadog dashboard templates\n\nthis package contains examples of cadence dashboards with datadog.\n\n * cadence-client is the dashboard that includes all the metrics to help you understand cadence client behavior. most of these metrics are emitted by the client sdks, with a few exceptions from server side (for example, workflow timeout).\n\n * cadence-server is the the server dashboard that you can use to monitor and undertand the health and status of your cadence cluster.\n\nto use datadog with cadence, follow this instruction to collect prometheus metrics using datadog agent.\n\nnote1: don't forget to adjust max_returned_metrics to a higher number(e.g. 100000). otherwise datadog agent won't be able to collect all metrics(default is 2000).\n\nnote2: the template contains templating variables $app and $availability_zone. feel free to remove them if you don't have them in your setup.\n\n\n# grafana+prometheus dashboard templates\n\nthis package contains examples of cadence dashboards with prometheus.\n\n * cadence-client is the dashboard of client metrics, and a few server side metrics that belong to client side but have to be emitted by server(for example, workflow timeout).\n\n * cadence-server-basic is the the basic server dashboard to monitor/navigate the health/status of a cadence cluster.\n\n * apart from the basic server dashboard, it's recommended to set up dashboards on different components for cadence server: frontend, history, matching, worker, persistence, archival, etc. any contribution is always welcome to enrich the existing templates or new templates!\n\n\n# periodic tests(canary) for health check\n\nit's recommended that you run periodical test to get signals on the healthness of your cluster. please following instructions in our canary package to set these tests up.\n\n\n# cadence frontend monitoring\n\nthis section describes recommended dashboards for monitoring cadence services in your cluster. the structure mostly follows the datadog dashboard template listed above.\n\n\n# service availability(server metrics)\n\n * meaning: the availability of cadence server using server metrics.\n * suggested monitor: below 95% > 5 min then alert, below 99% for > 5 min triggers a warning\n * monitor action: when fired, check if there is any persistence errors. if so then check the healthness of the database(may need to restart or scale up). if not then check the error logs.\n * datadog query example\n\nsum:cadence_frontend.cadence_errors{*}\nsum:cadence_frontend.cadence_requests{*}\n(1 - a / b) * 100\n\n\n\n# startworkflow per second\n\n * meaning: how many workflows are started per second. this helps determine if your server is overloaded.\n * suggested monitor: this is a business metrics. no monitoring required.\n * datadog query example\n\nsum:cadence_frontend.cadence_requests{(operation in (startworkflowexecution,signalwithstartworkflowexecution))} by {operation}.as_rate()\n\n\n\n# activities started per second\n\n * meaning: how many activities are started per second. helps determine if the server is overloaded.\n * suggested monitor: this is a business metrics. no monitoring required.\n * datadog query example\n\nsum:cadence_frontend.cadence_requests{operation:pollforactivitytask} by {operation}.as_rate()\n\n\n\n# decisions started per second\n\n * meaning: how many workflow decisions are started per second. helps determine if the server is overloaded.\n * suggested monitor: this is a business metrics. no monitoring required.\n * datadog query example\n\nsum:cadence_frontend.cadence_requests{operation:pollfordecisiontask} by {operation}.as_rate()\n\n\n\n# periodical test suite success(aka canary)\n\n * meaning: the success counter of canary test suite\n * suggested monitor: monitor needed. if fired, look at the failed canary test case and investigate the reason of failure.\n * datadog query example\n\nsum:cadence_history.workflow_success{workflowtype:workflow_sanity} by {workflowtype}.as_count()\n\n\n\n# frontend all api per second\n\n * meaning: all api on frontend per second. information only.\n * suggested monitor: this is a business metrics. no monitoring required.\n * datadog query example\n\nsum:cadence_frontend.cadence_requests{*}.as_rate()\n\n\n\n# frontend api per second (breakdown per operation)\n\n * meaning: api on frontend per second. information only.\n * suggested monitor: this is a business metrics. no monitoring required.\n * datadog query example\n\nsum:cadence_frontend.cadence_requests{*} by {operation}.as_rate()\n\n\n\n# frontend api errors per second(breakdown per operation)\n\n * meaning: api error on frontend per second. information only.\n * suggested monitor: this is to facilitate investigation. no monitoring required.\n * datadog query example\n\nsum:cadence_frontend.cadence_errors{*} by {operation}.as_rate()  \nsum:cadence_frontend.cadence_errors_bad_request{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_domain_not_active{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_service_busy{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_entity_not_exists{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_workflow_execution_already_completed{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_execution_already_started{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_domain_already_exists{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_cancellation_already_requested{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_query_failed{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_limit_exceeded{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_context_timeout{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_retry_task{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_bad_binary{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_client_version_not_supported{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_incomplete_history{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_nondeterministic{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_unauthorized{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_authorize_failed{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_remote_syncmatch_failed{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_domain_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_identity_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_workflow_id_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_signal_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_workflow_type_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_request_id_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_task_list_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_activity_id_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_activity_type_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_marker_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_frontend.cadence_errors_timer_id_exceeded_warn_limit{*} by {operation}.as_rate() \n\n\n * cadence_errors is internal service errors.\n * any cadence_errors_* is client side error\n\n\n# frontend regular api latency\n\n * meaning: the latency of regular core api -- excluding long-poll/queryworkflow/gethistory/listworkflow/countworkflow api.\n * suggested monitor: 95% of all apis and of all operations that take over 1.5 seconds triggers a warning, over 2 seconds triggers an alert\n * monitor action: if fired, investigate the database read/write latency. may need to throttle some spiky traffic from certain domains, or scale up the database\n * datadog query example\n\navg:cadence_frontend.cadence_latency.quantile{(operation not in (pollfordecisiontask,pollforactivitytask,getworkflowexecutionhistory,queryworkflow,listworkflowexecutions,listclosedworkflowexecutions,listopenworkflowexecutions)) and $pxxlatency} by {operation}\n\n\n\n# frontend listworkflow api latency\n\n * meaning: the latency of listworkflow api.\n * monitor: 95% of all apis and of all operations that take over 2 seconds triggers a warning, over 3 seconds triggers an alert\n * monitor action: if fired, investigate the elasticsearch read latency. may need to throttle some spiky traffic from certain domains, or scale up elasticsearch cluster.\n * datadog query example\n\navg:cadence_frontend.cadence_latency.quantile{(operation in (listclosedworkflowexecutions,listopenworkflowexecutions,listworkflowexecutions,countworkflowexecutions)) and $pxxlatency} by {operation}\n\n\n\n# frontend long poll api latency\n\n * meaning: long poll means that the worker is waiting for a task. the latency is an indicator for how busy the worker is. poll for activity task and poll for decision task are the types of long poll requests.the api call times out at 50 seconds if no task can be picked up.a very low latency could mean that more workers need to be added.\n * suggested monitor: no monitor needed as long latency is expected.\n * datadog query example\n\navg:cadence_frontend.cadence_latency.quantile{$pxxlatency,operation:pollforactivitytask} by {operation}\navg:cadence_frontend.cadence_latency.quantile{$pxxlatency,operation:pollfordecisiontask} by {operation}\n\n\n\n# frontend get history/query workflow api latency\n\n * meaning: gethistory api acts like a long poll api, but there’s no explicit timeout. long-poll of gethistory is being used when workflowclient is waiting for the result of the workflow(essentially, workflowexecutioncompletedevent). this latency depends on the time it takes for the workflow to complete. queryworkflow api latency is also unpredictable as it depends on the availability and performance of workflow workers, which are owned by the application and workflow implementation(may require replaying history).\n * suggested monitor: no monitor needed\n * datadog query example\n\navg:cadence_frontend.cadence_latency.quantile{(operation in (getworkflowexecutionhistory,queryworkflow)) and $pxxlatency} by {operation}\n\n\n\n# frontend workflowclient api per seconds by domain\n\n * meaning: shows which domains are making the most requests using workflowclient(excluding worker api like pollfordecisiontask and responddecisiontaskcompleted). used for troubleshooting. in the future it can be used to set some rate limiting per domain.\n * suggested monitor: no monitor needed.\n * datadog query example\n\nsum:cadence_frontend.cadence_requests{(operation in (signalwithstartworkflowexecution,signalworkflowexecution,startworkflowexecution,terminateworkflowexecution,resetworkflowexecution,requestcancelworkflowexecution,listworkflowexecutions))} by {domain,operation}.as_rate()\n\n\n\n# cadence application monitoring\n\nthis section describes the recommended dashboards for monitoring cadence application using metrics emitted by sdk. see the setup section about how to collect those metrics.\n\n\n# workflow start and successful completion\n\n * workflow successfully started/signalwithstart and completed/canceled/continuedasnew\n * monitor: not recommended\n * datadog query example\n\nsum:cadence_client.cadence_workflow_start{$domain,$tasklist,$workflowtype} by {workflowtype,env,domain,tasklist}.as_rate()\nsum:cadence_client.cadence_workflow_completed{$domain,$tasklist,$workflowtype} by {workflowtype,env,domain,tasklist}.as_rate()\nsum:cadence_client.cadence_workflow_canceled{$domain,$tasklist,$workflowtype} by {workflowtype,domain,env,tasklist}.as_rate()\nsum:cadence_client.cadence_workflow_continue_as_new{$domain,$tasklist,$workflowtype} by {workflowtype,domain,env,tasklist}.as_rate()\nsum:cadence_client.cadence_workflow_signal_with_start{$domain,$tasklist,$workflowtype} by {workflowtype,domain,env,tasklist}.as_rate()\n\n\n\n# workflow failure\n\n * metrics for all types of failures, including workflow failures(throw uncaught exceptions), workflow timeout and termination.\n * for timeout and termination, workflow worker doesn’t have a chance to emit metrics when it’s terminate, so the metric comes from the history service\n * monitor: application should set monitor on timeout and failure to make sure workflow are not failing. cancel/terminate are usually triggered by human intentionally.\n * when the metrics fire, go to cadence ui to find the failed workflows and investigate the workflow history to understand the type of failure\n * datadog query example\n\nsum:cadence_client.cadence_workflow_failed{$domain,$tasklist,$workflowtype} by {workflowtype,domain,env}.as_count()\nsum:cadence_history.workflow_failed{$domain,$workflowtype} by {domain,env,workflowtype}.as_count()\nsum:cadence_history.workflow_terminate{$domain,$workflowtype} by {domain,env,workflowtype}.as_count()\nsum:cadence_history.workflow_timeout{$domain,$workflowtype} by {domain,env,workflowtype}.as_count()\n\n\n\n# decision poll counters\n\n * indicates if the workflow worker is available and is polling tasks. if the worker is not available no counters will show. can also check if the worker is using the right task list. “no task” poll type means that the worker exists and is idle. the timeout for this long poll api is 50 seconds. if no task is received within 50 seconds, then an empty response will be returned and another long poll request will be sent.\n * monitor: application can should monitor on it to make sure workers are available\n * when fires, investigate the worker deployment to see why they are not available, also check if they are using the right domain/tasklist\n * datadog query example\n\nsum:cadence_client.cadence_decision_poll_total{$domain,$tasklist}.as_count()\nsum:cadence_client.cadence_decision_poll_failed{$domain,$tasklist}.as_count()\nsum:cadence_client.cadence_decision_poll_no_task{$domain,$tasklist}.as_count()\nsum:cadence_client.cadence_decision_poll_succeed{$domain,$tasklist}.as_count()\n\n\n\n# decisiontasks scheduled per second\n\n * indicate how many decision tasks are scheduled\n * monitor: not recommended -- information only to know whether or not a tasklist is overloaded\n * datadog query example\n\nsum:cadence_matching.cadence_requests_per_tl{*,operation:adddecisiontask,$tasklist,$domain} by {tasklist,domain}.as_rate()\n\n\n\n# decision scheduled to start latency\n\n * if this latency is too high then either: the worker is not available or too busy after the task has been scheduled. the task list is overloaded(confirmed by decisiontaskscheduled per second widget). by default a task list only has one partition and a partition can only be owned by one host and so the throughput of a task list is limited. more task lists can be added to scale or a scalable task list can be used to add more partitions.\n * monitor: application can set monitor on it to make sure latency is tolerable\n * when fired, check if worker capacity is enough, then check if tasklist is overloaded. if needed, contact the cadence cluster admin to enable scalable tasklist to add more partitions to the tasklist\n * datadog query example\n\navg:cadence_client.cadence_decision_scheduled_to_start_latency.avg{$domain,$tasklist} by {env,domain,tasklist}\nmax:cadence_client.cadence_decision_scheduled_to_start_latency.max{$domain,$tasklist} by {env,domain,tasklist}\nmax:cadence_client.cadence_decision_scheduled_to_start_latency.95percentile{$domain,$tasklist} by {env,domain,tasklist}\n\n\n\n# decision execution failure\n\n * this means some critical bugs in workflow code causing decision task execution failure\n * monitor: application should set monitor on it to make sure no consistent failure\n * when fired, you may need to terminate the problematic workflows to mitigate the issue. after you identify the bugs, you can fix the code and then reset the workflow to recover\n * datadog query example\n\nsum:cadence_client.cadence_decision_execution_failed{$domain,$tasklist} by {tasklist,workflowtype}.as_count()\n\n\n\n# decision execution timeout\n\n * this means some critical bugs in workflow code causing decision task execution timeout\n * monitor: application should set monitor on it to make sure no consistent timeout\n * when fired, you may need to terminate the problematic workflows to mitigate the issue. after you identify the bugs, you can fix the code and then reset the workflow to recover\n * datadog query example\n\nsum:cadence_history.start_to_close_timeout{operation:timeractivetaskdecision*,$domain}.as_count()\n\n\n\n# workflow end to end latency\n\n * this is for the client application to track their slos for example, if you expect a workflow to take duration d to complete, you can use this latency to set a monitor.\n * monitor: application can monitor this metrics if expecting workflow to complete within a certain duration.\n * when fired, investigate the workflow history to see the workflow takes longer than expected to complete\n * datadog query example\n\navg:cadence_client.cadence_workflow_endtoend_latency.median{$domain,$tasklist,$workflowtype} by {env,domain,tasklist,workflowtype}\navg:cadence_client.cadence_workflow_endtoend_latency.95percentile{$domain,$tasklist,$workflowtype} by {env,domain,tasklist,workflowtype}\n\n\n\n# workflow panic and nondeterministicerror\n\n * these errors mean that there is a bug in the code and the deploy should be rolled back.\n * a monitor should be set on this metric\n * when fired, you may rollback the deployment to mitigate your issue. usually this caused by bad (non-backward compatible) code change. after rollback, look at your worker error logs to see where the bug is.\n * datadog query example\n\nsum:cadence_client.cadence_worker_panic{$domain} by {env,domain}.as_rate()\nsum:cadence_client.cadence_non_deterministic_error{$domain} by {env,domain}.as_rate()\n\n\n\n# workflow sticky cache hit rate and miss count\n\n * this metric can be used for performance optimization. this can be improved by adding more worker instances, or adjust the workeroption(gosdk) or workferfactoryoption(java sdk). cachehitrate too low means workers will have to replay history to rebuild the workflow stack when executing a decision task. depending on the the history size\n   * if less than 1mb, then it’s okay to be lower than 50%\n   * if greater than 1mb, then it’s okay to be greater than 50%\n   * if greater than 5mb, , then it’s okay to be greater than 60%\n   * if greater than 10mb , then it’s okay to be greater than 70%\n   * if greater than 20mb , then it’s okay to be greater than 80%\n   * if greater than 30mb , then it’s okay to be greater than 90%\n   * workflow history size should never be greater than 50mb.\n * a monitor can be set on this metric, if performance is important.\n * when fired, adjust the stickycachesize in the workerfactoryoption, or add more workers\n * datadog query example\n\nsum:cadence_client.cadence_sticky_cache_miss{$domain} by {env,domain}.as_count()\nsum:cadence_client.cadence_sticky_cache_hit{$domain} by {env,domain}.as_count()\n(b / (a+b)) * 100\n\n\n\n# activity task operations\n\n * activity started/completed counters\n * monitor: not recommended\n * datadog query example\n\nsum:cadence_client.cadence_activity_task_failed{$domain,$tasklist} by {activitytype}.as_rate()\nsum:cadence_client.cadence_activity_task_completed{$domain,$tasklist} by {activitytype}.as_rate()\nsum:cadence_client.cadence_activity_task_timeouted{$domain,$tasklist} by {activitytype}.as_rate()\n\n\n\n# local activity task operations\n\n * local activity execution counters\n * monitor: not recommended\n * datadog query example\n\nsum:cadence_client.cadence_local_activity_total{$domain,$tasklist} by {activitytype}.as_count()\n\n\n\n# activity execution latency\n\n * if it’s expected that an activity will take x amount of time to complete, a monitor on this metric could be helpful to enforce that expectation.\n * monitor: application can set monitor on it if expecting workflow start/complete activities with certain latency\n * when fired, investigate the activity code and its dependencies\n * datadog query example\n\navg:cadence_client.cadence_activity_execution_latency.avg{$domain,$tasklist} by {env,domain,tasklist,activitytype}\nmax:cadence_client.cadence_activity_execution_latency.max{$domain,$tasklist} by {env,domain,tasklist,activitytype}\n\n\n\n# activity poll counters\n\n * indicates the activity worker is available and is polling tasks. if the worker is not available no counters will show. can also check if the worker is using the right task list. “no task” poll type means that the worker exists and is idle. the timeout for this long poll api is 50 seconds. if within that 50 seconds, no task is received then an empty response will be returned and another long poll request will be sent.\n * monitor: application can set monitor on it to make sure activity workers are available\n * when fires, investigate the worker deployment to see why they are not available, also check if they are using the right domain/tasklist\n * datadog query example\n\nsum:cadence_client.cadence_activity_poll_total{$domain,$tasklist} by {activitytype}.as_count()\nsum:cadence_client.cadence_activity_poll_failed{$domain,$tasklist} by {activitytype}.as_count()\nsum:cadence_client.cadence_activity_poll_succeed{$domain,$tasklist} by {activitytype}.as_count()\nsum:cadence_client.cadence_activity_poll_no_task{$domain,$tasklist} by {activitytype}.as_count()\n\n\n\n# activitytasks scheduled per second\n\n * indicate how many activities tasks are scheduled\n * monitor: not recommended -- information only to know whether or not a tasklist is overloaded\n * datadog query example\n\nsum:cadence_matching.cadence_requests_per_tl{*,operation:addactivitytask,$tasklist,$domain} by {tasklist,domain}.as_rate()\n\n\n\n# activity scheduled to start latency\n\n * if the latency is too high either: the worker is not available or too busy there are too many activities scheduled into the same tasklist and the tasklist is not scalable. same as decision scheduled to start latency\n * monitor: application should set monitor on it\n * when fired, check if workers are enough, then check if the tasklist is overloaded. if needed, contact the cadence cluster admin to enable scalable tasklist to add more partitions to the tasklist\n * datadog query example\n\navg:cadence_client.cadence_activity_scheduled_to_start_latency.avg{$domain,$tasklist} by {env,domain,tasklist,activitytype}\nmax:cadence_client.cadence_activity_scheduled_to_start_latency.max{$domain,$tasklist} by {env,domain,tasklist,activitytype}\nmax:cadence_client.cadence_activity_scheduled_to_start_latency.95percentile{$domain,$tasklist} by {env,domain,tasklist,activitytype}\n\n\n\n# activity failure\n\n * a monitor on this metric will alert the team that activities are failing the activity timeout metrics are emitted by the history service, because a timeout causes a hard stop and the client doesn’t have time to emit metrics.\n * monitor: application can set monitor on it\n * when fired, investigate the activity code and its dependencies\n * cadence_activity_execution_failed vs cadence_activity_task_failed: only have different when using retrypolicy cadence_activity_task_failed counter increase per activity attempt cadence_activity_execution_failed counter increase when activity fails after all attempts\n * should only monitor on cadence_activity_execution_failed\n * datadog query example\n\nsum:cadence_client.cadence_activity_execution_failed{$domain} by {domain,env}.as_rate()\nsum:cadence_client.cadence_activity_task_panic{$domain} by {domain,env}.as_count()\nsum:cadence_client.cadence_activity_task_failed{$domain} by {domain,env}.as_rate()\nsum:cadence_client.cadence_activity_task_canceled{$domain} by {domain,env}.as_count()\nsum:cadence_history.heartbeat_timeout{$domain} by {domain,env}.as_count()\nsum:cadence_history.schedule_to_start_timeout{$domain} by {domain,env}.as_rate()\nsum:cadence_history.start_to_close_timeout{$domain} by {domain,env}.as_rate()\nsum:cadence_history.schedule_to_close_timeout{$domain} by {domain,env}.as_count()\n\n\n\n# service api success rate\n\n * the client’s experience of the service availability. it encompasses many apis. things that could affect the service’s api success rate are:\n   * service availability\n   * the network could have issues.\n   * a required api is not available.\n   * client side errors like entitynotexists, workflowalreadystarted etc. this means that application code has potential bugs of calling cadence service.\n * monitor: application can set monitor on it\n * when fired, check application logs to see if the error is cadence server error or client side error. error like entitynotexists/executionalreadystarted/queryworkflowfailed/etc are client side error, meaning that the application is misusing the apis. if most errors are server side errors(internalserviceerror), you can contact cadence admin.\n * datadog query example\n\nsum:cadence_client.cadence_error{*} by {domain}.as_count()\nsum:cadence_client.cadence_request{*} by {domain}.as_count()\n(1 - a / b) * 100\n\n\n\n# service api latency\n\n * the latency of the api, excluding long poll apis.\n * application can set monitor on certain apis, if necessary.\n * datadog query example\n\navg:cadence_client.cadence_latency.95percentile{$domain,!cadence_metric_scope:cadence-pollforactivitytask,!cadence_metric_scope:cadence-pollfordecisiontask} by {cadence_metric_scope}\n\n\n\n# service api breakdown\n\n * a counter breakdown by api to help investigate availability\n * no monitor needed\n * datadog query example\n\nsum:cadence_client.cadence_request{$domain,!cadence_metric_scope:cadence-pollforactivitytask,!cadence_metric_scope:cadence-pollfordecisiontask} by {cadence_metric_scope}.as_count()\n\n\n\n# service api error breakdown\n\n * a counter breakdown by api error to help investigate availability\n * no monitor needed\n * datadog query example\n\nsum:cadence_client.cadence_error{$domain} by {cadence_metric_scope}.as_count()\n\n\n\n# max event blob size\n\n * by default the max size is 2 mb. if the input is greater than the max size the server will reject the request. the size of a single history event. this applies to any event input, like start workflow event, start activity event, or signal event. it should never be greater than 2mb.\n * a monitor should be set on this metric.\n * when fired, please review the design/code asap to reduce the blob size. reducing the input/output of workflow/activity/signal will help.\n * datadog query example\n\n​​max:cadence_history.event_blob_size.quantile{!domain:all,$domain} by {domain}\n\n\n\n# max history size\n\n * workflow history cannot grow indefinitely. it will cause replay issues. if the workflow exceeds the history’s max size the workflow will be terminate automatically. the max size by default is 200 megabytes. as a suggestion for workflow design, workflow history should never grow greater than 50mb. use continueasnew to break long workflows into multiple runs.\n * a monitor should be set on this metric.\n * when fired, please review the design/code asap to reduce the history size. reducing the input/output of workflow/activity/signal will help. also you may need to use continueasnew to break a single execution into smaller pieces.\n * datadog query example\n\n​​max:cadence_history.history_size.quantile{!domain:all,$domain} by {domain}\n\n\n\n# max history length\n\n * the number of events of workflow history. it should never be greater than 50k(workflow exceeding 200k events will be terminated by server). use continueasnew to break long workflows into multiple runs.\n * a monitor should be set on this metric.\n * when fired, please review the design/code asap to reduce the history length. you may need to use continueasnew to break a single execution into smaller pieces.\n * datadog query example\n\n​​max:cadence_history.history_count.quantile{!domain:all,$domain} by {domain}\n\n\n\n# cadence history service monitoring\n\nhistory is the most critical/core service for cadence which implements the workflow logic.\n\n\n# history shard movements\n\n * should only happen during deployment or when the node restarts. if there’s shard movement without deployments then that’s unexpected and there’s probably a performance issue. the shard ownership is assigned by a particular history host, so if the shard is moving it’ll be hard for the frontend service to route a request to a particular history shard and to find it.\n * a monitor can be set to be alerted on shard movements without deployment.\n * datadog query example\n\nsum:cadence_history.membership_changed_count{operation:shardcontroller}\nsum:cadence_history.shard_closed_count{operation:shardcontroller}\nsum:cadence_history.sharditem_created_count{operation:shardcontroller}\nsum:cadence_history.sharditem_removed_count{operation:shardcontroller}\n\n\n\n# transfer tasks per second\n\n * transfertask is an internal background task that moves workflow state and transfers an action task from the history engine to another service(e.g. matching service, elasticsearch, etc)\n * no monitor needed\n * datadog query example\n\nsum:cadence_history.task_requests{operation:transferactivetask*} by {operation}.as_rate()\n\n\n\n# timer tasks per second\n\n * timer tasks are tasks that are scheduled to be triggered at a given time in future. for example, workflow.sleep() will wait an x amount of time then the task will be pushed somewhere for a worker to pick up.\n * datadog query example\n\nsum:cadence_history.task_requests{operation:timeractivetask*} by {operation}.as_rate()\n\n\n\n# transfer tasks per domain\n\n * count breakdown by domain\n * datadog query example\n\nsum:cadence_history.task_requests_per_domain{operation:transferactive*} by {domain}.as_count()\n\n\n\n# timer tasks per domain\n\n * count breakdown by domain\n * datadog query example\n\nsum:cadence_history.task_requests_per_domain{operation:timeractive*} by {domain}.as_count()\n\n\n\n# transfer latency by type\n\n * if latency is too high then it’s an issue for a workflow. for example, if transfer task latency is 5 second, then it takes 5 second for activity/decision to actual receive the task.\n * monitor should be set on diffeernt types of latency. note that queue_latency can go very high during deployment and it's expected. see below note for explanation.\n * when fired, check if it’s due to some persistence issue. if so then investigate the database(may need to scale up) if not then see if need to scale up cadence deployment(k8s instance)\n * datadog query example\n\navg:cadence_history.task_latency.quantile{$pxxlatency,operation:transfer*} by {operation}\navg:cadence_history.task_latency_processing.quantile{$pxxlatency,operation:transfer*} by {operation}\navg:cadence_history.task_latency_queue.quantile{$pxxlatency,operation:transfer*} by {operation}\n\n\n\n# timer task latency by type\n\n * if latency is too high then it’s an issue for a workflow. for example, if you set the workflow.sleep() for 10 seconds and the timer latency is 5 secs then the workflow will sleep for 15 seconds.\n * monitor should be set on diffeernt types of latency.\n * when fired, check if it’s due to some persistence issue. if so then investigate the database(may need to scale up) [mostly] if not then see if need to scale up cadence deployment(k8s instance)\n * datadog query example\n\navg:cadence_history.task_latency.quantile{$pxxlatency,operation:timer*} by {operation}\navg:cadence_history.task_latency_processing.quantile{$pxxlatency,operation:timer*} by {operation}\navg:cadence_history.task_latency_queue.quantile{$pxxlatency,operation:timer*} by {operation}\n\n\n\n# note: task queue latency vs executing latency vs processing latency in transfer & timer task latency metrics\n\n * task_latency_queue: “queue latency” is “end to end” latency for users. the latency could go to several minutes during deployment because of metrics being re-emitted (but the actual latency is not that high)\n * task_latency: “executing latency” is the time from submission to executing pool to completion. it includes scheduling, retry and processing time of the task.\n * task_latency_processing: “processing latency” is the processing time of the task of a single attempt(without retry)\n\n\n# transfer task latency per domain\n\n * latency breakdown by domain\n * no monitor needed.\n * datadog query example: modify above queries to use domain tag.\n\n\n# timer task latency per domain\n\n * latency breakdown by domain\n * no monitor needed.\n * datadog query example: modify above queries to use domain tag.\n\n\n# history api per second\n\ninformation about history api datadog query example\n\nsum:cadence_history.cadence_requests{*} by {operation}.as_rate()\n\n\n\n# history api errors per second\n\n * information about history api\n * no monitor needed\n * datadog query example\n\nsum:cadence_history.cadence_errors{*} by {operation}.as_rate()\nsum:cadence_history.cadence_errors_bad_request{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_domain_not_active{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_service_busy{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_entity_not_exists{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_workflow_execution_already_completed{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_execution_already_started{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_domain_already_exists{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_cancellation_already_requested{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_query_failed{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_limit_exceeded{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_context_timeout{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_retry_task{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_bad_binary{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_client_version_not_supported{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_incomplete_history{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_nondeterministic{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_unauthorized{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_authorize_failed{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_remote_syncmatch_failed{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_domain_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_identity_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_workflow_id_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_signal_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_workflow_type_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_request_id_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_task_list_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_activity_id_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_activity_type_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_marker_name_exceeded_warn_limit{*} by {operation}.as_rate() \nsum:cadence_history.cadence_errors_timer_id_exceeded_warn_limit{*} by {operation}.as_rate() \n\n\n * cadence_errors is internal service errors.\n * any cadence_errors_* is client side error\n\n\n# max history size\n\nthe history size of the workflow cannot be too large otherwise it will cause performance issue during replay. the soft limit is 200mb. if exceeding workflow will be terminated by server.\n\n * no monitor needed\n * datadog query is same as the client section\n\n\n# max history length\n\nsimilarly, the history length of the workflow cannot be too large otherwise it will cause performance issues during replay. the soft limit is 200k events. if exceeding, workflow will be terminated by server.\n\n * no monitor needed\n * datadog query is same as the client section\n\n\n# max event blob size\n\n * the size of each event(e.g. decided by input/output of workflow/activity/signal/chidlworkflow/etc) cannot be too large otherwise it will also cause performance issue. the soft limit is 2mb. if exceeding, the requests will be rejected by server, meaning that workflow won’t be able to make any progress.\n * no monitor needed\n * datadog query is same as the client section\n\n\n# cadence matching service monitoring\n\nmatching service is to match/assign tasks from cadence service to workers. matching got the tasks from history service. if workers are active the task will be matched immediately , it’s called “sync match”. if workers are not available, matching will persist into database and then reload the tasks when workers are back(called “async match”)\n\n\n# matching apis per second\n\n * api processed by matching service per second\n * no monitor needed\n * datadog query example\n\nsum:cadence_matching.cadence_requests{*} by {operation}.as_rate()\n\n\n\n# matching api errors per second\n\n * api errors by matching service per second\n * no monitor needed\n * datadog query example\n\nsum:cadence_matching.cadence_errors_per_tl{*} by {operation,domain,tasklist}.as_rate()\nsum:cadence_matching.cadence_errors_bad_request_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_bad_request{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_domain_not_active_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_domain_not_active{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_service_busy_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_service_busy{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_entity_not_exists_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_entity_not_exists{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_execution_already_started_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_execution_already_started{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_domain_already_exists_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_domain_already_exists{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_cancellation_already_requested_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_cancellation_already_requested{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_query_failed_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_query_failed{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_limit_exceeded_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_limit_exceeded{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_context_timeout_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_context_timeout{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_retry_task_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_retry_task{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_bad_binary_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_bad_binary{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_client_version_not_supported_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_client_version_not_supported{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_incomplete_history_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_incomplete_history{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_nondeterministic_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_nondeterministic{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_unauthorized_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_unauthorized{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_authorize_failed_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_authorize_failed{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_remote_syncmatch_failed_per_tl{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_remote_syncmatch_failed{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_shard_ownership_lost{*} by {operation,domain,tasklist}\nsum:cadence_matching.cadence_errors_event_already_started{*} by {operation,domain,tasklist}\n\n\n * cadence_errors is internal service errors.\n * any cadence_errors_* is client side error\n\n\n# matching regular api latency\n\n * regular apis are the apis excluding long polls\n * no monitor needed\n * datadog query example\n\navg:cadence_matching.cadence_latency_per_tl.quantile{$pxxlatency,!operation:pollfor*,!operation:queryworkflow} by {operation,tasklist}\n\n\n\n# sync match latency:\n\n * if the latency is too high, probably the tasklist is overloaded. consider using multiple tasklist, or enable scalable tasklist feature by adding more partition to the tasklist(default is one) to confirm if there are too many tasks being added to the tasklist, use “addtasks per second - domain, tasklist breakdown”\n * no monitor needed\n * datadog query example\n\nsum:cadence_matching.syncmatch_latency_per_tl.quantile{$pxxlatency} by {operation,tasklist,domain}\n\n\n\n# async match latency\n\n * if a match is done asynchronously it writes a match to the db to use later. measures the time when the worker is not actively looking for tasks. if this is high, more workers are needed.\n * no monitor needed\n * datadog query example\n\nsum:cadence_matching.asyncmatch_latency_per_tl.quantile{$pxxlatency} by {operation,tasklist,domain}\n\n\n\n# cadence default persistence monitoring\n\nthe following monotors should be set up for cadence persistence.\n\n\n# persistence availability\n\n * the availability of the primary database for your cadence server\n * monitor required: below 95% > 5min then alert, below 99% triggers a slack warning\n * when fired, check if it’s due to some persistence issue. if so then investigate the database(may need to scale up) [mostly] if not then see if need to scale up cadence deployment(k8s instance)\n * datadog query example\n\nsum:cadence_frontend.persistence_errors{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_requests{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors{*} by {operation}.as_count()\nsum:cadence_matching.persistence_requests{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors{*} by {operation}.as_count()\nsum:cadence_history.persistence_requests{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors{*} by {operation}.as_count()\nsum:cadence_worker.persistence_requests{*} by {operation}.as_count()\n(1 - a / b) * 100\n(1 - c / d) * 100\n(1 - e / f) * 100\n(1 - g / h) * 100\n\n\n\n# persistence by service tps\n\n * no monitor needed\n * datadog query example\n\nsum:cadence_frontend.persistence_requests{*}.as_rate()\nsum:cadence_history.persistence_requests{*}.as_rate()\nsum:cadence_worker.persistence_requests{*}.as_rate()\nsum:cadence_matching.persistence_requests{*}.as_rate()\n\n\n\n\n# persistence by operation tps\n\n * no monitor needed\n * datadog query example\n\nsum:cadence_frontend.persistence_requests{*} by {operation}.as_rate()\nsum:cadence_history.persistence_requests{*} by {operation}.as_rate()\nsum:cadence_worker.persistence_requests{*} by {operation}.as_rate()\nsum:cadence_matching.persistence_requests{*} by {operation}.as_rate()\n\n\n\n\n# persistence by operation latency\n\n * monitor required, alert if 95% of all operation latency is greater than 1 second for 5mins, warning if greater than 0.5 seconds\n * when fired, investigate the database(may need to scale up) [mostly] if there’s a high latency, then there could be errors or something wrong with the db\n * datadog query example\n\navg:cadence_matching.persistence_latency.quantile{$pxxlatency} by {operation}\navg:cadence_worker.persistence_latency.quantile{$pxxlatency} by {operation}\navg:cadence_frontend.persistence_latency.quantile{$pxxlatency} by {operation}\navg:cadence_history.persistence_latency.quantile{$pxxlatency} by {operation}\n\n\n\n# persistence error by operation count\n\n * it's to help investigate availability issue\n * no monitor needed\n * datadog query example\n\nsum:cadence_frontend.persistence_errors{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors{*} by {operation}.as_count()\n\nsum:cadence_frontend.persistence_errors_shard_exists{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_shard_ownership_lost{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_condition_failed{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_current_workflow_condition_failed{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_timeout{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_busy{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_entity_not_exists{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_execution_already_started{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_domain_already_exists{*} by {operation}.as_count()\nsum:cadence_frontend.persistence_errors_bad_request{*} by {operation}.as_count()\n\nsum:cadence_history.persistence_errors_shard_exists{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_shard_ownership_lost{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_condition_failed{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_current_workflow_condition_failed{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_timeout{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_busy{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_entity_not_exists{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_execution_already_started{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_domain_already_exists{*} by {operation}.as_count()\nsum:cadence_history.persistence_errors_bad_request{*} by {operation}.as_count()\n\nsum:cadence_matching.persistence_errors_shard_exists{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_shard_ownership_lost{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_condition_failed{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_current_workflow_condition_failed{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_timeout{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_busy{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_entity_not_exists{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_execution_already_started{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_domain_already_exists{*} by {operation}.as_count()\nsum:cadence_matching.persistence_errors_bad_request{*} by {operation}.as_count()\n\nsum:cadence_worker.persistence_errors_shard_exists{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_shard_ownership_lost{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_condition_failed{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_current_workflow_condition_failed{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_timeout{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_busy{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_entity_not_exists{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_execution_already_started{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_domain_already_exists{*} by {operation}.as_count()\nsum:cadence_worker.persistence_errors_bad_request{*} by {operation}.as_count()\n\n\n\n * cadence_errors is internal service errors.\n * any cadence_errors_* is client side error\n\n\n# cadence advanced visibility persistence monitoring(if applicable)\n\nkafka & elasticsearch are only for visibility. only applicable if using advanced visibility. for writing visibility records, cadence history service will write down the records into kafka, and then cadence worker service will read from kafka and write into elasticsearch(in batch, for performance optimization) for reading visibility records, frontend service will query elasticsearch directly.\n\n\n# persistence availability\n\n * the availability of cadence server using database\n * monitor can be set\n * datadog query example\n\nsum:cadence_frontend.elasticsearch_errors{*} by {operation}.as_count()\nsum:cadence_frontend.elasticsearch_requests{*} by {operation}.as_count()\nsum:cadence_history.elasticsearch_errors{*} by {operation}.as_count()\nsum:cadence_history.elasticsearch_requests{*} by {operation}.as_count()\n(1 - a / b) * 100\n(1 - c / d) * 100\n\n\n\n# persistence by service tps\n\n * the error of persistence api call by service\n * no monitor needed\n * datadog query example\n\nsum:cadence_frontend.elasticsearch_requests{*}.as_rate()\nsum:cadence_history.elasticsearch_requests{*}.as_rate()\n\n\n\n# persistence by operation tps(read: es, write: kafka)\n\n * the rate of persistence api call by api\n * no monitor needed\n * datadog query example\n\nsum:cadence_frontend.elasticsearch_requests{*} by {operation}.as_rate()\nsum:cadence_history.elasticsearch_requests{*} by {operation}.as_rate()\n\n\n\n# persistence by operation latency(in seconds) (read: es, write: kafka)\n\n * the latency of persistence api call\n * no monitor needed\n * datadog query example\n\navg:cadence_frontend.elasticsearch_latency.quantile{$pxxlatency} by {operation}\navg:cadence_history.elasticsearch_latency.quantile{$pxxlatency} by {operation}\n\n\n\n# persistence error by operation count (read: es, write: kafka)\n\n * the error of persistence api call\n * no monitor needed\n * datadog query example\n\nsum:cadence_frontend.elasticsearch_errors{*} by {operation}.as_count()\nsum:cadence_history.elasticsearch_errors{*} by {operation}.as_count()\n\n\n\n# kafka->es processor counter\n\n * this is the metrics of a background processing: consuming kafka messages and then populate to elasticsearch in batch\n * monitor on the running of the background processing(counter metrics is > 0)\n * when fired, restart cadence service first to mitigate. then look at logs to see why the process is stopped(process panic/error/etc). may consider add more pods (replicacount) to sys-worker service for higher availability\n * datadog query example\n\nsum:cadence_worker.es_processor_requests{*} by {operation}.as_count()\nsum:cadence_worker.es_processor_retries{*} by {operation}.as_count()\n\n\n\n# kafka->es processor error\n\n * this is the error metrics of the above processing logic almost all errors are retryable errors so it’s not a problem.\n * need to monitor error\n * when fired, go to kibana to find logs about the error details. the most common error is missing the elasticsearch index field -- an index field is added in dynamicconfig but not in elasticsearch, or vice versa . if so, follow the runbook to add the field to elasticsearch or dynamic config.\n * datadog query example\n\nsum:cadence_worker.es_processor_error{*} by {operation}.as_count()\nsum:cadence_worker.es_processor_corrupted_data{*} by {operation}.as_count()\n\n\n\n# kafka->es processor latency\n\n * the latency of the processing logic\n * no monitor needed\n * datadog query example\n\nsum:cadence_worker.es_processor_process_msg_latency.quantile{$pxxlatency} by {operation}.as_count()\n\n\n\n# cadence dependency metrics monitor suggestion\n\n\n# computing platform metrics for cadence deployment\n\ncadence server being deployed on any computing platform(e.g. kubernetese) should be monitored on the blow metrics:\n\n * cpu\n * memory\n\n\n# database\n\ndepends on which database, you should at least monitor on the below metrics\n\n * disk usage\n * cpu\n * memory\n * read api latency\n * write api latency\n\n\n# kafka (if applicable)\n\n * disk usage\n * cpu\n * memory\n\n\n# elasticsearch (if applicable)\n\n * disk usage\n * cpu\n * memory\n\n\n# cadence service slo recommendation\n\n * core api availability: 99.9%\n * core api latency: <1s\n * overall task dispatch latency: <2s (queue_latency for transfer task and timer task)",charsets:{}},{title:"Cluster Troubleshooting",frontmatter:{layout:"default",title:"Cluster Troubleshooting",permalink:"/docs/operation-guide/troubleshooting",readingShow:"top"},regularPath:"/docs/07-operation-guide/04-troubleshooting.html",relativePath:"docs/07-operation-guide/04-troubleshooting.md",key:"v-6f38e6b6",path:"/docs/operation-guide/troubleshooting/",headers:[{level:2,title:"Errors",slug:"errors",normalizedTitle:"errors",charIndex:292},{level:2,title:"API high latency, timeout, Task disptaching slowness Or Too many operations onto DB and timeouts",slug:"api-high-latency-timeout-task-disptaching-slowness-or-too-many-operations-onto-db-and-timeouts",normalizedTitle:"api high latency, timeout, task disptaching slowness or too many operations onto db and timeouts",charIndex:1003}],codeSwitcherOptions:{},headersStr:"Errors API high latency, timeout, Task disptaching slowness Or Too many operations onto DB and timeouts",content:'# Cluster Troubleshooting\n\nThis section is to cover some common operation issues as a RunBook. Feel free to add more, or raise issues in the to ask for more in cadence-docs project.Or talk to us in Slack support channel!\n\nWe will keep adding more stuff. Any contribution is very welcome.\n\n\n# Errors\n\n * Persistence Max QPS Reached for List Operations\n   * Check metrics to see how many List operations are performed per second on the domain. Alternatively you can enable debug log level to see more details of how a List request is ratelimited, if it\'s a staging/QA cluster.\n   * Raise the ratelimiting for the domain if you believe the default ratelimit is too low\n * Failed to lock shard. Previous range ID: 132; new range ID: 133 and Failed to update shard. Previous range ID: 210; new range ID: 212\n   * When this keep happening, it\'s very likely a critical configuration error. Either there are two clusters using the same database, or two clusters are using the same ringpop(bootstrap hosts).\n\n\n# API high latency, timeout, Task disptaching slowness Or Too many operations onto DB and timeouts\n\n * If it happens after you attemped to truncate tables inorder to reuse the same database/keyspace for a new cluster, it\'s possible that the data is not deleted completely. You should make sure to shutdown the Cadence when trucating, and make sure the database is cleaned. Alternatively, use a different keyspace/database is a safer way.\n\n * Timeout pushing task to matching engine, e.g. "Fail to process task","service":"cadence-history","shard-id":431,"address":"172.31.48.64:7934","component":"transfer-queue-processor","cluster-name":"active","shard-id":431,"queue-task-id":590357768,"queue-task-visibility-timestamp":1637356594382077880,"xdc-failover-version":-24,"queue-task-type":0,"wf-domain-id":"f4d6824f-9d24-4a82-81e0-e0e080be4c21","wf-id":"55d64d58-e398-4bf5-88bc-a4696a2ba87f:63ed7cda-afcf-41cd-9d5a-ee5e1b0f2844","wf-run-id":"53b52ee0-3218-418e-a9bf-7768e671f9c1","error":"code:deadline-exceeded message:timeout","lifecycle":"ProcessingFailed","logging-call-at":"task.go:331"\n   \n   * If this happens after traffic increased for a certain domain, it\'s likely that a tasklist is overloaded. Consider scale up the tasklist\n\n * If the request volume aligned with the traffic increased on all domain, consider scale up the cluster',normalizedContent:'# cluster troubleshooting\n\nthis section is to cover some common operation issues as a runbook. feel free to add more, or raise issues in the to ask for more in cadence-docs project.or talk to us in slack support channel!\n\nwe will keep adding more stuff. any contribution is very welcome.\n\n\n# errors\n\n * persistence max qps reached for list operations\n   * check metrics to see how many list operations are performed per second on the domain. alternatively you can enable debug log level to see more details of how a list request is ratelimited, if it\'s a staging/qa cluster.\n   * raise the ratelimiting for the domain if you believe the default ratelimit is too low\n * failed to lock shard. previous range id: 132; new range id: 133 and failed to update shard. previous range id: 210; new range id: 212\n   * when this keep happening, it\'s very likely a critical configuration error. either there are two clusters using the same database, or two clusters are using the same ringpop(bootstrap hosts).\n\n\n# api high latency, timeout, task disptaching slowness or too many operations onto db and timeouts\n\n * if it happens after you attemped to truncate tables inorder to reuse the same database/keyspace for a new cluster, it\'s possible that the data is not deleted completely. you should make sure to shutdown the cadence when trucating, and make sure the database is cleaned. alternatively, use a different keyspace/database is a safer way.\n\n * timeout pushing task to matching engine, e.g. "fail to process task","service":"cadence-history","shard-id":431,"address":"172.31.48.64:7934","component":"transfer-queue-processor","cluster-name":"active","shard-id":431,"queue-task-id":590357768,"queue-task-visibility-timestamp":1637356594382077880,"xdc-failover-version":-24,"queue-task-type":0,"wf-domain-id":"f4d6824f-9d24-4a82-81e0-e0e080be4c21","wf-id":"55d64d58-e398-4bf5-88bc-a4696a2ba87f:63ed7cda-afcf-41cd-9d5a-ee5e1b0f2844","wf-run-id":"53b52ee0-3218-418e-a9bf-7768e671f9c1","error":"code:deadline-exceeded message:timeout","lifecycle":"processingfailed","logging-call-at":"task.go:331"\n   \n   * if this happens after traffic increased for a certain domain, it\'s likely that a tasklist is overloaded. consider scale up the tasklist\n\n * if the request volume aligned with the traffic increased on all domain, consider scale up the cluster',charsets:{}},{title:"Overview",frontmatter:{layout:"default",title:"Overview",permalink:"/docs/operation-guide",readingShow:"top"},regularPath:"/docs/07-operation-guide/",relativePath:"docs/07-operation-guide/index.md",key:"v-fc381aca",path:"/docs/operation-guide/",codeSwitcherOptions:{},headersStr:null,content:"# Operation Guide Overview\n\nThis document will cover things that you need to know to run a Cadence cluster in production. Topics including: setup, monitoring, maintenance and troubleshooting.",normalizedContent:"# operation guide overview\n\nthis document will cover things that you need to know to run a cadence cluster in production. topics including: setup, monitoring, maintenance and troubleshooting.",charsets:{}},{title:"Cluster Migration",frontmatter:{layout:"default",title:"Cluster Migration",permalink:"/docs/operation-guide/migration",readingShow:"top"},regularPath:"/docs/07-operation-guide/05-migration.html",relativePath:"docs/07-operation-guide/05-migration.md",key:"v-3569388c",path:"/docs/operation-guide/migration/",headers:[{level:2,title:"Migrate with naive approach",slug:"migrate-with-naive-approach",normalizedTitle:"migrate with naive approach",charIndex:397},{level:2,title:"Migrate with Global Domain Replication feature",slug:"migrate-with-global-domain-replication-feature",normalizedTitle:"migrate with global domain replication feature",charIndex:1261},{level:3,title:"Step 0 - Verify clusters' setup is correct",slug:"step-0-verify-clusters-setup-is-correct",normalizedTitle:"step 0 - verify clusters' setup is correct",charIndex:1513},{level:3,title:"Step 1 - Connect the two clusters using global domain(replication) feature",slug:"step-1-connect-the-two-clusters-using-global-domain-replication-feature",normalizedTitle:"step 1 - connect the two clusters using global domain(replication) feature",charIndex:2793},{level:3,title:"Step 2 - Test Replicating one domain",slug:"step-2-test-replicating-one-domain",normalizedTitle:"step 2 - test replicating one domain",charIndex:5051},{level:3,title:"Step 3 - Start to replicate all domains",slug:"step-3-start-to-replicate-all-domains",normalizedTitle:"step 3 - start to replicate all domains",charIndex:7266},{level:3,title:"Step 4 - Complete the migration",slug:"step-4-complete-the-migration",normalizedTitle:"step 4 - complete the migration",charIndex:8110}],codeSwitcherOptions:{},headersStr:"Migrate with naive approach Migrate with Global Domain Replication feature Step 0 - Verify clusters' setup is correct Step 1 - Connect the two clusters using global domain(replication) feature Step 2 - Test Replicating one domain Step 3 - Start to replicate all domains Step 4 - Complete the migration",content:'# Migrate Cadence cluster.\n\nThere could be some reasons that you need to migrate Cadence clusters:\n\n * Migrate to different storage, for example from Postgres/MySQL to Cassandra, or using multiple SQL database as a sharded SQL cluster for Cadence\n * Split traffic\n * Datacenter migration\n * Scale up -- to change numOfHistoryShards.\n\nBelow is two different approaches for migrating a cluster.\n\n\n# Migrate with naive approach\n\n 1. Set up a new Cadence cluster\n 2. Connect client workers to both old and new clusters\n 3. Change workflow code to start new workflows only in the new cluster\n 4. Wait for all old workflows to finish in the old cluster\n 5. Shutdown the old Cadence cluster and stop the client workers from connecting to it.\n\nNOTE 1: With this approach, workflow history/visibility will not be migrated to new cluster.\n\nNOTE 2: This is the only way to migrate a local domain, because a local domain cannot be converted to a global domain, even after a cluster enables XDC feature.\n\nNOTE 3: Starting from version 0.22.0, global domain is preferred/recommended. Please ensure you create and use global domains only. If you are using local domains, an easy way is to create a global domain and migrate to the new global domain using the above steps.\n\n\n# Migrate with Global Domain Replication feature\n\nNOTE 1: If a domain are NOT a global domain, you cannot use the XDC feature to migrate. The only way is to migrate in a naive approach\n\nNOTE 2: Only migrating to the same numHistoryShards is allowed.\n\n\n# Step 0 - Verify clusters\' setup is correct\n\n * Make sure the new cluster doesn’t already have the domain names that needs to be migrated (otherwise domain replication would fail).\n\nTo get all the domains from current cluster:\n\ncadence --address <currentClusterAddress> admin domain list\n\n\nThen For each global domain\n\ncadence --address <newClusterAddress> --do <domain_name> domain describe\n\n\nto make sure it doesn\'t exist in the new cluster.\n\n * Target replication cluster should have numHistoryShards >= source cluster\n\n * Target cluster should have the same search attributes enabled in dynamic configuration and in ElasticSearch.\n   \n   * Check the dynamic configuration to see if they have the same list of frontend.validSearchAttributes. If any is missing in the new cluster, update the dynamic config for the new cluster.\n   \n   * Check results of the below command to make sure that the ES fields matched with the dynamic configuration\n\ncurl -u <UNAME>:<PW> -X GET https://<ES_HOST_OF_NEW_CLUSTER>/cadence-visibility-index  -H \'Content-Type: application/json\'| jq .\n\n\nIf any search attribute is missing, add the missing search attributes to target cluster.\n\ncadence --address <newClusterAddress> adm cluster add-search-attr --search_attr_key <> --search_attr_type <>\n\n\n\n# Step 1 - Connect the two clusters using global domain(replication) feature\n\nInclude the Cluster Information for both the old and new clusters in the ClusterMetadata config of both clusters. Example config for currentCluster\n\ndcRedirectionPolicy:\n  policy: "all-domain-apis-forwarding" # use selected-apis-forwarding if using older versions don\'t support this policy\n\nclusterMetadata:\n  enableGlobalDomain: true\n  failoverVersionIncrement: 10\n  masterClusterName: "<newClusterName>"\n  currentClusterName: "<currentClusterName>"\n  clusterInformation:\n    <currentClusterName>:\n      enabled: true\n      initialFailoverVersion: 1\n      rpcName: "cadence-frontend"\n      rpcAddress: "<currentClusterAddress>"\n    <newClusterName>:\n      enabled: true\n      initialFailoverVersion: 0\n      rpcName: "cadence-frontend"\n      rpcAddress: "<newClusterAddress>"\n\n\nfor newClusterName:\n\ndcRedirectionPolicy:\n  policy: "all-domain-apis-forwarding"\n\nclusterMetadata:\n  enableGlobalDomain: true\n  failoverVersionIncrement: 10\n  masterClusterName: "<newClusterName>"\n  currentClusterName: "<newClusterName>"\n  clusterInformation:\n    <currentClusterName>:\n      enabled: true\n      initialFailoverVersion: 1\n      rpcName: "cadence-frontend"\n      rpcAddress: "<currentClusterAddress>"\n    <newClusterName>:\n      enabled: true\n      initialFailoverVersion: 0\n      rpcName: "cadence-frontend"\n      rpcAddress: "<newClusterAddress>"\n\n\nDeploy the config. In older versions(<= v0.22), only selected-apis-forwarding is supported. This would require you to deploy a different set of workflow/activity connected to the new Cadence cluster during migration, if high availability/seamless migration is required. Because selected-apis-forwarding only forwarding the non-worker APIs.\n\nWith all-domain-apis-forwarding policy, all worker + non-worker APIs are forwarded by Cadence cluster. You don\'t need to make any deployment change to your workflow/activity workers during migration. Once migration, let all workers connect to the new Cadence cluster before removing/shutdown the old cluster.\n\nTherefore, it\'s recommended to upgrade your Cadence cluster to a higher version with all-domain-apis-forwarding policy supported. The below steps assuming you are using this policy.\n\n\n# Step 2 - Test Replicating one domain\n\nFirst of all, try replicating a single domain to make sure everything work. Here uses domain update to failover, you can also use managed failover feature to failover. You may use some testing domains for this like cadence-canary.\n\n * 2.1 Assuming the domain only contain currentCluster in the cluster list, let\'s add the new cluster to the domain.\n\ncadence --address <currentClusterAddress> --do <domain_name> domain update --clusters <currentClusterName> <newClusterName>\n\n\nRun the command below to refresh the domain after adding a new cluster to the cluster list; we need to update the active_cluster to the same value that it appears to be.\n\ncadence --address <currentClusterAddress> --do <domain_name> domain update --active_cluster <currentClusterName>\n\n\n * 2.2 failover the domain to be active in new cluster\n\ncadence --address <currentClusterAddress> --do workflow-prototype domain update --active_cluster <newClusterName>\n\n\nUse the domain describe command to verify the entire domain is replicated to the new cluster.\n\ncadence --address <newClusterAddress> --do <domain_name> domain describe\n\n\nFind an open workflowID that we want to replicate (you can get it from the UI). Use this command to describe it to make sure it’s open and running:\n\ncadence --address <initialClusterAddress> --do <domain_name> workflow describe --workflow_id <wfID>\n\n\nRun a signal command against any workflow and check that it was replicated to the new cluster. Example:\n\ncadence --address <initialClusterAddress> --do <domain_name> workflow signal --workflow_id <wfID> --name <anything not functional, e.g. replicationTriggeringSignal>\n\n\nThis command will send a noop signal to workflows to trigger a decision, which will trigger history replication if needed.\n\nVerify the workflow is replicated in the new cluster\n\ncadence --address <newClusterAddress> --st <adminOperationToken> --do <domain_name> workflow describe --workflow_id <wfID>\n\n\nAlso compare the history between the two clusters:\n\ncadence --address <newClusterAddress> --do <domain_name> workflow show --workflow_id <wfID>\n\n\ncadence --address <initialClusterAddress> --do <domain_name> workflow show --workflow_id <wfID>\n\n\n\n# Step 3 - Start to replicate all domains\n\nYou can repeat Step 2 for all the domains. Or you can use the managed failover feature to failover all the domains in the cluster with a single command. See more details in the global domain documentation.\n\nBecause replication cannot be triggered without a decision. Again best way is to send a garbage signal to all the workflows.\n\nIf advanced visibility is enabled, then use batch signal command to start a batch job to trigger replication for all open workflows:\n\ncadence --address <initialClusterAddress> --do <domain_name> workflow batch start --batch_type signal --query “CloseTime = missing” --signal_name <anything, e.g. xdcTest> --reason <anything> --input <anything> --yes\n\n\nWatch metrics & dashboard while this is happening. Also observe the signal batch job to make sure it\'s completed.\n\n\n# Step 4 - Complete the migration\n\nAfter a few days, make sure everything is stable on the new cluster. The old cluster should only be forwarding requests to new cluster.\n\nA few things need to do in order to shutdown the old cluster.\n\n * Migrate all applications to connect to the frontend of new cluster instead of relying on the forwarding\n * Watch metric dashboard to make sure no any traffic is happening on the old cluster\n * Delete the old cluster from domain cluster list. This needs to be done for every domain.\n\ncadence --address <newHostAddress> --do <domain_name> domain update --clusters <newClusterName>\n\n\n * Delete the old cluster from the configuration of the new cluster.\n\nOnce above is done, you can shutdown the old cluster safely.',normalizedContent:'# migrate cadence cluster.\n\nthere could be some reasons that you need to migrate cadence clusters:\n\n * migrate to different storage, for example from postgres/mysql to cassandra, or using multiple sql database as a sharded sql cluster for cadence\n * split traffic\n * datacenter migration\n * scale up -- to change numofhistoryshards.\n\nbelow is two different approaches for migrating a cluster.\n\n\n# migrate with naive approach\n\n 1. set up a new cadence cluster\n 2. connect client workers to both old and new clusters\n 3. change workflow code to start new workflows only in the new cluster\n 4. wait for all old workflows to finish in the old cluster\n 5. shutdown the old cadence cluster and stop the client workers from connecting to it.\n\nnote 1: with this approach, workflow history/visibility will not be migrated to new cluster.\n\nnote 2: this is the only way to migrate a local domain, because a local domain cannot be converted to a global domain, even after a cluster enables xdc feature.\n\nnote 3: starting from version 0.22.0, global domain is preferred/recommended. please ensure you create and use global domains only. if you are using local domains, an easy way is to create a global domain and migrate to the new global domain using the above steps.\n\n\n# migrate with global domain replication feature\n\nnote 1: if a domain are not a global domain, you cannot use the xdc feature to migrate. the only way is to migrate in a naive approach\n\nnote 2: only migrating to the same numhistoryshards is allowed.\n\n\n# step 0 - verify clusters\' setup is correct\n\n * make sure the new cluster doesn’t already have the domain names that needs to be migrated (otherwise domain replication would fail).\n\nto get all the domains from current cluster:\n\ncadence --address <currentclusteraddress> admin domain list\n\n\nthen for each global domain\n\ncadence --address <newclusteraddress> --do <domain_name> domain describe\n\n\nto make sure it doesn\'t exist in the new cluster.\n\n * target replication cluster should have numhistoryshards >= source cluster\n\n * target cluster should have the same search attributes enabled in dynamic configuration and in elasticsearch.\n   \n   * check the dynamic configuration to see if they have the same list of frontend.validsearchattributes. if any is missing in the new cluster, update the dynamic config for the new cluster.\n   \n   * check results of the below command to make sure that the es fields matched with the dynamic configuration\n\ncurl -u <uname>:<pw> -x get https://<es_host_of_new_cluster>/cadence-visibility-index  -h \'content-type: application/json\'| jq .\n\n\nif any search attribute is missing, add the missing search attributes to target cluster.\n\ncadence --address <newclusteraddress> adm cluster add-search-attr --search_attr_key <> --search_attr_type <>\n\n\n\n# step 1 - connect the two clusters using global domain(replication) feature\n\ninclude the cluster information for both the old and new clusters in the clustermetadata config of both clusters. example config for currentcluster\n\ndcredirectionpolicy:\n  policy: "all-domain-apis-forwarding" # use selected-apis-forwarding if using older versions don\'t support this policy\n\nclustermetadata:\n  enableglobaldomain: true\n  failoverversionincrement: 10\n  masterclustername: "<newclustername>"\n  currentclustername: "<currentclustername>"\n  clusterinformation:\n    <currentclustername>:\n      enabled: true\n      initialfailoverversion: 1\n      rpcname: "cadence-frontend"\n      rpcaddress: "<currentclusteraddress>"\n    <newclustername>:\n      enabled: true\n      initialfailoverversion: 0\n      rpcname: "cadence-frontend"\n      rpcaddress: "<newclusteraddress>"\n\n\nfor newclustername:\n\ndcredirectionpolicy:\n  policy: "all-domain-apis-forwarding"\n\nclustermetadata:\n  enableglobaldomain: true\n  failoverversionincrement: 10\n  masterclustername: "<newclustername>"\n  currentclustername: "<newclustername>"\n  clusterinformation:\n    <currentclustername>:\n      enabled: true\n      initialfailoverversion: 1\n      rpcname: "cadence-frontend"\n      rpcaddress: "<currentclusteraddress>"\n    <newclustername>:\n      enabled: true\n      initialfailoverversion: 0\n      rpcname: "cadence-frontend"\n      rpcaddress: "<newclusteraddress>"\n\n\ndeploy the config. in older versions(<= v0.22), only selected-apis-forwarding is supported. this would require you to deploy a different set of workflow/activity connected to the new cadence cluster during migration, if high availability/seamless migration is required. because selected-apis-forwarding only forwarding the non-worker apis.\n\nwith all-domain-apis-forwarding policy, all worker + non-worker apis are forwarded by cadence cluster. you don\'t need to make any deployment change to your workflow/activity workers during migration. once migration, let all workers connect to the new cadence cluster before removing/shutdown the old cluster.\n\ntherefore, it\'s recommended to upgrade your cadence cluster to a higher version with all-domain-apis-forwarding policy supported. the below steps assuming you are using this policy.\n\n\n# step 2 - test replicating one domain\n\nfirst of all, try replicating a single domain to make sure everything work. here uses domain update to failover, you can also use managed failover feature to failover. you may use some testing domains for this like cadence-canary.\n\n * 2.1 assuming the domain only contain currentcluster in the cluster list, let\'s add the new cluster to the domain.\n\ncadence --address <currentclusteraddress> --do <domain_name> domain update --clusters <currentclustername> <newclustername>\n\n\nrun the command below to refresh the domain after adding a new cluster to the cluster list; we need to update the active_cluster to the same value that it appears to be.\n\ncadence --address <currentclusteraddress> --do <domain_name> domain update --active_cluster <currentclustername>\n\n\n * 2.2 failover the domain to be active in new cluster\n\ncadence --address <currentclusteraddress> --do workflow-prototype domain update --active_cluster <newclustername>\n\n\nuse the domain describe command to verify the entire domain is replicated to the new cluster.\n\ncadence --address <newclusteraddress> --do <domain_name> domain describe\n\n\nfind an open workflowid that we want to replicate (you can get it from the ui). use this command to describe it to make sure it’s open and running:\n\ncadence --address <initialclusteraddress> --do <domain_name> workflow describe --workflow_id <wfid>\n\n\nrun a signal command against any workflow and check that it was replicated to the new cluster. example:\n\ncadence --address <initialclusteraddress> --do <domain_name> workflow signal --workflow_id <wfid> --name <anything not functional, e.g. replicationtriggeringsignal>\n\n\nthis command will send a noop signal to workflows to trigger a decision, which will trigger history replication if needed.\n\nverify the workflow is replicated in the new cluster\n\ncadence --address <newclusteraddress> --st <adminoperationtoken> --do <domain_name> workflow describe --workflow_id <wfid>\n\n\nalso compare the history between the two clusters:\n\ncadence --address <newclusteraddress> --do <domain_name> workflow show --workflow_id <wfid>\n\n\ncadence --address <initialclusteraddress> --do <domain_name> workflow show --workflow_id <wfid>\n\n\n\n# step 3 - start to replicate all domains\n\nyou can repeat step 2 for all the domains. or you can use the managed failover feature to failover all the domains in the cluster with a single command. see more details in the global domain documentation.\n\nbecause replication cannot be triggered without a decision. again best way is to send a garbage signal to all the workflows.\n\nif advanced visibility is enabled, then use batch signal command to start a batch job to trigger replication for all open workflows:\n\ncadence --address <initialclusteraddress> --do <domain_name> workflow batch start --batch_type signal --query “closetime = missing” --signal_name <anything, e.g. xdctest> --reason <anything> --input <anything> --yes\n\n\nwatch metrics & dashboard while this is happening. also observe the signal batch job to make sure it\'s completed.\n\n\n# step 4 - complete the migration\n\nafter a few days, make sure everything is stable on the new cluster. the old cluster should only be forwarding requests to new cluster.\n\na few things need to do in order to shutdown the old cluster.\n\n * migrate all applications to connect to the frontend of new cluster instead of relying on the forwarding\n * watch metric dashboard to make sure no any traffic is happening on the old cluster\n * delete the old cluster from domain cluster list. this needs to be done for every domain.\n\ncadence --address <newhostaddress> --do <domain_name> domain update --clusters <newclustername>\n\n\n * delete the old cluster from the configuration of the new cluster.\n\nonce above is done, you can shutdown the old cluster safely.',charsets:{cjk:!0}},{title:"MIT License",frontmatter:{layout:"default",title:"MIT License",permalink:"/docs/about/license",readingShow:"top"},regularPath:"/docs/08-about/01-license.html",relativePath:"docs/08-about/01-license.md",key:"v-00ee1f44",path:"/docs/about/license/",codeSwitcherOptions:{},headersStr:null,content:'# MIT License\n\nCopyright (c) 2017 Uber Technologies, Inc.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the "Software"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n',normalizedContent:'# mit license\n\ncopyright (c) 2017 uber technologies, inc.\n\npermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the "software"), to deal\nin the software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the software, and to permit persons to whom the software is\nfurnished to do so, subject to the following conditions:\n\nthe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the software.\n\nthe software is provided "as is", without warranty of any kind, express or\nimplied, including but not limited to the warranties of merchantability,\nfitness for a particular purpose and noninfringement. in no event shall the\nauthors or copyright holders be liable for any claim, damages or other\nliability, whether in an action of contract, tort or otherwise, arising from,\nout of or in connection with the software or the use or other dealings in\nthe software.\n',charsets:{}},{title:"Contact us",frontmatter:{layout:"default",title:"Contact us",permalink:"/docs/about",readingShow:"top"},regularPath:"/docs/08-about/",relativePath:"docs/08-about/index.md",key:"v-fa725f4a",path:"/docs/about/",codeSwitcherOptions:{},headersStr:null,content:"# Contact us\n\nIf you have a question, check whether it is already answered at stackoverflow under cadence-workflow tag.\n\nIf you still need help, visit .\n\nIf you have a feature request or a bug to report file an issue against one of the Cadence github repositories:\n\n * Cadence Service and CLI\n * Cadence Go Client\n * Cadence Go Client Samples\n * Cadence Java Client\n * Cadence Java Client Samples\n * Cadence Web UI",normalizedContent:"# contact us\n\nif you have a question, check whether it is already answered at stackoverflow under cadence-workflow tag.\n\nif you still need help, visit .\n\nif you have a feature request or a bug to report file an issue against one of the cadence github repositories:\n\n * cadence service and cli\n * cadence go client\n * cadence go client samples\n * cadence java client\n * cadence java client samples\n * cadence web ui",charsets:{}},{title:"Home",frontmatter:{home:!0,heroText:"Fault-Tolerant Stateful Code Platform",tagline:"Focus on your business logic and let Cadence take care of the complexity of distributed systems",actionText:"Get Started →",actionLink:"/docs/get-started/",readingShow:"top"},regularPath:"/",relativePath:"index.md",key:"v-7256933b",path:"/",codeSwitcherOptions:{},headersStr:null,content:"© {{ new Date().getFullYear() }} Uber Technologies, Inc.\n\n\nEasy to use\n\nWorkflows provide primitives to allow application developers to express complex business logic as code.\n\nThe underlying platform abstracts scalability, reliability and availability concerns from individual developers/teams.\n\n\nFault tolerant\n\nCadence enables writing stateful applications without worrying about the complexity of handling process failures.\n\nCadence preserves complete multithreaded application state including thread stacks with local variables across hardware and software failures.\n\n\n\n\nScalable & Reliable\n\nCadence is designed to scale out horizontally to handle millions of concurrent workflows.\n\nCadence provides out-of-the-box asynchronous history event replication that can help you recover from zone failures.",normalizedContent:"© {{ new date().getfullyear() }} uber technologies, inc.\n\n\neasy to use\n\nworkflows provide primitives to allow application developers to express complex business logic as code.\n\nthe underlying platform abstracts scalability, reliability and availability concerns from individual developers/teams.\n\n\nfault tolerant\n\ncadence enables writing stateful applications without worrying about the complexity of handling process failures.\n\ncadence preserves complete multithreaded application state including thread stacks with local variables across hardware and software failures.\n\n\n\n\nscalable & reliable\n\ncadence is designed to scale out horizontally to handle millions of concurrent workflows.\n\ncadence provides out-of-the-box asynchronous history event replication that can help you recover from zone failures.",charsets:{}}],themeConfig:{logo:"/img/logo-white.svg",nav:[{text:"Docs",items:[{text:"Get Started",link:"/docs/get-started/"},{text:"Use cases",link:"/docs/use-cases/"},{text:"Concepts",link:"/docs/concepts/"},{text:"Java client",link:"/docs/java-client/"},{text:"Go client",link:"/docs/go-client/"},{text:"Command line interface",link:"/docs/cli/"},{text:"Operation Guide",link:"/docs/operation-guide/"},{text:"Glossary",link:"/GLOSSARY"},{text:"About",link:"/docs/about/"}]},{text:"Blog",link:"/blog/"},{text:"Client",items:[{text:"Java Docs",link:"https://www.javadoc.io/doc/com.uber.cadence/cadence-client"},{text:"Java Client",link:"https://mvnrepository.com/artifact/com.uber.cadence/cadence-client"},{text:"Go Docs",link:"https://godoc.org/go.uber.org/cadence"},{text:"Go Client",link:"https://github.com/uber-go/cadence-client/releases/latest"}]},{text:"Community",items:[{text:"Github Discussion",link:"https://github.com/uber/cadence/discussions"},{text:"StackOverflow",link:"https://stackoverflow.com/questions/tagged/cadence-workflow"},{text:"Github Issues",link:"https://github.com/uber/cadence/issues"},{text:"Slack",link:"http://t.uber.com/cadence-slack"},{text:"Office Hours Calendar",link:"https://calendar.google.com/event?action=TEMPLATE&tmeid=MjFwOW01NWhlZ3MyZWJkcmo2djVsMjNkNzNfMjAyMjA3MjVUMTYwMDAwWiBlNnI0MGdwM2MycjAxMDU0aWQ3ZTk5ZGxhY0Bn&tmsrc=e6r40gp3c2r01054id7e99dlac%40group.calendar.google.com&scp=ALL"}]},{text:"GitHub",items:[{text:"Cadence Service and CLI",link:"https://github.com/uber/cadence"},{text:"Cadence Go Client",link:"https://github.com/uber-go/cadence-client"},{text:"Cadence Go Client Samples",link:"https://github.com/uber-common/cadence-samples"},{text:"Cadence Java Client",link:"https://github.com/uber-java/cadence-client"},{text:"Cadence Java Client Samples",link:"https://github.com/uber/cadence-java-samples"},{text:"Cadence Web UI",link:"https://github.com/uber/cadence-web"},{text:"Cadence Docs",link:"https://github.com/uber/cadence-docs"}]},{text:"Docker",items:[{text:"Cadence Service",link:"https://hub.docker.com/r/ubercadence/server/tags"},{text:"Cadence CLI",link:"https://hub.docker.com/r/ubercadence/cli/tags"},{text:"Cadence Web UI",link:"https://hub.docker.com/r/ubercadence/web/tags"}]}],docsRepo:"uber/cadence-docs",docsDir:"src",editLinks:!0,sidebar:{"/docs/":[{title:"Get Started",path:"/docs/01-get-started",children:["01-get-started/","01-get-started/01-server-installation","01-get-started/02-java-hello-world","01-get-started/03-golang-hello-world","01-get-started/04-video-tutorials"]},{title:"Use cases",path:"/docs/02-use-cases",children:["02-use-cases/","02-use-cases/01-periodic-execution","02-use-cases/02-orchestration","02-use-cases/03-polling","02-use-cases/04-event-driven","02-use-cases/05-partitioned-scan","02-use-cases/06-batch-job","02-use-cases/07-provisioning","02-use-cases/08-deployment","02-use-cases/09-operational-management","02-use-cases/10-interactive","02-use-cases/11-dsl","02-use-cases/12-big-ml"]},{title:"Concepts",path:"/docs/03-concepts",children:["03-concepts/","03-concepts/01-workflows","03-concepts/02-activities","03-concepts/03-events","03-concepts/04-queries","03-concepts/05-topology","03-concepts/06-task-lists","03-concepts/07-archival","03-concepts/08-cross-dc-replication","03-concepts/09-search-workflows","03-concepts/10-http-api"]},{title:"Java client",path:"/docs/04-java-client",children:["04-java-client/","04-java-client/01-client-overview","04-java-client/02-workflow-interface","04-java-client/03-implementing-workflows","04-java-client/04-starting-workflow-executions","04-java-client/05-activity-interface","04-java-client/06-implementing-activities","04-java-client/07-versioning","04-java-client/08-distributed-cron","04-java-client/09-workers","04-java-client/10-signals","04-java-client/11-queries","04-java-client/12-retries","04-java-client/13-child-workflows","04-java-client/14-exception-handling","04-java-client/15-continue-as-new","04-java-client/16-side-effect","04-java-client/17-testing","04-java-client/18-workflow-replay-shadowing"]},{title:"Go client",path:"/docs/05-go-client",children:["05-go-client/","05-go-client/01-workers","05-go-client/02-create-workflows","05-go-client/02.5-starting-workflows","05-go-client/03-activities","05-go-client/04-execute-activity","05-go-client/05-child-workflows","05-go-client/06-retries","05-go-client/07-error-handling","05-go-client/08-signals","05-go-client/09-continue-as-new","05-go-client/10-side-effect","05-go-client/11-queries","05-go-client/12-activity-async-completion","05-go-client/13-workflow-testing","05-go-client/14-workflow-versioning","05-go-client/15-sessions","05-go-client/16-distributed-cron","05-go-client/17-tracing","05-go-client/18-workflow-replay-shadowing"]},{title:"Command line interface",path:"/docs/06-cli/"},{title:"Production Operation",path:"/docs/07-operation-guide/",children:["07-operation-guide/","07-operation-guide/01-setup","07-operation-guide/02-maintain","07-operation-guide/03-monitoring","07-operation-guide/04-troubleshooting","07-operation-guide/05-migration"]},{title:"Glossary",path:"../GLOSSARY"},{title:"About",path:"/docs/08-about",children:["08-about/","08-about/01-license"]}]}}};n(241);Vn.component("slack-link",()=>n.e(23).then(n.bind(null,328))),Vn.component("Badge",()=>Promise.all([n.e(0),n.e(4)]).then(n.bind(null,330))),Vn.component("CodeBlock",()=>Promise.all([n.e(0),n.e(5)]).then(n.bind(null,324))),Vn.component("CodeGroup",()=>Promise.all([n.e(0),n.e(6)]).then(n.bind(null,325)));n(242);var Ns={name:"BackToTop",props:{threshold:{type:Number,default:300}},data:()=>({scrollTop:null}),computed:{show(){return this.scrollTop>this.threshold}},mounted(){this.scrollTop=this.getScrollTop(),window.addEventListener("scroll",_s()(()=>{this.scrollTop=this.getScrollTop()},100))},methods:{getScrollTop:()=>window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,scrollToTop(){window.scrollTo({top:0,behavior:"smooth"}),this.scrollTop=0}}},Rs=(n(243),Object(Es.a)(Ns,(function(){var e=this._self._c;return e("transition",{attrs:{name:"fade"}},[this.show?e("svg",{staticClass:"go-to-top",attrs:{xmlns:"http://www.w3.org/2000/svg",viewBox:"0 0 49.484 28.284"},on:{click:this.scrollToTop}},[e("g",{attrs:{transform:"translate(-229 -126.358)"}},[e("rect",{attrs:{fill:"currentColor",width:"35",height:"5",rx:"2",transform:"translate(229 151.107) rotate(-45)"}}),this._v(" "),e("rect",{attrs:{fill:"currentColor",width:"35",height:"5",rx:"2",transform:"translate(274.949 154.642) rotate(-135)"}})])]):this._e()])}),[],!1,null,"5fd4ef0c",null).exports);n(244);Vn.component("CodeSwitcher",()=>n.e(25).then(n.bind(null,329)));var Ls={name:"ReadingProgress",data:()=>({readingTop:0,readingHeight:1,progressStyle:null,transform:void 0,running:!1}),watch:{$readingShow(){this.progressStyle=this.getProgressStyle(),this.$readingShow&&window.addEventListener("scroll",this.base)}},mounted(){this.transform=this.getTransform(),this.progressStyle=this.getProgressStyle(),this.$readingShow&&window.addEventListener("scroll",this.base)},beforeDestroy(){this.$readingShow&&window.removeEventListener("scroll",this.base)},methods:{base(){this.running||(this.running=!0,requestAnimationFrame(this.getReadingBase))},getReadingBase(){this.readingHeight=this.getReadingHeight()-this.getScreenHeight(),this.readingTop=this.getReadingTop(),this.progressStyle=this.getProgressStyle(),this.running=!1},getReadingHeight:()=>Math.max(document.body.scrollHeight,document.body.offsetHeight,0),getScreenHeight:()=>Math.max(window.innerHeight,document.documentElement.clientHeight,0),getReadingTop:()=>Math.max(window.pageYOffset,document.documentElement.scrollTop,0),getTransform(){const e=document.createElement("div");return["transform","-webkit-transform","-moz-transform","-o-transform","-ms-transform"].find(t=>t in e.style)||void 0},getProgressStyle(){const e=this.readingTop/this.readingHeight;switch(this.$readingShow){case"top":case"bottom":return this.transform?`${this.transform}: scaleX(${e})`:`width: ${100*e}%`;case"left":case"right":return this.transform?`${this.transform}: scaleY(${e})`:`height: ${100*e}%`;default:return null}}}},zs=(n(245),Object(Es.a)(Ls,(function(){var e=this._self._c;return e("ClientOnly",[this.$readingShow?e("div",{staticClass:"reading-progress",class:this.$readingShow},[e("div",{staticClass:"progress",style:this.progressStyle})]):this._e()])}),[],!1,null,"3640397f",null).exports);function Fs(e,t){let n=!0;void 0===e?(e="Term not found in the glossary",n=!1):e=Ms(e);return`<a title="${e}" class="term${n?"":" term-not-found"}">${t=Hs(t)}</a>`}function Ms(e){return e.replace(/:[\w+]*:([\w+]*):/g,(e,t)=>t).replace(/:([\w+]*):/g,(e,t)=>t)}function Hs(e){return e.split("_").join(" ")}function $s(e){return e.split("_").join(" ")}var Us={name:"Term",props:{term:{type:String,required:!0},show:{type:String,required:!1,default:""}},data:()=>({termNotFound:!1}),computed:{terms(){return this.$site.pages.find(e=>"/GLOSSARY.html"===e.path).frontmatter.terms},definition(){const e=$s(this.term),t=this.terms[e];return t?Ms(t):(this.termNotFound=!0,"Term not found in the glossary")},displayText(){return $s(this.show?this.show:this.term)}}},Gs=Object(Es.a)(Us,(function(){return(0,this._self._c)("a",{class:{"term-not-found":this.termNotFound,term:!0},attrs:{title:this.definition}},[this._v(this._s(this.displayText))])}),[],!1,null,null,null).exports,Bs={props:{terms:{type:Object,required:!0}},methods:{definition(e){return function(e,t){let n=t[Hs(e)];return n=n.replace(/:([\w+]*):([\w+]*):/g,(e,n,o)=>Fs(t[Hs(n)],o)),n=n.replace(/:([\w+]*):/g,(e,n,o)=>Fs(t[Hs(n)],n)),n}(e,this.terms)}}},Vs=(n(246),Object(Es.a)(Bs,(function(){var e=this,t=e._self._c;return t("dl",e._l(Object.keys(e.terms),(function(n){return t("div",[t("dt",{staticClass:"defined-term"},[e._v(e._s(n))]),e._v(" "),t("dd",{staticClass:"term-definition",domProps:{innerHTML:e._s(e.definition(n,e.terms))}})])})),0)}),[],!1,null,null,null).exports),Ys=n(46);const Ks={redirectors:[{base:"/docs/",alternative:["get-started"]}]};var Xs=[({router:e})=>{e.beforeResolve((e,t,n)=>{const o="undefined"!=typeof window?window:null;o&&e.matched.length&&("*"!==e.matched[0].path&&e.redirectedFrom||"/blog/"===e.path)?o.location.href=e.fullPath:n()})},{},({Vue:e})=>{e.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},{},({Vue:e})=>{e.component("BackToTop",Rs)},{},{},({Vue:e})=>{e.component(zs.name,zs),e.mixin({computed:{$readingShow(){return this.$page.frontmatter.readingShow}}})},({Vue:e})=>{e.component("CodeCopy",Ps)},({Vue:e,options:t,router:n,siteData:o})=>{e.component("Term",Gs),e.component("Glossary",Vs)},({router:e,siteData:t})=>{const{routes:n=[]}=e.options,{redirectors:o=[]}=Ks;function i(e){return n.some(t=>t.path.toLowerCase()===e.toLowerCase())}function a(e){if(i(e))return e;if(!/\/$/.test(e)){const t=e+"/";if(i(t))return t}if(!/\.html$/.test(e)){const t=e.replace(/\/$/,"")+".html";if(i(t))return t}return null}if(Ks.locales&&t.locales){const e=t.locales,n=Object.keys(e),i=n.map(t=>({key:t.replace(/^\/|\/$/,""),lang:e[t].lang}));"object"!=typeof Ks.locales&&(Ks.locales={});const{fallback:a,storage:r=!0}=Ks.locales;a&&n.unshift(a),o.unshift({storage:r,base:"/",alternative(){if("undefined"!=typeof window&&window.navigator){const e=window.navigator.languages||[window.navigator.language],t=i.find(({lang:t})=>e.includes(t));if(t)return t.key}return n}})}const r=o.map(({base:e="/",storage:t=!1,alternative:n})=>{let o=!1;if(t)if("object"!=typeof t){const n="string"!=typeof t?"vuepress:redirect:"+e:t;o={get:()=>"undefined"==typeof localStorage?null:localStorage.getItem(n),set(e){"undefined"!=typeof localStorage&&localStorage.setItem(n,e)}}}else t.get&&t.set&&(o=t);return{base:e,storage:o,alternative:n}});e.beforeEach((e,t,n)=>{if(a(e.path))return n();let o;for(const t of r){const{base:n="/",storage:i=!1}=t;let{alternative:r}=t;if(!e.path.startsWith(n))continue;const s=e.path.slice(n.length)||"/";if(i){const e=i.get(t);if(e){const t=a(Object(Ys.join)(n,e,s));if(t){o=t;break}}}if("function"==typeof r&&(r=r(s)),r){"string"==typeof r&&(r=[r]);for(const e of r){const t=a(Object(Ys.join)(n,e,s));if(t){o=t;break}}if(o)break}}n(o)}),e.afterEach(e=>{if(i(e.path))for(const t of r){const{base:n,storage:o}=t;if(!o||!e.path.startsWith(n))continue;const i=e.path.slice(n.length).split("/")[0];i&&o.set(i,t)}})}],Qs=["BackToTop","ReadingProgress"];class Js extends class{constructor(){this.store=new Vn({data:{state:{}}})}$get(e){return this.store.state[e]}$set(e,t){Vn.set(this.store.state,e,t)}$emit(...e){this.store.$emit(...e)}$on(...e){this.store.$on(...e)}}{}Object.assign(Js.prototype,{getPageAsyncComponent:ss,getLayoutAsyncComponent:cs,getAsyncComponent:ls,getVueComponent:ds});var Zs={install(e){const t=new Js;e.$vuepress=t,e.prototype.$vuepress=t}};function ec(e,t){const n=t.toLowerCase();return e.options.routes.some(e=>e.path.toLowerCase()===n)}var tc={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(e){const t=this.pageKey||this.$parent.$page.key;return hs("pageKey",t),Vn.component(t)||Vn.component(t,ss(t)),Vn.component(t)?e(t):e("")}},nc={functional:!0,props:{slotKey:String,required:!0},render:(e,{props:t,slots:n})=>e("div",{class:["content__"+t.slotKey]},n()[t.slotKey])},oc={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},ic=(n(247),n(248),Object(Es.a)(oc,(function(){var e=this._self._c;return e("span",[e("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[e("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),e("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),e("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),ac={functional:!0,render(e,{parent:t,children:n}){if(t._isMounted)return n;t.$once("hook:mounted",()=>{t.$forceUpdate()})}};Vn.config.productionTip=!1,Vn.use(Gr),Vn.use(Zs),Vn.mixin(function(e,t,n=Vn){!function(e){e.locales&&Object.keys(e.locales).forEach(t=>{e.locales[t].path=t});Object.freeze(e)}(t),n.$vuepress.$set("siteData",t);const o=new(e(n.$vuepress.$get("siteData"))),i=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(o)),a={};return Object.keys(i).reduce((e,t)=>(t.startsWith("$")&&(e[t]=i[t].get),e),a),{computed:a}}(e=>class{setPage(e){this.__page=e}get $site(){return e}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:e={}}=this.$site;let t,n;for(const o in e)"/"===o?n=e[o]:0===this.$page.path.indexOf(o)&&(t=e[o]);return t||n||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:e}=this.$page.frontmatter;return"string"==typeof e&&e}get $title(){const e=this.$page,{metaTitle:t}=this.$page.frontmatter;if("string"==typeof t)return t;const n=this.$siteTitle,o=e.frontmatter.home?null:e.frontmatter.title||e.title;return n?o?o+" | "+n:n:o||"VuePress"}get $description(){const e=function(e){if(e){const t=e.filter(e=>"description"===e.name)[0];if(t)return t.content}}(this.$page.frontmatter.meta);return e||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(e,t){for(let n=0;n<e.length;n++){const o=e[n];if(o.path.toLowerCase()===t.toLowerCase())return o}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},js)),Vn.component("Content",tc),Vn.component("ContentSlotsDistributor",nc),Vn.component("OutboundLink",ic),Vn.component("ClientOnly",ac),Vn.component("Layout",cs("Layout")),Vn.component("NotFound",cs("NotFound")),Vn.prototype.$withBase=function(e){const t=this.$site.base;return"/"===e.charAt(0)?t+e.slice(1):e},window.__VUEPRESS__={version:"1.9.10",hash:"41a16f4"},async function(e){const t="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:js.routerBase||js.base,n=new Gr({base:t,mode:"history",fallback:!1,routes:Os,scrollBehavior:(e,t,n)=>n||(e.hash?!Vn.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(e.hash)}:{x:0,y:0})});!function(e){e.beforeEach((t,n,o)=>{if(ec(e,t.path))o();else if(/(\/|\.html)$/.test(t.path))if(/\/$/.test(t.path)){const n=t.path.replace(/\/$/,"")+".html";ec(e,n)?o(n):o()}else o();else{const n=t.path+"/",i=t.path+".html";ec(e,i)?o(i):ec(e,n)?o(n):o()}})}(n);const o={};try{await Promise.all(Xs.filter(e=>"function"==typeof e).map(t=>t({Vue:Vn,options:o,router:n,siteData:js,isServer:e})))}catch(e){console.error(e)}return{app:new Vn(Object.assign(o,{router:n,render:e=>e("div",{attrs:{id:"app"}},[e("RouterView",{ref:"layout"}),e("div",{class:"global-ui"},Qs.map(t=>e(t)))])})),router:n}}(!1).then(({app:e,router:t})=>{t.onReady(()=>{e.$mount("#app")})})}]);