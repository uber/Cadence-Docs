(window.webpackJsonp=window.webpackJsonp||[]).push([[45],{350:function(e,t,r){"use strict";r.r(t);var a=r(0),s=Object(a.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"event-handling"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#event-handling"}},[e._v("#")]),e._v(" Event handling")]),e._v(" "),t("p",[e._v("Fault-oblivious stateful "),t("Term",{attrs:{term:"workflow",show:"workflows"}}),e._v(" can be "),t("Term",{attrs:{term:"signal",show:"signalled"}}),e._v(" about an external "),t("Term",{attrs:{term:"event"}}),e._v(". A "),t("Term",{attrs:{term:"signal"}}),e._v(" is always point to point destined to a specific "),t("Term",{attrs:{term:"workflow"}}),e._v(" instance. "),t("Term",{attrs:{term:"signal",show:"Signals"}}),e._v(" are always processed in the order in which they are received.")],1),e._v(" "),t("p",[e._v("There are multiple scenarios for which "),t("Term",{attrs:{term:"signal",show:"signals"}}),e._v(" are useful.")],1),e._v(" "),t("h2",{attrs:{id:"event-aggregation-and-correlation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#event-aggregation-and-correlation"}},[e._v("#")]),e._v(" Event Aggregation and Correlation")]),e._v(" "),t("p",[e._v("Cadence is not a replacement for generic stream processing engines like Apache Flink or Apache Spark. But in certain scenarios it is a better fit. For example, when all "),t("Term",{attrs:{term:"event",show:"events"}}),e._v(" that should be aggregated and correlated are always applied to some business entity with a clear ID. And then when a certain condition is met, actions should be executed.")],1),e._v(" "),t("p",[e._v("The main limitation is that a single Cadence "),t("Term",{attrs:{term:"workflow"}}),e._v(" has a pretty limited throughput, while the number of "),t("Term",{attrs:{term:"workflow",show:"workflows"}}),e._v(" is practically unlimited. So if you need to aggregate "),t("Term",{attrs:{term:"event",show:"events"}}),e._v(" per customer, and your application has 100 million customers and each customer doesn't generate more than 20 "),t("Term",{attrs:{term:"event",show:"events"}}),e._v(" per second, then Cadence would work fine. But if you want to aggregate all "),t("Term",{attrs:{term:"event",show:"events"}}),e._v(" for US customers then the rate of these "),t("Term",{attrs:{term:"event",show:"events"}}),e._v(" would be beyond the single "),t("Term",{attrs:{term:"workflow"}}),e._v(" capacity.")],1),e._v(" "),t("p",[e._v("For example, an IoT device generates "),t("Term",{attrs:{term:"event",show:"events"}}),e._v(" and a certain sequence of "),t("Term",{attrs:{term:"event",show:"events"}}),e._v(" indicates that the device should be reprovisioned. A "),t("Term",{attrs:{term:"workflow"}}),e._v(" instance per device would be created and each instance would manage the state machine of the device and execute reprovision "),t("Term",{attrs:{term:"activity"}}),e._v(" when necessary.")],1),e._v(" "),t("p",[e._v("Another use case is a customer loyalty program. Every time a customer makes a purchase, an "),t("Term",{attrs:{term:"event"}}),e._v(" is generated into Apache Kafka for downstream systems to process. A loyalty service Kafka consumer receives the "),t("Term",{attrs:{term:"event"}}),e._v(" and "),t("Term",{attrs:{term:"signal",show:"signals"}}),e._v(" a customer "),t("Term",{attrs:{term:"workflow"}}),e._v(" about the purchase using the Cadence "),t("code",[e._v("signalWorkflowExecution")]),e._v(" API. The "),t("Term",{attrs:{term:"workflow"}}),e._v(" accumulates the count of the purchases. If a specified threshold is achieved, the "),t("Term",{attrs:{term:"workflow"}}),e._v(" executes an "),t("Term",{attrs:{term:"activity"}}),e._v(" that notifies some external service that the customer has reached the next level of loyalty program. The "),t("Term",{attrs:{term:"workflow"}}),e._v(" also executes "),t("Term",{attrs:{term:"activity",show:"activities"}}),e._v(" to periodically message the customer about their current status.")],1),e._v(" "),t("h2",{attrs:{id:"human-tasks"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#human-tasks"}},[e._v("#")]),e._v(" Human Tasks")]),e._v(" "),t("p",[e._v("A lot of business processes involve human participants. The standard Cadence pattern for implementing an external interaction is to execute an "),t("Term",{attrs:{term:"activity"}}),e._v(" that creates a human "),t("Term",{attrs:{term:"task"}}),e._v(" in an external system. It can be an email with a form, or a record in some external database, or a mobile app notification. When a user changes the status of the "),t("Term",{attrs:{term:"task"}}),e._v(", a "),t("Term",{attrs:{term:"signal"}}),e._v(" is sent to the corresponding "),t("Term",{attrs:{term:"workflow"}}),e._v(". For example, when the form is submitted, or a mobile app notification is acknowledged. Some "),t("Term",{attrs:{term:"task",show:"tasks"}}),e._v(" have multiple possible actions like claim, return, complete, reject. So multiple "),t("Term",{attrs:{term:"signal",show:"signals"}}),e._v(" can be sent in relation to it.")],1),e._v(" "),t("h2",{attrs:{id:"process-execution-alteration"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#process-execution-alteration"}},[e._v("#")]),e._v(" Process Execution Alteration")]),e._v(" "),t("p",[e._v("Some business processes should change their behavior if some external "),t("Term",{attrs:{term:"event"}}),e._v(" has happened. For example, while executing an order shipment "),t("Term",{attrs:{term:"workflow"}}),e._v(", any change in item quantity could be delivered in a form of a "),t("Term",{attrs:{term:"signal"}}),e._v(".")],1),e._v(" "),t("p",[e._v("Another example is a service deployment "),t("Term",{attrs:{term:"workflow"}}),e._v(". While rolling out new software version to a Kubernetes cluster some problem was identified. A "),t("Term",{attrs:{term:"signal"}}),e._v(" can be used to ask the "),t("Term",{attrs:{term:"workflow"}}),e._v(" to pause while the problem is investigated. Then either a continue or a rollback "),t("Term",{attrs:{term:"signal"}}),e._v(" can be used to execute the appropriate action.")],1),e._v(" "),t("h2",{attrs:{id:"synchronization"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#synchronization"}},[e._v("#")]),e._v(" Synchronization")]),e._v(" "),t("p",[e._v("Cadence "),t("Term",{attrs:{term:"workflow",show:"workflows"}}),e._v(" are strongly consistent so they can be used as a synchronization point for executing actions. For example, there is a requirement that all messages for a single user are processed sequentially but the underlying messaging infrastructure can deliver them in parallel. The Cadence solution would be to have a "),t("Term",{attrs:{term:"workflow"}}),e._v(" per user and "),t("Term",{attrs:{term:"signal"}}),e._v(" it when an "),t("Term",{attrs:{term:"event"}}),e._v(" is received. Then the "),t("Term",{attrs:{term:"workflow"}}),e._v(" would buffer all "),t("Term",{attrs:{term:"signal",show:"signals"}}),e._v(" in an internal data structure and then call an "),t("Term",{attrs:{term:"activity"}}),e._v(" for every "),t("Term",{attrs:{term:"signal"}}),e._v(" received. See the following "),t("a",{attrs:{href:"https://stackoverflow.com/a/56615120/1664318",target:"_blank",rel:"noopener noreferrer"}},[e._v("Stack Overflow answer"),t("OutboundLink")],1),e._v(" for an example.")],1)])}),[],!1,null,null,null);t.default=s.exports}}]);