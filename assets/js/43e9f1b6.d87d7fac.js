"use strict";(self.webpackChunkcadence=self.webpackChunkcadence||[]).push([[8817],{4512:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>r,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"operation-guide/troubleshooting","title":"Cluster Troubleshooting","description":"This section is to cover some common operation issues as a RunBook. Feel free to add more, or raise issues in the to ask for more in cadence-docs project.Or talk to us in Slack support channel!","source":"@site/docs/07-operation-guide/04-troubleshooting.md","sourceDirName":"07-operation-guide","slug":"/operation-guide/troubleshooting","permalink":"/Cadence-Docs/docs/operation-guide/troubleshooting","draft":false,"unlisted":false,"editUrl":"https://github.com/cadence-workflow/Cadence-Docs/tree/master/docs/07-operation-guide/04-troubleshooting.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"layout":"default","title":"Cluster Troubleshooting","permalink":"/docs/operation-guide/troubleshooting"},"sidebar":"docsSidebar","previous":{"title":"Cluster Monitoring","permalink":"/Cadence-Docs/docs/operation-guide/monitoring"},"next":{"title":"Cluster Migration","permalink":"/Cadence-Docs/docs/operation-guide/migration"}}');var n=s(4848),i=s(8453);const r={layout:"default",title:"Cluster Troubleshooting",permalink:"/docs/operation-guide/troubleshooting"},a="Cluster Troubleshooting",l={},c=[{value:"Errors",id:"errors",level:2},{value:"API high latency, timeout, Task disptaching slowness Or Too many operations onto DB and timeouts",id:"api-high-latency-timeout-task-disptaching-slowness-or-too-many-operations-onto-db-and-timeouts",level:2}];function d(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,i.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"cluster-troubleshooting",children:"Cluster Troubleshooting"})}),"\n",(0,n.jsxs)(t.p,{children:["This section is to cover some common operation issues as a RunBook. Feel free to add more, or raise issues in the to ask for more in ",(0,n.jsx)(t.a,{href:"https://github.com/cadence-workflow/Cadence-Docs/issues",children:"cadence-docs"})," project.Or talk to us in Slack support channel!"]}),"\n",(0,n.jsx)(t.p,{children:"We will keep adding more stuff. Any contribution is very welcome."}),"\n",(0,n.jsx)(t.h2,{id:"errors",children:"Errors"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.code,{children:"Persistence Max QPS Reached for List Operations"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["Check metrics to see how many List operations are performed per second on the domain. Alternatively you can enable ",(0,n.jsx)(t.code,{children:"debug"})," log level to see more details of how a List request is ratelimited, if it's a staging/QA cluster."]}),"\n",(0,n.jsx)(t.li,{children:"Raise the ratelimiting for the domain if you believe the default ratelimit is too low"}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.code,{children:"Failed to lock shard. Previous range ID: 132; new range ID: 133"})," and ",(0,n.jsx)(t.code,{children:"Failed to update shard. Previous range ID: 210; new range ID: 212"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"When this keep happening, it's very likely a critical configuration error. Either there are two clusters using the same database, or two clusters are using the same ringpop(bootstrap hosts)."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"api-high-latency-timeout-task-disptaching-slowness-or-too-many-operations-onto-db-and-timeouts",children:"API high latency, timeout, Task disptaching slowness Or Too many operations onto DB and timeouts"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"If it happens after you attemped to truncate tables inorder to reuse the same database/keyspace for a new cluster, it's possible that the data is not deleted completely. You should make sure to shutdown the Cadence when trucating, and make sure the database is cleaned. Alternatively, use a different keyspace/database is a safer way."}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:["Timeout pushing task to matching engine, e.g. ",(0,n.jsx)(t.code,{children:'"Fail to process task","service":"cadence-history","shard-id":431,"address":"172.31.48.64:7934","component":"transfer-queue-processor","cluster-name":"active","shard-id":431,"queue-task-id":590357768,"queue-task-visibility-timestamp":1637356594382077880,"xdc-failover-version":-24,"queue-task-type":0,"wf-domain-id":"f4d6824f-9d24-4a82-81e0-e0e080be4c21","wf-id":"55d64d58-e398-4bf5-88bc-a4696a2ba87f:63ed7cda-afcf-41cd-9d5a-ee5e1b0f2844","wf-run-id":"53b52ee0-3218-418e-a9bf-7768e671f9c1","error":"code:deadline-exceeded message:timeout","lifecycle":"ProcessingFailed","logging-call-at":"task.go:331"'})]}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["If this happens after traffic increased for a certain domain, it's likely that a tasklist is overloaded. Consider ",(0,n.jsx)(t.a,{href:"/docs/operation-guide/maintain/#scale-up-a-tasklist-using-scalable-tasklist-feature",children:"scale up the tasklist"})]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:["If the request volume aligned with the traffic increased on all domain, consider ",(0,n.jsx)(t.a,{href:"/docs/operation-guide/maintain/#scale-up--down-cluster",children:"scale up the cluster"})]}),"\n"]}),"\n"]})]})}function u(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},8453:(e,t,s)=>{s.d(t,{R:()=>r,x:()=>a});var o=s(6540);const n={},i=o.createContext(n);function r(e){const t=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),o.createElement(i.Provider,{value:t},e.children)}}}]);