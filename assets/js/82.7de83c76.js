(window.webpackJsonp=window.webpackJsonp||[]).push([[82],{389:function(t,e,r){"use strict";r.r(e);var n=r(0),s=Object(n.a)({},(function(){var t=this,e=t._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"continue-as-new"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#continue-as-new"}},[t._v("#")]),t._v(" Continue as new")]),t._v(" "),e("p",[e("Term",{attrs:{term:"workflow",show:"Workflows"}}),t._v(" that need to rerun periodically could naively be implemented as a big "),e("strong",[t._v("for")]),t._v(" loop with\na sleep where the entire logic of the "),e("Term",{attrs:{term:"workflow"}}),t._v(" is inside the body of the "),e("strong",[t._v("for")]),t._v(" loop. The problem\nwith this approach is that the history for that "),e("Term",{attrs:{term:"workflow"}}),t._v(" will keep growing to a point where it\nreaches the maximum size enforced by the service.")],1),t._v(" "),e("p",[e("strong",[t._v("ContinueAsNew")]),t._v(" is the low level construct that enables implementing such "),e("Term",{attrs:{term:"workflow",show:"workflows"}}),t._v(" without the\nrisk of failures down the road. The operation atomically completes the current execution and starts\na new execution of the "),e("Term",{attrs:{term:"workflow"}}),t._v(" with the same "),e("strong",[e("Term",{attrs:{term:"workflow_ID"}})],1),t._v(". The new execution will not carry\nover any history from the old execution. To trigger this behavior, the "),e("Term",{attrs:{term:"workflow"}}),t._v(" function should\nterminate by returning the special "),e("strong",[t._v("ContinueAsNewError")]),t._v(" error:")],1),t._v(" "),e("div",{staticClass:"language-go extra-class"},[e("pre",{pre:!0,attrs:{class:"language-go"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("SimpleWorkflow")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("workflow"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Context ctx"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value "),e("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("string")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("error")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" workflow"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("NewContinueAsNewError")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ctx"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SimpleWorkflow"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])])}),[],!1,null,null,null);e.default=s.exports}}]);